<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-tw">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Post Training Quantization (PTQ),Quantization Aware Training (QAT),Data Free Quantization (DFQ),AIMET," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="ç¸½æ­¸ä¾†èªª Data-Free Quantization (DFQ) çš„ç›®çš„æ˜¯è®“ floating model åš weights å„ç¨®èª¿æ•´, ä½¿å¾—ä¸ç®¡æ˜¯ weights or activations éƒ½è®Šå¾—é©åˆ per tensor é‡åŒ–.é€™æ¨£ç†æƒ³ä¸Šå°±ä¸éœ€ç”¨åˆ° per channel é‡åŒ–, å› ç‚º per channel é›–ç„¶æ•ˆæœå¾ˆå¥½, ä½†ç¡¬é«”æ¯”è¼ƒä¸å‹å–„, ä¸”èŠ±çš„é‹ç®—é‡è¼ƒé«˜. å¦å¤– DFQ">
<meta property="og:type" content="article">
<meta property="og:title" content="Qualcomm Data-Free Quantization è©³è®€">
<meta property="og:url" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/index.html">
<meta property="og:site_name" content="æ£’æ£’ç”Ÿ">
<meta property="og:description" content="ç¸½æ­¸ä¾†èªª Data-Free Quantization (DFQ) çš„ç›®çš„æ˜¯è®“ floating model åš weights å„ç¨®èª¿æ•´, ä½¿å¾—ä¸ç®¡æ˜¯ weights or activations éƒ½è®Šå¾—é©åˆ per tensor é‡åŒ–.é€™æ¨£ç†æƒ³ä¸Šå°±ä¸éœ€ç”¨åˆ° per channel é‡åŒ–, å› ç‚º per channel é›–ç„¶æ•ˆæœå¾ˆå¥½, ä½†ç¡¬é«”æ¯”è¼ƒä¸å‹å–„, ä¸”èŠ±çš„é‹ç®—é‡è¼ƒé«˜. å¦å¤– DFQ">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 1.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 2.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 3.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 4.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/absorbing_bias-row.drawio.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/eq8.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/eq_9_12.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 5.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 6.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 7.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 8.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 9.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 10.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 11.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/appendix1.png">
<meta property="og:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/appendix2.png">
<meta property="og:updated_time" content="2023-12-28T13:00:22.133Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Qualcomm Data-Free Quantization è©³è®€">
<meta name="twitter:description" content="ç¸½æ­¸ä¾†èªª Data-Free Quantization (DFQ) çš„ç›®çš„æ˜¯è®“ floating model åš weights å„ç¨®èª¿æ•´, ä½¿å¾—ä¸ç®¡æ˜¯ weights or activations éƒ½è®Šå¾—é©åˆ per tensor é‡åŒ–.é€™æ¨£ç†æƒ³ä¸Šå°±ä¸éœ€ç”¨åˆ° per channel é‡åŒ–, å› ç‚º per channel é›–ç„¶æ•ˆæœå¾ˆå¥½, ä½†ç¡¬é«”æ¯”è¼ƒä¸å‹å–„, ä¸”èŠ±çš„é‹ç®—é‡è¼ƒé«˜. å¦å¤– DFQ">
<meta name="twitter:image" content="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'åšä¸»'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/"/>





  <title> Qualcomm Data-Free Quantization è©³è®€ | æ£’æ£’ç”Ÿ </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  




<!-- hexo-inject:begin --><!-- hexo-inject:end --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '[object Object]', 'auto');
  ga('send', 'pageview');
</script>











  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">æ£’æ£’ç”Ÿ</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">è®“å­¸ç¿’è®Šæˆä¸€ç¨®ç¿’æ…£</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            é¦–é 
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            åˆ†é¡
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            é—œæ–¼
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            æ­¸æª”
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            æ¨™ç±¤
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chih-Sheng Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="æ£’æ£’ç”Ÿ">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Qualcomm Data-Free Quantization è©³è®€
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">ç™¼è¡¨æ–¼</span>
              
              <time title="å‰µå»ºæ–¼" itemprop="dateCreated datePublished" datetime="2023-11-24T23:20:05+08:00">
                2023-11-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†é¡æ–¼</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>[object Object]
            </span>
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<hr>
<p>ç¸½æ­¸ä¾†èªª Data-Free Quantization (DFQ) çš„ç›®çš„æ˜¯è®“ floating model åš weights å„ç¨®èª¿æ•´, ä½¿å¾—ä¸ç®¡æ˜¯ weights or activations éƒ½è®Šå¾—é©åˆ per tensor é‡åŒ–.é€™æ¨£ç†æƒ³ä¸Šå°±ä¸éœ€ç”¨åˆ° per channel é‡åŒ–, å› ç‚º per channel é›–ç„¶æ•ˆæœå¾ˆå¥½, ä½†ç¡¬é«”æ¯”è¼ƒä¸å‹å–„, ä¸”èŠ±çš„é‹ç®—é‡è¼ƒé«˜. å¦å¤– DFQ å±¬æ–¼ Post-Training Quantization (PTQ) æ–¹æ³•. PTQ å°ä½ˆç½²åˆ° edge ç«¯å¾ˆæ–¹ä¾¿, ä½†ä¸€èˆ¬ä¾†èªª PTQ éƒ½ä¸å¦‚ Quantization-Aware Training (QAT) çš„æ•ˆæœå¥½, å› æ­¤ DFQ å˜—è©¦æå‡æ•ˆæœ.</p>
<p>DFQ å…±å››æ­¥, å°ç…§åœ–çœ‹, éœ€ç…§é †åº:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled.png" width="100%" height="100%"></p>
<ol>
<li><strong>Cross-Layer Equalization (CLE)</strong>: è¼¸å…¥ fused BN å¾Œçš„ float model <span>$M_f^1$</span><!-- Has MathJax -->, floating æ“ä½œå° weights åšèª¿æ•´ä½¿å¾—æ›´å‡è¡¡æ–¹ä¾¿ per tensor é‡åŒ–, ç‚º step 3 çš„å‰ç½®ä½œæ¥­, è¼¸å‡ºä»ç‚º float model <span>$M_f^2$</span><!-- Has MathJax -->.</li>
<li><strong>Bias Absorption (BA)</strong>: è¼¸å…¥ CLE å¾Œçš„ float model <span>$M_f^2$</span><!-- Has MathJax -->, floating æ“ä½œå° activations åšèª¿æ•´ä½¿å¾—æ›´å‡è¡¡æ–¹ä¾¿ per tensor é‡åŒ–, ç‚º step 3 çš„å‰ç½®ä½œæ¥­, è¼¸å‡ºä»ç‚º float model <span>$M_f^3$</span><!-- Has MathJax -->.</li>
<li><strong>PTQ é‡åŒ–</strong>: è¼¸å…¥ CLE+BA å¾Œçš„ float model <span>$M_f^3$</span><!-- Has MathJax -->, æ­¤æ™‚ä¸ç®¡ weights or activations éƒ½é©åˆåš per-tensor é‡åŒ–äº†, æ‰€ä»¥ç›´æ¥ PTQ è¼¸å‡º int model <span>$M_i^1$</span><!-- Has MathJax -->.</li>
<li><strong>Bias Correction (BC)</strong>: è¼¸å…¥ float model <span>$M_f^1$</span><!-- Has MathJax --> å’Œ step 3 çš„ <span>$M_i^1$</span><!-- Has MathJax -->, ä¸¦ä¸”(option)çµ¦ä¸€äº› unlabeled çš„ä»£è¡¨ data, BC æœƒå° <span>$M_i^1$</span><!-- Has MathJax --> çš„ bias åƒæ•¸è£œå„Ÿå› ç‚ºé‡åŒ–é€ æˆçš„æ•¸å€¼ mean åç§», è¼¸å‡ºç‚ºæœ€çµ‚ fixed point model <span>$M_i^2$</span><!-- Has MathJax -->.</li>
</ol>
<blockquote>
<p>Qualcomm AI Lab çš„ tool <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/index.html" target="_blank" rel="external">AIMET</a> èªª BC é€™ä¸€æ­¥é©Ÿå¯ä»¥ç”¨ <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/adaround.html#ug-adaround" target="_blank" rel="external">AdaRound</a> (éœ€è¦ä¸€å°éƒ¨åˆ†çš„ unlabelled training data) å–ä»£</p>
</blockquote>
<p>å…¶å¯¦èªçœŸçœ‹å®Œè«–æ–‡, è¦ºå¾—é™åˆ¶æœ‰é»å¤šå•Š! å¾ˆå¤šæ™‚å€™ä¸èƒ½å¥— CLE, æœ‰æ™‚ BA ä¹Ÿç”¨ä¸äº†. æŠŠé™åˆ¶æ¢åˆ—ä¸€ä¸‹:<br><a id="more"></a></p>
<p>âš ï¸ <strong>CLE é™åˆ¶</strong>:<br>&emsp;1. Activation functions $f(\cdot)$ éœ€ç‚º piece-wise linear (e.g. ReLU, ReLU6, LeakyReLU, â€¦)<br>&emsp;2. å¦‚æœæœ‰ BN (Batch normalization) layer, å…ˆæŠŠå®ƒ fuse åˆ° Conv è£¡é¢, æ‰€ä»¥ç¬¬3é»çš„é™åˆ¶æ‰å¯ä»¥å¿½ç•¥ BN layer.<br>&emsp;3. ç›¸é„°çš„ layers åªèƒ½å¾ˆå–®ç´”æ˜¯ $f(W^{(2)}f(W^{(1)}x+b^{(1)})+b^{(2)})$, æ‰€ä»¥å¦‚æœæœ‰ residual add æˆ– concat æ‰çµ¦ $W^{(2)}$ ä½œç”¨çš„è©±å°±ä¸è¡Œ.<br>âš ï¸ <strong>BA é™åˆ¶</strong>:<br>&emsp;1. activations çš„æ¯å€‹ç¶­åº¦æ˜¯é«˜æ–¯åˆ†ä½ˆ, æˆ–èƒ½å–å¾—å…¶åˆ†å¸ƒ, ä¾‹å¦‚é€é <code>observer</code>; ä½†åœ¨ <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/post_training_quant_techniques.html" target="_blank" rel="external">AIMET å·¥å…·</a>æ˜¯å‡è¨­æœ‰ BN æ‰€ä»¥æ˜¯é«˜æ–¯åˆ†å¸ƒ, å¦å‰‡ä¸ç”¨å¥—ç”¨ BA<br>&emsp;2. Activation functions $f(\cdot)$ éœ€ç‚º ReLU (or ReLU6), LeakyReLU é€™ç¨®ä¸è¡Œ<br>âš ï¸ <strong>BC é™åˆ¶</strong>:<br>&emsp;Empirical BC éœ€è¦çµ¦ representative data (å¯ä»¥æ˜¯ unlabeled). å¦‚æœ Analytical BC (data-free) å‰‡éœ€æœ‰ BN â€”&gt; ReLU â€”&gt; Conv/FC é€™æ¨£é †åºçš„å‡è¨­æ‰èƒ½è£œå„Ÿå›  quantize å¾Œ Conv/FC é€™å±¤è¼¸å‡ºçš„ mean åç§»</p>
<p>æ¥è‘—æˆ‘å€‘æè¿°ä¸€ä¸‹ CLE, BA å’Œ BC çš„å‹•æ©Ÿ, ç„¶å¾Œå†è©³ç´°ä»‹ç´¹è«–æ–‡æå‡ºçš„é€™ä¸‰å€‹æ–¹æ³•</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><hr>
<h3 id="CLE-å‹•æ©Ÿ"><a href="#CLE-å‹•æ©Ÿ" class="headerlink" title="CLE å‹•æ©Ÿ"></a>CLE å‹•æ©Ÿ</h3><p>Convolution kernels åœ¨ä¸åŒ output channels ä¾†çœ‹, weights çš„åˆ†ä½ˆæœ‰äº›å¾ˆå¤§æœ‰äº›å¾ˆå°, é€™ä½¿å¾—ç”¨çµ±ä¸€ä¸€å€‹ quantization parameter set æœƒä¸å¥½. æ‰€ä»¥å¦‚æœèƒ½äº‹å…ˆè®“ weights åœ¨ä¸åŒ channel çš„æ•¸å€¼åˆ†ä½ˆæ¥è¿‘, é€™æ¨£å°±é©åˆç”¨ per tensor quantization äº†. ç‚ºæ­¤ä½œè€…æå‡º Cross-Layer Equalizaiton (CLE) æ–¹æ³•.<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 1.png" width="100%" height="100%"> åœ–ä¾†æºç‚º <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/post_training_quant_techniques.html" target="_blank" rel="external">AIMET Post-Training Quantization Techniques</a></p>
<h3 id="BA-å‹•æ©Ÿ"><a href="#BA-å‹•æ©Ÿ" class="headerlink" title="BA å‹•æ©Ÿ"></a>BA å‹•æ©Ÿ</h3><p>ä¸éåšäº† CLE æœ‰å€‹ side-effect å°±æ˜¯è®“ activations æœ‰å¯èƒ½åè€Œä¸åŒ channels åˆ†ä½ˆè®Šçš„æ›´ä¸åŒ, ç‚ºæ­¤ä½œè€…æå‡º Bias Absorption (BA) æ–¹æ³•ä½¿å¾— activations åŒæ¨£é©åˆ per-tensor quant.</p>
<h3 id="BC-å‹•æ©Ÿ"><a href="#BC-å‹•æ©Ÿ" class="headerlink" title="BC å‹•æ©Ÿ"></a>BC å‹•æ©Ÿ</h3><p>å¦ä¸€æ–¹é¢, å…¶å¯¦ weights or input activations ç¶“é quantization å¾Œ, output activations ç†æƒ³ä¸Šå¸Œæœ›æ˜¯ un-biased, ä½†å¯¦éš›ä¸Šéƒ½æœƒæœ‰ bias, å¦‚ä¸‹åœ–<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 2.png" width="70%" height="70%"></p>
<p><span>$$\begin{align}
\mathbb{E}[\tilde{y}_j-y_j]\approx{1\over N}\sum_n\left(\tilde{W}x_n\right)_j - \left(Wx_n\right)_j
\end{align}$$</span><!-- Has MathJax --> å…¶ä¸­ <span>$\tilde{W},\tilde{y}$</span><!-- Has MathJax --> åˆ†åˆ¥æ˜¯ quantized weight and output activation. æ‰€ä»¥ä½œè€…æå‡ºä½¿ç”¨ Bias Correction (BC) æŠ€å·§ä¾†å½Œè£œ.</p>
<h2 id="Data-Free-Quantization-DFQ-è©³ç´°è§£é‡‹"><a href="#Data-Free-Quantization-DFQ-è©³ç´°è§£é‡‹" class="headerlink" title="Data Free Quantization (DFQ) è©³ç´°è§£é‡‹"></a>Data Free Quantization (DFQ) è©³ç´°è§£é‡‹</h2><hr>
<h3 id="Cross-Layer-Equalization-CLE-å¹«åŠ©-weights-per-tensor-é‡åŒ–"><a href="#Cross-Layer-Equalization-CLE-å¹«åŠ©-weights-per-tensor-é‡åŒ–" class="headerlink" title="Cross-Layer Equalization (CLE), å¹«åŠ© weights per-tensor é‡åŒ–"></a>Cross-Layer Equalization (CLE), å¹«åŠ© weights per-tensor é‡åŒ–</h3><p>å°ä»»ä½• $s&gt;0$, ä¸” $f(\cdot)$ æ˜¯ piece-wise linear activation function:<br><span>$$\begin{align}
f(x)=\left\{
\begin{array}{rl}
a_1x+b_1 &amp; \text{if }x\leq c_1 \\
a_2x+b_2 &amp; \text{if }c_1&lt;x\leq c_2 \\
\vdots \\
a_nx+b_n &amp; \text{if } c_{n-1}&lt;x \\
\end{array}
\right.
\end{align}$$</span><!-- Has MathJax --> å‰‡æˆ‘å€‘å¯ä»¥æ‰¾å‡ºç­‰åƒ¹çš„ $\hat{f}(\cdot)$ ä½¿å¾— $f(sx)=s\hat{f}(x)$: è¨­å®š $\hat{a}_i=a_i$, $\hat{b}_i=b_i/s$ and $\hat{c}_i=c_i/s$.<br>é€™éº¼åšæœ‰ä»€éº¼å¥½è™•å‘¢? è€ƒæ…®ä»¥ä¸‹çš„æƒ…å½¢<br>çµ¦å®šå…©å€‹ç›¸é„°çš„ layers: $h=f(W^{(1)}x+b^{(1)})$ å’Œ $y=f(W^{(2)}h+b^{(2)})$, å…¶ä¸­ $f$ æ˜¯ piece-wise linear activation function.<br>å‰‡æˆ‘å€‘æœ‰:</p>
<p><span>$$\begin{align}
y=f(W^{(2)}f(W^{(1)}x+b^{(1)})+b^{(2)}) \\
=f(W^{(2)}S\hat{f}(S^{-1}W^{(1)}x+S^{-1}b^{(1)})+b^{(2)}) \\
=f(\hat{W}^{(2)}f(\hat{W}^{(1)}x+\hat{b}^{(1)})+b^{(2)})
\end{align}$$</span><!-- Has MathJax --> å…¶ä¸­ <span>$S=\text{diag}(s)$</span><!-- Has MathJax --> è¡¨ç¤ºå°è§’çŸ©é™£, <span>$S_{ii}$</span><!-- Has MathJax --> æ˜¯ neuron $i$ çš„ scaling factor $s_i$. å°±æ˜¯é é€™ $s$ ä¾†èª¿ç¯€ weights åˆ†å¸ƒ.<br>æ‰€ä»¥æˆ‘å€‘é‡æ–°ç¸®æ”¾äº† weights: <span>$\hat{W}^{(2)}=W^{(2)}S$</span><!-- Has MathJax -->, <span>$\hat{W}^{(1)}=S^{-1}W^{(1)}$</span><!-- Has MathJax --> and <span>$\hat{b}^{(1)}=S^{-1}b^{(1)}$</span><!-- Has MathJax -->.<br>é‚£éº¼æ€éº¼è¨­å®šæœ€ä½³çš„ $S$ å‘¢? ç†æƒ³ä¸Š, é€é $S$ æˆ‘å€‘å¸Œæœ›å°‡ <span>$\hat{W}^{(1)}, \hat{W}^{(2)}$</span><!-- Has MathJax --> è®Šæˆé©åˆ per tensor quantization.<br>&emsp;- å®šç¾© <span>$r_i^{(1)}:=\max(W_{i,:}^{(1)})$</span><!-- Has MathJax -->, å³ç‚º $W^{(1)}$ çš„ $i^{th}$ row vector å– max.<br>&emsp;- åŒç† <span>$\hat{r}_i^{(1)}:=\max(\hat{W}_{i,:}^{(1)})=r_i^{(1)}/s_i$</span><!-- Has MathJax -->.<br>é¡ä¼¼åœ°æˆ‘å€‘å®šç¾©<br>&emsp;- <span>$r_j^{(2)}:=\max(W_{:,j}^{(2)})$</span><!-- Has MathJax -->, å³ç‚º $W^{(2)}$ çš„ $j^{th}$ column vector å– max.<br>&emsp;- <span>$\hat{r}_j^{(2)}:=\max(\hat{W}_{:,j}^{(2)})=s_j\cdot r_j^{(2)}$</span><!-- Has MathJax -->.<br>æ³¨æ„åˆ°ä¸€å€‹æ˜¯ row vector å¦ä¸€å€‹æ˜¯ column vector é€™æ˜¯å› ç‚º $W^{(1)}$ çš„ row vector å°æ‡‰çš„æ˜¯ $W^{(2)}$ çš„ column vector. å³ç¬¬ä¸€å±¤ layer çš„ output channel å°æ‡‰çš„æ˜¯ç¬¬äºŒå±¤ layer çš„ input channel çš„æ¦‚å¿µ<br>ç„¶å¾Œå†ä»¤æ•´å€‹ weight matrix çš„æœ€å¤§å€¼ç‚º: $R^{(1)}:=\max_i(r_i^{(1)})$ å’Œ $R^{(2)}:=\max_j(r_j^{(2)})$<br>å¤§æ¦‚ç¤ºæ„åœ–é•·é€™æ¨£å­<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 3.png" width="100%" height="100%"> æœ€å¾Œå°±å¯ä»¥å®šç¾©æ¯ä¸€å€‹ channel (1~m) å°æ–¼æ•´å€‹ weight matrix çš„å æ¯”:<br>$p_i^{(1)}=r_i^{(1)}/R^{(1)}$; $\hat{p}_i^{(1)}=\hat{r}_i^{(1)}/\hat{R}^{(1)}$; åŒç† $p_j^{(2)},\hat{p}_j^{(2)}$<br>åˆ°é€™è£¡ä¸é›£ç†è§£, åªæ˜¯å¾ˆå¤š terms è¦æ¶ˆåŒ–ä¸€ä¸‹è€Œå·²<br>$p_i^{(1)}$ è¡¨ç¤º $i^{th}$ row vector å°æ•´å€‹ matrix $W^{(1)}$ çš„ä½”æ¯”, æƒ³åƒä¸Šå¦‚æœæ¯å€‹ rows çš„ä½”æ¯”éƒ½å¾ˆå¤§, é‚£å°±æ•´é«”é©åˆ per-tensor quantization.<br>å¯ä»¥æƒ³åƒ, è‹¥ $\hat{p}_i^{(1)}$ æ¯” $p_i^{(1)}$ å¤§è¡¨ç¤º $i^{th}$ row vector çš„ä½”æ¯”ç¶“é $s_i$ çš„èª¿æ•´è®Šå¤§, ä½†ç”±æ–¼ $s_i$ åœ¨ $W^{(1)}$ ç”¨é™¤çš„ä½†åœ¨ $W^{(2)}$ ç”¨ä¹˜çš„, å°è‡´ $\hat{p}_i^{(2)}$ æ¯” $p_i^{(2)}$ å°äº†, æ„æ€æ˜¯ $i^{th}$ column vector çš„ä½”æ¯”åè€Œè®Šå°. æ‰€ä»¥ä¸€é‚Šè®Šå¤§äº†ä½†åè€Œä½¿å¦ä¸€é‚Šè®Šå°äº†, é€™ä¸€å®šæ˜¯å€‹ trade-off.<br>æ‰€ä»¥æˆ‘å€‘å¸Œæœ›å…©é‚Šéƒ½é¡§åˆ° ($\hat{p}_i^{(1)} \hat{p}_i^{(2)}$ ä¸€èµ·è€ƒæ…®)  , ä½œè€…å°±å®šç¾©äº†é€™æ¨£çš„ç›®æ¨™å‡½å¼:</p>
<p><span>$$\begin{align}
\max_S \sum_i \hat{p}_i^{(1)} \hat{p}_i^{(2)}
\end{align}$$</span><!-- Has MathJax --> èª¿æ•´ $S$ ä½¿å…©é‚Š matrix $W^{(1)},W^{(2)}$ çš„å æ¯”éƒ½è¦é¡§åˆ°, æ‰¾å‡ºä½¿å¾—ç¸½ä½”æ¯”é‡æœ€å¤§çš„ $S$.<br>é€™å€‹å•é¡Œçš„æœ€ä½³è§£åœ¨è«–æ–‡çš„ Appendix A æœ‰è­‰æ˜, æˆ‘å€‘å…ˆæŠŠè§£å¯«å‡ºä¾†:</p>
<p><span>$$\begin{align}
s_i=\frac{1}{r_i^{(2)}}\sqrt{r_i^{(1)}r_i^{(2)}}
\end{align}$$</span><!-- Has MathJax --> é€™æ¨£çš„ $s_i$ æœƒä½¿å¾— <span>$\hat{r}_i^{(1)}=\hat{r}_i^{(2)}$</span><!-- Has MathJax -->, $\forall i$. æŠŠ $s_i$ ä»£åˆ° <span>$\hat{r}_i^{(1)}$</span><!-- Has MathJax --> and <span>$\hat{r}_i^{(2)}$</span><!-- Has MathJax --> å°±çŸ¥é“äº†. (é€™è£¡åŸè«–æ–‡å¯« <span>$r_i^{(1)}=r_i^{(2)}$</span><!-- Has MathJax --> æ‡‰è©²æ˜¯ typo)<br>è©³ç´°è­‰æ˜è¨˜éŒ„åœ¨æœ€å¾Œçš„ Appendix (è«–æ–‡è­‰æ˜æœ‰äº›æ²’æ‡‚è£œå……ä¸€ä¸‹è‡ªå·±æƒ³æ³•).</p>
<h3 id="Bias-Absorption-BA-å¹«åŠ©-activation-per-tensor-é‡åŒ–"><a href="#Bias-Absorption-BA-å¹«åŠ©-activation-per-tensor-é‡åŒ–" class="headerlink" title="Bias Absorption (BA), å¹«åŠ© activation per-tensor é‡åŒ–"></a>Bias Absorption (BA), å¹«åŠ© activation per-tensor é‡åŒ–</h3><p>å†èªªä¹‹å‰, å…ˆäº†è§£ä»¥ä¸‹ç¯„ä¾‹.<br>é¦–å…ˆå°æ–¼ ReLU $r(\cdot)$ ä¾†èªªä¸€å®šå­˜åœ¨ä¸€å€‹ non-negative vector $c$ ä½¿å¾— $\forall x$</p>
<p><span>$$r(Wx+b-c)=r(Wx+b)-c; \quad \forall x \qquad\qquad (\star)$$</span><!-- Has MathJax --> $c=0$ å°±æ˜¯ä¸€å€‹ trivial è§£.<br>èˆ‰ä¸€å€‹ç°¡å–®ç¯„ä¾‹, è€ƒæ…®æŸä¸€å€‹ channel $i$, data $Wx_i$ çš„æ©Ÿç‡åˆ†ä½ˆç‚ºç›´è§’ä¸‰è§’å½¢:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 4.png" width="50%" height="50%"> ç•¶ $b=3$ çš„æƒ…æ³æ™‚, å‰‡é¸ $c=0.5$ æ»¿è¶³ $(\star)$ æ¢ä»¶, è¦‹ä¸‹åœ–:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/absorbing_bias-row.drawio.png" width="100%" height="100%"> é€™å€‹æƒ…æ³æœƒ<strong>æ»¿è¶³æ‰€æœ‰</strong> $x$, ä½†å¦‚æœ $Wx$ çš„åˆ†å¸ƒä¸åƒç¯„ä¾‹ä¸€å®šå¤§æ–¼æŸä¸€å€‹å€¼ (æƒ³åƒä¸Šé¢çš„ç›´è§’ä¸‰è§’å½¢åˆ†å¸ƒè®Šæˆé«˜æ–¯åˆ†ä½ˆ) å‰‡æˆ‘å€‘åªèƒ½é¸æ“‡<strong>æ»¿è¶³å¤§éƒ¨ä»½çš„å€¼</strong></p>
<blockquote>
<p>å¦‚æœæ˜¯é«˜æ–¯åˆ†ä½ˆçš„è©± (å‰‡ Batch norm çš„ mean, std å°±å¯æ‹¿ä¾†ç”¨), è«–æ–‡é¸æ“‡ 3 å€‹æ¨™æº–å·®æ‰€ä»¥ä¿è­‰ 99.865% æ»¿è¶³. é«˜æ–¯åˆ†ä½ˆåœ¨ $\mu\pm3\sigma$ å…§çš„æ©Ÿç‡ç´„ç‚º $0.9973002$ [<a href="https://www.wikiwand.com/zh/68%E2%80%9395%E2%80%9399.7%E6%B3%95%E5%89%87" target="_blank" rel="external">ref</a>], ä½†ç”±æ–¼æˆ‘å€‘è¦æ‰¾çš„ $c$ åªæœƒå¿½ç•¥ $&lt;\mu-3\sigma$ çš„æƒ…æ³æ‰€ä»¥æ˜¯ $1-(1-0.9973002)/2\approx99.865$, ä¹‹å¾Œæœƒæœ‰åœ–ç¤ºæ¯”è¼ƒæ¸…æ¥š</p>
</blockquote>
<p>æœ‰äº†ä»¥ä¸Šæ¦‚å¿µå¾Œ, å›é ­éä¾†çœ‹çœ‹ç¶“é CLE å¾Œé‚„æœƒç™¼ç”Ÿä»€éº¼ç¾è±¡, å…¶ä¸­ <span>$r(\cdot)$</span><!-- Has MathJax --> æ˜¯ ReLU.<br>(çªç„¶æ¸²æŸ“ä¸å‡ºæ•¸å­¸å¼å­â€¦ç…©é˜¿)<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/eq8.png" width="30%" height="30%"> $\hat{W}^{(1)}$ and $\hat{W}^{(2)}$ å·²ç¶“è¢« CLE èª¿æ•´ä¸€æ³¢å¾Œæ•¸å€¼åˆ†ä½ˆè®Šå¾—å¾ˆæ¥è¿‘ (é©åˆ per-tensor quantization ğŸ‘ğŸ»)<br>ä½† <span>$\hat{b}^{(1)}=S^{-1}b^{(1)}$</span><!-- Has MathJax -->, ç•¶ <span>$s_i&lt;1$</span><!-- Has MathJax --> çš„æ™‚å€™æœƒè®“ channel $i$ çš„ activation æ”¾å¤§å°è‡´ activations, <span>$\hat{W}^{(1)}x+\hat{b}^{(1)}$</span><!-- Has MathJax -->, çš„å„ channel ä¹‹é–“åˆ†ä½ˆä½ç½®æœƒä¸åŒ, å› æ­¤ä¹Ÿæœƒè®“ activations ä¸å¥½åš quantization!<br>åˆ©ç”¨ä¸Šé¢èªªçš„æ¦‚å¿µæˆ‘å€‘é€™æ¨£æ¨å°:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/eq_9_12.png" width="70%" height="70%"> å…¶ä¸­ $b^{\star(1)}=\hat{b}^{(1)}-c$ å’Œ $b^{\star(2)}=\hat{W}^{(2)}c+b^{(2)}$.<br>ğŸ’¡ <strong>ç›®çš„æ˜¯æŠŠ</strong> $\color{orange}{\hat{W}^{(1)}x+\hat{b}^{(1)}}$ <strong>å¾ä¸é©åˆåš per-tensor quant è®Šæˆ</strong> $\color{orange}{\hat{W}^{(1)}x+b^{\star(1)}}$ <strong>å®¹æ˜“åš per-tensor quant.</strong><br>å‰‡ $c$ å¯ä»¥é¸æ“‡ç›¡é‡æ»¿è¶³æ‰€æœ‰ $\hat{W}^{(1)}x+\hat{b}^{(1)}$ çš„å€¼, è¦é€™éº¼åšæœ€æš´åŠ›çš„æ–¹å¼æ˜¯é¤µæ‰€æœ‰ training data å»çœ‹è³‡æ–™åˆ†å¸ƒ, é¸æ“‡æ»¿è¶³å¤§éƒ¨åˆ†çš„æƒ…æ³, ä¾‹å¦‚æ»¿è¶³ 99.99% çš„æ•¸å€¼.<br>å¦å¤–å¦‚æœæˆ‘å€‘çŸ¥é“ $\hat{W}^{(1)}x+\hat{b}^{(1)}$ æœƒå†ç¶“é Batch normalization, i.e. $BN(\hat{W}^{(1)}x+\hat{b}^{(1)})$ åªæ˜¯ BN å¿½ç•¥ä¸å¯«è€Œå·², å‰‡ä»¤ $c=\max(0,\beta-3\gamma)$, å…¶ä¸­ $\beta,\gamma$ åˆ†åˆ¥æ˜¯ Batch normalization çš„ shift and scale parameters, é€™æ¨£ç›´æ¥å°±æ»¿è¶³å¤§æ–¼-3æ¨™æº–å·®çš„ 99.865% æ©Ÿç‡äº†.</p>
<blockquote>
<p>é–‹é ­çš„ DFQ æµç¨‹åœ–æœ‰å…ˆåš BN folding, æ‰€ä»¥æ­¤æ™‚çš„ $\tilde{W}^{(1)}$ å·²ç¶“æ˜¯ folding å¾Œçš„, å› æ­¤è¦äº‹å…ˆæŠŠ $\beta,\gamma$ å­˜èµ·ä¾†æ‰èƒ½åœ¨é€™æ­¥é©Ÿç”¨</p>
</blockquote>
<p>æˆ‘å€‘ä¾†æ€è€ƒç‚ºå•¥ activations å¾ $\hat{W}^{(1)}x+\hat{b}^{(1)}$ è®Šæˆ $\hat{W}^{(1)}x+b^{\star(1)}$ å¾Œå°±æœƒæ¯”è¼ƒå¥½åš per-tensor quantization, é€™æ˜¯å› ç‚ºæˆ‘å€‘é¸æ“‡çš„é€™äº› $c_i$ æœƒè®“ç¶­åº¦ $i$ çš„ activation å°é½Šåˆ°å‰›å¥½æœ‰ 99.865% å¤§æ–¼ 0, è€Œæ¯å€‹ç¶­åº¦éƒ½ä¾é€™æ¨£çš„æ¨™æº– align è‡ªç„¶å°±å®¹æ˜“å°æ•´å€‹ activations åš quantization äº† (ä¸éœ€è¦ per-channel quant äº†)!<br>åœ–ç¤ºä¸€ä¸‹ä¸Šé¢çš„æ„æ€, ç‚ºäº†æ–¹ä¾¿ä»¤ $\hat{k}=\hat{W}^{(1)}x+\hat{b}^{(1)}$, å…¶ä¸­ $\hat{k}_i$ è¡¨ç¤ºç¬¬ $i$ ç¶­, åŒç† $k^{\star}=\hat{W}^{(1)}x+b^{\star(1)}$ å’Œ $k^\star_i$:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 5.png" width="70%" height="70%"> æ³¨æ„åˆ°é›–ç„¶ activations $k^\star$ é©åˆ per-tensor quant äº†, ä½†æˆ‘å€‘åªæ˜¯æŠŠé€™å›°é›£ pass åˆ° $b^{\star(2)}$, ç‚ºå•¥é€™éº¼èªªå‘¢? å› ç‚º $b^{\star(2)}$ éœ€è¦å¤šåŠ ä¸€é … $\hat{W}^{(2)}c$, ä½†æˆ‘å€‘ä¸¦ä¸åšä»»ä½•ä¿è­‰ ,å› æ­¤ activations $z$ (çœ‹å¼ (8))ä»ç„¶æœ‰å¯èƒ½æ¯å€‹ channel ç¶­åº¦åˆ†ä½ˆä½ç½®ä¹Ÿéƒ½ä¸åŒ, æ‰€ä»¥å¯¦å‹™ä¸Šæ¡å– layer 1 and 2 åšå®Œ, å†åš layer 2 and 3, ä¾æ­¤åˆ—æ¨ä¸‹å».</p>
<h3 id="Bias-Correction-BC"><a href="#Bias-Correction-BC" class="headerlink" title="Bias Correction (BC)"></a>Bias Correction (BC)</h3><p>å¦‚åŒåœ¨ motivation ç¨å¾®æåˆ°çš„, ä»¤ $\epsilon=\tilde{W}-W$ æ˜¯ quantization error, $\tilde{W}$ æ˜¯ quant å¾Œçš„åƒæ•¸. ä¸”ä»¤ $y=Wx,\tilde{y}=\tilde{W}x$, åˆ†åˆ¥æ˜¯ quant å‰å¾Œçš„ output activations, å‰‡æˆ‘å€‘æœ‰ $\tilde{y}=y+\epsilon x$.<br>ç”±æ–¼ quantization å¾Œå¯èƒ½ activations çš„åˆ†å¸ƒ mean å€¼ä¸æœƒè·ŸåŸä¾†ä¸€æ¨£, i.e. å¯èƒ½æœƒ $\mathbb{E}[\epsilon x]\neq0$, ä½†å¯ä»¥é€éä¸‹å¼è¢«çŸ¯æ­£å›ä¾†: $\mathbb{E}[y]=\mathbb{E}[\tilde{y}]-\epsilon\mathbb{E}[x]$<br>æ‰€ä»¥åªéœ€è¦å° quant å®Œçš„ output åŠ ä¸Š $-\epsilon\mathbb{E}[x]$, ä½†å¯¦å‹™ä¸Šä¸æœƒé€™éº¼åš, è€Œæ˜¯åšåœ¨ bias parameter è£¡ (bias åŠ ä¸Š $-\epsilon\mathbb{E}[x]$).<br>ä¸éæˆ‘å€‘æ€éº¼æœƒçŸ¥é“ input activation çš„æœŸæœ›å€¼, $\mathbb{E}[x]$?<br>åšå®Œä¸Šè¿° CLE + bias absorption ä¸¦å¾—åˆ°é‡åŒ– model å¾Œè·ŸåŸæœ¬ float model æ¯”è¼ƒå¯ä»¥å¾—åˆ° $\epsilon$, å¦‚æœæœ‰ representative data (å¯ä»¥æ˜¯ unlabeled) æƒ…æ³ä¸‹, å‰‡ä¸Ÿ data  å»è¨ˆç®— $\mathbb{E}[x]$ å°±å¯ä»¥äº†. æ³¨æ„è¦æŒ‰ç…§ layer åš, ä¹Ÿå°±æ˜¯åš $l^{th}$ layer çš„ BC é …æ™‚, å‡è¨­ $1, 2,..,l-1$ layer çš„ BC é …éƒ½ apply ä¸Šå»äº†. é€™å«åš Empirical Bias Correction, è©³è¦‹è«–æ–‡ Appendix D.<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 6.png" width="100%" height="100%"> (åœ–ä¾†æºç‚º <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/post_training_quant_techniques.html" target="_blank" rel="external">AIMET Post-Training Quantization Techniques</a>)<br>ä½†è«–æ–‡æ¨™é¡Œæ˜¯ â€œData-freeâ€, æ€éº¼è¾¦å‘¢? æ­¤æ™‚è«–æ–‡è¦æ±‚è¦æœ‰é€™æ¨£çš„ blocks é—œè¯:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 7.png" width="100%" height="100%"> å·²çŸ¥ç›®å‰è¦è™•ç†çš„ layer æ˜¯ $\tilde{y}=\tilde{W}x$. è«–æ–‡å‡è¨­æ­¤ layer ä¹‹å‰é‚„æœ‰ BN and ReLU å…©å€‹ blocks. æ³¨æ„åˆ°éœ€æœ‰é€™æ¨£çš„é—œè¯å­˜åœ¨æ‰å¯ä»¥.<br>è€Œ $\mathbb{E}[x]$ å¯ä»¥åˆ©ç”¨ BN å¾Œ $x^{pre}$ æ˜¯ normal distribution çš„ç‰¹æ€§ä¾†ç®—. æ³¨æ„åˆ°ç¶“é ReLU å¾Œçš„ $x$ è®Šæˆ clipped normal distribution, è€Œå…¶ mean å¯ä»¥åˆ©ç”¨ BN çš„ shift and scale parameters å¯«å‡º closed form è§£.<br>è©³ç´°ç›´æ¥åƒè€ƒè«–æ–‡, Appendix C æœ‰æ¨å°. é€™æ¨£çš„åšæ³•ç¨± Analytical Bias Correction.<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 8.png" width="100%" height="100%"> (åœ–ä¾†æºç‚º <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/post_training_quant_techniques.html" target="_blank" rel="external">AIMET Post-Training Quantization Techniques</a>)</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><hr>
<p>ç”±æ–¼ CLE and BA ç›®çš„æ˜¯è®“å¾Œé¢çš„ quantization æ¯”è¼ƒé©åˆ per-tensor, æ‰€ä»¥è¦è§€å¯Ÿä»¥ä¸‹å…©é»:<br>&emsp;1. ç”¨äº† CLE and/or BA å¾Œ, ç”±æ–¼è¼¸å‡ºé‚„æ˜¯ float model, é‚£è·Ÿç”¨ä¹‹å‰çš„ float model æœ‰ç„¡ performance å½±éŸ¿?<br>&emsp;2. ç”¨äº† CLE and/or BA å¾Œ, å†ç”¨äº† per-tensor é‡åŒ–å¾Œ, èƒ½å¦é€¼è¿‘åŸæœ¬ float model (æ²’ç”¨ CLE/BA) çš„ per-channel é‡åŒ–?<br>çµæœ Table 1 é¡¯ç¤ºä»¥ä¸Šå…©é»éƒ½æ²’å•é¡Œ.<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 9.png" width="60%" height="60%"> å†ä¾†å¦‚æœåŠ å…¥ BC å‰‡è§€å¯Ÿèƒ½å¦è£œå„Ÿå›  quantization é€ æˆçš„ mean åç§»æå¤±? å…¶ä¸­å¯ä»¥çœ‹ quantization model æœ‰ç„¡å¥—ç”¨ CLE+BA.<br>çµæœå¦‚ Table 2:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 10.png" width="60%" height="60%"> Original model ç›´æ¥ç¡¬åš PTQ to INT8 æ˜¯æ…˜ä¸å¿ç¹çš„ random è¡Œç‚º, ä½†ç›´æ¥åŠ ä¸Š BC è£œå„Ÿå¾Œç«Ÿç„¶å°±å›åˆ° 52.02%!<br>å¦‚æœå…ˆç”¨ CLE+BA åœ¨é‡åŒ–åˆ° INT8, performance ç‚º Table 1 çš„æœ€ä½³ 70.92%. é€™ç¨®æƒ…æ³å†åŠ ä¸Š BC é‚„èƒ½æå‡ä¸€é»é» (å¤šå°‘è¡¨ç¤ºå¯èƒ½é‚„æ˜¯å­˜åœ¨ä¸€é»é»çš„ mean åç§»)<br>Clip@15 é€™å€‹æ–¹æ³•æ˜¯ç›´æ¥å° weights ç åˆ° [-15, 15] å€é–“, è·Ÿ CLE ç›®çš„ä¸€æ¨£åªæ˜¯ç›´æ¥ç²—æš´, ç•¶ç„¶ BC å°±èƒ½ç™¼æ®æ›´å¥½çš„ä½œç”¨ (2.55% â€”&gt; 70.43%).<br>å‰©ä¸‹çš„å¯¦é©—å°±ä¸ç´°èªª.</p>
<h2 id="AIMET-Quantization-Flow"><a href="#AIMET-Quantization-Flow" class="headerlink" title="AIMET Quantization Flow"></a>AIMET Quantization Flow</h2><hr>
<p>ä»¥ä¸‹ç‚º <a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/auto_quant.html#ug-auto-quant" target="_blank" rel="external">AIMET AutoQuant</a> å»ºè­°çš„é‡åŒ–æµç¨‹, ç¸½çµå¾—å¾ˆä¸éŒ¯:<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/Untitled 11.png" width="100%" height="100%"></p>
<blockquote>
<p>åœ–ä¸­çš„ CLE æˆ‘çŒœå·²ç¶“åŒ…å« BA äº†, ç„¶å¾Œå¯ä»¥çœ‹åˆ°æ²’æœ‰ BC, å› ç‚ºè¢« AdaRound å–ä»£æ‰<br>ä¹Ÿæ³¨æ„åˆ°åœ¨çµ¦ CLE ä¹‹å‰è¦å…ˆåš BatchNorm folding (å¦‚åŒæˆ‘å€‘åœ¨è¬› CLE çš„é™åˆ¶ 2)</p>
</blockquote>
<p>æµç¨‹å°±æ˜¯å»ºè­°å…ˆå° floating model æ’å¥½ fake quant op ä¾†æ¨¡æ“¬ target HW çš„ operators è¡Œç‚º (QuantScheme Selection é‚£æ­¥). å…ˆçœ‹çœ‹æ•ˆæœå¦‚ä½•, å¦‚æœ OK é‚£ PTQ/QAT éƒ½ä¸éœ€è¦.<br>æ¥è‘—æ‰ç¢ºèª BN folding æ˜¯å¦èƒ½å¹«åŠ©æå‡æ•ˆæœ? ä¸è¡Œçš„è©±å¥—çœ‹çœ‹ PTQ çš„ CLE (w/wo AdaRound). å†ä¸è¡Œå°±è¦èµ° QAT äº†.</p>
<p>åˆ°é€™çµ‚æ–¼ç´€éŒ„å®Œ, é€™ç¯‡åˆçœ‹æ„Ÿè¦ºæ‡‰è©²å¯ä»¥å¾ˆå¿«çœ‹å®Œ, ä¸€è®€æ‰ç™¼ç¾ç´°ç¯€çœŸçš„æœ‰å¤ å¤š, é —ä¸å®¹æ˜“. ä¹Ÿå› ç‚ºå¾ˆèªçœŸç´°è®€æ‰ç™¼ç¾å…¶å¯¦æœ‰ä¸å°‘é™åˆ¶. ä¸éé‚„æ˜¯å¾ˆæœ‰æ”¶ç©«æ‹‰~<br>ç¸½ä¹‹æ­å–œè®€è€…(è‡ªå·±?)æœ‰è€å¿ƒçœ‹å®Œ(å¯«å®Œ). ~~ æ’’èŠ±æ”¶å·¥ ~~</p>
<h2 id="Appendix-è­‰æ˜-CLE-çš„æœ€ä½³è§£"><a href="#Appendix-è­‰æ˜-CLE-çš„æœ€ä½³è§£" class="headerlink" title="Appendix è­‰æ˜ CLE çš„æœ€ä½³è§£"></a>Appendix è­‰æ˜ CLE çš„æœ€ä½³è§£</h2><hr>
<p>Render çˆ›æ‰äº†, ç›´æ¥æ€’è²¼åœ–â€¦<br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/appendix1.png" width="80%" height="80%"><br><img src="/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/appendix2.png" width="80%" height="80%"></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><hr>
<ol>
<li>Data-Free Quantization Through Weight Equalization and Bias Correction, [<a href="https://arxiv.org/abs/1906.04721" target="_blank" rel="external">arxiv</a>]</li>
<li>Up or Down? Adaptive Rounding for Post-Training Quantization, [<a href="https://arxiv.org/abs/2004.10568" target="_blank" rel="external">arxiv</a>]</li>
<li>AI Model Efficiency Toolkit (<a href="https://quic.github.io/aimet-pages/releases/latest/user_guide/index.html" target="_blank" rel="external">AIMET</a>)</li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>Post authorï¼š</strong>
      Chih-Sheng Chen
    </li>
    <li class="post-copyright-link">
      <strong>Post linkï¼š</strong>
      <a href="https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/" title="Qualcomm Data-Free Quantization è©³è®€">https://bobondemon.github.io/2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/</a>
    </li>
    <li class="post-copyright-license">
      <strong>Copyright Noticeï¼š </strong>
      All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Post-Training-Quantization-PTQ/" rel="tag"># Post Training Quantization (PTQ)</a>
          
            <a href="/tags/Quantization-Aware-Training-QAT/" rel="tag"># Quantization Aware Training (QAT)</a>
          
            <a href="/tags/Data-Free-Quantization-DFQ/" rel="tag"># Data Free Quantization (DFQ)</a>
          
            <a href="/tags/AIMET/" rel="tag"># AIMET</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2023/11/04/Quantization-Error-Case-with-Clipping/" rel="next" title="Quantization Error (Case with Clipping)">
                <i class="fa fa-chevron-left"></i> Quantization Error (Case with Clipping)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2023/12/28/SmoothQuant-ç­†è¨˜/" rel="prev" title="SmoothQuant ç­†è¨˜">
                SmoothQuant ç­†è¨˜ <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            æ–‡ç« ç›®éŒ„
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            æœ¬ç«™æ¦‚è¦½
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.png"
               alt="Chih-Sheng Chen" />
          <p class="site-author-name" itemprop="name">Chih-Sheng Chen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">108</span>
                <span class="site-state-item-name">æ–‡ç« </span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">åˆ†é¡</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">225</span>
                <span class="site-state-item-name">æ¨™ç±¤</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation"><span class="nav-number">1.</span> <span class="nav-text">Motivation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CLE-å‹•æ©Ÿ"><span class="nav-number">1.1.</span> <span class="nav-text">CLE å‹•æ©Ÿ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BA-å‹•æ©Ÿ"><span class="nav-number">1.2.</span> <span class="nav-text">BA å‹•æ©Ÿ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BC-å‹•æ©Ÿ"><span class="nav-number">1.3.</span> <span class="nav-text">BC å‹•æ©Ÿ</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Free-Quantization-DFQ-è©³ç´°è§£é‡‹"><span class="nav-number">2.</span> <span class="nav-text">Data Free Quantization (DFQ) è©³ç´°è§£é‡‹</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cross-Layer-Equalization-CLE-å¹«åŠ©-weights-per-tensor-é‡åŒ–"><span class="nav-number">2.1.</span> <span class="nav-text">Cross-Layer Equalization (CLE), å¹«åŠ© weights per-tensor é‡åŒ–</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias-Absorption-BA-å¹«åŠ©-activation-per-tensor-é‡åŒ–"><span class="nav-number">2.2.</span> <span class="nav-text">Bias Absorption (BA), å¹«åŠ© activation per-tensor é‡åŒ–</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias-Correction-BC"><span class="nav-number">2.3.</span> <span class="nav-text">Bias Correction (BC)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Experiments"><span class="nav-number">3.</span> <span class="nav-text">Experiments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AIMET-Quantization-Flow"><span class="nav-number">4.</span> <span class="nav-text">AIMET Quantization Flow</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Appendix-è­‰æ˜-CLE-çš„æœ€ä½³è§£"><span class="nav-number">5.</span> <span class="nav-text">Appendix è­‰æ˜ CLE çš„æœ€ä½³è§£</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">6.</span> <span class="nav-text">References</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chih-Sheng Chen</span>
</div>


<div class="powered-by">
  ç”± <a class="theme-link" href="https://hexo.io">Hexo</a> å¼·åŠ›é©…å‹•
</div>

<div class="theme-info">
  ä¸»é¡Œ -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      [object Object]
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      [object Object]
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  



  




	





  





  





  






  





  

  

  

  

</body>
</html>
