<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-tw">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Weight Normalization,Batch Normalization,Scale Invariant Function," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="ä½¿ç”¨ SGD åšå„ªåŒ–æ™‚, å¦‚æœ ill-conditioned of Hessian matrix, i.e. $\sigma_1/\sigma_n$ æœ€å¤§æœ€å°çš„ eigenvalues ä¹‹æ¯”å€¼, æœƒä½¿å¾—æ”¶æ–‚æ•ˆç‡ä¸å½°(ref zig-zag).

å¯ä»¥æƒ³æˆ loss function çš„æ›²é¢æ„ˆä¸åƒæ­£åœ“å‰‡æ„ˆ ill-conditioned (æ„ˆæ‰å¹³).

å¸Œæœ›è—‰ç”± re-parameteri">
<meta property="og:type" content="article">
<meta property="og:title" content="Weight Normalization çš„ç­†è¨˜">
<meta property="og:url" content="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/index.html">
<meta property="og:site_name" content="æ£’æ£’ç”Ÿ">
<meta property="og:description" content="ä½¿ç”¨ SGD åšå„ªåŒ–æ™‚, å¦‚æœ ill-conditioned of Hessian matrix, i.e. $\sigma_1/\sigma_n$ æœ€å¤§æœ€å°çš„ eigenvalues ä¹‹æ¯”å€¼, æœƒä½¿å¾—æ”¶æ–‚æ•ˆç‡ä¸å½°(ref zig-zag).

å¯ä»¥æƒ³æˆ loss function çš„æ›²é¢æ„ˆä¸åƒæ­£åœ“å‰‡æ„ˆ ill-conditioned (æ„ˆæ‰å¹³).

å¸Œæœ›è—‰ç”± re-parameteri">
<meta property="og:image" content="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled.png">
<meta property="og:image" content="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled 1.png">
<meta property="og:image" content="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled 2.png">
<meta property="og:image" content="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/wn_pytorch.png">
<meta property="og:updated_time" content="2022-10-15T11:58:14.077Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Weight Normalization çš„ç­†è¨˜">
<meta name="twitter:description" content="ä½¿ç”¨ SGD åšå„ªåŒ–æ™‚, å¦‚æœ ill-conditioned of Hessian matrix, i.e. $\sigma_1/\sigma_n$ æœ€å¤§æœ€å°çš„ eigenvalues ä¹‹æ¯”å€¼, æœƒä½¿å¾—æ”¶æ–‚æ•ˆç‡ä¸å½°(ref zig-zag).

å¯ä»¥æƒ³æˆ loss function çš„æ›²é¢æ„ˆä¸åƒæ­£åœ“å‰‡æ„ˆ ill-conditioned (æ„ˆæ‰å¹³).

å¸Œæœ›è—‰ç”± re-parameteri">
<meta name="twitter:image" content="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'åšä¸»'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/"/>





  <title> Weight Normalization çš„ç­†è¨˜ | æ£’æ£’ç”Ÿ </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">æ£’æ£’ç”Ÿ</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">è®“å­¸ç¿’è®Šæˆä¸€ç¨®ç¿’æ…£</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            é¦–é 
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            åˆ†é¡
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            é—œæ–¼
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            æ­¸æª”
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            æ¨™ç±¤
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chih-Sheng Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="æ£’æ£’ç”Ÿ">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Weight Normalization çš„ç­†è¨˜
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">ç™¼è¡¨æ–¼</span>
              
              <time title="å‰µå»ºæ–¼" itemprop="dateCreated datePublished" datetime="2022-09-26T21:37:42+08:00">
                2022-09-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†é¡æ–¼</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>[object Object]
            </span>
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<hr>
<p>ä½¿ç”¨ SGD åšå„ªåŒ–æ™‚, å¦‚æœ ill-conditioned of Hessian matrix, i.e. $\sigma_1/\sigma_n$ æœ€å¤§æœ€å°çš„ eigenvalues ä¹‹æ¯”å€¼, æœƒä½¿å¾—æ”¶æ–‚æ•ˆç‡ä¸å½°<br>(ref <a href="https://trond.hjorteland.com/thesis/node26.html" target="_blank" rel="external">zig-zag</a>).</p>
<blockquote>
<p>å¯ä»¥æƒ³æˆ loss function çš„æ›²é¢æ„ˆä¸åƒæ­£åœ“å‰‡æ„ˆ ill-conditioned (æ„ˆæ‰å¹³).</p>
</blockquote>
<p>å¸Œæœ›è—‰ç”± re-parameterization ä¾†å°‡ ill-conditioned ç‹€æ³é™ä½.<br>ä¸€èˆ¬ä¾†èªª NN çš„ layer å¯ä»¥é€™éº¼å¯«:<br><span>$$y=\phi(w^Tx+b)$$</span><!-- Has MathJax --> æŠŠ weight vector $w$ é‡æ–°æ”¹å¯«å¦‚ä¸‹:</p>
<span>$$w={g\over\|v\|}v\quad\quad(\star)$$</span><!-- Has MathJax --> WN å°±æ˜¯å°‡ $w$ æ‹†æˆç”¨ unit vector $v/||v||$ å’Œ magnitude $g$ å…©å€‹ variables ä¾†è¡¨ç¤º<br><br><a id="more"></a>
<h2 id="å°å¤§å°-g-çš„å¾®åˆ†"><a href="#å°å¤§å°-g-çš„å¾®åˆ†" class="headerlink" title="å°å¤§å° $g$ çš„å¾®åˆ†"></a>å°å¤§å° $g$ çš„å¾®åˆ†</h2><hr>
<p>å› æ­¤ loss function $L$ å° $g$ å¾®åˆ†ç‚º:<br><span>$$\begin{align}
\frac{dL}{dg}=\nabla_wL^T\frac{\partial w}{\partial g}=\nabla_wL^T\frac{v}{\|v\|}
\end{align}$$</span><!-- Has MathJax --></p>
<blockquote>
<p>é€™è£¡æˆ‘å€‘å¯« gradient vector éƒ½ä»¥ column vector ä¾†å¯«<br>æ‰€ä»¥å¦‚æœ loss function $L$ æ˜¯ scalar çš„è©±, gradient å°±æ˜¯ transpose of Jacobian matrix (å‰›å¥½æ˜¯ 1xn çš„ row vector)</p>
</blockquote>
<h2 id="å°æ–¹å‘å‘é‡-v-çš„å¾®åˆ†"><a href="#å°æ–¹å‘å‘é‡-v-çš„å¾®åˆ†" class="headerlink" title="å°æ–¹å‘å‘é‡ $v$ çš„å¾®åˆ†"></a>å°æ–¹å‘å‘é‡ $v$ çš„å¾®åˆ†</h2><hr>
<p>Loss function $L$ å° $v$ å¾®åˆ†ç‚º:</p>
<blockquote>
<p>é€™è£¡è¦åƒè€ƒåˆ° <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf" target="_blank" rel="external">matrix cookbook</a> equation (130)</p>
</blockquote>
<span>$$\begin{align}
\nabla_vL^T = \nabla_wL^T\left(g\frac{I}{\|v\|}-g\frac{vv^T}{\|v\|^3}\right)\quad \\
= \nabla_wL^T\frac{g}{\|v\|}\left(
I-\frac{vv^T}{\|v\|^2}
\right)\quad
\end{align}$$</span><!-- Has MathJax -->
<span>$$\therefore \quad \nabla_vL=\frac{g}{\|v\|}M_v\nabla_wL \quad\text{where}\ M_v:=I-\frac{vv^T}{\|v\|^2}$$</span><!-- Has MathJax -->
<blockquote>
<p>è«–æ–‡è£¡å¼ (3) çš„ gradient æ¨å°å¯è—‰ç”±å°‡ (1) ä»£é€²åˆ° (2) è£¡å¾—åˆ°.</p>
</blockquote>
<h2 id="nabla-vL-çš„ç‰©ç†æ„ç¾©"><a href="#nabla-vL-çš„ç‰©ç†æ„ç¾©" class="headerlink" title="$\nabla_vL$ çš„ç‰©ç†æ„ç¾©"></a>$\nabla_vL$ çš„ç‰©ç†æ„ç¾©</h2><hr>
<p>æ³¨æ„åˆ°ç”±æ–¼ $v$ è·Ÿ $w$ æ˜¯åŒæ–¹å‘ä½†å¤§å°ä¸åŒè€Œå·². æ‰€ä»¥<br><span>$$M_v=I-\frac{vv^T}{\|v\|^2}=I-\frac{ww^T}{\|w\|^2}=:M_w$$</span><!-- Has MathJax --></p>
<p><span>$$\begin{align}
\therefore \quad 
\nabla_vL=\frac{g}{\|v\|}M_w\nabla_wL \quad\text{where}\ M_w:=I-
\color{orange}{\frac{ww^T}{\|w\|^2}}
\end{align}$$</span><!-- Has MathJax --> è§€å¯Ÿä¸€ä¸‹ $M_w$ è£¡çš„ç¬¬äºŒé … ((4) çš„æ©˜è‰²éƒ¨åˆ†) ä¹˜ä¸Šä¸€å€‹ vector $x$ ä»£è¡¨çš„æ„ç¾©:<br><span>$$\frac{w}{\|w\|}\cdot\frac{w^T}{\|w\|}\cdot x$$</span><!-- Has MathJax --> å…¶ä¸­ <span>$w/\|w\|$</span><!-- Has MathJax --> è¡¨ç¤º $w$ æ–¹å‘çš„ unit vector, è€Œ <span>$w^Tx/\|w\|$</span><!-- Has MathJax --> è¡¨ç¤º $x$ æŠ•å½±åœ¨ $w$ æ–¹å‘ä¸Šçš„é•·åº¦.</p>
<p><img src="/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled.png" width="60%" height="60%"></p>
<p>æ‰€ä»¥ <span>$$M_w\nabla_wL=\nabla_wL-\frac{w}{\|w\|}\cdot\frac{w^T}{\|w\|}\cdot \nabla_wL$$</span><!-- Has MathJax --> <span>$M_w\nabla_wL$</span><!-- Has MathJax --> å°±æ˜¯å°‡ $\nabla_wL$ æ‰£æ‰åœ¨ $w$ æ–¹å‘ä¸Šçš„åˆ†é‡, è€Œ <span>$\nabla_vL$</span><!-- Has MathJax --> åªæ˜¯å†å¤šä¹˜ä¸€å€‹ scalar,<br>ä¹Ÿå°±æ˜¯èªª <span>$\nabla_vL\perp w$</span><!-- Has MathJax -->, i.e. <span>$w^T\nabla_vL=0$</span><!-- Has MathJax --> (åªè¦åˆ©ç”¨ (4) è¨ˆç®—å°±å¯çŸ¥é“)</p>
<h2 id="SGD-æœƒä½¿å¾—-v-é•·åº¦æ„ˆä¾†æ„ˆå¤§"><a href="#SGD-æœƒä½¿å¾—-v-é•·åº¦æ„ˆä¾†æ„ˆå¤§" class="headerlink" title="SGD æœƒä½¿å¾— $v$ é•·åº¦æ„ˆä¾†æ„ˆå¤§"></a>SGD æœƒä½¿å¾— $v$ é•·åº¦æ„ˆä¾†æ„ˆå¤§</h2><hr>
<p>ç”¨ SGD update $v$ çš„æ™‚å€™å…¬å¼ç‚º:<br><span>$$v&apos;=v+\Delta v$$</span><!-- Has MathJax --> ä¸” <span>$\Delta v\propto\nabla_vL$</span><!-- Has MathJax --> by steepest descent.<br>è€Œå› ç‚º <span>$\nabla_vL\perp w$</span><!-- Has MathJax --> æ‰€ä»¥ <span>$\Delta v\perp w$</span><!-- Has MathJax -->. (è¦ update çš„å‘é‡èˆ‡ç›®å‰çš„ weight å‚ç›´)<br>ç”±æœ€é–‹å§‹çš„åˆ†è§£ $(\star)$ æˆ‘å€‘çŸ¥é“ $v$ èˆ‡ weight $w$ åŒæ–¹å‘. æ‰€ä»¥è‡ªç„¶ $\Delta v\perp v$.<br>é€™å°±å°è‡´äº† update å¾Œçš„ $vâ€™$ é•·åº¦æœƒæ¯” $v$ ä¾†å¾—å¤§ (ä¸‰è§’ä¸ç­‰å¼), å¦‚ä¸‹åœ–:</p>
<p><img src="/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled 1.png" width="50%" height="50%"></p>
<p>æ‰€ä»¥ç¶“éå¤šæ¬¡ SGD, $v$ é•·åº¦æœƒæ„ˆä¾†æ„ˆå¤§.</p>
<h2 id="èˆ‡-Batch-Normalization-çš„é—œè¯"><a href="#èˆ‡-Batch-Normalization-çš„é—œè¯" class="headerlink" title="èˆ‡ Batch Normalization çš„é—œè¯"></a>èˆ‡ Batch Normalization çš„é—œè¯</h2><hr>
<p>BN åœ¨éä¸€å±¤ linear weight $v$ å¾Œç‚º:<br><span>$$\begin{align}
v^Tf_{BN}(x)= v^T\left(g\cdot\frac{x-\mu}{\sigma}+b\right)
\end{align}$$</span><!-- Has MathJax --> å…¶ä¸­ $\mu,\sigma$ éƒ½æ˜¯å¾è¨“ç·´æ™‚çš„ mini-batch çµ±è¨ˆçš„, è€Œ $g,b$ æ˜¯ trainable çš„åƒæ•¸<br>è€Œ WN å° weight $w$ ç‚º (ä¸çœ‹ non-linear activation é‚£é …):<br><span>$$f_{WN}(x;w)= w^Tx  = {g\over\|v\|}v^Tx \\
= v^T\left(g\cdot\frac{x}{\|v\|}\right) = v^Tf_{BN}(x)$$</span><!-- Has MathJax --> å°ç…§ BN å¯ä»¥çŸ¥é“è¨­å®š <span>$\sigma=\|v\|,\mu=0,b=0$</span><!-- Has MathJax --> å°±è®Šæˆ WN!<br>ä½† WN çš„å¥½è™•æ˜¯ä¸ä¾è³´ mini-batch çš„è¨­å®š, é€™åœ¨å¦‚æœ batch size è¼ƒå°çš„æƒ…æ³æœƒæ¯”è¼ƒæœ‰åˆ©.</p>
<h2 id="BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰Scale-Invariantç‰¹æ€§"><a href="#BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰Scale-Invariantç‰¹æ€§" class="headerlink" title="BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰Scale Invariantç‰¹æ€§"></a>BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰<strong>Scale Invariant</strong>ç‰¹æ€§</h2><hr>
<p>WN å°æ–¼ $v$ æœƒæ„ˆ update æ„ˆå¤§, è€ƒæ…® BN æ˜¯å¦ä¹Ÿæœ‰é€™æ¨£çš„ç‹€æ³?<br>ä¸€èˆ¬ä¾†èªª, æˆ‘å€‘æœƒé€™éº¼ä¸²: <code>activation(BN(convolution(x)))</code><br>å°‡ BN æ”¾åœ¨ convolution å¾Œ activation ä¹‹å‰, é€™æ¨£å¯ä»¥æœ€å¾Œåšå®Œ quantizaiton çš„æ™‚å€™, convolution å’Œ BN çš„ weight åšèåˆ.<br>ä»¤ $w$ ç•¶ä½œ convolution çš„ weights, å¦‚æœ weights åš $\alpha$ å€çš„ scale: $wâ€™=\alpha w$, å‰‡å° BN å¾Œçš„çµæœä¸æœƒæœ‰å½±éŸ¿, é€™æ˜¯<strong>å› ç‚º $\muâ€™=\alpha\mu$, and $\sigmaâ€™=\alpha\sigma$ ä¹Ÿè·Ÿè‘—ä¸€èµ· scale</strong><br><span>$$f_{BN}(\alpha w^Tx)=f_{BN}(w^Tx)$$</span><!-- Has MathJax --> æ˜ç¢ºå¯«å‡ºä¾†ä¸€å€‹ function $f$ å° input $w$ æ˜¯ scale invariant:<br><span>$$f(\alpha w)=f(w),\quad \forall \alpha\in\mathbb{R}$$</span><!-- Has MathJax --> å¾®ç©åˆ†æˆ‘å€‘å­¸é gradient vector æœƒè·Ÿ coutour çš„ level curve å‚ç›´<br>æŠŠ scale invariant function çš„ â€œç­‰é«˜ç·šâ€ contour map ç•«å‡ºä¾†, ç¤ºæ„åœ–å¤§æ¦‚é€™æ¨£:</p>
<p><img src="/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/Untitled 2.png" width="80%" height="80%"></p>
<p>å¯ä»¥çœ‹åˆ°åš SGD update çš„æ–¹å‘æœƒè·Ÿ contour å‚ç›´, å°è‡´è·Ÿä¹‹å‰è¨è«– WN $v$ æœƒæ„ˆä¾†æ„ˆå¤§çš„ç‹€æ³ä¸€æ¨£, <strong>Convolution çš„ weight $w$ ä¹Ÿæœƒéš¨è‘— SGD update æ„ˆä¾†æ„ˆå¤§</strong>.<br>å› æ­¤æˆ‘å€‘åœ¨ä½¿ç”¨ <code>activation(BN(convolution(x)))</code> é€™æ¨£çš„ layer çš„æ™‚å€™å¯èƒ½æœƒè§€å¯Ÿåˆ°é€™æ¨£çš„ç¾è±¡.<br>åˆ°é€™é‚Šæˆ‘å€‘å¯èƒ½æœƒæ“”å¿ƒ, æœƒä¸æœƒè¨“ç·´ä¸‹å» <span>$\|w\|_2$</span><!-- Has MathJax --> æœƒç™¼æ•£?<br>é€šå¸¸ä¾†èªªä¸ç”¨æ“”å¿ƒ, å› ç‚ºé›¢é›¶é»æ„ˆé å‰‡ gradient æ„ˆå°. é€™æ˜¯å› ç‚º loss surface åªè·Ÿè§’åº¦æœ‰é—œ, é›¢é›¶é»æ„ˆé çš„ loss surface æœƒæ„ˆç¨€ç–ã€å¹³å¦. é€™æ¨£ä¸€ä¾†é›–ç„¶æ¯æ¬¡ update <span>$\|w\|_2$</span><!-- Has MathJax --> éƒ½æœƒè®Šå¤§, ä½†è®Šå¤§çš„å¹…åº¦æ„ˆä¾†æ„ˆå°. é€™ç¯‡ <a href="https://www.inference.vc/exponentially-growing-learning-rate-implications-of-scale-invariance-induced-by-batchnorm/" target="_blank" rel="external">blog æ–‡ç« </a> (by <a href="https://www.inference.vc/" target="_blank" rel="external">inFERENCe</a>) ä¹Ÿæœ‰æè¿°, è£¡é¢çš„åœ–ä¹Ÿè§£é‡‹å¾—å¾ˆå¥½.</p>
<blockquote>
<p>ğŸ’¡ å¦å¤–ä¹Ÿå¯ä»¥ update å®Œ weight å¾Œ, å†æŠŠ convolution çš„ weight ç›´æ¥ normalized, å› ç‚ºåæ­£æ˜¯ scale invariant function, ä¸å½±éŸ¿è¼¸å‡ºçµæœ.</p>
</blockquote>
<h2 id="v-å’Œ-g-çš„åˆå§‹åŒ–"><a href="#v-å’Œ-g-çš„åˆå§‹åŒ–" class="headerlink" title="$v$ å’Œ $g$ çš„åˆå§‹åŒ–"></a>$v$ å’Œ $g$ çš„åˆå§‹åŒ–</h2><hr>
<p>å¯ä»¥åƒè€ƒ <strong><strong><a href="https://zhuanlan.zhihu.com/p/55102378" target="_blank" rel="external">æ¨¡å‹ä¼˜åŒ–ä¹‹Weight Normalization</a></strong></strong> çš„èªªæ˜å°±å¥½.<br>è«–æ–‡æœ‰é¡Œåˆ° WN å°æ–¼ initialization æ¯”è¼ƒæ•æ„Ÿ</p>
<h2 id="Pytorch-çš„-API"><a href="#Pytorch-çš„-API" class="headerlink" title="Pytorch çš„ API"></a>Pytorch çš„ API</h2><hr>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html" target="_blank" rel="external">torch.nn.utils.weight_norm</a><br>æ³¨æ„ weight normalization æ˜¯é€™ç¨®å½¢å¼:<br><span>$$y=\phi(w^Tx+b)$$</span><!-- Has MathJax --> (markdownæ¸²æŸ“æ€ªæ€ªçš„, æ”¹ç”¨åœ–)<br><img src="/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/wn_pytorch.png" width="80%" height="80%"></p>
<p>æ³¨æ„åˆ° conv2d ä¸€æ¬¡çš„â€å…§ç©â€ æ˜¯è™•ç† <code>in_channel * kernel_height * kernel_width</code>, æ‰€ä»¥ä¸€å€‹ $w$ çš„ç¶­åº¦ä¹Ÿæ˜¯å¦‚æ­¤.<br>ç¸½å…±æœ‰ <code>out_channel</code> é€™éº¼å¤šå€‹çš„ â€œå…§ç©â€, ä¹Ÿå°±æ˜¯æœ‰é€™éº¼å¤šçš„ $w$.<br>å¦å¤–, æŠŠ stride or dilation æ”¹å‹•ä¸æœƒå½±éŸ¿ <code>weight_g</code> and <code>weight_v</code> çš„ size</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><hr>
<p>WN ç›´æ¥å°‡åƒæ•¸æ‹†æˆå¤§å°å’Œæ–¹å‘å‘é‡åˆ†åˆ¥ update. å¸Œæœ›è—‰ç”±é€™æ¨£æ‹†è§£èƒ½æ¸›ç·© ill-conditioned ç‹€æ³, ä½¿æ¨¡å‹æ”¶æ–‚é€Ÿåº¦åŠ å¿«. åŒæ™‚ WN ä¹Ÿä¸ä¾è³´ mini-batch, é€™åœ¨ batch size å¦‚æœæ¯”è¼ƒå°çš„æ™‚å€™ä¸æœƒåƒ BN æ•ˆæœè®Šå·®, æˆ–æ˜¯æ¯”è¼ƒé©ç”¨æ–¼ RNN.<br>ä¸éæ‹†æˆé€™æ¨£åƒæ•¸é‡ä¹Ÿæœƒå¢åŠ , ä½†å…¶å¯¦ BN ä¹Ÿéœ€è¦é¡å¤–çš„ memory ä¾†å­˜ $\mu,\sigma$, é€™æ¨£æ¯”å°±è¦çœ‹èª°åˆ’ç®—äº†.<br>å¦å¤–æ¢è¨äº† <code>activation(BN(convolution(x)))</code> æœ‰æ™‚æœƒè§€å¯Ÿåˆ° <strong>Convolution çš„ weight $w$ ä¹Ÿæœƒéš¨è‘— SGD update æ„ˆä¾†æ„ˆå¤§.</strong><br>é€™å€‹ç¾è±¡è·Ÿæœ¬æ–‡ WN è£¡é¢è¨è«–åˆ°æ–¹å‘å‘é‡ $v$ çš„å¤§å°ä¹Ÿæœƒæ„ˆ update æ„ˆå¤§é“ç†æ˜¯å¾ˆåƒçš„.</p>
<p>ä¸éç›®å‰é‡åˆ°çš„å¯¦å‹™ä¸Š, æ¯”è¼ƒå°‘ä½¿ç”¨ WN, å¤§éƒ¨åˆ†é‚„æ˜¯ç”¨ BN, LN (Layer Normalization).<br>æœ‰æ•ˆæ€§æˆ‘è‡ªå·±é‚„è¦å†å¤šè§€å¯Ÿ</p>
<p>æœ€å¾Œé€éçœ‹é€™ç¯‡è«–æ–‡, ä»”ç´°æ¨å°è£¡é¢çš„æ•¸å­¸å’Œç†è§£å…¶ç‰©ç†æ„ç¾©, é€™å°æˆ‘ä¾†èªªé‚„æ˜¯å¾ˆæœ‰å¹«åŠ©çš„.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><hr>
<ol>
<li><a href="https://arxiv.org/abs/1602.07868?context=cs.NE" target="_blank" rel="external">Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33173246" target="_blank" rel="external">è¯¦è§£æ·±åº¦å­¦ä¹ ä¸­çš„Normalizationï¼ŒBN/LN/WN</a></li>
<li><a href="https://www.zhihu.com/question/55132852/answer/171250929" target="_blank" rel="external">Weight Normalization ç›¸æ¯”batch Normalization æœ‰ä»€ä¹ˆä¼˜ç‚¹å‘¢ï¼Ÿ</a></li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html" target="_blank" rel="external">torch.nn.utils.weight_norm</a></li>
<li><a href="https://www.inference.vc/exponentially-growing-learning-rate-implications-of-scale-invariance-induced-by-batchnorm/" target="_blank" rel="external">Exponentially Growing Learning Rate? Implications of Scale Invariance induced by Batch Normalization</a> by <a href="https://www.inference.vc/" target="_blank" rel="external">inFERENCe</a></li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>Post authorï¼š</strong>
      Chih-Sheng Chen
    </li>
    <li class="post-copyright-link">
      <strong>Post linkï¼š</strong>
      <a href="http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/" title="Weight Normalization çš„ç­†è¨˜">http://yoursite.com/2022/09/26/Weight-Normalization-çš„ç­†è¨˜/</a>
    </li>
    <li class="post-copyright-license">
      <strong>Copyright Noticeï¼š </strong>
      All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Weight-Normalization/" rel="tag"># Weight Normalization</a>
          
            <a href="/tags/Batch-Normalization/" rel="tag"># Batch Normalization</a>
          
            <a href="/tags/Scale-Invariant-Function/" rel="tag"># Scale Invariant Function</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/07/20/Why-Stochastic-Weight-Averaging-averaging-results-V-S-averaging-weights/" rel="next" title="Why Stochastic Weight Averaging? averaging results V.S. averaging weights">
                <i class="fa fa-chevron-left"></i> Why Stochastic Weight Averaging? averaging results V.S. averaging weights
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/11/19/ææ‡‚-Quantization-Aware-Training-ä¸­çš„-Fake-Quantization/" rel="prev" title="ææ‡‚ Quantization Aware Training ä¸­çš„ Fake Quantization">
                ææ‡‚ Quantization Aware Training ä¸­çš„ Fake Quantization <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            æ–‡ç« ç›®éŒ„
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            æœ¬ç«™æ¦‚è¦½
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.png"
               alt="Chih-Sheng Chen" />
          <p class="site-author-name" itemprop="name">Chih-Sheng Chen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">81</span>
                <span class="site-state-item-name">æ–‡ç« </span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">åˆ†é¡</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">171</span>
                <span class="site-state-item-name">æ¨™ç±¤</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#å°å¤§å°-g-çš„å¾®åˆ†"><span class="nav-number">1.</span> <span class="nav-text">å°å¤§å° $g$ çš„å¾®åˆ†</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å°æ–¹å‘å‘é‡-v-çš„å¾®åˆ†"><span class="nav-number">2.</span> <span class="nav-text">å°æ–¹å‘å‘é‡ $v$ çš„å¾®åˆ†</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nabla-vL-çš„ç‰©ç†æ„ç¾©"><span class="nav-number">3.</span> <span class="nav-text">$\nabla_vL$ çš„ç‰©ç†æ„ç¾©</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SGD-æœƒä½¿å¾—-v-é•·åº¦æ„ˆä¾†æ„ˆå¤§"><span class="nav-number">4.</span> <span class="nav-text">SGD æœƒä½¿å¾— $v$ é•·åº¦æ„ˆä¾†æ„ˆå¤§</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#èˆ‡-Batch-Normalization-çš„é—œè¯"><span class="nav-number">5.</span> <span class="nav-text">èˆ‡ Batch Normalization çš„é—œè¯</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰Scale-Invariantç‰¹æ€§"><span class="nav-number">6.</span> <span class="nav-text">BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰Scale Invariantç‰¹æ€§</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#v-å’Œ-g-çš„åˆå§‹åŒ–"><span class="nav-number">7.</span> <span class="nav-text">$v$ å’Œ $g$ çš„åˆå§‹åŒ–</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pytorch-çš„-API"><span class="nav-number">8.</span> <span class="nav-text">Pytorch çš„ API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">9.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">10.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chih-Sheng Chen</span>
</div>


<div class="powered-by">
  ç”± <a class="theme-link" href="https://hexo.io">Hexo</a> å¼·åŠ›é©…å‹•
</div>

<div class="theme-info">
  ä¸»é¡Œ -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      [object Object]
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      [object Object]
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  



  




	





  





  





  






  





  

  

  

  

</body>
</html>
