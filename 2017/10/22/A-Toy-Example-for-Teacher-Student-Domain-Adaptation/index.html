<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-tw">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="ML,Deep Learning,Adaptation," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="看了這篇 2017 Microsoft AI and Research 的文章 “Large-Scale Domain Adaptation via Teacher-Student Learning“ 覺得滿有意思的，加上很容易實作，因此就分析一下這篇的可行性。
設計了一個 MNIST Toy Example 來展示 T/S Learning 的能力，自己也想知道這個方法有多可靠。相關的實">
<meta property="og:type" content="article">
<meta property="og:title" content="A Toy Example for Teacher Student Domain Adaptation">
<meta property="og:url" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/index.html">
<meta property="og:site_name" content="棒棒生">
<meta property="og:description" content="看了這篇 2017 Microsoft AI and Research 的文章 “Large-Scale Domain Adaptation via Teacher-Student Learning“ 覺得滿有意思的，加上很容易實作，因此就分析一下這篇的可行性。
設計了一個 MNIST Toy Example 來展示 T/S Learning 的能力，自己也想知道這個方法有多可靠。相關的實">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/cover.png">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/TS-paper-fig1.png">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/TS-paper-algo.png">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/flip69_4.png">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/flip69_2.png">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/what-ts-learn.png">
<meta property="og:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/modified-s-model.png">
<meta property="og:updated_time" content="2017-10-23T14:08:46.868Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Toy Example for Teacher Student Domain Adaptation">
<meta name="twitter:description" content="看了這篇 2017 Microsoft AI and Research 的文章 “Large-Scale Domain Adaptation via Teacher-Student Learning“ 覺得滿有意思的，加上很容易實作，因此就分析一下這篇的可行性。
設計了一個 MNIST Toy Example 來展示 T/S Learning 的能力，自己也想知道這個方法有多可靠。相關的實">
<meta name="twitter:image" content="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/cover.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/"/>





  <title> A Toy Example for Teacher Student Domain Adaptation | 棒棒生 </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">棒棒生</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">讓學習變成一種習慣</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首頁
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分類
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            關於
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            歸檔
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            標籤
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chih-Sheng Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="棒棒生">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                A Toy Example for Teacher Student Domain Adaptation
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2017-10-22T10:19:54+08:00">
                2017-10-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>[object Object]
            </span>
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<hr>
<p>看了這篇 2017 Microsoft AI and Research 的文章 “<a href="https://www.researchgate.net/publication/319186662_Large-Scale_Domain_Adaptation_via_Teacher-Student_Learninghttps://www.researchgate.net/publication/319186662_Large-Scale_Domain_Adaptation_via_Teacher-Student_Learning" target="_blank" rel="external">Large-Scale Domain Adaptation via Teacher-Student Learning</a>“ 覺得滿有意思的，加上很容易實作，因此就分析一下這篇的可行性。</p>
<p>設計了一個 MNIST Toy Example 來展示 T/S Learning 的能力，自己也想知道這個方法有多可靠。相關的實驗 code 請參考 <a href="https://github.com/bobondemon/TS-Learning-Toy-Example" target="_blank" rel="external">github</a></p>
<p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/cover.png" width="60%" height="60%"></p>
<a id="more"></a>
<hr>
<h3 id="TS-Learning-Methods"><a href="#TS-Learning-Methods" class="headerlink" title="TS Learning Methods"></a>TS Learning Methods</h3><p>介紹一下 TS Learning 的方法。他要解決的問題描述如下</p>
<blockquote>
<p>假設我們已經有了一個訓練好的語音辨識模型，現在要辨識<strong>遠場</strong>的聲音，原 Domain (近場錄製的聲音)，可能效果就會不好。<br>要解決最直接的方法就是重新錄製遠場語料，錄製的過程中很容易可以取得同時有近場和遠場未標記的語料 (放兩個麥克風，一個近一個遠)，不過關鍵是標記成本太高。因此這篇就是想利用<strong>未標記的語料直接針對原 Domain 的模型 Adapt 到新的 Domain 上</strong>。</p>
</blockquote>
<p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/TS-paper-fig1.png" width="60%" height="60%"></p>
<p>以上面論文中的圖來說，左邊 Teacher network 只能在 Source Domain 有好的辨識能力，目標是希望得到右邊的 Student network 能在 Target Domain 針對同樣問題也有好的辨識能力。論文方法是一開始先將 Teacher network 拷貝一份給 Student network ，接著就開始餵 parallel data 給兩個 networks。</p>
<p>所謂 parallel data 意思是相同的資料來源，但是在不同 domain 蒐集，例如同一個人講同一句話，一個近場麥克風蒐集到，另一個遠場蒐集到。目標函式就是希望兩個 network 的後驗概率相同 (兩者的後驗概率平方誤差為0)，而我們只更新 Student network。在實作上不會使用後驗概率來計算兩個 network 的誤差，會使用未經過 softmax 的那層，也就是一般說的 logits 來計算。原因簡單說明如下:</p>
<blockquote>
<p>softmax 會將同樣是 negative 的類別的機率都壓到很低，但是 <strong>negative examples 也有分好壞</strong>，讀者可以試試 [10,2,1] 經過 softmax 後， 2 跟 1 之間的差異會被抹平。<br>因此好的做法是，不要使用 softmax ，而是使用 logits。 Hinton 在這篇<a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="external">論文</a>裡修改了 softmax 函式，多了一個 temperature $T$，論文裡推導這樣修改的 softmax，其實跟目標函式使用 logits 的平方誤差是一樣的 (在 <em>“T跟logits差異很大”</em> 且 <em>“logits的分布均值為0”</em> 的條件下)</p>
</blockquote>
<p>這樣做的物理意義就相當於，<strong>將 “某聲音的遠場表現在 Student network 眼裡”，視為跟 “該聲音的近場表現在 Teacher network 眼裡” 認定為相同一件事情。</strong>因此就不需要針對 data 做標記了，只需要拿到這樣的一大堆 parallel data 就可以，而這很容易。</p>
<p>附上論文上的步驟如下:</p>
<p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/TS-paper-algo.png" width="60%" height="60%"></p>
<p>演算法就這樣而已，很單純吧。但是究竟有多靠普? 好奇心下，就用 MNIST 設計了 toy example，就是接下來的內容囉。</p>
<hr>
<h3 id="MNIST-Toy-Example-for-TS-Learning"><a href="#MNIST-Toy-Example-for-TS-Learning" class="headerlink" title="MNIST Toy Example for TS Learning"></a>MNIST Toy Example for TS Learning</h3><h4 id="實驗設定-and-Teacher-Network"><a href="#實驗設定-and-Teacher-Network" class="headerlink" title="實驗設定 and Teacher Network"></a>實驗設定 and Teacher Network</h4><p>首先設定兩個 Domain 為: 一個原圖 (原世界)，另一個上下顛倒的圖 (上下顛倒的世界)。</p>
<p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/flip69_4.png" width="40%" height="40%"></p>
<p>Teacher network 是一個很簡單的 “6” 和 “9” 的辨識器，當然是在原世界訓練好的。如果直接拿 teacher network 去看顛倒的 6，期望它認出一樣是 6 是辨識不出來的! (同樣期望 teacher network 看出顛倒的 9 仍然是 9 也是辦不到的)</p>
<p>之所以會選 6 和 9，是因為就算上下顛倒，顛倒的 6 和正向的 9 看起來仍然是不同的! 同樣的，顛倒的 9 和正向的 6 一樣看起來不同 !</p>
<p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/flip69_2.png" width="60%" height="60%"></p>
<p>我們得到的 Teacher network 辨識情況如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Training...</div><div class="line"></div><div class="line">EPOCH <span class="number">1</span> ...</div><div class="line">Train Accuracy = <span class="number">0.967</span>; Flip Accuracy = <span class="number">0.098</span></div><div class="line"></div><div class="line">EPOCH <span class="number">2</span> ...</div><div class="line">Train Accuracy = <span class="number">0.999</span>; Flip Accuracy = <span class="number">0.151</span></div><div class="line"></div><div class="line">EPOCH <span class="number">3</span> ...</div><div class="line">Train Accuracy = <span class="number">0.999</span>; Flip Accuracy = <span class="number">0.110</span></div></pre></td></tr></table></figure>
<p>明顯看到辨識率接近 100%，但是一旦上下顛倒，辨識率只剩 10%。有意思的是，由於我們只有兩個類別，對於上下顛倒的辨識率剩10%可以看做: <strong>顛倒的 6，會被認成 9，而顛倒的 9 會被認為 6</strong>。但事實上，顛倒的 6 和 9 還是不一樣。</p>
<h4 id="Student-network-訓練"><a href="#Student-network-訓練" class="headerlink" title="Student network 訓練"></a>Student network 訓練</h4><p>我們將 MNIST 其他影像上下顛倒，做出 parallel dataset，然後按照論文的做法做 unsupervised training。有趣的是得到結果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">EPOCH <span class="number">1</span> ...</div><div class="line">Acc loss = <span class="number">3.871242271944786</span></div><div class="line">Train Accuracy = <span class="number">0.156</span>; Flip Accuracy = <span class="number">0.998</span></div><div class="line"></div><div class="line">EPOCH <span class="number">2</span> ...</div><div class="line">Acc loss = <span class="number">0.40557907682784994</span></div><div class="line">Train Accuracy = <span class="number">0.101</span>; Flip Accuracy = <span class="number">0.999</span></div><div class="line"></div><div class="line">EPOCH <span class="number">3</span> ...</div><div class="line">Acc loss = <span class="number">0.3005437100890939</span></div><div class="line">Train Accuracy = <span class="number">0.103</span>; Flip Accuracy = <span class="number">0.999</span></div><div class="line"></div><div class="line">EPOCH <span class="number">4</span> ...</div><div class="line">Acc loss = <span class="number">0.2651689475203995</span></div><div class="line">Train Accuracy = <span class="number">0.097</span>; Flip Accuracy = <span class="number">0.999</span></div><div class="line"></div><div class="line">EPOCH <span class="number">5</span> ...</div><div class="line">Acc loss = <span class="number">0.23342516055794454</span></div><div class="line">Train Accuracy = <span class="number">0.116</span>; Flip Accuracy = <span class="number">0.999</span></div></pre></td></tr></table></figure>
<p>Student network 可以成功辨識 <strong>顛倒的 6 和顛倒的 9 了!</strong> 注意，我們從來沒有給過 Student network 顛倒的 6 和顛倒的 9 這些訓練資料! 但是現在它有能力辨識這兩種圖了!</p>
<p>但是同樣的，如果給 student network 看一個正向的 6，在他的眼哩，看起來就如同 teacher network 看到 9 一樣。</p>
<p><strong>也就是說，Student network 失去了原 Domain 的辨識能力。</strong> 這與論文原作者的結論不大一樣。</p>
<h4 id="用-parallel-data-非監督學習到底學到了什麼"><a href="#用-parallel-data-非監督學習到底學到了什麼" class="headerlink" title="用 parallel data 非監督學習到底學到了什麼?"></a>用 parallel data 非監督學習到底學到了什麼?</h4><p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/what-ts-learn.png" width="60%" height="60%"></p>
<p>給 T/S 網路看過很多很多的 parallel data 後，Teacher 眼裡的圖，在 Student 眼裡看起來就反過來，反之亦然。因此這時候如果給 Student network 看一個 “正向的6”，它會認為: 啊!這在 Teacher 眼裡看到的是一個顛倒的 6 。(而 teacher network 會將顛倒的 6 看做是 9)</p>
<p>因此我認為，Student netowrk 很容易失去原先 domain 的辨識能力，就像這個例子 student network 無法認出正向的 6 一樣。</p>
<hr>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>如何讓一個 network 同時有原 Domain 和新 Domain 的辨識能力呢 ? 以上面的 toy example 為例，就是辨識兩個 classes</p>
<p>class 1: 6 and 顛倒的6<br>class 2: 9 and 顛倒的9</p>
<p>最直覺的做法，就是 T and S models 都跑一次辨識，然後將兩個後驗概率加起來後算 argmax。缺點就是 model size 立馬變成兩倍。</p>
<p>怎麼讓模型 size 不要變成兩倍呢? 簡單想了一個方式，就是讓 student model 改成這樣的模型:</p>
<p><img src="/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/modified-s-model.png" width="40%" height="40%"></p>
<p>其中 M model 的部分負責將 上下顛倒的 domain 轉換成原 domain 的 input，然後這樣的 input 就可以原封不動地用 teacher model 去辨識。剛好這個問題其實用一個 permuation matrix 可以做上下顛倒，因此實驗上就直接使用一個 linear layer (沒有 activation function)，當然 backprob 算出來的不會正好是 permutation matrix 就是了。</p>
<p>收斂情況如下: 基本上比原先要慢，因為原來是所有的 weights 都可以調整，而現在只能動一個 linear layer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">EPOCH <span class="number">1</span> ...</div><div class="line">Acc loss = <span class="number">9.52696829760659</span></div><div class="line">Train Accuracy = <span class="number">0.460</span>; Flip Accuracy = <span class="number">0.806</span></div><div class="line"></div><div class="line">EPOCH <span class="number">2</span> ...</div><div class="line">Acc loss = <span class="number">3.6580730849143146</span></div><div class="line">Train Accuracy = <span class="number">0.364</span>; Flip Accuracy = <span class="number">0.955</span></div><div class="line"></div><div class="line">EPOCH <span class="number">3</span> ...</div><div class="line">Acc loss = <span class="number">2.454553008463332</span></div><div class="line">Train Accuracy = <span class="number">0.304</span>; Flip Accuracy = <span class="number">0.980</span></div><div class="line"></div><div class="line">EPOCH <span class="number">4</span> ...</div><div class="line">Acc loss = <span class="number">1.823352760733923</span></div><div class="line">Train Accuracy = <span class="number">0.277</span>; Flip Accuracy = <span class="number">0.988</span></div><div class="line"></div><div class="line">EPOCH <span class="number">5</span> ...</div><div class="line">Acc loss = <span class="number">1.4707165408316494</span></div><div class="line">Train Accuracy = <span class="number">0.235</span>; Flip Accuracy = <span class="number">0.992</span></div></pre></td></tr></table></figure>
<p>這樣做法雖然 model size 小了很多，但是要同時辨識正的和顛倒的仍然要跑兩遍的 model。</p>
<p>有沒有方法結合 TS learning unsupervised 的方式，且同時兼顧兩邊的 domain 辨識能力呢? 就再思考看看囉。</p>
<hr>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a href="https://arxiv.org/abs/1708.05466" target="_blank" rel="external">Large-Scale Domain Adaptation via Teacher-Student Learning</a></li>
<li><a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="external">Distilling the Knowledge in a Neural Network</a></li>
<li><a href="https://github.com/bobondemon/TS-Learning-Toy-Example" target="_blank" rel="external">Toy Example github</a></li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>Post author：</strong>
      Chih-Sheng Chen
    </li>
    <li class="post-copyright-link">
      <strong>Post link：</strong>
      <a href="https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/" title="A Toy Example for Teacher Student Domain Adaptation">https://bobondemon.github.io/2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/</a>
    </li>
    <li class="post-copyright-license">
      <strong>Copyright Notice： </strong>
      All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ML/" rel="tag"># ML</a>
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/Adaptation/" rel="tag"># Adaptation</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/09/07/Word-Embeddings-and-Encoder-Decoder-Neural-Net/" rel="next" title="Word Embeddings (Encoder-Decoder 架構)">
                <i class="fa fa-chevron-left"></i> Word Embeddings (Encoder-Decoder 架構)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/01/TF-Notes-Speedup-and-Benchmark-with-Two-GPU-Cards/" rel="prev" title="TF Notes (2), Speedup and Benchmark with Two GPU Cards">
                TF Notes (2), Speedup and Benchmark with Two GPU Cards <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目錄
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            本站概覽
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.png"
               alt="Chih-Sheng Chen" />
          <p class="site-author-name" itemprop="name">Chih-Sheng Chen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">101</span>
                <span class="site-state-item-name">文章</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分類</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">216</span>
                <span class="site-state-item-name">標籤</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#TS-Learning-Methods"><span class="nav-number">1.</span> <span class="nav-text">TS Learning Methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MNIST-Toy-Example-for-TS-Learning"><span class="nav-number">2.</span> <span class="nav-text">MNIST Toy Example for TS Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#實驗設定-and-Teacher-Network"><span class="nav-number">2.1.</span> <span class="nav-text">實驗設定 and Teacher Network</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Student-network-訓練"><span class="nav-number">2.2.</span> <span class="nav-text">Student network 訓練</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#用-parallel-data-非監督學習到底學到了什麼"><span class="nav-number">2.3.</span> <span class="nav-text">用 parallel data 非監督學習到底學到了什麼?</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summary"><span class="nav-number">3.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chih-Sheng Chen</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 強力驅動
</div>

<div class="theme-info">
  主題 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      [object Object]
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      [object Object]
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  



  




	





  





  





  






  





  

  

  

  

</body>
</html>
