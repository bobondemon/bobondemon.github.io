[{"title":"Introduction of Probably Approximately Correct (PAC) æ—è»’ç”°èª²ç¨‹ç­†è¨˜","date":"2024-03-19T11:55:05.000Z","path":"2024/03/19/Introduction-of-Probably-Approximately-Correct-PAC-æ—è»’ç”°èª²ç¨‹ç­†è¨˜/","text":"é€™æ˜¯æ—è»’ç”°æ•™æˆåœ¨ Coursera æ©Ÿå™¨å­¸ç¿’åŸºçŸ³ä¸Š (Machine Learning Foundations)â€”Mathematical Foundations Week4 çš„èª²ç¨‹ç­†è¨˜.èªªæ˜äº†ç‚ºä»€éº¼æˆ‘å€‘ç”¨ training data å­¸å‡ºä¾†çš„ model å¯ä»¥å°æ²’çœ‹éçš„ data æœ‰æ³›åŒ–èƒ½åŠ›, å› æ­¤æ©Ÿå™¨å­¸ç¿’æ‰æœ‰å¯èƒ½çœŸæ­£æ‡‰ç”¨ä¸Š.èª²ç¨‹å–®å…ƒçš„é€™å¥è©±ç¸½çµå¾—å¾ˆå¥½ â€œlearning can be probably approximately correct when given enough statistical data and finite number of hypothesesâ€ä»¥ä¸‹ç‚ºç­†è¨˜å…§å®¹ æ€éº¼èªªéƒ½ä½ å°, training data å¤–çš„ predition$\\mathcal{D}$ is training data, learning algorithm æ‰¾åˆ°çš„ function $g$ å° $\\mathcal{D}$ å®Œç¾çš„ predict, ä½† training data å¤–çš„è³‡æ–™ä¹Ÿèƒ½ä¿è­‰å¾ˆå¥½å—? æ‰€ä»¥å° training data $\\mathcal{D}$ æ‰¾ hypothesis æ²’å•é¡Œå—??ç”± Probably Approximately Correct (PAC) å‡ºç™¼, å‘Šè¨´æˆ‘å€‘ç•¶ data é‡å¤ å¤§çš„æ™‚å€™æ˜¯æ²’å•é¡Œçš„. å¤§æ¦‚å·®ä¸å¤šæ­£ç¢º Probably Approximately Correct (PAC)Hoeffdingâ€™s Inequalityè«‹çœ‹æŠ•å½±ç‰‡ $\\mathbb{P}[|\\nu-\\mu|&gt;\\epsilon]$ æƒ³æˆå£äº‹ç™¼ç”Ÿçš„æ©Ÿç‡. æ‰€ä»¥å‘Šè¨´æˆ‘å€‘, å£äº‹ç™¼ç”Ÿçš„æ©Ÿç‡æœ‰å€‹ upper bound. å°±æ˜¯ç•¶ $N$ å¤ å¤§, å£äº‹ç™¼ç”Ÿçš„æ©Ÿç‡å°±å¾ˆå°. Wiki: Hoeffdingâ€™s inequalityLet $X_1,â€¦,X_N$ be independent r.v.s such that $a_i\\leq X_i\\leq b_i$ almost surely. Consider $S_N=X_1+â€¦+X_N$. Then for all $t&gt;0$,$$\\begin{align} P(S_N-\\mathbb{E}[S_N]\\geq t)\\leq \\exp\\left( -\\frac{2t^2}{\\sum_{i=1}^N(b_i-a_i)^2}\\right) \\\\ P(|S_N-\\mathbb{E}[S_N]|\\geq t)\\leq 2\\exp\\left( -\\frac{2t^2}{\\sum_{i=1}^N(b_i-a_i)^2}\\right) \\end{align}$$ ä»¥è€å¸«çš„æŠ•å½±ç‰‡ä¾†èªª, random variable $X_i$ è¡¨ç¤ºæ˜¯ä¸æ˜¯æ©˜çƒ, æ˜¯çš„è©±å°±æ˜¯ $1$, ä¸æ˜¯å°±æ˜¯ $0$. æ‰€ä»¥ $0\\leq X_i \\leq 1$.å› æ­¤ $S_N=X_1+â€¦+X_N$ å°±è¡¨ç¤º $N$ å€‹çƒä¸­æ˜¯æ©˜çƒçš„æ•¸é‡çš„ random variable. ç„¶å¾Œå¸¶å…¥ wiki çš„å…¬å¼å°±å¯ä»¥è·Ÿè€å¸«çš„æŠ•å½±ç‰‡çµæœå°ç…§èµ·ä¾†. æ³¨æ„ wiki ä½¿ç”¨ $S_N$, ä½†æŠ•å½±ç‰‡ç”¨çš„æ˜¯ $\\nu=S_N/N, \\mu=\\mathbb{E}[S_N]/N$. æ‰€ä»¥ $t=N\\epsilon$. æ‰€ä»¥å° training data $\\mathcal{D}$ ä¸é Hoeffdingâ€™s inequality å®ƒçš„ bound ä¸æ˜¯å¾ˆ tight. Connection to Learningä¸Šé¢ç½å­æŠ½å½ˆç çš„ä¾‹å­, å…¶å¯¦è·Ÿ ML è¦æ€éº¼ç¢ºèªæ‰¾åˆ°çš„ $h$ æ˜¯ä¸æ˜¯è·Ÿ oracle $f$ å¤ åƒæ˜¯åŒä¸€å€‹å•é¡Œ æŠŠæ•´å€‹ $\\mathcal{X}$ ç•¶æˆæ˜¯æ•´å€‹ç½å­çš„å½ˆç , è€Œ training dataset $\\mathcal{D}$ æ˜¯æŠ½æ¨£å‡ºä¾†çš„ $N$-sample.å°æŸä¸€å€‹ $x\\in\\mathcal{X}$, $h(x)\\neq f(x)$ å°±æ˜¯æ©˜è‰²å½ˆç , å¦å‰‡å°±æ˜¯ç¶ è‰²å½ˆç . å‰‡ $\\mu$ å°±æ˜¯ $\\mathbb{E}{out}$, $\\nu$ å°±æ˜¯ $\\mathbb{E}{in}$.æ‰€ä»¥åŸä¾†å£äº‹ç™¼ç”Ÿçš„æ©Ÿç‡ $\\mathbb{P}[|\\nu-\\mu|&gt;\\epsilon]$ åœ¨é€™è£¡è®Šæˆ $\\mathbb{P}[|\\mathbb{E}_{in}-\\mathbb{E}_{out}|&gt;\\epsilon]$ (inside-test å’Œ outside-test çš„éŒ¯èª¤ç‡å·®å¤ªå¤šçš„æ©Ÿç‡)å‰‡æ ¹æ“š Hoeffdingâ€™s Inequality, å°æŸä¸€å›ºå®šçš„ hypothesis $h$ åœ¨ training data ä¸Šçš„è¡¨ç¾å’Œ out-of-sample çš„ data è¡¨ç¾å¤§æ¦‚æ¥è¿‘.$$\\mathbb{P}\\left[|E_{in}(h)-E_{out}(h)|&gt;\\epsilon\\right]\\leq 2\\exp\\left(-2\\epsilon^2N\\right)$$ ä¸Šåœ–ä¸­, å…ˆä¸çœ‹ learning algorithm $\\mathcal{A}$ ä»¥åŠå®ƒæŒ‘å‡ºä¾†çš„ final hypothesis $g$ é‚£å…©å¡Š.æ³¨æ„åˆ°, ç›®å‰æ‰€èªªçš„æ˜¯æŒ‡å·²ç¶“å›ºå®šä¸€å€‹ $h$ äº†, ç„¶å¾Œæˆ‘å€‘å¯ä»¥ç”¨ unknown probability $P$ æ¡æ¨£å‡ºä¾†çš„ set $\\mathcal{X}$ å¾—åˆ° $\\mathbb{E}_{in}\\approx\\mathbb{E}_{out}$. æ„æ€å°±æ˜¯é€™å€‹ $h$ ä¸èƒ½é‡å° $\\mathbb{E}_{in}$ å»å­¸ç¿’æ‰¾å‡ºä¾†.å†ç™½è©±ä¸€é» â€œå›ºå®šä¸€å€‹ $h$â€ æ„æ€æ˜¯ç½å­è£¡å½ˆç çš„é¡è‰²å·²ç¶“å…ˆå›ºå®šäº†! Hoeffdingâ€™s åªæ˜¯å‘Šè¨´æˆ‘å€‘æŠ½æ¨£çš„è³‡æ–™ (size $N$ çš„å½ˆç , set $\\mathcal{D}$) æŸ¥çœ‹åˆ°çš„éŒ¯èª¤ç‡è·Ÿæ•´å€‹ç½å­çš„éŒ¯èª¤ç‡æœƒå¾ˆæ¥è¿‘. æ‰€ä»¥ç•¶ç„¶ä¸èƒ½é‡å°æŠ½å‡ºä¾†çš„è³‡æ–™å†ä¾†æŒ‘é¸ $h$, é€™æ¨£ç­‰æ–¼äº‹å¾Œæ”¹è®Šå½ˆç é¡è‰². ä¹Ÿå°±æ˜¯èªªé€™æ™‚å€™çš„ $\\mathbb{E}_{in}(g)$ æŒ‡çš„æ˜¯ç”¨ verification data ä¾†çœ‹ error, æˆ–è¨±å« $\\mathbb{E}_{ver}$ æ¯”è¼ƒå¥½. è€ŒçœŸæ­£çš„ training data çµ¦ learning algorithm $\\mathcal{A}$ ç”¨ä¾†æŒ‘ $g$.é€™å°±æ˜¯ Verification dataset åœ¨åšçš„äº‹æƒ…. ğŸ’¡ ä¸‹ä¸€æ®µæ‰€è¬›çš„ $\\mathbb{E}_{in}$ å…¶å¯¦æŒ‡çš„æ˜¯ $\\mathbb{E}_{ver}$, training data $\\mathcal{D}$ å…¶å¯¦æ˜¯ verification data Connection to Real Learningä¸€å€‹å›ºå®šçš„ hypothesis $h$ æœƒå°æ‡‰åˆ°ä¸€ç¨®å½ˆç é¡è‰²åˆ†å¸ƒæƒ…å½¢, æ©˜è‰²ä»£è¡¨å®ƒè·Ÿ oracle $f$ ä¸ä¸€æ¨£çš„ input $x$.Hoeffding å‘Šè¨´æˆ‘å€‘, å°é€™ä¸€å€‹ $h$ æˆ‘å€‘çœ‹ $\\mathbb{E}_{in}(h)$ å¤§æ¦‚å·®ä¸å¤šç­‰æ–¼ $\\mathbb{E}_{out}(h)$. æ›å¥è©±èªª BAD çš„æ©Ÿç‡å¾ˆå°, æ‰€ä»¥æˆ‘å€‘å¯ä»¥ç›¸ä¿¡ $\\mathbb{E}_{in}(h)$ çš„è©•ä¼°çµæœ. $$\\mathbb{P}_{\\mathcal{D}}[{\\color{orange}{\\text{BAD }}} \\mathcal{D}] = \\sum_{D\\in\\mathcal{D}}{\\mathbb{P}(D)\\cdot 1[D \\text{ is}{\\color{orange}{\\text{ BAD}}}]}$$ Hypothesis set $\\mathcal{H}$ é€šå¸¸æœƒæœ‰ç„¡çª®å¤šå€‹ hypothesis, æˆ‘å€‘å…ˆå‡è¨­å®ƒåªæœ‰ $M$ å€‹å°±å¥½. ç„¡çª®å¤šçš„ case ä¹‹å¾Œèª²ç¨‹æœƒä»‹ç´¹. çµæœå° sampling å‡ºä¾†çš„ data (training data), æˆ‘å€‘ç™¼ç¾å…¶ä¸­æœ‰ä¸€å€‹ hypothesis è¡¨ç¾å…¨å°, æˆ‘å€‘å¯ä»¥é¸å®ƒå—? ç•¶ç„¶ä¸èƒ½. é‚£ä¸èƒ½çš„è©±, learning algorithm $\\mathcal{A}$ æ ¹æ“š training data (é€™è£¡å…¶å¯¦æŒ‡çš„æ˜¯ verification data) æŒ‘æœ€å¥½çš„ $\\mathbb{E}_{in}$ ä¸å°±æ²’æ„ç¾©äº†? åˆ¥ç·Šå¼µ, æˆ‘å€‘å…ˆçœ‹ä¸€ä¸‹æ‰€æœ‰ hypothesis å°æ‡‰ training data çš„è¡¨: é—œéµåœ¨ column, å› ç‚º learning algorithm $\\mathcal{A}$, å°æŸä¸€ sampling å‡ºä¾†çš„ training data $\\mathcal{D}_i$ (é€™è£¡å…¶å¯¦æŒ‡çš„æ˜¯ verification data) æœƒæŒ‘ä¸€å€‹ error æœ€å°çš„ hypothesis. ä½†æœƒæŒ‘åˆ°å“ªä¸€å€‹ä¸çŸ¥é“ (å› ç‚º $\\mathcal{A}$ æ˜¯ç”¨çœŸæ­£çš„ training data æŒ‘çš„, ä¸æ˜¯ç”¨ $\\mathcal{D}_i$ æŒ‘çš„, åˆ¥å¿˜äº† $\\mathcal{D}_i$ æ˜¯ verification data), æ‰€ä»¥ä»»ä½•çš„ $h_i$ éƒ½æœ‰å¯èƒ½è¢« $\\mathcal{A}$ æŒ‘åˆ°.æ‰€ä»¥åªè¦ column ä¸­æœ‰æŸä¸€å€‹ hypothesis æ˜¯ BAD çš„è©±, learning algorithm å°±å¤±å»ä½œç”¨äº†. å°æ–¼ all æœ€å¾Œé‚£å€‹ row ä¾†èªª, åªè¦æœ‰ä¸€å€‹ hypothesis æ˜¯ BAD, all å°±ç®— BAD. å¦‚åŒ PAC ä¸€æ¨£, æˆ‘å€‘å¸Œæœ›æœ€å¾Œä¸€å€‹ row BAD çš„æ©Ÿç‡è¶Šä½æ„ˆå¥½.è©•ä¼°ä¸€ä¸‹é€™æ¨£æƒ…æ³ä¸‹, ç™¼ç”Ÿ BAD çš„æ©Ÿç‡: $$\\mathbb{P}_{\\mathcal{D}}[{\\color{orange}{\\text{BAD }}} \\mathcal{D}] = 2{\\color{orange}{M}}\\exp\\left(-2\\epsilon^2N\\right)$$ æ‰€ä»¥å…¶å¯¦é‚„æ˜¯æœ‰ upper bound, æ›å¥è©±èªª, learening algorithm æŒ‘å‡ºä¾†çš„ $g$ ä»ç„¶æ»¿è¶³ PAC!","tags":[{"name":"Probably Approximately Correct (PAC)","slug":"Probably-Approximately-Correct-PAC","permalink":"https://bobondemon.github.io/tags/Probably-Approximately-Correct-PAC/"}]},{"title":"é‡åŒ–æŠ€è¡“è·¯ç·š","date":"2024-02-17T12:41:45.000Z","path":"2024/02/17/é‡åŒ–æŠ€è¡“è·¯ç·š/","text":"ç¸½çµä¸€ä¸‹ (up to 2024-02-17) ç›®å‰å­¸ç¿’çš„é‡åŒ–æŠ€è¡“å’Œæµç¨‹åœ–, åŒæ™‚ä¹Ÿè¨˜éŒ„åœ¨ github è£¡. Post Training Quantization (PTQ) ç¨±äº‹å¾Œé‡åŒ–. Quantization Aware Training (QAT) è¡¨ç¤ºè¨“ç·´æ™‚è€ƒæ…®é‡åŒ–é€ æˆçš„æå¤±ä¾†åšè¨“ç·´ç‚ºäº†å¾—åˆ° fixed point model å¯ä»¥å°äº‹å…ˆè¨“ç·´å¥½çš„ float model åš PTQ æˆ– QAT, æˆ–æ˜¯ç›´æ¥å¾ QAT æµç¨‹é–‹å§‹åŒæ™‚ QAT ä¹Ÿå¯ä»¥ç”¨ PTQ ä¾†åˆå§‹åŒ–è¨“ç·´. å¦‚æœè¦å¾ float model é–‹å§‹åšé‡åŒ–çš„è©±, å¯ä»¥è€ƒæ…®åœ¨è¨“ç·´ float model æ™‚å°±å°ä¹‹å¾Œé‡åŒ–èƒ½æ›´åŠ å‹å–„çš„æŠ€è¡“ (å¦‚ R^2, KURE, PACT) æ¥è‘—å°æ¯å€‹æŠ€è¡“é»ç›¡é‡ä»¥æœ€ç°¡å–®çš„æ–¹å¼è§£èªª. å¦‚æœå°é‡åŒ–é‚„ä¸æ˜¯é‚£éº¼ç†Ÿæ‚‰, å»ºè­°åƒè€ƒä¸€ä¸‹æ–‡ç« å¾ŒåŠæ®µçš„â€ç°¡å–®å›é¡§é‡åŒ–â€ é‡åŒ–æŠ€è¡“å’Œæµç¨‹ Floating Model Trainingé€™éšæ®µä¸»è¦æ˜¯è®“è¨“ç·´å‡ºä¾†çš„ floating model æœ‰åˆ©æ–¼ä¹‹å¾Œé‡åŒ–çš„æŠ€è¡“ R^2 [paper]: èªç‚º outliers æ„ˆå°‘, æ„ˆæœ‰åˆ©æ–¼å¾Œé¢çš„é‡åŒ–æˆ–å£“ç¸®. æå‡ºäº† 3 ç¨® regularization losses. KURE [paper]: ä½¿ç”¨ 4th moments Kurtosis (KURE, KUrtosis REgularization) ä¾†ç•¶ regularization è®“åˆ†ä½ˆæ¥è¿‘ uniform, åŒæ¨£æœƒæœ‰åˆ©æ–¼å¾Œé¢çš„é‡åŒ–. PACT [paper]: ä½¿å¾— $l,u$ é€™å…©å€‹ clipping ä¸Šä¸‹ç•Œèƒ½è¢«å­¸ç¿’, é™åˆ¶æ•¸å€¼ç¯„åœ PTQPTQ æ˜¯é‡å° float model åšé‡åŒ–çš„æŠ€è¡“, ä¸éœ€è¦ training data, é€šå¸¸åªéœ€è¦äº›è¨±çš„ calibration data å³å¯, æœ‰äº›æŠ€è¡“ä»æœƒéœ€è¦ç®— gradients, è€Œæœ‰äº›ä¸ç”¨, ç”šè‡³é€£ calibration data éƒ½ä¸ç”¨.ä¸€èˆ¬ä¾†èªª PTQ æ•ˆæœæœƒæ¯” QAT å·®, ä½†é€Ÿåº¦æ¯” QAT å¿«å¤šäº†, åŒæ™‚é‡å° LLM é€™ç¨®å¤§æ¨¡å‹ QAT æˆæœ¬å¤ªé«˜éƒ½åªèƒ½ä½¿ç”¨ PTQ. CLE, Bias Absorption, Bias Correction [paper]: Qaulcomm DFQ (Data Free Quantization æŠ€è¡“), è©³è¦‹ [blog] AdaRound [paper]: weight é‡åŒ–æ™‚ (å¼ (1)) çš„ rounding (å››æ¨äº”å…¥) ä¸ä¸€å®šæ˜¯æœ€ä½³çš„, æ‰¾å‡ºä½¿ç”¨ floor æˆ– ceil çš„æœ€ä½³çµ„åˆä¾†å–ä»£å…¨éƒ¨éƒ½ç”¨ rounding çš„æ–¹å¼ OBQ (Optimal Brain Quantization) [paper]: å°æ–¼ weights åœ¨ quantize å…¶ä¸­ä¸€å€‹å…ƒç´ å¾Œé‚„è¦èª¿æ•´å…¶ä»–å…ƒç´ , ä½¿å¾— quantization å° output activatyions çš„ re-construction error æœ€å°. OCTAV (Optimally Clipped Tensors And Vectors)[paper]: æ‰¾å‡ºæœ€ä½³çš„ scale $S$ ä½¿å¾— quantization MSE æœ€å° (å¼ (4)), è©³è¦‹[blog1, blog2] Transformer GPTQ (WOQ) [paper]: åŸºæ–¼ OBQ çš„æŠ€è¡“ä¾†é‡å° Transformer åšäº›æ”¹é€²å’ŒåŠ é€Ÿ. Weight-Only-Quantization (WOQ) Transformer AWQ (WOQ) [paper]: å° input activations å€¼åŸŸç‰¹åˆ¥å¤§çš„é‚£äº› channels åš scaling è™•ç†, é€™æ¨£èƒ½ç¶­æŒ LLM çš„æ•ˆæœ, è©³è¦‹ç­†è¨˜ [blog]. Weight-Only-Quantization (WOQ) Transformer SmoothQuant [paper]: é€éä¸€äº›ç­‰åƒ¹çš„è½‰æ›å°‡ activations çš„ scale ç¸®å°ä¸¦æ”¾å¤§ weights çš„ scale, ä½¿å¾— activations è®Šçš„è¼ƒå®¹æ˜“ quant è€Œ weights ä»ç„¶å®¹æ˜“ quant. è©³è¦‹ç­†è¨˜ [blog] QATä¸€èˆ¬ä¾†èªªé€éæ’å…¥ fake-quant op (ä¸æ¸…æ¥šçš„è©±åƒè¦‹ â€œç°¡å–®å›é¡§é‡åŒ–â€ è£¡çš„èªªæ˜) ä½¿å¾—åœ¨è¨“ç·´æ™‚èƒ½æ„ŸçŸ¥åˆ°é‡åŒ–çš„èª¤å·® STE (Straight Through Estimator): åœ¨åšé‡åŒ–æ™‚ clip and round é€™å…©å€‹é‹ç®—ä¸å¯å¾®åˆ†, ç‚ºäº†èƒ½ back propagation å‡è£æ²’æœ‰é€™å…©å€‹ä¸å¯å¾®åˆ†çš„ ops. é€™æ˜¯æœ€å¸¸è¦‹å’Œæ¨™æº–çš„ QAT æŠ€å·§. EWGS [paper]: ç”±æ–¼å¤šå€‹ floating å€¼æœƒå°æ‡‰åˆ°åŒä¸€å€‹ quantized å€¼, ä½¿å¾—é€™äº›ä¸åŒçš„ floating å€¼å› ç‚º STE çš„åŸå› éƒ½ä½¿ç”¨ç›¸åŒçš„ gradients, EWGS æ”¹å–„äº†é€™é». è«–æ–‡çš„ figure 1 åœ–ç¤ºå¾ˆæ¸…æ¥š. MAD [in OCTAV paper]: æ”¹å–„äº† STE å°æ–¼ clipping op çš„ under estimate å•é¡Œ, è©³è¦‹è«–æ–‡è£¡çš„ figure 3 and appendix C. PACT [paper]: ä½¿å¾— $l,u$ é€™å…©å€‹ clipping ä¸Šä¸‹ç•Œèƒ½è¢«å­¸ç¿’, é™åˆ¶æ•¸å€¼ç¯„åœ. å¯ä»¥æ”¾åœ¨ QAT éç¨‹ä¸­ä½¿ç”¨. LSQ+ [paper]: ä½¿å¾— $S,Z$ é€™å…©å€‹ qparam èƒ½è¢«å­¸ç¿’, è©³è¦‹ç­†è¨˜ [blog] OCTAV (Optimally Clipped Tensors And Vectors)[paper]: æ‰¾å‡ºæœ€ä½³çš„ scale $S$ ä½¿å¾— quantization MSE æœ€å° (å¼ (4)), è©³è¦‹[blog1, blog2]. é™¤äº†ä¸Šé¢ PTQ åšä¹‹å¤–, ä¹Ÿå¯æ”¾åœ¨ QAT éç¨‹ä¸­. K-means [paper], DKM [paper]: å±¬æ–¼ nonlinear é‡åŒ–, åˆ©ç”¨ Kmeans æ±‚å‡ºä»£è¡¨æ€§çš„ codebook. DKM ç‚ºé€²ä¸€æ­¥æ”¹é€²çš„æ–¹æ³•. N2UQ [paper]: å±¬æ–¼ nonlinear é‡åŒ–, è®“é‡åŒ–å€é–“è®Šæˆå¯å­¸çš„ (å›ºå®šçš„é‡åŒ–å€é–“å°±æ˜¯ç·šæ€§é‡åŒ–). ç°¡å–®å›é¡§é‡åŒ– é‡åŒ–å°±æ˜¯å°‡ float $X$ ç”¨æœ‰é™å€‹é»ä¾†è¡¨ç¤º, å¦‚ä¸‹åœ– $\\tilde{X}$ çš„ 4 å€‹é»å°æ‡‰åˆ°åŸä¾†çš„ $X$ å¯ä»¥çœ‹åˆ°æ˜¯å¾ˆä¸è¦å‰‡çš„, æˆ–æ˜¯èªªéç·šæ€§å¦‚æœèªªé€™æœ‰é™å€‹é»æ¡ç”¨â€ç·šæ€§â€çš„å°æ‡‰æ–¹å¼, å‰‡æˆ‘å€‘å¯ä»¥å¯«æˆä¸‹é¢å¼å­å°æ‡‰é—œä¿‚: $$\\begin{align} \\hat{X}=\\text{clip}\\left(\\text{round}\\left(X\\over S\\right)+Z,l,u\\right) \\\\ \\tilde{X}=S(\\hat{X}-Z) \\end{align}$$ $Z,S$ åˆ†åˆ¥ç¨±ç‚º zero point å’Œ scale, è€Œ $l,u$ æ˜¯ clipping çš„ lower and upper bound.æ‰€ä»¥é‡åŒ–åƒæ•¸ quantization parameters (ç”¨ qparam ç°¡ç¨±) å°±æ˜¯$$\\begin{align} \\text{qparam}=\\{Z,S,l,u\\} \\end{align}$$ Quantization Meam Square Error (MSE): $$\\begin{align}\\mathbb{E}_X[(X-\\tilde{X})^2] \\end{align}$$ Symmetric: $Z=0$ æ™‚ç‚ºå°ç¨±é‡åŒ– Dynamic: qparam åœ¨ inference æ™‚æ‰å»çµ±è¨ˆå‡º Static: qparam åœ¨ inference ä¹‹å‰å°±äº‹å…ˆçµ±è¨ˆå¥½ Quantization Granuity [SongHan slide]: per-tensor: æ•´å€‹ weight or activation tensor å…±ç”¨åŒä¸€çµ„ qparam per-channel: åŒä¸€å€‹ channel å…±ç”¨åŒä¸€çµ„ qparam, ä¾‹å¦‚ä»¥ convolution kernel ä¾†èªª, åŒä¸€å€‹ output channel çš„ weights å…±ç”¨åŒä¸€çµ„ qparam per-group: å¸¸ç”¨åœ¨ LLM çš„ Transformer, é€šå¸¸ä»¥ 64, 128 ç‚ºä¸€çµ„å…±ç”¨ qparam å¦å¤–, æˆ‘å€‘å¸¸èªªçš„ quant, de-quant, re-quant, fake-quant å¯ä»¥ç”¨ä¸‹åœ–ä¾†è¡¨ç¤º: Model Compression Toolkits ä»¥ä¸‹è’é›†ä¸€äº›é‡è¦çš„æ¨¡å‹å£“ç¸® repositories, å› æ­¤ä¸é™æ–¼é‡åŒ–, æœ‰äº›é‚„åŒ…å« pruning, NAS, distillation, æˆ–åœ–å„ªåŒ–ç­‰ Microsoft Olive Microsoft NNI (Neural Network Intelligence): with NAS, Pruning, Quantization, Distilling OpenVino Neural Network Compression Framework (NNCF) Intel Neural Compressor: with NAS, Pruning, Quantization, Distillation Qualcomm AIMET: Quantization (DFQ and AdaRound, QAT), Model Compression (Spatial SVD, Channel pruning) NVidia TensorRT-LLM: optimize LLM (Transformer-based) models on NVidia GPU, using techniques such as Multi-query Attention (MQA), Group-query Attention(GQA), Paged KV Cache, SmoothQuant, GPTQ, AWQ, Speculative decoding, â€¦ Sony Model Compression Toolkit (MCT): Quantization with PTQ, GPTQ, QAT, Enhanced Post-Training Quantization (EPTQ). Structured Pruning","tags":[{"name":"Post Training Quantization (PTQ)","slug":"Post-Training-Quantization-PTQ","permalink":"https://bobondemon.github.io/tags/Post-Training-Quantization-PTQ/"},{"name":"Activation-aware Weight Quantization (AWQ)","slug":"Activation-aware-Weight-Quantization-AWQ","permalink":"https://bobondemon.github.io/tags/Activation-aware-Weight-Quantization-AWQ/"},{"name":"Weight Only Quantization (WOQ)","slug":"Weight-Only-Quantization-WOQ","permalink":"https://bobondemon.github.io/tags/Weight-Only-Quantization-WOQ/"},{"name":"Straight Through Estimator (STE)","slug":"Straight-Through-Estimator-STE","permalink":"https://bobondemon.github.io/tags/Straight-Through-Estimator-STE/"},{"name":"Quantization Aware Training (QAT)","slug":"Quantization-Aware-Training-QAT","permalink":"https://bobondemon.github.io/tags/Quantization-Aware-Training-QAT/"},{"name":"Fake Quantization","slug":"Fake-Quantization","permalink":"https://bobondemon.github.io/tags/Fake-Quantization/"},{"name":"LSQ","slug":"LSQ","permalink":"https://bobondemon.github.io/tags/LSQ/"},{"name":"LSQ+","slug":"LSQ","permalink":"https://bobondemon.github.io/tags/LSQ/"},{"name":"Data Free Quantization (DFQ)","slug":"Data-Free-Quantization-DFQ","permalink":"https://bobondemon.github.io/tags/Data-Free-Quantization-DFQ/"},{"name":"Quantization Error","slug":"Quantization-Error","permalink":"https://bobondemon.github.io/tags/Quantization-Error/"},{"name":"Linear Quantization","slug":"Linear-Quantization","permalink":"https://bobondemon.github.io/tags/Linear-Quantization/"},{"name":"Nonlinear Quantization","slug":"Nonlinear-Quantization","permalink":"https://bobondemon.github.io/tags/Nonlinear-Quantization/"},{"name":"OCTAV","slug":"OCTAV","permalink":"https://bobondemon.github.io/tags/OCTAV/"},{"name":"Asymmetric Quantization","slug":"Asymmetric-Quantization","permalink":"https://bobondemon.github.io/tags/Asymmetric-Quantization/"},{"name":"Symmetric Quantization","slug":"Symmetric-Quantization","permalink":"https://bobondemon.github.io/tags/Symmetric-Quantization/"},{"name":"SmoothQuant","slug":"SmoothQuant","permalink":"https://bobondemon.github.io/tags/SmoothQuant/"},{"name":"AdaRound","slug":"AdaRound","permalink":"https://bobondemon.github.io/tags/AdaRound/"},{"name":"PACT","slug":"PACT","permalink":"https://bobondemon.github.io/tags/PACT/"},{"name":"Optimal Brain Quantization (OBQ)","slug":"Optimal-Brain-Quantization-OBQ","permalink":"https://bobondemon.github.io/tags/Optimal-Brain-Quantization-OBQ/"},{"name":"GPTQ","slug":"GPTQ","permalink":"https://bobondemon.github.io/tags/GPTQ/"},{"name":"EWGS","slug":"EWGS","permalink":"https://bobondemon.github.io/tags/EWGS/"},{"name":"N2UQ","slug":"N2UQ","permalink":"https://bobondemon.github.io/tags/N2UQ/"},{"name":"DKM","slug":"DKM","permalink":"https://bobondemon.github.io/tags/DKM/"}]},{"title":"é«˜æ•ˆç‡è¨ˆç®— Jacobian, Hessian, VJP, JVP, HVP","date":"2024-02-07T13:56:22.000Z","path":"2024/02/07/é«˜æ•ˆç‡è¨ˆç®—-Jacobian-Hessian-VJP-JVP-HVP/","text":"âš ï¸ å¯èƒ½å¯«çš„æ¯”è¼ƒç‘£ç¢å’Œé›œäº‚, ä¸»è¦çµ¦è‡ªå·±ç­†è¨˜ç”¨ ä»¤ $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m}$ çš„ Jacobian matrix ç‚º $J_f(x)$ æ˜¯ $(m\\times n)$ çŸ©é™£, è€Œ Hessian ç‚º $H_f(x)$ æ˜¯ $(m\\times n \\times n)$ é«˜ç¶­ tensor&emsp;$\\circ$ VJP ç¨±ç‚º Vector-Jacobian Product, $vJ_f(x)$, å…¶ä¸­ $v$ æ˜¯ ($1\\times m$) çš„ row vector&emsp;$\\circ$ JVP ç¨±ç‚º Jacobian-Vector Product, $J_f(x)v$, å…¶ä¸­ $v$ æ˜¯ ($m\\times 1$) çš„ column vector&emsp;$\\circ$ HVP ç¨±ç‚º Hessian-Vector Product, $H_f(x)v$, å…¶ä¸­ $v$ æ˜¯ ($n\\times 1$) çš„ column vectorè¨ˆç®— $vJ_f(x)$ ä¸ç”¨å…ˆæŠŠçŸ©é™£ $J_f(x)$ æ±‚å‡ºä¾†å†è·Ÿ $v$ ç›¸ä¹˜, è€Œæ˜¯å¯ä»¥ç›´æ¥å¾—åˆ°ç›¸ä¹˜çš„çµæœ(é€™æ¨£åšé‚„æ›´å¿«), è½èµ·ä¾†æœ‰é»çŸ›ç›¾å°å§~åŒæ¨£çš„ JVP å’Œ HVP ä¹Ÿæ˜¯å¦‚æ­¤æœ¬æ–‡æœƒèªªæ˜æ€éº¼é«˜æ•ˆç‡è¨ˆç®— VJP, JVP, Jacobian, Hessian, ä»¥åŠ HVP ä¸»è¦åƒè€ƒ PyTorch æ–‡ç« : JACOBIANS, HESSIANS, HVP, VHP, AND MORE: COMPOSING FUNCTION TRANSFORMS HVP å¯ä»¥ç”¨ä¾†æœ‰æ•ˆç‡åœ°è¨ˆç®— $tr(H_f(x))$, è€Œé€™å€‹ term æœ‰æ™‚å€™æœƒè¢«ç•¶ä½œ loss ä¾†ç”¨, èˆ‰ä¾‹ä¾†èªª:&emsp;$\\circ$ Sliced Score Matching (SSM) æœƒç”¨åˆ°&emsp;$\\circ$ EWGS quantization (Network Quantization with Element-wise Gradient Scaling, arxiv) æœƒç”¨åˆ°&emsp;$\\circ$ More and details see: Thoughts on Trace Estimation in Deep Learning, æ›´å¤šä¾‹å­ä¸”æœ‰éå¸¸æ·±å…¥çš„è¨è«–ç¸½çµå¯ä»¥åƒè€ƒæ–‡æœ« Summaryå…ˆæŠŠ function $f$ å®šç¾©å¥½: (åå­—ç‚ºpredict) Vector-Jacobian Products (VJPs) $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m}$, $y=f(x)$, VJP åŸºæœ¬å°±æ˜¯ $vJ_f(x)$.è¨ˆç®—ä¸Šå°±æ˜¯ä¸€å€‹ row vector ($1\\times m$) ä¹˜ä¸Š Jacobian matrix, $J_f(x)=\\partial y/\\partial x:m\\times n$ çŸ©é™£, æˆ‘å€‘é€™éº¼å¯«: $$\\text{VJP }:(x,v)\\mapsto v J_f(x)$$ $$v J_f(x)= [v_1, v_2,...,v_m] \\left[ \\begin{array}{c} \\partial y_1/\\partial x \\\\ \\partial y_2/\\partial x \\\\ \\vdots \\\\ \\partial y_m/\\partial x \\end{array} \\right] = v_1\\frac{\\partial f_1(x)}{\\partial x}+\\dots+v_m\\frac{\\partial f_m(x)}{\\partial x}$$ PyTorch function torch.func.vjp(*func*, **primals*, ...) çš„ primals æŒ‡çš„æ˜¯ $x$, æœƒ return ä¸€å€‹ function ä¾‹å¦‚ç¨± $g$, å‰‡ $g(v)=vJ_f(x)$. é€™æ¨£çœ‹èµ·ä¾†è¦è¨ˆç®— $vJ_f(x)$ é‚„æ˜¯è¦å…ˆæŠŠ $J_f(x)$ é€™å€‹ $m\\times n$ çŸ©é™£å…ˆç®—å‡ºä¾†å†è·Ÿ $v$ ç›¸ä¹˜. ä½†å…¶å¯¦ä¸ç”¨, æˆ‘å€‘å¯ä»¥ç›´æ¥ç®—çµæœ, i.e. çœå»é¡¯å¼åœ°å…ˆç®— $J_f(x)$, è€Œé€™æ¨£åšæœƒæ›´æœ‰æ•ˆç‡!æ€éº¼åšåˆ°å‘¢? æˆ‘å€‘å¯ä»¥é€™éº¼æ”¹å¯«: $$vJ_f(x)=v\\frac{\\partial f(x)}{\\partial x}=\\frac{\\partial (vf(x))}{\\partial x}$$ $v$ æ˜¯ä¸€å€‹ ($1\\times m$) çš„ row vector, $f(x)$ æ˜¯ä¸€å€‹ ($m\\times 1$) column vector. $J_f(x)=\\partial f(x)/\\partial x:m\\times n$ çŸ©é™£.é€™æ¨£æ”¹å¯«çš„å¥½è™•æ˜¯ $vf(x)$ å·²ç¶“æ˜¯ä¸€å€‹ scalar äº†, ç¾åœ¨æ”¹æˆå° scalar åš gradient å°±å¯ä»¥å¾—åˆ°ç­”æ¡ˆ, ä¸¦ä¸”æ˜¯å¾ˆæœ‰æ•ˆç‡çš„, æ‰€ä»¥ä¸ç”¨å…ˆç®—å‡º $J_f(x)$ é€™å€‹ $m\\times n$ Jacobian çŸ©é™£.å°ç…§ä¸€ä¸‹ PyTorch çš„ torch.autograd.grad1torch.autograd.grad(outputs, inputs, grad_outputs=None, ...) grad_outputs å…¶å¯¦å°±æ˜¯ä¸Šé¢çš„ $v$. ä»¥ chainrule ä¾†çœ‹, $${\\partial L \\over \\partial x} = {\\partial L \\over \\partial y} \\cdot {\\partial y \\over \\partial x}=v\\cdot J_f(x)$$ å› ç‚º PyTorch çš„ loss ä¸€å®šæ˜¯ $L:\\mathbb{R}^m\\rightarrow\\mathbb{R}$, æ‰€ä»¥ $\\partial L / \\partial y: (1\\times m)$ çš„ row vector, ä»¥ VJP çš„å‹å¼ä¾†çœ‹å°±æ˜¯æ˜¯æŒ‡ $v$.æˆ–èªªåˆ©ç”¨ grad è¨ˆç®— $\\partial L/\\partial x$ çš„æ™‚å€™ grad_outputs çµ¦çš„å°±æ˜¯ $\\partial L / \\partial y: (1\\times m)$. æ±‚ Jacobian Matrix PyTorch ä»‹ç´¹3ç¨®æ±‚ Jacobian çš„æ–¹å¼:&emsp;1. For-loop æ±‚ Jacobian&emsp;2. ç”¨ vmap-vjp æ±‚ Jacobian&emsp;3. ç”¨ jacrev æ±‚ Jacobian 1. For-loop æ±‚ Jacobianå¦‚æœ $v=e_i$, å‰‡ $vJ_f(x)$ ç‚º i-th row of $J_f(x)$. å› æ­¤åªè¦æŠŠ $i=1,â€¦,m$ éƒ½åŸ·è¡Œä¸€æ¬¡, å‰‡èƒ½å¾—åˆ°å®Œæ•´çš„ $J_f(x)$. 2. ç”¨ vmap-vjp æ±‚ Jacobianä½†æƒ³åƒä¸Šæ¯ä¸€å€‹ row çš„è¨ˆç®—å¯ä»¥ä¸¦è¡Œ, å› æ­¤ä½¿ç”¨ vjp and vmap ä¾†ä¸¦è¡Œè¨ˆç®—. vjp å°±æ˜¯ç®—ä¸€æ¬¡ $vJ_f(x)$, ä½†é€™æ˜¯ä¸€ç­† sample, å¦‚æœè¦å°ä¸€å€‹ batch $V^T=[v_1^T,â€¦,v_N^T]$ è¨ˆç®— $VJ_f(x)$, å°±å¥—ç”¨ vmap åœ¨ vjp ä¸Š, è®“ä»–ä¸¦è¡Œ vectorized ç®—. è§£èªªä¸€ä¸‹ vmap, ä»¥é€™å€‹ç¯„ä¾‹ä¾†èªªæœƒå›å‚³ vmap_vjp_fn é€™å€‹ function, å…¶ input argument æœƒè·Ÿ vjp_fn ä¸€æ¨£.å·®åˆ¥æ˜¯ vmap_vjp_fn çš„ input argument unit_vectors æœƒæ¯” vjp_fn çš„ input argument x å¤šäº†ä¸€å€‹ batch çš„ç¶­åº¦ (é è¨­åœ¨ç¶­åº¦0)å³ x æ˜¯ç¶­åº¦ (n, ), unit_vectors æ˜¯ç¶­åº¦ (m, n) é€™è£¡çš„ m æ˜¯ batch ç¶­åº¦. 3. ç”¨ jacrev æ±‚ Jacobianæˆ–ç›´æ¥ä½¿ç”¨ jacrev ç›´æ¥å¹«å¿™åšå¥½ vmap-vjp å…©æ­¥é©Ÿ torch.func.jacrev(*func*, *argnums=0*, ...) çš„èªªæ˜:Returns a function that takes in the same inputs as func and returns the Jacobian of func with respect to the arg(s) at argnums ç•¶ç„¶æˆ‘å€‘ä¹Ÿå¯ä»¥é‡å° weight or bias è¨ˆç®— Jacobian, åªéœ€è¦å° argnums æ”¹æˆ 0 or 1 å³å¯ Jacobian-Vector Products (JVPs) $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m}$, $y=f(x)$, JVP åŸºæœ¬å°±æ˜¯ $J_f(x)v$, è¨ˆç®—ä¸Šå°±æ˜¯ Jacobian matrix, $J_f(x)=\\partial y/\\partial x:m\\times n$, ä¹˜ä¸Šä¸€å€‹ column vector ($n\\times 1$) æˆ‘å€‘é€™éº¼å¯«: PyTorch function torch.func.jvp(*func*, *primals*, *tangents,* ...) çš„ primals æŒ‡çš„æ˜¯ $x$, tangents æŒ‡çš„æ˜¯ $v$. åŒæ¨£çš„å¦‚æœ $v=e_i$, å‰‡ $J_f(x)v$ ç‚º i-th column of $J_f(x)$. æ‰€ä»¥å°æ–¼è¨ˆç®— Jacobian matrix:&emsp;$\\circ$ VJP æœ‰ jacrev (ç¨± reverse-mode Jacobian)&emsp;$\\circ$ JVP æœ‰ jacfwd (ç¨± forward-mode Jacobian) VJP and JVP é€Ÿåº¦ä¸Šçš„è€ƒé‡ Let $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m}$, VJP ä½¿ç”¨ vmap åœ¨ output ç¶­åº¦ $m$ ä¸Š, åä¹‹ JVP ä½¿ç”¨ vmap åœ¨ input ç¶­åº¦ $n$ ä¸Š.ä½¿ç”¨ vmap çš„é‚£å€‹ç¶­åº¦å¦‚æœæ¯”è¼ƒå¤§çš„è©±, æ•ˆç‡å¯èƒ½æœƒæ¯”è¼ƒå·®, å› æ­¤å»ºè­° vmap ä½œç”¨åœ¨å°çš„ç¶­åº¦ä¸Š.å› æ­¤å¦‚æœ Jacobian æ˜¯ç˜¦é«˜çŸ©é™£ $m&gt;n$ å»ºè­°ä½¿ç”¨ JVP jacfwd, åä¹‹èƒ–çŸ®çŸ©é™£ $n&gt;m$ å»ºè­°ä½¿ç”¨ VJP jacrev. Hessian è¨ˆç®— ä½¿ç”¨ torch.func.hessian å¯ä»¥å¹«å¿™è¨ˆç®—å‡º Hessian matrix.æˆ‘å€‘çŸ¥é“ Hessian matrix æ˜¯äºŒæ¬¡å¾®åˆ†, å› æ­¤å¯ä»¥å¥—ç”¨ç®— Jacobian çš„ Jacobian matrix å¾—åˆ°.æ‰€ä»¥å¯¦éš›ä¸Šåº•å±¤é‹ä½œç‚º hessian(f)=jacfwd(jacrev(f)). ä¹Ÿå¯ä»¥ä½¿ç”¨ jacfwd(jacfwd(f)) æˆ– jacrev(jacrev(f)) æ ¹æ“šçŸ©é™£å¯¬é«˜ç¶­åº¦ä¾†å¢åŠ æ•ˆç‡. è¨ˆç®— Batch Jacobian and Batch Hessian èªªæ˜ä¸€ä¸‹ func = jacrev(predict, argnums=2) å’Œ vmap(func, in_dims) é€™å…©è¡Œ:jacrev(predict, argnums=2) æœƒå›å‚³ä¸€å€‹ function ç¨± func, é€™å€‹ func çš„ input arguments æœƒè·Ÿ predict ä¸€æ¨£, ä¹Ÿå°±æ˜¯ (weight, bias, x)ç„¶å¾Œ argnums=2 è¡¨ç¤ºåå¾®åˆ†çš„è®Šæ•¸ç‚º index 2 å³ x.åŸ·è¡Œ func æœƒ return Jacobian matrix, å³ç‚ºä¸€å€‹ shape (Dout, Din) çš„çŸ©é™£.ç„¶å¾Œ vmap çš„ in_dims=(None, None, 0) è¡¨ç¤º func çš„é€™3å€‹ input arguments è¦å°å“ªä¸€å€‹ argument çš„å“ªä¸€å€‹ç¶­åº¦ index ç•¶ä½œåŸ·è¡Œ vectorized ä¸¦è¡Œé‹ç®—. é€™è£¡çš„ä¾‹å­æ˜¯å°ç¬¬3å€‹ argument çš„ index 0, å³ argument x çš„ batch_size é‚£ä¸€ç¶­åº¦. è€Œ vmap ä¹Ÿæ˜¯ return ä¸€å€‹ function å« compute_batch_jacobian åªæ˜¯ output æœƒæ¯”åŸæœ¬çš„ func å›å‚³çµæœå¤šäº†ä¸€å€‹ batch çš„ç¶­åº¦.å¦å¤–å¯ä»¥ä½¿ç”¨ sum trick ä¾†é¿æ‰ä½¿ç”¨ vmap é€™æœ‰é» tricky æ³¨æ„åˆ°é€™å€‹ function predict_with_output_summed æ˜¯ $\\mathbb{R}^b\\times \\mathbb{R}^n\\rightarrow\\mathbb{R}^{m}$ æ‰€ä»¥é€™å€‹ function çš„ Jacobian matrix ç¶­åº¦æ˜¯ $(m, (b, n))$, å¯¦éš›ä¸Šæ˜¯ $(m, b, n)$ é€™å€‹æ­£æ˜¯ jacrev return çš„ shape, ç„¶å¾Œå† movedim è®Šæˆ $(b, m, n)$. è¨ˆç®— Hessian-Vector Products (HVP) $$y=H_L(x)v$$ å…¶ä¸­ $x\\in\\mathbb{R}^n$, $L:\\mathbb{R}^n\\rightarrow \\mathbb{R}$, $H(x)=\\partial^2L/(\\partial x)^2:\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$, $v:\\mathbb{R}^n$.å¦‚åŒæˆ‘å€‘åœ¨ VJP, $vJ_f(x)$, æåˆ°ä¸ç”¨å…ˆç®—å‡º $J_f(x)$ é€™å€‹ $m\\times n$ Jacobian çŸ©é™£, å› æ­¤ VJP å¯ä»¥å¾ˆæœ‰æ•ˆç‡è¨ˆç®—. HVP ä¹Ÿä¸€æ¨£, ä¸ç”¨å…ˆç®—å‡º $H_L(x)$, å¯ä»¥ç›´æ¥æœ‰æ•ˆç‡åœ°ç®—å‡º $H_L(x)v$:$$H_L(x)v=\\frac{\\partial G_L^T(x)}{\\partial x}v=\\frac{\\partial G_L(x)^Tv}{\\partial x}$$ å…¶ä¸­ $G_L(x)$ æ˜¯ gradient, ç‚º $n\\times 1$ çš„ column vector. é€™æ¨£åšçš„å¥½è™•æ˜¯ $G_L(x)^Tv$ å·²ç¶“æ˜¯ä¸€å€‹ scalar äº†, åšåå¾®åˆ†å¾ˆæœ‰æ•ˆç‡, ä¹Ÿé¿é–‹è¦ç®— $H_L(x)$.ç”¨ jvp å’Œ grad ä¾†å®Œæˆ HVP, primals æŒ‡çš„æ˜¯ $x$, tangents æŒ‡çš„æ˜¯ $v$.æ³¨æ„åˆ° grad [link] (æ³¨æ„é€™è£¡èªªçš„æ˜¯ torch.func.grad ä¸æ˜¯ torch.autograd.grad å–”) çš„ function åªèƒ½æ¥å— output dimension æ˜¯ $\\mathbb{R}$ (f åªèƒ½ return scalar), è€Œ jacrev or jacfwd å¯ä»¥è™•ç† function çš„ output æ˜¯ $\\mathbb{R}^m$.é›–ç„¶éƒ½æ˜¯ç®—ä¸€æ¬¡å¾®åˆ†ä½†æœ‰é€™å€‹ä¸åŒè¦æ³¨æ„! PyTorch æ–‡ä»¶èªªä½¿ç”¨ jvp é€™ç¨® forward-mode AD ä¸ç”¨å»ºç«‹ Autograd graph æ‰€ä»¥æœƒæ¯”è¼ƒçœ memory Benchmarking HVP æˆ‘å€‘å°æ¯”å…©å€‹æ–¹æ³•:&emsp;1. Baseline: å…ˆè¨ˆç®—å‡º $H_L(x)$, å†å’Œ $v$ ç›¸ä¹˜&emsp;2. ä¸Šé¢çš„ hvp é«˜æ•ˆç‡è¨ˆç®—æ–¹å¼ç°¡å–®å¯¦é©—å¾—åˆ° hvp æ‰€èŠ±çš„æ™‚é–“ç‚º Baseline çš„ 84.4477%, åŠ é€Ÿå¾ˆæœ‰æ•ˆ! (ä¸åŒæ©Ÿå™¨å¯èƒ½æœƒä¸åŒ) Benchmark codes é€™å€‹ hvp é›–ç„¶æœ‰æ•ˆç‡, ä½†æœ‰é»éº»ç…©æ˜¯å› ç‚ºä½¿ç”¨ torch.func.grad é€™å€‹ function å®ƒçš„ input f (ä¹Ÿå°±æ˜¯ä¸Šé¢ç¯„ä¾‹çš„ predict) å¿…é ˆ return scalar.è€Œå¯¦éš›ä¸Šæˆ‘å€‘éƒ½æœƒæ˜¯å¤šç¶­çš„çµæœ, è‡³å°‘æœƒæœ‰ä¸€å€‹ batch size ç¶­åº¦.è€ƒé‡åˆ°é€™ç¨®ç”¨æ³•, æˆ‘æƒ³ç›´æ¥åƒè€ƒ Sliced score matching çš„ toy example codes é€™æ®µ, å¯èƒ½é€™éº¼å¯«å°±å¥½. æ³¨æ„åˆ°è£¡é¢çš„ score å·²ç¶“æ˜¯ gradient äº†, è«‹è®€è€…å†è®€ä¸€ä¸‹ codes å¯ä»¥ç™¼ç¾ç¢ºå¯¦è·Ÿä¸Šè¿° hvp çš„åšæ³•ä¸€æ¨£. Summary ä»¤ $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m}$ çš„ Jacobian matrix ç‚º $J_f(x)$ with shape $(m, n)$, è€Œ Hessian ç‚º $H_f(x)$ with shape $(m,n,n)$&emsp;$\\circ$ VJP: torch.func.vjp å¯ä»¥æœ‰æ•ˆç‡çš„ä¾†è¨ˆç®— $vJ_f(x)$, ä¸ç”¨çœŸçš„æŠŠ $J_f(x)$ å…ˆç®—å‡ºä¾†, å°±å¯ä»¥ç›´æ¥è¨ˆç®— vjp çš„çµæœ.&emsp;$\\circ$ JVP: torch.func.jvp å¯ä»¥æœ‰æ•ˆç‡çš„ä¾†è¨ˆç®— $J_f(x)v$, ä¸ç”¨çœŸçš„æŠŠ $J_f(x)$ å…ˆç®—å‡ºä¾†, å°±å¯ä»¥ç›´æ¥è¨ˆç®— jvp çš„çµæœ.&emsp;$\\circ$ Vectorized: å¯åˆ©ç”¨ vmap ä¾†åšåˆ° batch processing&emsp;$\\circ$ Jacobian: torch.func.jacrev å’Œ torch.func.jacfwd å¯ä»¥æœ‰æ•ˆç‡æ±‚å‡º $J_f(x)$: ç”¨ vmap + jvp or vjp&emsp;$\\circ$ Hessian: torch.func.hessian=jacfwd(jacrev(f)) å¯ä»¥æœ‰æ•ˆç‡æ±‚å‡º $H_f(x)$&emsp;$\\circ$ HVP: å¯ä»¥åˆ©ç”¨ jvp and grad ä¾†æœ‰æ•ˆç‡è¨ˆç®—å‡º hvp: $H_f(x)v$, ä¸ç”¨çœŸçš„æŠŠ Hessian matrix $H_f(x)$ å…ˆç®—å‡ºä¾†, å°±å¯ä»¥ç›´æ¥è¨ˆç®— hvp çš„çµæœ. References JACOBIANS, HESSIANS, HVP, VHP, AND MORE: COMPOSING FUNCTION TRANSFORMS [link] JAX: Hessian-vector products with grad-of-grad [link] Sliced score matching çš„ toy example codes [link] Thoughts on Trace Estimation in Deep Learning [link]","tags":[{"name":"Jacobian","slug":"Jacobian","permalink":"https://bobondemon.github.io/tags/Jacobian/"},{"name":"Hessian","slug":"Hessian","permalink":"https://bobondemon.github.io/tags/Hessian/"},{"name":"Vector Jacobian Product (VJP)","slug":"Vector-Jacobian-Product-VJP","permalink":"https://bobondemon.github.io/tags/Vector-Jacobian-Product-VJP/"},{"name":"Jacobian Vector Product (JVP)","slug":"Jacobian-Vector-Product-JVP","permalink":"https://bobondemon.github.io/tags/Jacobian-Vector-Product-JVP/"},{"name":"Hessian Vector Product (HVP)","slug":"Hessian-Vector-Product-HVP","permalink":"https://bobondemon.github.io/tags/Hessian-Vector-Product-HVP/"}]},{"title":"Speculative Decoding è©³è®€ (ä¸‹)","date":"2024-01-08T14:21:17.000Z","path":"2024/01/08/Speculative-Decoding-è©³è®€2/","text":"æ¥çºŒä¸Šä¸€ç¯‡ç¾åœ¨æˆ‘å€‘å¯ä»¥çœŸæ­£çš„ä¾†æ¢è¨ä»¥ä¸‹å•é¡Œäº†:&emsp;A. é€Ÿåº¦çš„åˆ†æ: åŠ é€Ÿåˆ°ä»€éº¼ç¨‹åº¦? è·Ÿå°æ¨¡å‹çš„é€Ÿåº¦å’Œæº–ç¢ºåº¦æœ‰é—œè¯å—? (æƒ³åƒå¦‚æœ draft ä¸€ç›´è¢«æ‹’çµ•, å‰‡å°æ¨¡å‹éƒ½æ˜¯å¤šè·‘çš„)&emsp;B. é‹ç®—é‡çš„åˆ†æ: Operation æ•¸ (è¨ˆç®—é‡) ä¹Ÿæœƒæ¸›å°‘å—? é‚„æ˜¯æœƒå¢åŠ ?&emsp;C. Memory bandwidth çš„åˆ†æ: æœƒæ¸›å°‘é‚„æ˜¯å¢åŠ ?&emsp;D. Performance èƒ½ç¶­æŒä½å— (PPL, WER, BLEU, â€¦ ç«¯çœ‹ model task æ˜¯ä»€éº¼): é‚„æ˜¯æœƒæœ‰ degrade? A. é€Ÿåº¦çš„åˆ†æ å°‡ä¸Šä¸€ç¯‡çš„å…¬å¼ (10):$$\\mathbb{E}[\\#\\text{generated tokens}]=\\frac{1-\\alpha^{\\gamma+1}}{1-\\alpha}$$ ä»£å…¥ä¸Šä¸€ç¯‡çš„å…¬å¼ (3)$$\\text{Walltime Improvement}=\\frac{\\mathbb{E}(\\#\\text{generated tokens})}{(c\\gamma+1)}$$ æˆ‘å€‘å¾—åˆ°$$\\begin{align} \\text{Walltime Improvement}=\\frac{1-\\alpha^{\\gamma+1}}{(c\\gamma+1)(1-\\alpha)} \\end{align}$$ å…ˆåˆ†æä¸€ä¸‹ walltime, æˆ‘å€‘è¨­å®š $c=[0.1,0.4,0.8]$, $\\gamma=[3, 5, 7]$ è§€å¯Ÿ walltime V.S. $\\alpha$ çš„è®ŠåŒ–å›é¡§ä¸€ä¸‹ $c$ è¡¨ç¤º approx. è·Ÿ target model ä¹‹é–“çš„é€Ÿåº¦æ¯”, æ„ˆå°è¡¨ç¤º approx. model é€Ÿåº¦æ„ˆå¿«. $\\gamma$ è¡¨ç¤º proposal tokens çš„æ•¸ç›®. è€Œ $\\alpha$ å¯ä»¥ä»£è¡¨ approx. and target models ä¹‹é–“çš„åŒ¹é…ç¨‹åº¦ (æ„ˆé«˜è¡¨ç¤ºæ„ˆåŒ¹é…, proposal token è¢«æ¥å—çš„æ©Ÿç‡æ„ˆé«˜)è§€å¯Ÿåˆ°å¹¾é» (æ³¨æ„åˆ°æ¯”é»‘è‰²å¯¦ç·šå°, walltime improvement $&lt;1$, ä»£è¡¨æ²’æœ‰åŠ é€Ÿåˆ°):&emsp;1. å¦‚æœ $\\alpha$ æ„ˆå¤§, è¡¨ç¤ºå¤§å°æ¨¡å‹ä¹‹é–“æ„ˆåŒ¹é…å¯ä»¥åŠ é€Ÿæ„ˆå¤š&emsp;2. $c$ æ„ˆå° (å°æ¨¡å‹é€Ÿåº¦æ„ˆå¿«) å‰‡åŠ é€Ÿæ„ˆå¤š&emsp;3. $\\gamma$ å‰‡ä¸ä¸€å®š (çœ‹$c=0.1$ çš„ case), æ‰€ä»¥å¯èƒ½è¦æ‰¾å‡ºæœ€ä½³å€¼ é‚£æœ‰æ²’æœ‰å¯èƒ½ $\\gamma$ ä¸ç®¡æ€éº¼æ‰¾éƒ½æ‰¾ä¸å‡º walltime improvement è‡³å°‘ $&gt;1$ å‘¢? é€™ç¨®æƒ…æ³å°±ä¸ç”¨èŠ±åŠ›å»æ°£æ‰¾äº†.è«–æ–‡ Corollary 3.9. èªªæ˜ $\\alpha&gt;c$ çš„æƒ…æ³å‰‡å­˜åœ¨ $\\gamma$ ä½¿å¾—æœƒæœ‰åŠ é€Ÿå¥½è™•. åŠ é€Ÿæ•ˆæœè‡³å°‘æ˜¯ $(1+\\alpha)/(1+c)$ å€.æ‰€ä»¥ approx. and target models çš„é¸æ“‡å°±å…ˆè€ƒæ…® $\\alpha&gt;c$ çš„é…å°, ç„¶å¾Œå° $\\gamma$ æ‰¾å‡ºæœ€ä½³å€¼. å¯¦å‹™ä¸Šæˆ‘å€‘å¯ä»¥ç”¨ä¸€å€‹ calibration set ç”¨ $\\alpha := \\mathbb{E}_t[\\beta_t]=\\sum_t\\sum_x\\min(p_t(x),q_t(x))$ ä¼°è¨ˆå‡ºä¾†è€Œ $c$ å‰‡è·‘ $M_p,M_q$ çš„ inference æ¸¬å‡ºä¾†.æ¥è‘—é¸æ“‡ approx. and target models æœ‰ $\\alpha&gt;c$ çš„é…å°, æœ€å¾Œ $\\gamma$ å‰‡æ±‚è§£æœ¬ç¯‡å…¬å¼ (1) æ‰¾å‡ºæœ€ä½³å€¼ä¾†. çµ¦å®š $\\alpha,c$ å°å¼ (1) åšæ•¸å€¼æœ€ä½³åŒ–æ‰¾å‡ºæœ€ä½³ $\\gamma$, çµæœå¦‚ä¸‹: æœ€å¾Œ walltime improvement ç†è«–å€¼å¼ (1) å’Œå¯¦éš›ä¸Šé‡æ¸¬å‡ºä¾†çš„å€¼æœ‰æ²’æœ‰å·®å¾ˆå¤š? ä½œè€…åšäº†å€‹æ¯”è¼ƒEXP æ˜¯å¼(1) è¨ˆç®—çš„, EMP æ˜¯å¯¦éš›é‡æ¸¬çš„, é›–ç„¶æ²’å¾ˆæº–ç¢º, ä½†ä¹Ÿç®—æ˜¯æ­£ç›¸é—œ B. é‹ç®—é‡çš„åˆ†æ å°‡ä¸Šä¸€ç¯‡çš„å…¬å¼ (10):$$\\mathbb{E}[\\#\\text{generated tokens}]=\\frac{1-\\alpha^{\\gamma+1}}{1-\\alpha}$$ ä»£å…¥ä¸Šä¸€ç¯‡çš„å…¬å¼ (6)$$\\#\\text{OPs Increasing Ratio}= \\frac{\\hat{c}\\gamma+\\gamma+1}{\\mathbb{E}(\\#\\text{generated tokens})}$$ æˆ‘å€‘å¾—åˆ°$$\\begin{align} \\#\\text{OPs Increasing Ratio}=\\frac{(\\hat{c}\\gamma+\\gamma+1)(1-\\alpha)}{1-\\alpha^{\\gamma+1}} \\end{align}$$ æˆ‘å€‘ä¸€æ¨£æŠŠåœ–ç•«å‡ºä¾†è§€å¯Ÿåˆ°å¹¾é» (é™¤äº†æœ€å¾Œç¬¬4é»çš„çµè«–, å…¶ä»–è½èµ·ä¾†éƒ½åƒâ€æ¯60ç§’å°±æœƒæœ‰1åˆ†é˜éå»â€ä¸€æ¨£åœ°å»¢è©±):&emsp;1. å¦‚æœ $\\alpha$ æ„ˆå° (å¤§å°æ¨¡å‹æ„ˆä¸åŒ¹é…), å‰‡é‹ç®—é‡å¢åŠ æ„ˆå¤š&emsp;2. $c$ æ„ˆå° (å°æ¨¡å‹é€Ÿåº¦æ„ˆå¿«) å‰‡é‹ç®—é‡å¢åŠ çš„ overhead æ„ˆå°‘&emsp;3. $\\gamma$ æ„ˆå¤§å‰‡èŠ±æ„ˆå¤šé‹ç®—é‡&emsp;4. æ¯”è¼ƒéœ€è¦æ³¨æ„çš„æ˜¯, ä¸ç®¡æ€æ¨£éƒ½æœƒèŠ±é¡å¤–çš„è¨ˆç®—é‡, å› ç‚ºéƒ½æ¯” baseline é«˜ æ˜¯ä¸æ˜¯æœ‰é»åç›´è¦º, ä¸Šé¢èªªå¯ä»¥åŠ é€Ÿ, ä½†åˆèªªé‹ç®—é‡æœƒæ¯”è¼ƒå¤š. å…¶å¯¦åŸå› å°±æ˜¯ target model å¯ä»¥ä¸¦è¡Œç®— C. Memory Bandwidth çš„åˆ†æ é€™å€‹ç†è«–åˆ†ææ¯”è¼ƒå–®ç´”, ç”±æ–¼ speculative ä¸€å€‹ run çš„æ™‚å€™ target model åªæœƒå‘¼å«ä¸€æ¬¡, å°æ¯”åŸæœ¬æ¯ç”¢ç”Ÿä¸€å€‹ token éƒ½è¦å‘¼å«ä¸€æ¬¡ target modelLoading åƒæ•¸å’Œ kv cache é€™äº› memory bandwidth çš„æ¬¡æ•¸å°±å°‘éå¸¸å¤š, å°‘çš„æ¯”ä¾‹æ¬¡æ•¸åŸºæœ¬ä¸Šå°±æ˜¯ $\\mathbb{E}(\\# \\text{generated tokens})$ ä¸Šä¸€ç¯‡çš„å…¬å¼ (10) çš„æ¯”ä¾‹:$$\\mathbb{E}[\\#\\text{generated tokens}]=\\frac{1-\\alpha^{\\gamma+1}}{1-\\alpha}$$ D. Performance èƒ½ç¶­æŒä½å—? å›åˆ°ä¸€é–‹å§‹å°±ç ´é¡Œèªª performance èƒ½ç¶­æŒä½é€™ä»¶äº‹. å¦‚æœä¸èƒ½ç¶­æŒ, ä¸Šé¢æ‰€æœ‰åˆ†æéƒ½åœ¨åšç™½å·¥.è«–æ–‡çš„ Appendix A.1. è­‰æ˜å¯«çš„å¾ˆæ˜ç™½, åŸºæœ¬é‡è¤‡ä¸€éè€Œå·²å›é¡§ $\\beta$ è¡¨ç¤ºæ™‚é–“ $t$ çš„ accept probability (å¿½ç•¥ä¸‹æ¨™ $t$)$$\\beta = \\sum_x\\min(p(x),q(x))$$ Modified distribution:$$p&apos;(x)=norm(\\max(0,p(x)-q(x))) \\\\ =\\frac{p(x)-\\min(q(x),p(x))}{\\sum_{x&apos;}(p(x&apos;)-\\min(q(x&apos;),p(x&apos;)))} \\\\ = \\frac{p(x)-\\min(q(x),p(x))}{\\sum_{x&apos;}p(x&apos;)-\\sum_{x&apos;}\\min(q(x&apos;),p(x&apos;))} \\\\ = \\frac{p(x)-\\min(q(x),p(x))}{1-\\beta}$$ è€ƒæ…® speculative decoding æœ€çµ‚æ¡æ¨£å‡º token $xâ€™$ çš„æ©Ÿç‡ç‚º:$$P(x=x&apos;)=P(\\text{guess accept},x=x&apos;) + P(\\text{guess reject},x=x&apos;)$$ å…¶ä¸­$$P(\\text{guess accept},x=x&apos;)=q(x&apos;)\\min\\left(1, \\frac{p(x&apos;)}{q(x&apos;)}\\right)=\\min(q(x&apos;),p(x&apos;))$$ æ³¨æ„åˆ° speculative decoding æ¥å—çš„æƒ…æ³æ˜¯:&emsp;1. ç•¶ $p(x&apos;) \\geq q(x&apos;)$ æ™‚æœƒ accept&emsp;2. å¦å‰‡æœ‰ $p(x&apos;)/q(x&apos;)$ çš„æ©Ÿç‡ accepté€™æ¨£å¯«èµ·ä¾†å°±æ˜¯ $\\min(1, p(x&apos;)/q(x&apos;))$ çš„æ©Ÿç‡. ç„¶å¾Œ accept çš„è©±, token æ˜¯å¾ approx. model æ¡æ¨£çš„, å› æ­¤æ˜¯ $q(xâ€™)$.å¦å¤–$$P(\\text{guess reject},x=x&apos;)=(1-\\beta)p&apos;(x&apos;)=p(x&apos;)-\\min(q(x&apos;),p(x&apos;))$$ Reject çš„è©±è¦å¾ modified distribution $pâ€™(x)$ å»æ¡æ¨£.æ‰€ä»¥åˆåœ¨ä¸€èµ·æˆ‘å€‘å¾—åˆ° $P(x=xâ€™)=p(xâ€™)$ References Google: Fast Inference from Transformers via Speculative Decoding [arvix] DeepMind: Accelerating Large Language Model Decoding with Speculative Sampling [arxiv] Speculative Decoding è©³è®€ (ä¸Š)","tags":[{"name":"Speculative Decoding","slug":"Speculative-Decoding","permalink":"https://bobondemon.github.io/tags/Speculative-Decoding/"},{"name":"Speculative Sampling","slug":"Speculative-Sampling","permalink":"https://bobondemon.github.io/tags/Speculative-Sampling/"},{"name":"Transformer","slug":"Transformer","permalink":"https://bobondemon.github.io/tags/Transformer/"}]},{"title":"Speculative Decoding è©³è®€ (ä¸Š)","date":"2024-01-08T13:29:43.000Z","path":"2024/01/08/Speculative-Decoding-è©³è®€/","text":"é€™æ˜¯ Transformer inference çš„åŠ é€Ÿ, æœ‰äººçŒœæ¸¬ GPT-4 ä¹Ÿä½¿ç”¨é€™å€‹æ–¹æ³•: https://archive.ph/2RQ8XSpeculative decoding åšåˆ°äº†ä¸å½±éŸ¿æº–ç¢ºç‡æƒ…æ³ä¸‹ç›´æ¥åŠ é€Ÿ (ä¸æ”¹ model æ¶æ§‹, ä¸ fine tune, ä¸åš PTQ ç­‰)é€™éº¼ç¥å¥‡çš„æ“ä½œå°±æ˜¯åˆ©ç”¨äº†ä¸€å€‹å°æ¨¡å‹ä¾†å…ˆè·‘ä¸€äº› tokens, å†ç”±åŸä¾†çš„å¤§æ¨¡å‹è©•ä¼°æˆ–ä¿®æ­£.è«–æ–‡é¡¯ç¤º LLM æ•ˆæœç„¡æç›´æ¥å¯æé€Ÿ 2~3 å€, è®“æˆ‘å€‘çœ‹ä¸‹å» Motivation ä½¿ç”¨ SongHan æ•™æˆçš„èª²ç¨‹ slides. åˆ©ç”¨ small model å…ˆæå‡ºä¸€äº› draft tokens, ç„¶å¾Œç”¨ large model ä¾†é©—è­‰. å¦‚æœå¤§éƒ¨åˆ†éƒ½æ¥å—, ç›´è¦ºä¸Šå¯ä»¥çœå»å¾ˆå¤š large model çš„å‘¼å«æ¬¡æ•¸, å› æ­¤åŠ é€Ÿ. æ–¹æ³•ååˆ†ç°¡å–®, ä¸éå…¶å¯¦é­”é¬¼è—åœ¨ç´°ç¯€è£¡, è·ŸåŸæœ¬åªä½¿ç”¨ large model çš„æ–¹æ³•æ¯”è¼ƒæœ‰å¹¾å€‹å•é¡Œè¦å›ç­”:&emsp;A. é€Ÿåº¦çš„åˆ†æ: åŠ é€Ÿåˆ°ä»€éº¼ç¨‹åº¦? è·Ÿå°æ¨¡å‹çš„é€Ÿåº¦å’Œæº–ç¢ºåº¦æœ‰é—œè¯å—? (æƒ³åƒå¦‚æœ draft ä¸€ç›´è¢«æ‹’çµ•, å‰‡å°æ¨¡å‹éƒ½æ˜¯å¤šè·‘çš„)&emsp;B. é‹ç®—é‡çš„åˆ†æ: Operation æ•¸ (è¨ˆç®—é‡) ä¹Ÿæœƒæ¸›å°‘å—? é‚„æ˜¯æœƒå¢åŠ ?&emsp;C. Memory bandwidth çš„åˆ†æ: æœƒæ¸›å°‘é‚„æ˜¯å¢åŠ ?&emsp;D. Performance èƒ½ç¶­æŒä½å— (PPL, WER, BLEU, â€¦ ç«¯çœ‹ model task æ˜¯ä»€éº¼): é‚„æ˜¯æœƒæœ‰ degrade?Google é€™ç¯‡è«–æ–‡å¾ˆç²¾å½©çš„ç†è«–åˆ†æäº†ä»¥ä¸Šæ‰€æœ‰å•é¡Œ, ä¸¦æœ‰å¯¦å‹™é©—è­‰å…ˆç ´é¡Œ, performance (PPL, WER, BLEU, â€¦) å¯ä»¥ä¿è­‰ç¶­æŒä½! æˆ‘å€‘ç­‰åˆ°æœ¬ç¯‡ç­†è¨˜æœ€å¾Œåœ¨è¨è«–, ä»¥ä¸‹æœƒå…ˆè¨è«–ç®—æ³•æµç¨‹ã€åŠ é€Ÿå’Œé‹ç®—é‡çš„åˆ†æ. Speculative Decoding ç®—æ³•æµç¨‹ ä½¿ç”¨è«–æ–‡çš„è¡“èª, ä¾‹å¦‚ä¸Šé¢èªªçš„ small model æ”¹ç¨± approximation model, large model æ”¹ç¨± target model, draft ç”¨ proposal tokens.Approx. model, $M_q$, ç”¨ auto-regressive æ–¹å¼ç”¢ç”Ÿ $\\gamma$ å€‹ proposal tokens $\\{x_1,...,x_\\gamma\\}$ å’Œæ©Ÿç‡åˆ†å¸ƒ $\\{q_1(x),...,q_\\gamma(x)\\}$, æ¥è‘—æŠŠ proposal token çµåˆä¸Šæ¬¡ä¸€çš„ prefix tokens (ä½†é€™è£¡æˆ‘å€‘ç‚ºäº†ç°¡åŒ–å…ˆå¿½ç•¥ prefix) çµ¦ target model, $M_p$, åšä¸€æ¬¡ non-autoregressive forward (parallel) è·‘å‡ºæ©Ÿç‡åˆ†å¸ƒ $\\{p_1(x),...,p_\\gamma(x),p_{\\gamma+1}(x)\\}$.æ¯”è¼ƒ $p(x),q(x)$ ä¾†æ±ºå®šæ˜¯å¦æ¥å— proposal tokens, å¦‚æœ $p(x)\\geq q(x)$ å‰‡æ¡ç”¨ $M_q$ çš„ proposal token, å¦å‰‡æœ‰ $p(x)/q(x)$ æ©Ÿç‡ä»æœƒæ¥å— proposal token, æœ‰ $1-p(x)/q(x)$ çš„æ©Ÿç‡è¦æ ¹æ“šä¿®æ”¹çš„æ©Ÿç‡åˆ†å¸ƒ $p&apos;(x)=norm(\\max(0,p(x)-q(x)))$ é‡æ–°æ¡æ¨£ token.å¦å¤–å¦‚æœæ‰€æœ‰ $\\gamma$ å€‹ proposal tokens éƒ½è¢«æ¥å—äº†, å‰‡ç›´æ¥å¾ target model çš„ $p_{\\gamma+1}(x)$ æ¡æ¨£token.ä»¥ä¸Šç‚ºä¸€å€‹ step or run, é‡è¤‡ç›´åˆ°å¥å­ç”¢ç”ŸçµæŸ.åƒè€ƒä¸‹åœ–: æ³¨æ„åˆ° $\\{p_1(x),...,p_\\gamma(x),p_{\\gamma+1}(x)\\}$ æ˜¯ä¸€æ¬¡ forward å°±è·‘å‡ºä¾†çš„, ç›¸æ¯” auto-regressive çš„æ–¹å¼è¦è·‘ $\\gamma$ æ¬¡ forward (load $\\gamma$ æ¬¡ model åƒæ•¸), ç¾åœ¨åªéœ€è¦ load ä¸€æ¬¡åƒæ•¸(and kv-cache)å› æ­¤å¯ä»¥ç¯€çœ memory bandwidth. ä½†æ³¨æ„åˆ°é€™å…©ç¨®æ–¹å¼çš„ç¸½è¨ˆç®—é‡æ˜¯ä¸è®Šçš„. ä¸€èˆ¬ä¾†èªª $M_p$ çš„è¼¸å…¥æœƒçµåˆä¸Šä¸€æ¬¡ decode çš„ tokens (ç¨± prefix) åŠ ä¸Š $M_q$ çš„ proposal tokens ç•¶è¼¸å…¥, ä½†æ˜¯é€™äº› prefix ç”±æ–¼ä¸Šä¸€æ¬¡ decode æ™‚ forward é, åœ¨ä½¿ç”¨ kv-cache çš„æŠ€å·§ä¸‹å¯ä»¥çœç•¥è¨ˆç®—. é€Ÿåº¦å’Œé‹ç®—é‡çš„åˆæ­¥åˆ†æ å…ˆå®šç¾© $\\mathbb{E}(\\# \\text{generated tokens})$ è¡¨ç¤º speculative decoding å¹³å‡ä¸€å€‹ run å¯ä»¥ç”¢ç”Ÿå¤šå°‘â€æœ‰æ•ˆâ€ tokens (å› ç‚ºä¸æ˜¯æ‰€æœ‰ proposal tokens éƒ½æœƒè¢«æ¥å—) æ¨è«–é€Ÿåº¦ (Walltime) è®ŠåŒ–?æ¯ä¸€å€‹ run éœ€è¦çš„æ™‚é–“ç‚º $Tc\\gamma + T$, å…¶ä¸­ $T$ æ˜¯è·‘ä¸€æ¬¡ target model æ‰€èŠ±çš„æ™‚é–“, $c$ (cost coefficient) æ˜¯ approx. model è·Ÿ target model çš„æ™‚é–“æ¯” (æ„ˆå°è¡¨ç¤º approx. model è·‘æ„ˆå¿«). æ‰€ä»¥:&emsp;- speculative decoding èŠ±äº† $Tc\\gamma + T$ çš„æ™‚é–“ç”¢ç”Ÿ $\\mathbb{E}(\\# \\text{generated tokens})$ å€‹ tokens&emsp;- åªç”¨ target model èŠ±äº† $T$ çš„æ™‚é–“ç”¢ç”Ÿ $1$ å€‹ tokenå› æ­¤åªè¦çŸ¥é“ $\\mathbb{E}(\\# \\text{generated tokens})$ æˆ‘å€‘å¯æ¨å¾—ä½¿ç”¨ speculative decoding çš„é€Ÿåº¦æå‡ (walltime improvement):$$\\begin{align} \\text{Walltime Improvement}=\\frac{\\text{Speculative decoding (tokens per time)}} {M_p\\text{ decoding (tokens per time)}}\\\\ =\\frac{\\mathbb{E}(\\#\\text{generated tokens})/(Tc\\gamma+T)} {1/T}\\\\ =\\frac{\\mathbb{E}(\\#\\text{generated tokens})}{(c\\gamma+1)} \\end{align}$$ æ•¸å€¼æ„ˆé«˜è¡¨ç¤ºä½¿ç”¨ speculative decoding åŠ é€Ÿæ„ˆå¤š é‹ç®—é‡çš„è®ŠåŒ–?å®šç¾© $\\hat{T}$ æ˜¯ target model â€per tokenâ€ çš„é‹ç®—é‡, è€Œ $\\hat{c}$ æ˜¯ approx. model è·Ÿ target model çš„é‹ç®—é‡æ¯”. æ¯ä¸€æ¬¡çš„ run, approx. model æœƒ auto-regressive $\\gamma$ æ¬¡, æ‰€ä»¥æ˜¯ $\\hat{T}\\hat{c}\\gamma$, è€Œ target model æœƒå° $\\gamma$ å€‹ proposal tokens parallel å»è·‘ $1$ æ¬¡, æ³¨æ„åˆ°é›–ç„¶æ˜¯ parallel, ä½†ç¸½é‹ç®—æ¬¡æ•¸æ˜¯æ­£æ¯”æ–¼ proposal token æ•¸é‡çš„ (åªæ˜¯ä¸¦è¡Œè·‘), æ‰€ä»¥èŠ±çš„é‹ç®—é‡ç‚º $\\hat{T}(\\gamma+1)$. æ‰€ä»¥:&emsp;- speculative decoding èŠ±äº† $\\hat{T}\\hat{c}\\gamma+\\hat{T}(\\gamma+1)$ é‹ç®—é‡ç”¢ç”Ÿ $\\mathbb{E}(\\# \\text{generated tokens})$ å€‹ tokens&emsp;- åªç”¨ target model èŠ±äº† $\\hat{T}$ çš„é‹ç®—é‡ç”¢ç”Ÿ $1$ å€‹ tokenåŒæ¨£åªè¦çŸ¥é“ $\\mathbb{E}(\\# \\text{generated tokens})$ æˆ‘å€‘å¯æ¨å¾—é‹ç®—é‡çš„è®ŠåŒ–.PS: æ³¨æ„åˆ° prefix tokens ä¸æœƒèŠ±åˆ°é‹ç®—é‡å› ç‚º kv-cache æŠ€å·§, æ‰€ä»¥è€ƒæ…®çš„æ™‚å€™å¯ä»¥å¿½ç•¥.$$\\begin{align} \\#\\text{OPs Increasing Ratio}=\\frac{\\text{Speculative decoding (\\#OPs per token)}}{M_p\\text{ decoding (\\#OPs per token)}} \\\\ =\\frac{(\\hat{T}\\hat{c}\\gamma+\\hat{T}(\\gamma+1))/\\mathbb{E}(\\#\\text{generated tokens})}{\\hat{T}/1} \\\\ = \\frac{\\hat{c}\\gamma+\\gamma+1}{\\mathbb{E}(\\#\\text{generated tokens})} \\end{align}$$ æ•¸å€¼æ„ˆé«˜è¡¨ç¤ºä½¿ç”¨ speculative decoding è¦èŠ±æ„ˆå¤š OPs æ•¸ (é‹ç®—é‡æ„ˆé«˜) å¹³å‡ç”Ÿæˆçš„ Tokens æ•¸ Proposal Tokens è¢«æ¥å—çš„æ©Ÿç‡ $\\beta_t,\\alpha$ç¶œä¸Šæ‰€è¿°, éœ€è¦å…ˆè¨ˆç®— $\\mathbb{E}(\\# \\text{generated tokens})$, ç­‰åŒæ–¼è¦è¨ˆç®— token çš„ accept æ©Ÿç‡æˆ‘å€‘æ‰èƒ½å¾—çŸ¥é€Ÿåº¦ä»¥åŠé‹ç®—é‡çš„è®ŠåŒ–.å°‡ proposal token $x_t\\sim q(x|x_1,...,x_{t-1})=:q_t(x)$ è¢« speculative decoding æ¥å—çš„æ©Ÿç‡å®šç¾©ç‚º $\\beta_t$.æ•¸å­¸ä¸Šå¯ä»¥éº¼è¡¨é” (ç‚ºäº†æ¸…æ¥š, åœ¨æ²’æœ‰æ··æ·†æƒ…æ³ä¸‹çœç•¥ä¸‹æ¨™ $t$):$$\\begin{align} \\beta = \\mathbb{E}_{x\\sim q(x)} \\left\\{ \\begin{array}{rl} 1 &amp; q(x)\\leq p(x) \\\\ {p(x)\\over q(x)} &amp; q(x)&gt;p(x) \\end{array} \\right.\\\\ = \\mathbb{E}_{x\\sim q(x)} \\min\\left(1, {p(x)\\over q(x)}\\right)=\\sum_x\\min(p(x),q(x)) \\end{align}$$ æ³¨æ„åˆ° $\\beta_t$ è·Ÿæ™‚é–“ $t$ ç›¸é—œ, ç‚ºäº†ç°¡åŒ–, è«–æ–‡å‡è¨­ $\\beta_t,\\forall t$ éƒ½æ˜¯å¾ä¸€æ¨£çš„ distribution sample çš„ random variables.æ‰€ä»¥å¯ä»¥ç°¡åŒ–ç‚ºå®šç¾©$$\\begin{align} \\alpha := \\mathbb{E}_t[\\beta_t]=\\sum_t\\sum_x\\min(p_t(x),q_t(x)) \\end{align}$$ è«–æ–‡è¨ˆç®—äº†ä¸åŒ $M_q,M_p$ ä¹‹é–“çš„ $\\alpha$. å¯ä»¥çœ‹åˆ° $M_q$ model size æ„ˆå¤§ $\\alpha$ æ„ˆé«˜, é¡¯ç¤ºæ„ˆåŒ¹é…. æœ‰è¶£çš„æ˜¯, ä»¥T5ç³»åˆ—çš„ models ä¾†çœ‹, $M_q$ é¸æ“‡ bi-gram é€™ç¨®éå¸¸ç°¡å–®çš„ LM $\\alpha$ é‚„æœ‰ $0.2$, ä»£è¡¨ bi-gram model çš„ proposal tokens å¹³å‡5å€‹æœ‰1å€‹æœƒè¢«æ¥å—. å¦‚æœ approx. model è·Ÿ target model æ„ˆåŒ¹é…çš„è©±, accept rate ($\\beta_t,\\alpha$) å°±æœƒæ„ˆé«˜å› æ­¤ $\\beta_t$ æˆ– $\\alpha$ å¯ä»¥çœ‹æˆæ˜¯å°æ¨¡å‹è·Ÿå¤§æ¨¡å‹çš„åŒ¹é…ç¨‹åº¦. ä½†æ˜¯å†ç¹¼çºŒä¹‹å‰, æˆ‘å€‘å¿…é ˆå…ˆå›é¡§ä¸€ä¸‹å¹¾ä½•åˆ†ä½ˆ Geometric distribution with capped number of trailsè€ƒæ…®ä¸€æ¬¡æ¸¬è©¦ (trail) çš„æˆåŠŸæ©Ÿç‡ç‚º $\\theta$, æœ€å¤šæ¸¬è©¦ $n$ æ¬¡ trails, random variable $X$ ä»£è¡¨è¦èŠ±å¤šå°‘æ¬¡çš„ trails æ‰æœƒè‡³å°‘æˆåŠŸä¸€æ¬¡. æ³¨æ„åˆ°å¦‚æœå‰ $n-1$ æ¬¡éƒ½ fail, å‰‡å¼·åˆ¶æœ€å¾Œç¬¬ $n$ æ¬¡ä¸€å®šæˆåŠŸ.å‰ $n-1$ æ¬¡è‡³å°‘æœƒ success ä¸€æ¬¡æ‰€éœ€èŠ±çš„ trails æ¬¡æ•¸æœŸæœ›å€¼ç‚º:&emsp;$1\\times\\text{ç¬¬ä¸€æ¬¡å°±æˆåŠŸçš„æ©Ÿç‡} + 2\\times\\text{ç¬¬äºŒæ¬¡æ‰å°±æˆåŠŸçš„æ©Ÿç‡} + ... + (n-1)\\times\\text{ç¬¬}(n-1)\\text{æ¬¡æ‰æˆåŠŸçš„æ©Ÿç‡}$$$\\theta\\sum_{x=1}^{n-1}x(1-\\theta)^{x-1}=\\theta \\sum_{x=1}^{n-1}\\left( -\\frac{d}{d\\theta}(1-\\theta)^x \\right) \\\\ =-\\theta\\frac{d}{d\\theta}\\left(\\sum_{x=1}^{n-1}(1-\\theta)^x\\right) = -\\theta\\frac{d}{d\\theta}\\left( \\frac{(1-\\theta)(1-(1-\\theta)^{n-1})}{1-(1-\\theta)}\\right) \\\\ = -\\theta\\frac{d}{d\\theta}\\left( \\frac{(1-\\theta)-(1-\\theta)^n}{\\theta} \\right) \\\\ =-\\theta\\frac{\\theta(-1+n(1-\\theta)^{n-1})-(1-\\theta)+(1-\\theta)^n}{\\theta^2}\\\\ =\\frac{\\theta-n\\theta(1-\\theta)^{n-1}+(1-\\theta)-(1-\\theta)^n}{\\theta}$$ åŠ ä¸Š $n-1$ æ¬¡éƒ½ fail, æ‰€ä»¥å¼·åˆ¶æœ€å¾Œç¬¬ $n$ æ¬¡ä¸€å®š success çš„æ©Ÿç‡ç‚º $(1-\\theta)^{n-1}$ ä¸¦ä¹˜ä¸Šæ¬¡æ•¸ $n$, å› æ­¤ç¸½é«”æœŸæœ›å€¼ç‚º:$$\\mathbb{E}\\left[X\\right]= \\frac{\\theta-n\\theta(1-\\theta)^{n-1}+(1-\\theta)-(1-\\theta)^n}{\\theta} + n(1-\\theta)^{n-1} \\\\ =\\frac{1-(1-\\theta)^n}{\\theta}$$ è¨ˆç®—å¹³å‡ç”Ÿæˆçš„ tokens æ•¸$\\mathbb{E}(\\# \\text{generated tokens})$ ç›¸ç•¶æ–¼è¦è¨ˆç®—è©¦é©—æ¬¡æ•¸æœ‰ä¸Šé™ (capped number of trails) çš„ geometric distribution çš„æœŸæœ›å€¼.å°æ‡‰åˆ° speculative decoding çš„å•é¡Œè£¡ $\\theta=1-\\alpha$, ä¸”è©¦é©—æ¬¡æ•¸æœ€å¤š $\\gamma+1$ æ¬¡., å› æ­¤å°‡ $\\theta = 1-\\alpha$, $n=\\gamma+1$ ä»£å…¥å¾—åˆ°:$$\\begin{align} \\mathbb{E}[\\#\\text{generated tokens}]=\\frac{1-\\alpha^{\\gamma+1}}{1-\\alpha} \\end{align}$$ è«–æ–‡æŠŠå°æ¨¡å‹èˆ‡å¤§æ¨¡å‹çš„åŒ¹é…ç¨‹åº¦ $\\alpha$ è·Ÿ (10) çš„é—œä¿‚ç•«å‡ºä¾†: æˆ‘å€‘ç™¼ç¾ $M_q$ èˆ‡ $M_p$ æ„ˆåŒ¹é…çš„è©±, speculative decoding ä¸€æ¬¡ run ç”¢ç”Ÿçš„ tokens æ„ˆå¤š (å¾ˆåˆç†, å› ç‚ºè¢«æ¥å—çš„æ©Ÿç‡æ„ˆé«˜)ç”¢ç”Ÿçš„ tokens ä¸Šé™å°±æ˜¯ $\\gamma+1$ ($\\gamma$ å€‹ proposal tokens å…¨è¢«æ¥å—åŠ ä¸Šæœ€å¾Œä¸€å€‹ $M_p$ ç”¢ç”Ÿçš„ token) å¾…çºŒ â€¦ References Google: Fast Inference from Transformers via Speculative Decoding [arvix] DeepMind: Accelerating Large Language Model Decoding with Speculative Sampling [arxiv] Speculative_sampling.drawio Speculative Decoding è©³è®€ (ä¸‹)","tags":[{"name":"Speculative Decoding","slug":"Speculative-Decoding","permalink":"https://bobondemon.github.io/tags/Speculative-Decoding/"},{"name":"Speculative Sampling","slug":"Speculative-Sampling","permalink":"https://bobondemon.github.io/tags/Speculative-Sampling/"},{"name":"Transformer","slug":"Transformer","permalink":"https://bobondemon.github.io/tags/Transformer/"}]},{"title":"AWQ ç­†è¨˜","date":"2023-12-28T15:05:36.000Z","path":"2023/12/28/AWQ-ç­†è¨˜/","text":"å¦‚åŒ SmoothQuant è«–æ–‡è£¡çš„åœ–, åœ¨ memory size å·²ç¶“è·Ÿä¸ä¸Šç®—åŠ›å’Œæ¨¡å‹å¤§å°æƒ…æ³ä¸‹, memory bandwidth å·²ç¶“è®Šæˆ bottleneck. å¦‚ä½•é™ä½ memory ä½¿ç”¨é‡å°‡è®Šçš„å¾ˆé—œéµ, å› æ­¤ Activation-aware Weight Quantization (AWQ) é€™ç¯‡æ–‡ç« å°±å°ˆæ³¨åœ¨ Weight Only Quantization (WOQ), é¡§åæ€ç¾©å°±æ˜¯ weight ä½¿ç”¨ integer 4/3 bits, activations ä»ç¶­æŒ FP16.å› ç‚º computation is cheap, memory is expensive. IntelÂ® Neural Compressor æœ‰å¯¦ä½œ WOQ è£¡é¢æœ‰ AWQ ä»¥ä¸‹å…§å®¹ç›´æ¥ç­†è¨˜ MIT SongHan æ•™æˆçš„èª²ç¨‹å…§å®¹[slides], [Video] å°‡ Weights quantize åˆ° 4/3 bits å° memory bandwidth æœƒæœ‰å¹«åŠ©, ä½†æ˜¯ç›´æ¥ä½¿ç”¨ round-to-nearest (RTN) performance æœƒå£æ‰, å°±ç®—æ˜¯ä½¿ç”¨ group-wise/block-wise çš„æ–¹å¼ä¹Ÿæ˜¯æ²’ç”¨.ä½œè€…ç™¼ç¾å¦‚æœä¿ç•™ç‰¹å®šçš„ $1\\%$ çš„ weights ä»èˆŠæ˜¯ FP16 çš„è©± (å…¶é¤˜éƒ½æ˜¯ 4/3 bits) å°±å¯ä»¥ä¿ç•™ä½ performance. å¦‚ä¸‹åœ–é¡¯ç¤º. ç‰¹å®šçš„ weights æ˜¯é‚£äº›å‘¢? å› ç‚º output activations æ˜¯ input activations ä¹—ä¸Š weights, æ‰€ä»¥æ‡‰è©²è¦çœ‹ activations ä¸èƒ½åªå–®ç¨è€ƒæ…® weights å¤§å°.é‚„è¨˜å¾—åœ¨ SmoothQuant è§€å¯Ÿåˆ°çš„ç¾è±¡å—? activations çš„ outliers æ˜¯ä»¥ per-channels æ–¹å¼å­˜åœ¨çš„, ä¹Ÿå°±æ˜¯èªª channels ä¹‹é–“å·®ç•°å¯èƒ½å¾ˆå¤§, ä½†åŒä¸€å€‹ channel å…§çš„å€¼åˆ†ä½ˆéƒ½æ¯”è¼ƒæ¥è¿‘ åœ–ä¸­çš„ activation $X$ çš„ row è¡¨ç¤º token (frame) ç¶­åº¦, column è¡¨ç¤º channel ç¶­åº¦. æ‰€ä»¥å°æ‡‰åˆ° weights çš„è©± input channel å°±æ˜¯ $W$ çš„ row vectors. è¦ä¿ç•™çš„é‚£ $1\\%$ çš„ row vectors çš„ weights å°±æ˜¯æ‰¾å°æ‡‰ $X$ çš„ column vectors ç¸½å’Œ magnitude æ¯”è¼ƒå¤§çš„é‚£äº›ä¾†ä¿ç•™. è¦‹ä¸‹åœ– (b) ä½†èƒ½ä¸èƒ½é€£ FP16 éƒ½ä¸è¦, æœ€å¥½å…¨éƒ¨éƒ½æ˜¯ INT å› ç‚ºé€™æ¨£å° HW æ¯”è¼ƒå‹å¥½.ä½œè€…ç™¼ç¾é€éä¸€å€‹ç°¡å–®çš„ scaling æ“ä½œå°±æœ‰å¹«åŠ© (å…¶å¯¦æ¦‚å¿µä¸€æ¨£å¾ˆåƒ SmoothQuant)é¡ä¼¼ SmoothQuant çš„æ–¹å¼, å…ˆå° quantization ä¹‹å‰çš„ Weights ä¹˜ä¸Š scale $s$, å°æ‡‰çš„åœ¨ input activations $X$ é™¤ä¸Š $s$, å¦‚æœæ²’æœ‰åš quantization æ•¸å­¸ä¸Šå°±æ˜¯ç­‰åƒ¹.ä¸‹åœ–é¡¯ç¤ºå°ç¬¬ 2 å€‹ input channel è¨­å®š $s=2$. é€™éº¼åšç›´æ¥ç„¡æ performance. ä½†æ˜¯ç‚ºä»€éº¼å‘¢? åŸä¾† output activation ç‚º $$\\hat{Y}=Q(\\mathbf{w})\\cdot \\mathbf{x}=\\Delta\\cdot Round(\\mathbf{w}/\\Delta)\\cdot \\mathbf{x}$$ ç¾åœ¨æ”¹æˆ:$$\\tilde{Y}=Q(\\mathbf{w}\\cdot s)\\cdot \\mathbf{x}/s=\\Delta\\cdot Round(s\\mathbf{w}/\\Delta)\\cdot \\mathbf{x}/s$$ äº’ç›¸å°æ¯”ä¸€ä¸‹, æ³¨æ„åˆ°ç”±æ–¼ $\\mathbb{E}[Round(\\mathbf{w}/\\Delta)]=\\mathbb{E}[Round(s\\mathbf{w}/\\Delta)]=0.25$, ç•¶ $s&gt;1$ çš„æ™‚å€™ $\\tilde{Y}&lt;\\hat{Y}$, ä½¿å¾— output activations çš„ dynamic range è®Šå°äº†, ç­‰åŒæ–¼è®“ outliers è®Šå°æ›´å®¹æ˜“ quantization äº†.æ³¨æ„åˆ°é€™è£¡æœ‰å€‹å‡è¨­: $\\Delta$ ä¸è®Šçš„æ¢ä»¶ä¸‹. é€™é€šå¸¸å¯ä»¥æ»¿è¶³, å› ç‚ºå¯¦å‹™ä¸Šè¨­å®š $1 æ˜¯ input activation çš„ magnitude, $\\alpha\\in[0,1]$, $0$ è¡¨ç¤ºæ²’æœ‰ scale; $1$ è¡¨ç¤ºæœ€å¼·çš„ scale. Grid search æ˜¯å° $\\alpha$ åš. æœ€å¾Œå¯¦é©—çµæœé¡¯ç¤ºå° LLMs, OpenFlamingo åšåˆ° 4/3bits çš„ weights quantization å¾ˆæœ‰æ•ˆ: é€™è£¡å¯¦é©—å¦‚æœæ˜¯ç”¨ per-channel æœƒæ•ˆæœä¸å¥½, æ‰€ä»¥å»ºè­°æ­é… per-vector æˆ–ç¨± per-group quantization. References AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration, [arxiv] MIT HAN Lab, Course: TinyML and Efficient Deep Learning Computing [slides], [Video] IntelÂ® Neural Compressorâ€˜s WOQ","tags":[{"name":"Post Training Quantization (PTQ)","slug":"Post-Training-Quantization-PTQ","permalink":"https://bobondemon.github.io/tags/Post-Training-Quantization-PTQ/"},{"name":"Activation-aware Weight Quantization (AWQ)","slug":"Activation-aware-Weight-Quantization-AWQ","permalink":"https://bobondemon.github.io/tags/Activation-aware-Weight-Quantization-AWQ/"},{"name":"Weight Only Quantization (WOQ)","slug":"Weight-Only-Quantization-WOQ","permalink":"https://bobondemon.github.io/tags/Weight-Only-Quantization-WOQ/"}]},{"title":"SmoothQuant ç­†è¨˜","date":"2023-12-28T12:59:28.000Z","path":"2023/12/28/SmoothQuant-ç­†è¨˜/","text":"é€™æ˜¯ MIT SongHan æ•™æˆå¯¦é©—å®¤çš„è«–æ–‡, ä½¿ç”¨ PTQ å° LLM åšåˆ° W8A8 çš„é‡åŒ–, ç”±æ–¼ activations æœƒæœ‰æ¯”è¼ƒå¤§çš„ outliers å°è‡´ quantization å¾Œæå¤±è¼ƒå¤§, è€Œä¸€èˆ¬ weights çš„ outliers å¾ˆå°‘, å› æ­¤é€éä¸€äº›ç­‰åƒ¹çš„è½‰æ›å°‡ activations çš„ scale ç¸®å°ä¸¦æ”¾å¤§ weights çš„ scale, ä½¿å¾— activations è®Šçš„è¼ƒå®¹æ˜“ quant è€Œ weights ä»ç„¶å®¹æ˜“ quant. å¦‚è«–æ–‡çš„åœ–é¡¯ç¤º: Quantization Granularity å…ˆèªªæ˜ä¸€ä¸‹ä¸åŒ quantization granularity, å…¶ä¸­&emsp;- Activation $X$ çš„ row æ˜¯ token ç¶­åº¦, col æ˜¯ input channel ç¶­åº¦.&emsp;- Weight $W$ çš„ row æ˜¯ input channel ç¶­åº¦, col æ˜¯ output channel ç¶­åº¦.&emsp;- $\\Delta_X$, $\\Delta_W$ åˆ†åˆ¥æŒ‡çš„æ˜¯ activation $X$ å’Œ weight $W$ çš„é‡åŒ–åƒæ•¸ (scales, zero points) å¯ä»¥çœ‹åˆ° per-tensor æŒ‡çš„æ˜¯æ•´å€‹ matrix å…±äº«åŒä¸€çµ„é‡åŒ–åƒæ•¸è€Œ per-token (per-frame) å‰‡è¡¨ç¤º $X$ åŒä¸€å€‹ row å…±äº«åŒä¸€çµ„é‡åŒ–åƒæ•¸; åŒç† per-channel æ˜¯å° $W$ çš„ output channel åŒä¸€å€‹ column å…±äº«åŒä¸€çµ„é‡åŒ–åƒæ•¸ GEMM åœ¨å° $XW$ çŸ©é™£ä¹˜æ³•ä¸¦è¡ŒåŠ é€Ÿçš„æ™‚å€™, å° $X$ æ¡ç”¨ row-major, $W$ æ¡ç”¨ col-major å‰‡ output æ¯å€‹ element éƒ½å¯ä»¥ç¨ç«‹é‹ç®—, æ‰€ä»¥å¯ä»¥ä¸¦è¡Œ.é€™é‚Šæ€è€ƒä¸€å€‹å•é¡Œ, å¦‚æœ $X$ æ¡ç”¨ per-channel (åŒä¸€å€‹ column å…±äº«åŒä¸€çµ„é‡åŒ–åƒæ•¸), åœ¨åš GEMM æ™‚, $X$ çš„ä¸€å€‹ row è£¡é¢æ¯å€‹å…ƒç´ éƒ½éœ€è¦æ¡ç”¨ä¸åŒçš„é‡åŒ–åƒæ•¸, é€™æœƒç ´å£æ‰ GEMM ä¸¦è¡Œçš„å¥½è™•.å› æ­¤ä¸€èˆ¬ä¾†èªª $X$ æ¡ç”¨ per-token, è€Œ $W$ æ¡ç”¨ per-channel (output channel) å° GEMM æ¯”è¼ƒå‹å–„. Motivation å¯¦éš›è§€å¯Ÿ $X$ çš„åˆ†ä½ˆ, ç™¼ç¾æ•¸å€¼åˆ†ä½ˆçš„ç‰¹æ€§æ˜¯ channel å…§å·®ç•°ä¸å¤§, ä½† channel ä¹‹é–“çš„å·®ç•°å¾ˆå¤§. å› æ­¤å° $X$ ä¾†èªªæ¡ç”¨ per-channel quantization æ‰æ˜¯æ¯”è¼ƒåˆé©çš„, ä½†æ˜¯å¾ä¸Šä¸€æ®µæˆ‘å€‘çŸ¥é“ $X$ æ¡ç”¨ per-token å° GEMM æ‰æœƒæ¯”è¼ƒå‹å–„. é‚£è©²æ€éº¼è¾¦? é€™å°±æ˜¯ SmoothQuant è¦åšçš„äº‹, é™ä½ $X$ çš„ outliers ä½¿å¾—å¯ä»¥ä»æ¡ç”¨ per-token. å¦‚è«–æ–‡ Figure 4, å’Œè¬›ç¾©èªªçš„ SmoothQuant æ–¹æ³• é€™äº› activations $X$ çš„ outliers éƒ½å­˜åœ¨æ–¼æŸå¹¾å€‹ç‰¹å®šçš„ channels, è·Ÿå“ªä¸€å€‹ tokens ç¶­åº¦ç„¡é—œ. æ‰€ä»¥æˆ‘å€‘å¦‚æœä½¿ç”¨ per-channel quant, å‰‡å¯ä»¥å° channels çš„ scales å°æ‡‰åšå€‹åˆ†é….å…¶ä¸­ $X diag(s)^{-1}$ å¯ä»¥æŠŠ $diag(s)^{-1}$ èåˆé€²å»å‰ä¸€å±¤çš„ layer normalization åƒæ•¸è£¡é ­. è€Œ $diag(s)W$ ç›´æ¥èé€²å» $W$ çš„ scaling factor è£¡.é¸æ“‡ channel çš„ re-scaling factor å¦‚ä¸‹: $$s_j=\\max(|X_j|)^\\alpha/\\max(|W_j|)^{1-\\alpha}$$ é€šå¸¸ $\\alpha=0.5$ æ˜¯å€‹å¾ˆå¥½çš„é¸æ“‡ (æ§åˆ¶ activation é‚„æ˜¯ weight é‡åŒ–é›£åº¦çš„ trade-off), ä½†å¦‚æœé‡åˆ° activation çš„ outlier æ¯”é‡å æ¯”è¼ƒå¤šçš„è©± ($\\sim30\\%$), å¯ä»¥é¸ $\\alpha=0.75$. æœ€å¾Œè«–æ–‡æ¡ç”¨çš„ format ç‚º: SmoothQuant é€éæŠŠ quantization å›°é›£ç§»è½‰åˆ° weight ä¸Š, æ‰€ä»¥ $X$ ä»å¯ä»¥ä½¿ç”¨ per-token(frame) æˆ–ç”šè‡³ per-tensor quant, åŒæ™‚ä¹Ÿä¸å½±éŸ¿ GEMM åŠ é€Ÿ. å¯¦é©—çµæœ å° OPT-172B èƒ½æœ‰æ•ˆæ¢å¾© acc to FP16 æ°´æº–, åŒæ™‚éœ€è¦çš„ GPU æ¸›åŠ, latency ä¹Ÿæ¸›å°‘. ç„¶å¾Œå°æ›´å¤§çš„ model ä¹ŸåŒæ¨£æœ‰æ•ˆ, like MT-NLG 530Bå° Llmma åŒæ¨£ä¹Ÿæ˜¯, ä¸»è¦æƒ³çœ‹ä¸€ä¸‹ SwishGLU, RoPE é€™ç¨®ä¸ä¸€æ¨£çš„ op å°æ–¼ SmoothQuant çš„å‡è¨­æ˜¯å¦ä¸€æ¨£æˆç«‹ References SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models, [arxiv] MIT HAN Lab, Course: TinyML and Efficient Deep Learning Computing [slides], [Video]","tags":[{"name":"Post Training Quantization (PTQ)","slug":"Post-Training-Quantization-PTQ","permalink":"https://bobondemon.github.io/tags/Post-Training-Quantization-PTQ/"},{"name":"SmoothQuant","slug":"SmoothQuant","permalink":"https://bobondemon.github.io/tags/SmoothQuant/"}]},{"title":"Qualcomm Data-Free Quantization è©³è®€","date":"2023-11-24T15:20:05.000Z","path":"2023/11/24/Qualcomm-Data-Free-Quantization-è©³è®€/","text":"ç¸½æ­¸ä¾†èªª Data-Free Quantization (DFQ) çš„ç›®çš„æ˜¯è®“ floating model åš weights å„ç¨®èª¿æ•´, ä½¿å¾—ä¸ç®¡æ˜¯ weights or activations éƒ½è®Šå¾—é©åˆ per tensor é‡åŒ–.é€™æ¨£ç†æƒ³ä¸Šå°±ä¸éœ€ç”¨åˆ° per channel é‡åŒ–, å› ç‚º per channel é›–ç„¶æ•ˆæœå¾ˆå¥½, ä½†ç¡¬é«”æ¯”è¼ƒä¸å‹å–„, ä¸”èŠ±çš„é‹ç®—é‡è¼ƒé«˜. å¦å¤– DFQ å±¬æ–¼ Post-Training Quantization (PTQ) æ–¹æ³•. PTQ å°ä½ˆç½²åˆ° edge ç«¯å¾ˆæ–¹ä¾¿, ä½†ä¸€èˆ¬ä¾†èªª PTQ éƒ½ä¸å¦‚ Quantization-Aware Training (QAT) çš„æ•ˆæœå¥½, å› æ­¤ DFQ å˜—è©¦æå‡æ•ˆæœ. DFQ å…±å››æ­¥, å°ç…§åœ–çœ‹, éœ€ç…§é †åº: Cross-Layer Equalization (CLE): è¼¸å…¥ fused BN å¾Œçš„ float model $M_f^1$, floating æ“ä½œå° weights åšèª¿æ•´ä½¿å¾—æ›´å‡è¡¡æ–¹ä¾¿ per tensor é‡åŒ–, ç‚º step 3 çš„å‰ç½®ä½œæ¥­, è¼¸å‡ºä»ç‚º float model $M_f^2$. Bias Absorption (BA): è¼¸å…¥ CLE å¾Œçš„ float model $M_f^2$, floating æ“ä½œå° activations åšèª¿æ•´ä½¿å¾—æ›´å‡è¡¡æ–¹ä¾¿ per tensor é‡åŒ–, ç‚º step 3 çš„å‰ç½®ä½œæ¥­, è¼¸å‡ºä»ç‚º float model $M_f^3$. PTQ é‡åŒ–: è¼¸å…¥ CLE+BA å¾Œçš„ float model $M_f^3$, æ­¤æ™‚ä¸ç®¡ weights or activations éƒ½é©åˆåš per-tensor é‡åŒ–äº†, æ‰€ä»¥ç›´æ¥ PTQ è¼¸å‡º int model $M_i^1$. Bias Correction (BC): è¼¸å…¥ float model $M_f^1$ å’Œ step 3 çš„ $M_i^1$, ä¸¦ä¸”(option)çµ¦ä¸€äº› unlabeled çš„ä»£è¡¨ data, BC æœƒå° $M_i^1$ çš„ bias åƒæ•¸è£œå„Ÿå› ç‚ºé‡åŒ–é€ æˆçš„æ•¸å€¼ mean åç§», è¼¸å‡ºç‚ºæœ€çµ‚ fixed point model $M_i^2$. Qualcomm AI Lab çš„ tool AIMET èªª BC é€™ä¸€æ­¥é©Ÿå¯ä»¥ç”¨ AdaRound (éœ€è¦ä¸€å°éƒ¨åˆ†çš„ unlabelled training data) å–ä»£ å…¶å¯¦èªçœŸçœ‹å®Œè«–æ–‡, è¦ºå¾—é™åˆ¶æœ‰é»å¤šå•Š! å¾ˆå¤šæ™‚å€™ä¸èƒ½å¥— CLE, æœ‰æ™‚ BA ä¹Ÿç”¨ä¸äº†. æŠŠé™åˆ¶æ¢åˆ—ä¸€ä¸‹: âš ï¸ CLE é™åˆ¶:&emsp;1. Activation functions $f(\\cdot)$ éœ€ç‚º piece-wise linear (e.g. ReLU, ReLU6, LeakyReLU, â€¦)&emsp;2. å¦‚æœæœ‰ BN (Batch normalization) layer, å…ˆæŠŠå®ƒ fuse åˆ° Conv è£¡é¢, æ‰€ä»¥ç¬¬3é»çš„é™åˆ¶æ‰å¯ä»¥å¿½ç•¥ BN layer.&emsp;3. ç›¸é„°çš„ layers åªèƒ½å¾ˆå–®ç´”æ˜¯ $f(W^{(2)}f(W^{(1)}x+b^{(1)})+b^{(2)})$, æ‰€ä»¥å¦‚æœæœ‰ residual add æˆ– concat æ‰çµ¦ $W^{(2)}$ ä½œç”¨çš„è©±å°±ä¸è¡Œ.âš ï¸ BA é™åˆ¶:&emsp;1. activations çš„æ¯å€‹ç¶­åº¦æ˜¯é«˜æ–¯åˆ†ä½ˆ, æˆ–èƒ½å–å¾—å…¶åˆ†å¸ƒ, ä¾‹å¦‚é€é observer; ä½†åœ¨ AIMET å·¥å…·æ˜¯å‡è¨­æœ‰ BN æ‰€ä»¥æ˜¯é«˜æ–¯åˆ†å¸ƒ, å¦å‰‡ä¸ç”¨å¥—ç”¨ BA&emsp;2. Activation functions $f(\\cdot)$ éœ€ç‚º ReLU (or ReLU6), LeakyReLU é€™ç¨®ä¸è¡Œâš ï¸ BC é™åˆ¶:&emsp;Empirical BC éœ€è¦çµ¦ representative data (å¯ä»¥æ˜¯ unlabeled). å¦‚æœ Analytical BC (data-free) å‰‡éœ€æœ‰ BN â€”&gt; ReLU â€”&gt; Conv/FC é€™æ¨£é †åºçš„å‡è¨­æ‰èƒ½è£œå„Ÿå›  quantize å¾Œ Conv/FC é€™å±¤è¼¸å‡ºçš„ mean åç§» æ¥è‘—æˆ‘å€‘æè¿°ä¸€ä¸‹ CLE, BA å’Œ BC çš„å‹•æ©Ÿ, ç„¶å¾Œå†è©³ç´°ä»‹ç´¹è«–æ–‡æå‡ºçš„é€™ä¸‰å€‹æ–¹æ³• Motivation CLE å‹•æ©ŸConvolution kernels åœ¨ä¸åŒ output channels ä¾†çœ‹, weights çš„åˆ†ä½ˆæœ‰äº›å¾ˆå¤§æœ‰äº›å¾ˆå°, é€™ä½¿å¾—ç”¨çµ±ä¸€ä¸€å€‹ quantization parameter set æœƒä¸å¥½. æ‰€ä»¥å¦‚æœèƒ½äº‹å…ˆè®“ weights åœ¨ä¸åŒ channel çš„æ•¸å€¼åˆ†ä½ˆæ¥è¿‘, é€™æ¨£å°±é©åˆç”¨ per tensor quantization äº†. ç‚ºæ­¤ä½œè€…æå‡º Cross-Layer Equalizaiton (CLE) æ–¹æ³•. åœ–ä¾†æºç‚º AIMET Post-Training Quantization Techniques BA å‹•æ©Ÿä¸éåšäº† CLE æœ‰å€‹ side-effect å°±æ˜¯è®“ activations æœ‰å¯èƒ½åè€Œä¸åŒ channels åˆ†ä½ˆè®Šçš„æ›´ä¸åŒ, ç‚ºæ­¤ä½œè€…æå‡º Bias Absorption (BA) æ–¹æ³•ä½¿å¾— activations åŒæ¨£é©åˆ per-tensor quant. BC å‹•æ©Ÿå¦ä¸€æ–¹é¢, å…¶å¯¦ weights or input activations ç¶“é quantization å¾Œ, output activations ç†æƒ³ä¸Šå¸Œæœ›æ˜¯ un-biased, ä½†å¯¦éš›ä¸Šéƒ½æœƒæœ‰ bias, å¦‚ä¸‹åœ– $$\\begin{align} \\mathbb{E}[\\tilde{y}_j-y_j]\\approx{1\\over N}\\sum_n\\left(\\tilde{W}x_n\\right)_j - \\left(Wx_n\\right)_j \\end{align}$$ å…¶ä¸­ $\\tilde{W},\\tilde{y}$ åˆ†åˆ¥æ˜¯ quantized weight and output activation. æ‰€ä»¥ä½œè€…æå‡ºä½¿ç”¨ Bias Correction (BC) æŠ€å·§ä¾†å½Œè£œ. Data Free Quantization (DFQ) è©³ç´°è§£é‡‹ Cross-Layer Equalization (CLE), å¹«åŠ© weights per-tensor é‡åŒ–å°ä»»ä½• $s&gt;0$, ä¸” $f(\\cdot)$ æ˜¯ piece-wise linear activation function:$$\\begin{align} f(x)=\\left\\{ \\begin{array}{rl} a_1x+b_1 &amp; \\text{if }x\\leq c_1 \\\\ a_2x+b_2 &amp; \\text{if }c_1&lt;x\\leq c_2 \\\\ \\vdots \\\\ a_nx+b_n &amp; \\text{if } c_{n-1}&lt;x \\\\ \\end{array} \\right. \\end{align}$$ å‰‡æˆ‘å€‘å¯ä»¥æ‰¾å‡ºç­‰åƒ¹çš„ $\\hat{f}(\\cdot)$ ä½¿å¾— $f(sx)=s\\hat{f}(x)$: è¨­å®š $\\hat{a}_i=a_i$, $\\hat{b}_i=b_i/s$ and $\\hat{c}_i=c_i/s$.é€™éº¼åšæœ‰ä»€éº¼å¥½è™•å‘¢? è€ƒæ…®ä»¥ä¸‹çš„æƒ…å½¢çµ¦å®šå…©å€‹ç›¸é„°çš„ layers: $h=f(W^{(1)}x+b^{(1)})$ å’Œ $y=f(W^{(2)}h+b^{(2)})$, å…¶ä¸­ $f$ æ˜¯ piece-wise linear activation function.å‰‡æˆ‘å€‘æœ‰: $$\\begin{align} y=f(W^{(2)}f(W^{(1)}x+b^{(1)})+b^{(2)}) \\\\ =f(W^{(2)}S\\hat{f}(S^{-1}W^{(1)}x+S^{-1}b^{(1)})+b^{(2)}) \\\\ =f(\\hat{W}^{(2)}f(\\hat{W}^{(1)}x+\\hat{b}^{(1)})+b^{(2)}) \\end{align}$$ å…¶ä¸­ $S=\\text{diag}(s)$ è¡¨ç¤ºå°è§’çŸ©é™£, $S_{ii}$ æ˜¯ neuron $i$ çš„ scaling factor $s_i$. å°±æ˜¯é é€™ $s$ ä¾†èª¿ç¯€ weights åˆ†å¸ƒ.æ‰€ä»¥æˆ‘å€‘é‡æ–°ç¸®æ”¾äº† weights: $\\hat{W}^{(2)}=W^{(2)}S$, $\\hat{W}^{(1)}=S^{-1}W^{(1)}$ and $\\hat{b}^{(1)}=S^{-1}b^{(1)}$.é‚£éº¼æ€éº¼è¨­å®šæœ€ä½³çš„ $S$ å‘¢? ç†æƒ³ä¸Š, é€é $S$ æˆ‘å€‘å¸Œæœ›å°‡ $\\hat{W}^{(1)}, \\hat{W}^{(2)}$ è®Šæˆé©åˆ per tensor quantization.&emsp;- å®šç¾© $r_i^{(1)}:=\\max(W_{i,:}^{(1)})$, å³ç‚º $W^{(1)}$ çš„ $i^{th}$ row vector å– max.&emsp;- åŒç† $\\hat{r}_i^{(1)}:=\\max(\\hat{W}_{i,:}^{(1)})=r_i^{(1)}/s_i$.é¡ä¼¼åœ°æˆ‘å€‘å®šç¾©&emsp;- $r_j^{(2)}:=\\max(W_{:,j}^{(2)})$, å³ç‚º $W^{(2)}$ çš„ $j^{th}$ column vector å– max.&emsp;- $\\hat{r}_j^{(2)}:=\\max(\\hat{W}_{:,j}^{(2)})=s_j\\cdot r_j^{(2)}$.æ³¨æ„åˆ°ä¸€å€‹æ˜¯ row vector å¦ä¸€å€‹æ˜¯ column vector é€™æ˜¯å› ç‚º $W^{(1)}$ çš„ row vector å°æ‡‰çš„æ˜¯ $W^{(2)}$ çš„ column vector. å³ç¬¬ä¸€å±¤ layer çš„ output channel å°æ‡‰çš„æ˜¯ç¬¬äºŒå±¤ layer çš„ input channel çš„æ¦‚å¿µç„¶å¾Œå†ä»¤æ•´å€‹ weight matrix çš„æœ€å¤§å€¼ç‚º: $R^{(1)}:=\\max_i(r_i^{(1)})$ å’Œ $R^{(2)}:=\\max_j(r_j^{(2)})$å¤§æ¦‚ç¤ºæ„åœ–é•·é€™æ¨£å­ æœ€å¾Œå°±å¯ä»¥å®šç¾©æ¯ä¸€å€‹ channel (1~m) å°æ–¼æ•´å€‹ weight matrix çš„å æ¯”:$p_i^{(1)}=r_i^{(1)}/R^{(1)}$; $\\hat{p}_i^{(1)}=\\hat{r}_i^{(1)}/\\hat{R}^{(1)}$; åŒç† $p_j^{(2)},\\hat{p}_j^{(2)}$åˆ°é€™è£¡ä¸é›£ç†è§£, åªæ˜¯å¾ˆå¤š terms è¦æ¶ˆåŒ–ä¸€ä¸‹è€Œå·²$p_i^{(1)}$ è¡¨ç¤º $i^{th}$ row vector å°æ•´å€‹ matrix $W^{(1)}$ çš„ä½”æ¯”, æƒ³åƒä¸Šå¦‚æœæ¯å€‹ rows çš„ä½”æ¯”éƒ½å¾ˆå¤§, é‚£å°±æ•´é«”é©åˆ per-tensor quantization.å¯ä»¥æƒ³åƒ, è‹¥ $\\hat{p}_i^{(1)}$ æ¯” $p_i^{(1)}$ å¤§è¡¨ç¤º $i^{th}$ row vector çš„ä½”æ¯”ç¶“é $s_i$ çš„èª¿æ•´è®Šå¤§, ä½†ç”±æ–¼ $s_i$ åœ¨ $W^{(1)}$ ç”¨é™¤çš„ä½†åœ¨ $W^{(2)}$ ç”¨ä¹˜çš„, å°è‡´ $\\hat{p}_i^{(2)}$ æ¯” $p_i^{(2)}$ å°äº†, æ„æ€æ˜¯ $i^{th}$ column vector çš„ä½”æ¯”åè€Œè®Šå°. æ‰€ä»¥ä¸€é‚Šè®Šå¤§äº†ä½†åè€Œä½¿å¦ä¸€é‚Šè®Šå°äº†, é€™ä¸€å®šæ˜¯å€‹ trade-off.æ‰€ä»¥æˆ‘å€‘å¸Œæœ›å…©é‚Šéƒ½é¡§åˆ° ($\\hat{p}_i^{(1)} \\hat{p}_i^{(2)}$ ä¸€èµ·è€ƒæ…®) , ä½œè€…å°±å®šç¾©äº†é€™æ¨£çš„ç›®æ¨™å‡½å¼: $$\\begin{align} \\max_S \\sum_i \\hat{p}_i^{(1)} \\hat{p}_i^{(2)} \\end{align}$$ èª¿æ•´ $S$ ä½¿å…©é‚Š matrix $W^{(1)},W^{(2)}$ çš„å æ¯”éƒ½è¦é¡§åˆ°, æ‰¾å‡ºä½¿å¾—ç¸½ä½”æ¯”é‡æœ€å¤§çš„ $S$.é€™å€‹å•é¡Œçš„æœ€ä½³è§£åœ¨è«–æ–‡çš„ Appendix A æœ‰è­‰æ˜, æˆ‘å€‘å…ˆæŠŠè§£å¯«å‡ºä¾†: $$\\begin{align} s_i=\\frac{1}{r_i^{(2)}}\\sqrt{r_i^{(1)}r_i^{(2)}} \\end{align}$$ é€™æ¨£çš„ $s_i$ æœƒä½¿å¾— $\\hat{r}_i^{(1)}=\\hat{r}_i^{(2)}$, $\\forall i$. æŠŠ $s_i$ ä»£åˆ° $\\hat{r}_i^{(1)}$ and $\\hat{r}_i^{(2)}$ å°±çŸ¥é“äº†. (é€™è£¡åŸè«–æ–‡å¯« $r_i^{(1)}=r_i^{(2)}$ æ‡‰è©²æ˜¯ typo)è©³ç´°è­‰æ˜è¨˜éŒ„åœ¨æœ€å¾Œçš„ Appendix (è«–æ–‡è­‰æ˜æœ‰äº›æ²’æ‡‚è£œå……ä¸€ä¸‹è‡ªå·±æƒ³æ³•). Bias Absorption (BA), å¹«åŠ© activation per-tensor é‡åŒ–å†èªªä¹‹å‰, å…ˆäº†è§£ä»¥ä¸‹ç¯„ä¾‹.é¦–å…ˆå°æ–¼ ReLU $r(\\cdot)$ ä¾†èªªä¸€å®šå­˜åœ¨ä¸€å€‹ non-negative vector $c$ ä½¿å¾— $\\forall x$ $$r(Wx+b-c)=r(Wx+b)-c; \\quad \\forall x \\qquad\\qquad (\\star)$$ $c=0$ å°±æ˜¯ä¸€å€‹ trivial è§£.èˆ‰ä¸€å€‹ç°¡å–®ç¯„ä¾‹, è€ƒæ…®æŸä¸€å€‹ channel $i$, data $Wx_i$ çš„æ©Ÿç‡åˆ†ä½ˆç‚ºç›´è§’ä¸‰è§’å½¢: ç•¶ $b=3$ çš„æƒ…æ³æ™‚, å‰‡é¸ $c=0.5$ æ»¿è¶³ $(\\star)$ æ¢ä»¶, è¦‹ä¸‹åœ–: é€™å€‹æƒ…æ³æœƒæ»¿è¶³æ‰€æœ‰ $x$, ä½†å¦‚æœ $Wx$ çš„åˆ†å¸ƒä¸åƒç¯„ä¾‹ä¸€å®šå¤§æ–¼æŸä¸€å€‹å€¼ (æƒ³åƒä¸Šé¢çš„ç›´è§’ä¸‰è§’å½¢åˆ†å¸ƒè®Šæˆé«˜æ–¯åˆ†ä½ˆ) å‰‡æˆ‘å€‘åªèƒ½é¸æ“‡æ»¿è¶³å¤§éƒ¨ä»½çš„å€¼ å¦‚æœæ˜¯é«˜æ–¯åˆ†ä½ˆçš„è©± (å‰‡ Batch norm çš„ mean, std å°±å¯æ‹¿ä¾†ç”¨), è«–æ–‡é¸æ“‡ 3 å€‹æ¨™æº–å·®æ‰€ä»¥ä¿è­‰ 99.865% æ»¿è¶³. é«˜æ–¯åˆ†ä½ˆåœ¨ $\\mu\\pm3\\sigma$ å…§çš„æ©Ÿç‡ç´„ç‚º $0.9973002$ [ref], ä½†ç”±æ–¼æˆ‘å€‘è¦æ‰¾çš„ $c$ åªæœƒå¿½ç•¥ $&lt;\\mu-3\\sigma$ çš„æƒ…æ³æ‰€ä»¥æ˜¯ $1-(1-0.9973002)/2\\approx99.865$, ä¹‹å¾Œæœƒæœ‰åœ–ç¤ºæ¯”è¼ƒæ¸…æ¥š æœ‰äº†ä»¥ä¸Šæ¦‚å¿µå¾Œ, å›é ­éä¾†çœ‹çœ‹ç¶“é CLE å¾Œé‚„æœƒç™¼ç”Ÿä»€éº¼ç¾è±¡, å…¶ä¸­ $r(\\cdot)$ æ˜¯ ReLU.(çªç„¶æ¸²æŸ“ä¸å‡ºæ•¸å­¸å¼å­â€¦ç…©é˜¿) $\\hat{W}^{(1)}$ and $\\hat{W}^{(2)}$ å·²ç¶“è¢« CLE èª¿æ•´ä¸€æ³¢å¾Œæ•¸å€¼åˆ†ä½ˆè®Šå¾—å¾ˆæ¥è¿‘ (é©åˆ per-tensor quantization ğŸ‘ğŸ»)ä½† $\\hat{b}^{(1)}=S^{-1}b^{(1)}$, ç•¶ $s_i&lt;1$ çš„æ™‚å€™æœƒè®“ channel $i$ çš„ activation æ”¾å¤§å°è‡´ activations, $\\hat{W}^{(1)}x+\\hat{b}^{(1)}$, çš„å„ channel ä¹‹é–“åˆ†ä½ˆä½ç½®æœƒä¸åŒ, å› æ­¤ä¹Ÿæœƒè®“ activations ä¸å¥½åš quantization!åˆ©ç”¨ä¸Šé¢èªªçš„æ¦‚å¿µæˆ‘å€‘é€™æ¨£æ¨å°: å…¶ä¸­ $b^{\\star(1)}=\\hat{b}^{(1)}-c$ å’Œ $b^{\\star(2)}=\\hat{W}^{(2)}c+b^{(2)}$.ğŸ’¡ ç›®çš„æ˜¯æŠŠ $\\color{orange}{\\hat{W}^{(1)}x+\\hat{b}^{(1)}}$ å¾ä¸é©åˆåš per-tensor quant è®Šæˆ $\\color{orange}{\\hat{W}^{(1)}x+b^{\\star(1)}}$ å®¹æ˜“åš per-tensor quant.å‰‡ $c$ å¯ä»¥é¸æ“‡ç›¡é‡æ»¿è¶³æ‰€æœ‰ $\\hat{W}^{(1)}x+\\hat{b}^{(1)}$ çš„å€¼, è¦é€™éº¼åšæœ€æš´åŠ›çš„æ–¹å¼æ˜¯é¤µæ‰€æœ‰ training data å»çœ‹è³‡æ–™åˆ†å¸ƒ, é¸æ“‡æ»¿è¶³å¤§éƒ¨åˆ†çš„æƒ…æ³, ä¾‹å¦‚æ»¿è¶³ 99.99% çš„æ•¸å€¼.å¦å¤–å¦‚æœæˆ‘å€‘çŸ¥é“ $\\hat{W}^{(1)}x+\\hat{b}^{(1)}$ æœƒå†ç¶“é Batch normalization, i.e. $BN(\\hat{W}^{(1)}x+\\hat{b}^{(1)})$ åªæ˜¯ BN å¿½ç•¥ä¸å¯«è€Œå·², å‰‡ä»¤ $c=\\max(0,\\beta-3\\gamma)$, å…¶ä¸­ $\\beta,\\gamma$ åˆ†åˆ¥æ˜¯ Batch normalization çš„ shift and scale parameters, é€™æ¨£ç›´æ¥å°±æ»¿è¶³å¤§æ–¼-3æ¨™æº–å·®çš„ 99.865% æ©Ÿç‡äº†. é–‹é ­çš„ DFQ æµç¨‹åœ–æœ‰å…ˆåš BN folding, æ‰€ä»¥æ­¤æ™‚çš„ $\\tilde{W}^{(1)}$ å·²ç¶“æ˜¯ folding å¾Œçš„, å› æ­¤è¦äº‹å…ˆæŠŠ $\\beta,\\gamma$ å­˜èµ·ä¾†æ‰èƒ½åœ¨é€™æ­¥é©Ÿç”¨ æˆ‘å€‘ä¾†æ€è€ƒç‚ºå•¥ activations å¾ $\\hat{W}^{(1)}x+\\hat{b}^{(1)}$ è®Šæˆ $\\hat{W}^{(1)}x+b^{\\star(1)}$ å¾Œå°±æœƒæ¯”è¼ƒå¥½åš per-tensor quantization, é€™æ˜¯å› ç‚ºæˆ‘å€‘é¸æ“‡çš„é€™äº› $c_i$ æœƒè®“ç¶­åº¦ $i$ çš„ activation å°é½Šåˆ°å‰›å¥½æœ‰ 99.865% å¤§æ–¼ 0, è€Œæ¯å€‹ç¶­åº¦éƒ½ä¾é€™æ¨£çš„æ¨™æº– align è‡ªç„¶å°±å®¹æ˜“å°æ•´å€‹ activations åš quantization äº† (ä¸éœ€è¦ per-channel quant äº†)!åœ–ç¤ºä¸€ä¸‹ä¸Šé¢çš„æ„æ€, ç‚ºäº†æ–¹ä¾¿ä»¤ $\\hat{k}=\\hat{W}^{(1)}x+\\hat{b}^{(1)}$, å…¶ä¸­ $\\hat{k}_i$ è¡¨ç¤ºç¬¬ $i$ ç¶­, åŒç† $k^{\\star}=\\hat{W}^{(1)}x+b^{\\star(1)}$ å’Œ $k^\\star_i$: æ³¨æ„åˆ°é›–ç„¶ activations $k^\\star$ é©åˆ per-tensor quant äº†, ä½†æˆ‘å€‘åªæ˜¯æŠŠé€™å›°é›£ pass åˆ° $b^{\\star(2)}$, ç‚ºå•¥é€™éº¼èªªå‘¢? å› ç‚º $b^{\\star(2)}$ éœ€è¦å¤šåŠ ä¸€é … $\\hat{W}^{(2)}c$, ä½†æˆ‘å€‘ä¸¦ä¸åšä»»ä½•ä¿è­‰ ,å› æ­¤ activations $z$ (çœ‹å¼ (8))ä»ç„¶æœ‰å¯èƒ½æ¯å€‹ channel ç¶­åº¦åˆ†ä½ˆä½ç½®ä¹Ÿéƒ½ä¸åŒ, æ‰€ä»¥å¯¦å‹™ä¸Šæ¡å– layer 1 and 2 åšå®Œ, å†åš layer 2 and 3, ä¾æ­¤åˆ—æ¨ä¸‹å». Bias Correction (BC)å¦‚åŒåœ¨ motivation ç¨å¾®æåˆ°çš„, ä»¤ $\\epsilon=\\tilde{W}-W$ æ˜¯ quantization error, $\\tilde{W}$ æ˜¯ quant å¾Œçš„åƒæ•¸. ä¸”ä»¤ $y=Wx,\\tilde{y}=\\tilde{W}x$, åˆ†åˆ¥æ˜¯ quant å‰å¾Œçš„ output activations, å‰‡æˆ‘å€‘æœ‰ $\\tilde{y}=y+\\epsilon x$.ç”±æ–¼ quantization å¾Œå¯èƒ½ activations çš„åˆ†å¸ƒ mean å€¼ä¸æœƒè·ŸåŸä¾†ä¸€æ¨£, i.e. å¯èƒ½æœƒ $\\mathbb{E}[\\epsilon x]\\neq0$, ä½†å¯ä»¥é€éä¸‹å¼è¢«çŸ¯æ­£å›ä¾†: $\\mathbb{E}[y]=\\mathbb{E}[\\tilde{y}]-\\epsilon\\mathbb{E}[x]$æ‰€ä»¥åªéœ€è¦å° quant å®Œçš„ output åŠ ä¸Š $-\\epsilon\\mathbb{E}[x]$, ä½†å¯¦å‹™ä¸Šä¸æœƒé€™éº¼åš, è€Œæ˜¯åšåœ¨ bias parameter è£¡ (bias åŠ ä¸Š $-\\epsilon\\mathbb{E}[x]$).ä¸éæˆ‘å€‘æ€éº¼æœƒçŸ¥é“ input activation çš„æœŸæœ›å€¼, $\\mathbb{E}[x]$?åšå®Œä¸Šè¿° CLE + bias absorption ä¸¦å¾—åˆ°é‡åŒ– model å¾Œè·ŸåŸæœ¬ float model æ¯”è¼ƒå¯ä»¥å¾—åˆ° $\\epsilon$, å¦‚æœæœ‰ representative data (å¯ä»¥æ˜¯ unlabeled) æƒ…æ³ä¸‹, å‰‡ä¸Ÿ data å»è¨ˆç®— $\\mathbb{E}[x]$ å°±å¯ä»¥äº†. æ³¨æ„è¦æŒ‰ç…§ layer åš, ä¹Ÿå°±æ˜¯åš $l^{th}$ layer çš„ BC é …æ™‚, å‡è¨­ $1, 2,..,l-1$ layer çš„ BC é …éƒ½ apply ä¸Šå»äº†. é€™å«åš Empirical Bias Correction, è©³è¦‹è«–æ–‡ Appendix D. (åœ–ä¾†æºç‚º AIMET Post-Training Quantization Techniques)ä½†è«–æ–‡æ¨™é¡Œæ˜¯ â€œData-freeâ€, æ€éº¼è¾¦å‘¢? æ­¤æ™‚è«–æ–‡è¦æ±‚è¦æœ‰é€™æ¨£çš„ blocks é—œè¯: å·²çŸ¥ç›®å‰è¦è™•ç†çš„ layer æ˜¯ $\\tilde{y}=\\tilde{W}x$. è«–æ–‡å‡è¨­æ­¤ layer ä¹‹å‰é‚„æœ‰ BN and ReLU å…©å€‹ blocks. æ³¨æ„åˆ°éœ€æœ‰é€™æ¨£çš„é—œè¯å­˜åœ¨æ‰å¯ä»¥.è€Œ $\\mathbb{E}[x]$ å¯ä»¥åˆ©ç”¨ BN å¾Œ $x^{pre}$ æ˜¯ normal distribution çš„ç‰¹æ€§ä¾†ç®—. æ³¨æ„åˆ°ç¶“é ReLU å¾Œçš„ $x$ è®Šæˆ clipped normal distribution, è€Œå…¶ mean å¯ä»¥åˆ©ç”¨ BN çš„ shift and scale parameters å¯«å‡º closed form è§£.è©³ç´°ç›´æ¥åƒè€ƒè«–æ–‡, Appendix C æœ‰æ¨å°. é€™æ¨£çš„åšæ³•ç¨± Analytical Bias Correction. (åœ–ä¾†æºç‚º AIMET Post-Training Quantization Techniques) Experiments ç”±æ–¼ CLE and BA ç›®çš„æ˜¯è®“å¾Œé¢çš„ quantization æ¯”è¼ƒé©åˆ per-tensor, æ‰€ä»¥è¦è§€å¯Ÿä»¥ä¸‹å…©é»:&emsp;1. ç”¨äº† CLE and/or BA å¾Œ, ç”±æ–¼è¼¸å‡ºé‚„æ˜¯ float model, é‚£è·Ÿç”¨ä¹‹å‰çš„ float model æœ‰ç„¡ performance å½±éŸ¿?&emsp;2. ç”¨äº† CLE and/or BA å¾Œ, å†ç”¨äº† per-tensor é‡åŒ–å¾Œ, èƒ½å¦é€¼è¿‘åŸæœ¬ float model (æ²’ç”¨ CLE/BA) çš„ per-channel é‡åŒ–?çµæœ Table 1 é¡¯ç¤ºä»¥ä¸Šå…©é»éƒ½æ²’å•é¡Œ. å†ä¾†å¦‚æœåŠ å…¥ BC å‰‡è§€å¯Ÿèƒ½å¦è£œå„Ÿå›  quantization é€ æˆçš„ mean åç§»æå¤±? å…¶ä¸­å¯ä»¥çœ‹ quantization model æœ‰ç„¡å¥—ç”¨ CLE+BA.çµæœå¦‚ Table 2: Original model ç›´æ¥ç¡¬åš PTQ to INT8 æ˜¯æ…˜ä¸å¿ç¹çš„ random è¡Œç‚º, ä½†ç›´æ¥åŠ ä¸Š BC è£œå„Ÿå¾Œç«Ÿç„¶å°±å›åˆ° 52.02%!å¦‚æœå…ˆç”¨ CLE+BA åœ¨é‡åŒ–åˆ° INT8, performance ç‚º Table 1 çš„æœ€ä½³ 70.92%. é€™ç¨®æƒ…æ³å†åŠ ä¸Š BC é‚„èƒ½æå‡ä¸€é»é» (å¤šå°‘è¡¨ç¤ºå¯èƒ½é‚„æ˜¯å­˜åœ¨ä¸€é»é»çš„ mean åç§»)Clip@15 é€™å€‹æ–¹æ³•æ˜¯ç›´æ¥å° weights ç åˆ° [-15, 15] å€é–“, è·Ÿ CLE ç›®çš„ä¸€æ¨£åªæ˜¯ç›´æ¥ç²—æš´, ç•¶ç„¶ BC å°±èƒ½ç™¼æ®æ›´å¥½çš„ä½œç”¨ (2.55% â€”&gt; 70.43%).å‰©ä¸‹çš„å¯¦é©—å°±ä¸ç´°èªª. AIMET Quantization Flow ä»¥ä¸‹ç‚º AIMET AutoQuant å»ºè­°çš„é‡åŒ–æµç¨‹, ç¸½çµå¾—å¾ˆä¸éŒ¯: åœ–ä¸­çš„ CLE æˆ‘çŒœå·²ç¶“åŒ…å« BA äº†, ç„¶å¾Œå¯ä»¥çœ‹åˆ°æ²’æœ‰ BC, å› ç‚ºè¢« AdaRound å–ä»£æ‰ä¹Ÿæ³¨æ„åˆ°åœ¨çµ¦ CLE ä¹‹å‰è¦å…ˆåš BatchNorm folding (å¦‚åŒæˆ‘å€‘åœ¨è¬› CLE çš„é™åˆ¶ 2) æµç¨‹å°±æ˜¯å»ºè­°å…ˆå° floating model æ’å¥½ fake quant op ä¾†æ¨¡æ“¬ target HW çš„ operators è¡Œç‚º (QuantScheme Selection é‚£æ­¥). å…ˆçœ‹çœ‹æ•ˆæœå¦‚ä½•, å¦‚æœ OK é‚£ PTQ/QAT éƒ½ä¸éœ€è¦.æ¥è‘—æ‰ç¢ºèª BN folding æ˜¯å¦èƒ½å¹«åŠ©æå‡æ•ˆæœ? ä¸è¡Œçš„è©±å¥—çœ‹çœ‹ PTQ çš„ CLE (w/wo AdaRound). å†ä¸è¡Œå°±è¦èµ° QAT äº†. åˆ°é€™çµ‚æ–¼ç´€éŒ„å®Œ, é€™ç¯‡åˆçœ‹æ„Ÿè¦ºæ‡‰è©²å¯ä»¥å¾ˆå¿«çœ‹å®Œ, ä¸€è®€æ‰ç™¼ç¾ç´°ç¯€çœŸçš„æœ‰å¤ å¤š, é —ä¸å®¹æ˜“. ä¹Ÿå› ç‚ºå¾ˆèªçœŸç´°è®€æ‰ç™¼ç¾å…¶å¯¦æœ‰ä¸å°‘é™åˆ¶. ä¸éé‚„æ˜¯å¾ˆæœ‰æ”¶ç©«æ‹‰~ç¸½ä¹‹æ­å–œè®€è€…(è‡ªå·±?)æœ‰è€å¿ƒçœ‹å®Œ(å¯«å®Œ). ~~ æ’’èŠ±æ”¶å·¥ ~~ Appendix è­‰æ˜ CLE çš„æœ€ä½³è§£ Render çˆ›æ‰äº†, ç›´æ¥æ€’è²¼åœ–â€¦ References Data-Free Quantization Through Weight Equalization and Bias Correction, [arxiv] Up or Down? Adaptive Rounding for Post-Training Quantization, [arxiv] AI Model Efficiency Toolkit (AIMET)","tags":[{"name":"Post Training Quantization (PTQ)","slug":"Post-Training-Quantization-PTQ","permalink":"https://bobondemon.github.io/tags/Post-Training-Quantization-PTQ/"},{"name":"Quantization Aware Training (QAT)","slug":"Quantization-Aware-Training-QAT","permalink":"https://bobondemon.github.io/tags/Quantization-Aware-Training-QAT/"},{"name":"Data Free Quantization (DFQ)","slug":"Data-Free-Quantization-DFQ","permalink":"https://bobondemon.github.io/tags/Data-Free-Quantization-DFQ/"},{"name":"AIMET","slug":"AIMET","permalink":"https://bobondemon.github.io/tags/AIMET/"}]},{"title":"Quantization Error (Case with Clipping)","date":"2023-11-04T02:57:38.000Z","path":"2023/11/04/Quantization-Error-Case-with-Clipping/","text":"ä¸Šä¸€ç¯‡æ–‡ç« æˆ‘å€‘æåˆ°, uniformly constrained quantizer æœ‰é€™æ¨£çš„ quantization error:$$\\begin{align} J=s_{\\text max}^2{4^{-B}\\over 3} \\end{align}$$ å…¶ä¸­ $s_{\\text {max}}$ è¡¨ç¤º input $x$ åœ¨ $[-s_{\\text {max}}, s_{\\text {max}}]$ä¹‹é–“.é€™éº¼åšé›–ç„¶èƒ½ç¢ºä¿æ‰€æœ‰ $x$ éƒ½ä¸æœƒç™¼ç”Ÿ clipping error, ä½†å¦‚æœæœ‰ä¸€äº› outlier å‰‡æœƒä½¿å¾— quantization step è®Šå¾ˆå¤§ (quantization resolution è®Šä½), å› æ­¤ quantization çš„é›¢æ•£åŒ–èª¤å·® (discretization error) è®Šå¤§. Quantization error = (Discretization error) + (Clipping error) èˆ‰ä¾‹ä¾†èªª, è€ƒæ…®ä¸‹åœ– (ref. from SongHan course EfficientML.ai Lecture 6):ä¸Šåœ–å·¦æ˜¯ clipping scalar è¨­å®šå¾ˆå¤§, ä¸Šåœ–å³å‰‡æ˜¯è¨­å®šå¾ˆå°. å¯ä»¥çœ‹è¦‹ discretization error è·Ÿ clipping error äº’ç‚º trade-off. é‚£éº¼å•é¡Œä¾†äº†, æ€éº¼è¨­å®š clipping scalar, æ‰æœƒä½¿å¾—æ•´é«”çš„ quantization error æœ€å°?é€™ç¯‡æ–‡ç«  â€œOptimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Trainingâ€ [arxiv] çµ¦å‡ºäº†ç†è«–å€¼, ä¸¦ä½¿ç”¨ Newtonâ€™s method å¹«åŠ©æˆ‘å€‘å¾ˆå¿«æ‰¾åˆ°æœ€ä½³è§£. Empirical Quantization Error Fake quantization çš„éç¨‹ç‚º:$$\\begin{align} \\mathcal{Q}(x; s) = \\text{clip}\\left( s\\cdot 2^{1-B}\\cdot \\text{round}\\left(x\\cdot 2^{B-1}/s\\right), -s, s \\right) \\end{align}$$ å…¶ä¸­ $B$ è¡¨ç¤ºæˆ‘å€‘ä½¿ç”¨çš„ quantization bit æ•¸, $s$ ç‚º clipping scalar. é€™è£¡å‡è¨­ä½¿ç”¨ symmetric quantization, i.e. zero point = 0.å› æ­¤ empirical çš„ error å¯ä»¥ç›´æ¥è¨ˆç®—å¦‚ä¸‹:$$\\begin{align} J_{em}(s)=\\mathbb{E}\\left[(\\mathcal{Q}(X; s)-X)^2\\right] \\end{align}$$ æˆ‘å€‘å° resnet-50 çš„ layer #17, #45 çš„ weights è¨ˆç®— empirical quantization error. (ç‚ºäº†é©—è­‰è«–æ–‡è£¡çš„ Figure 1 (a))å…ˆçœ‹ä¸€ä¸‹ layers #17, #45 çš„ weight åˆ†ä½ˆ:è¨ˆç®— $J_{em}(s)$ ä½¿ç”¨ $B=4$-bits å¾—åˆ°å¦‚ä¸‹çµæœ:é€™å€‹ error æ›²ç·šçœ‹èµ·ä¾†å¾ˆæ£’å•Š, å¦‚æœæ˜¯ convex function å‰‡å¯ä»¥å¾ˆæœ‰æ•ˆç‡åœ°æ‰¾åˆ° clipping scalar çš„æœ€ä½³è§£.ç†è§£ä¸€ä¸‹é€™å€‹æ›²ç·šä¸é›£ç™¼ç¾ç•¶ clipping scalar å¾ˆå°, error æœƒä¸Šå‡æ˜¯å› ç‚ºä¸»è¦ä¾†æºä¾†è‡ªæ–¼ clipping error.ä½†ç•¶ clipping scalar è®Šå¤§, å‰‡ clipping error æœƒè®Šå°ä½†æ˜¯ discretization error è®Šå¤§, å› æ­¤æ‰æœƒæœ‰ä¸€å€‹ç”œèœœé»æ˜¯æœ€å°å€¼.è¨ˆç®— empirical error ä¸»è¦å‡½å¼å¦‚ä¸‹: 12345678910111213141516def cal_qerror(w, qstepsize, zero, bit_num): quant_min, quant_max = -(2 ** (bit_num - 1)), 2 ** (bit_num - 1) - 1 w_q = torch.fake_quantize_per_tensor_affine(torch.as_tensor(w), qstepsize, zero, quant_min, quant_max).numpy() return w - w_qdef do_empirical_qerror_scanning(w, qstepsize, zero, bit_num=4, scalar_num=200, plot_ratio=7.0): # `qstepsize` stands for quantization step size qerrors = [] clipping_scalars = np.linspace(1e-2, qstepsize * plot_ratio, scalar_num) # for loop for each clipping scalar for cs in clipping_scalars: qerror = cal_qerror(w, 2 * cs / 2**bit_num, zero, bit_num) qerrors.append(np.mean(qerror**2)) return qerrors, clipping_scalars Theoretical Quantization Error Quantization çš„ MSE æˆ‘å€‘å¯ä»¥æ‹†æˆå…©éƒ¨åˆ†:$$\\begin{align} J_{th}(s)={4^{-B}\\over 3}s^2\\int_0^s f_{|X|}(x)dx + \\int_s^\\infty (s-x)^2 f_{|X|}(x)dx \\end{align}$$ å…¶ä¸­ $f_{|X|}(\\cdot)$ è¡¨ç¤º $|X|$ çš„ distribution åˆ†ä½ˆ.R.H.S. çš„ç¬¬ä¸€ã€äºŒé …åˆ†åˆ¥æ˜¯ discretization å’Œ clipping error, æ‡‰è©²ç®—å¥½ç†è§£.åªæ˜¯ç‰¹åˆ¥èªªæ˜ä¸€ä¸‹ä¹‹å‰æ¨å°çš„ discretization error æ˜¯åŸºæ–¼ error $(\\mathcal{Q}(x; s)-x)$ ç‚º uniformly distributed. (è«‹åƒè€ƒä¸Šä¸€ç¯‡æ–‡ç« ). å¦‚æœä¸åŒçš„ $f_{|X|}(\\cdot)$, æ˜¯å¦å°æ–¼ â€œ$(\\mathcal{Q}(x; s)-x)$ç‚º uniformly distributedâ€ é€™å€‹å‡è¨­å°±ä¸æˆç«‹å‘¢?æˆ‘èªç‚ºå¦‚æœ quantization resolution å¤ é«˜ (åˆ‡å¾—å¤ å¯†), å‰‡ error çš„æ•¸å€¼å…¶åˆ†ä½ˆæ‡‰è©²æœƒæ¥è¿‘ uniformly distributed. è«–æ–‡è£¡æœ‰é€™éº¼ä¸€æ®µè©±: For discretization noise, the term ${s^24^{-B}}/3$ does not require a priori knowledge of data distribution. It is obtained through sampling theory where quantization noise arises via approximating the neighborhood of a quantization level of any distribution as a local rectangle (Widrow &amp; KollarÂ´ , 2008, book: Quantization noise) Anyway, æˆ‘å€‘å¯ä»¥å°ä¸Šå¼æ”¹å¯«å¦‚ä¸‹:$$\\begin{align} J_{th}(s)= {4^{-B}\\over3}s^2\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] + \\mathbb{E}\\left[(s-|X|)^2\\mathbf{1}_{\\{|X|&gt;s\\}}\\right] \\\\ = J_1(s) + J_2(s)\\\\ \\end{align}$$ å…¶ä¸­ $\\mathbf{1}$ æ˜¯ indicator function, æ³¨æ„åˆ° $\\mathbf{1}_{\\{|X|\\leq s\\}}$ çš„è®Šæ•¸æ˜¯ $s$, å°æ–¼å›ºå®šçš„ $X$, $\\mathbf{1}_{\\{|X|\\leq s\\}}$ æ˜¯å€‹ step function, åªæœ‰ç•¶ $s\\geq|X|$ çš„æ™‚å€™ function å€¼æ‰æœƒæ˜¯ $1$, å…¶ä»–æƒ…æ³æ˜¯ $0$. æ­¤ step function çš„å¾®åˆ†ç‚º 0 almost everwhere. (æ•¸å­¸èªè¨€æ˜¯ â€œå¾®åˆ†ä¸ç‚º 0 çš„é›†åˆ, è©²é›†åˆçš„æ¸¬åº¦ç‚º $0$â€)æˆ‘å€‘ä½¿ç”¨ np.histogram ä¾†ç•«å‡º theoretical quantization error, ä¾†è·Ÿ empirical æ¯”è¼ƒ:å¯ä»¥ç™¼ç¾ theoretical and empirical error curves å¾ˆæ¥è¿‘! ğŸ‘ æ•¸å­¸çœŸæ¼‚äº®!è¨ˆç®— theoretical error ä¸»è¦å‡½å¼å¦‚ä¸‹: 123456789101112131415def theoretical_mse_qerror(w, clipping_scalar, bit_num, bins=500): hist, bin_edges = np.histogram(np.abs(w), bins=bins, density=False) hist = hist / np.sum(hist) # turn into probability mass (note that it is different with density) clip_start_idx = np.where(np.diff(bin_edges &gt; clipping_scalar))[0] clip_start_idx = 0 if len(clip_start_idx) == 0 else clip_start_idx[0] J1 = np.sum(hist[:clip_start_idx]) * (clipping_scalar**2 / (3 * 4**bit_num)) J2 = 0.0 for idx in range(clip_start_idx, len(hist)): prob_x_mass = hist[idx] x = (bin_edges[idx + 1] + bin_edges[idx]) / 2 J2 += (clipping_scalar - x) ** 2 * prob_x_mass return J1 + J2 æ‰¾å‡ºæœ€ä½³ Clipping Scalar æˆ‘å€‘è¨ˆç®—ä¸€ä¸‹ $J_1$ çš„ gradient:$$\\begin{align} J_1&apos;(s)={4^{-B}\\over3}\\cdot2 s\\cdot\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] + {4^{-B}\\over3}s^2\\frac{\\partial}{\\partial s}\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] \\\\ = {4^{-B}\\over3}\\cdot2 s\\cdot\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] + {4^{-B}\\over3}s^2\\mathbb{E}\\left[\\frac{\\partial}{\\partial s}\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] \\\\ ={4^{-B}\\over3}\\cdot2 s\\cdot\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] + 0 \\end{align}$$ (7) åˆ° (8) æ˜¯å› ç‚º expectation çš„è®Šæ•¸ç‚º $X$ è·Ÿ $s$ ç„¡é—œ, æ‰€ä»¥å¾®åˆ†è·Ÿ expectation å¯ä»¥äº’æ›.(9) æ˜¯å› ç‚ºä¹‹å‰èªªé, å› ç‚º $\\mathbf{1}_{\\{|X|\\leq s\\}}$ æ˜¯ step function, æ‰€ä»¥å…¶ gradient ç‚º $0$ almost everwhere.åŒç† $J_2$ çš„ gradient:$$\\begin{align} J_2&apos;(s) = \\frac{\\partial}{\\partial s}\\mathbb{E}\\left[ (s-|X|)^2\\mathbf{1}_{\\{|X|&gt;s\\}} \\right] = \\mathbb{E}\\left[ \\frac{\\partial}{\\partial s} \\left( (s-|X|)^2\\mathbf{1}_{\\{|X|&gt;s\\}} \\right) \\right] \\\\ =\\mathbb{E}\\left[ 2(s-|X|)\\mathbf{1}_{\\{|X|&gt;s\\}} + (s-|X|)^2\\frac{\\partial}{\\partial s}\\mathbf{1}_{\\{|X|&gt;s\\}} \\right] \\\\ = \\mathbb{E}\\left[ 2(s-|X|)\\mathbf{1}_{\\{|X|&gt;s\\}} + 0 \\right] \\end{align}$$ (12) æ˜¯å› ç‚ºä¹‹å‰èªªé, å› ç‚º $\\mathbf{1}_{\\{|X|&gt; s\\}}$ æ˜¯ step function, æ‰€ä»¥å…¶ gradient ç‚º $0$ almost everwhere.æ‰€ä»¥ $J_{th}$ çš„ gradient:$$\\begin{align} J_{th}&apos;(s)= {4^{-B}\\over3}\\cdot2 s\\cdot\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] + \\mathbb{E}\\left[ 2(s-|X|)\\mathbf{1}_{\\{|X|&gt;s\\}} \\right] \\end{align}$$ åŒæ¨£çš„æ¨å° $J_{th}&apos;&apos;$ ç‚º:$$\\begin{align} J_{th}&apos;&apos;(s) = {4^{-B}\\over3}\\cdot2 \\cdot\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s\\}}\\right] + 2\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|&gt;s\\}}\\right] \\end{align}$$ å› æ­¤æ ¹æ“š Newtonâ€™s method, $s_{n+1}=s_n-J_{th}&apos;(s)/J_{th}&apos;&apos;(s)$, å¾—åˆ°:$$\\begin{align} s_{n+1}=\\frac{\\mathbb{E}\\left[|X|\\cdot\\mathbf{1}_{\\{|X|&gt;s_n\\}}\\right]} { {4^{-B}\\over3}\\mathbb{E}\\left[\\mathbf{1}_{\\{|X|\\leq s_n\\}}\\right] + \\mathbb{E}\\left[\\mathbf{1}_{\\{|X|&gt;s_n\\}}\\right] } \\end{align}$$ å¯¦å‹™ä¸Š Newtonâ€™s method å¾ˆ robust, initial $s_1$ é¸æ“‡ $\\{0,s_{max},3\\sigma,4\\sigma,5\\sigma\\}$ éƒ½å¯ä»¥æœ‰æ•ˆæ”¶æ–‚. è«–æ–‡è£¡ç›´æ¥é¸æ“‡ $s_1=({\\sum_x|x|})/(\\sum_x\\mathbf{1}_{|x|&gt;0})$, ç›¸ç•¶æ–¼ $s_1=s_{max}$ iterates åˆ° $s_3$ çš„æƒ…æ³. æˆ‘å€‘å¯¦éš›ç”¨ Newtonâ€™s method è¨­å®š s_init=0.0 å’Œ 10 æ¬¡ iteration çš„çµæœå¦‚ä¸‹:ç¢ºå¯¦èƒ½æ‰¾å‡ºæœ€ä½³çš„ clipping scalar. åˆ°é€™è£¡ç®—æ˜¯è¤‡ç¾äº†è«–æ–‡è£¡çš„ Figure 1 (a) äº†.è¨ˆç®— optimal clipping scalar ä¸»è¦å‡½å¼å¦‚ä¸‹: 1234567891011def find_opt_by_Newton_method(weights, bit_num, cs_init=0.0, iter_num=10): # `cs` stands for `clipping scalar` weights_abs = np.abs(weights) cs_cur = cs_init for itr in range(iter_num): indicator_larger = weights_abs &gt; cs_cur indicator_smaller = weights_abs &lt;= cs_cur # should we ignore case with `==0`? numerator = np.sum(weights_abs[indicator_larger]) denominator = np.sum(indicator_smaller) / (3 * 4**bit_num) + np.sum(indicator_larger) cs_cur = numerator / denominator return cs_cur Short Summary å¸¸ç”¨çš„ uniform quantization åŒ…å«å…©å€‹åƒæ•¸ scale and zero_point, ä¸€èˆ¬å¯ä»¥ä½¿ç”¨ observer ä¾†çµ±è¨ˆå‡ºæ•¸å€¼åˆ†ä½ˆçš„æœ€å¤§æœ€å°å€¼é€²è€Œå¾—åˆ° clipping scalar (é€šå¸¸æœƒæ­é… moving averaging ä¾†æ¸›ç·© outlier çš„å½±éŸ¿).ä½†é€™æ¨£å¾—åˆ°çš„ quantization error æ²’æœ‰è¾¦æ³•ä¿è­‰æ˜¯æœ€å°çš„.æœ¬æ–‡ä»‹ç´¹çš„é€™ç¯‡è«–æ–‡æŠŠ quantization error çš„ç†è«–å€¼æ‰¾å‡ºä¾†, ä¸¦ä½¿ç”¨ Newtonâ€™s method éå¸¸æœ‰æ•ˆç‡çš„æ‰¾å‡ºæœ€ä½³ clipping scalar. ç”šè‡³å¯ä»¥é‘²åµŒåœ¨ QAT iteration ä¸­.å¦ä¸€æ–¹é¢, é€™ç¯‡è«–æ–‡æ‰¾çš„æœ€ä½³è§£è·Ÿä»»å‹™çš„ loss function $\\mathcal{L}$ ç„¡é—œ. å¦‚æœå¸Œæœ›è·Ÿ loss function æœ‰é—œ, å¯ä»¥è€ƒæ…®ä½¿ç”¨ LSQ+ æˆ– PACT çš„æ–¹å¼ä¾†å­¸ç¿’å‡º scale and zero_point.ç¸½ä¹‹é€™ç¯‡è«–æ–‡è®“æˆ‘å€‘å° uniform quantization çš„ error æœ‰äº†æ›´æ·±å…¥çš„ç†è§£, ä¹Ÿå¾ˆæ¼‚äº®å¾—æä¾›äº†é«˜æ•ˆæ±‚è§£æ–¹æ³•. References Optimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Training, [arxiv] SongHan course EfficientML.ai Lecture 6 è¤‡ç¾è«–æ–‡ Figure 1 (a) çš„ [Github] Learning Zero Point and Scale in Quantization Parameters [link]","tags":[{"name":"Quantization Error","slug":"Quantization-Error","permalink":"https://bobondemon.github.io/tags/Quantization-Error/"},{"name":"Linear Quantization","slug":"Linear-Quantization","permalink":"https://bobondemon.github.io/tags/Linear-Quantization/"},{"name":"Nonlinear Quantization","slug":"Nonlinear-Quantization","permalink":"https://bobondemon.github.io/tags/Nonlinear-Quantization/"},{"name":"OCTAV","slug":"OCTAV","permalink":"https://bobondemon.github.io/tags/OCTAV/"}]},{"title":"Quantization Error (Case without Clipping)","date":"2023-10-28T10:05:30.000Z","path":"2023/10/28/Quantization-Error-Case-without-Clipping/","text":"æˆ‘åœ¨é–±è®€é€™ç¯‡è«–æ–‡: â€œOptimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Trainingâ€ [arxiv] çš„æ™‚å€™, çœ‹åˆ°é€™å€‹å¼å­èªªæ˜ uniform constrained quantizer æœ‰é€™æ¨£çš„ quantization error:$$\\begin{align} J=s_{\\text max}^2{4^{-B}\\over 3} \\end{align}$$ ç•¶ä¸‹çœ‹å¾—æˆ‘ä¸€é ­éœ§æ°´, å¾Œä¾†æŸ¥äº†è³‡æ–™æ‰äº†è§£é€™å€‹ quantization error çš„æ¨å°, å› æ­¤ç­†è¨˜ä¸€ä¸‹. [ä¾†æº1], [ä¾†æº2] é€™è£¡è¦ç‰¹åˆ¥èªªæ˜ä¸€ä¸‹, é€™é‚Šçš„ quantization error æ²’æœ‰è€ƒæ…®è¶…éæœ€å¤§æœ€å°å€¼é€ æˆçš„ clipping error. å°‡ clipping error ä¸€èµ·è€ƒæ…®æ˜¯é–‹é ­èªªçš„é‚£ç¯‡è«–æ–‡æœƒæ¢è¨çš„æƒ…æ³. é€™æ¨£çš„ quantization error åˆ†æåœ¨å‚³çµ±è¨Šè™Ÿè™•ç†å¯ä»¥çœ‹åˆ°, ä¾‹å¦‚ analog è¨Šè™Ÿç¶“é ADC è®Šæˆ digital è¨Šè™Ÿå¾Œæœƒæœ‰ quantization æå¤±. å¦‚æœ quantization bit å¢åŠ  1 bit å‰‡ SNR å¢åŠ ç´„ 6dB. åˆå¦‚æœæ¡ç”¨ nonlinear quantization å‰‡å°éŸ³é‡è¼ƒä½çš„æƒ…æ³å…¶ SNR ææ˜‡æœƒæ¯” linear quantization å¥½. Nonlinear quantization åˆåˆ† $\\mu$-law (åŒ—ç¾ and æ—¥æœ¬) å’Œ A-law (æ­æ´² and å…¶ä»–). é€™äº›å…§å®¹åœ¨ä¸‹é¢çš„ç­†è¨˜éƒ½æœƒè§£é‡‹. Letâ€™s go~ Uniform Quantization ä»¤ quantization step size ç‚º $\\Delta v=s_{\\text max}/2^{B-1}$, å…¶ä¸­ $B$ ç‚º bit æ•¸, æ•¸å€¼ç¯„åœåœ¨ $[-s_{\\text max},s_{\\text max}]$ ä¹‹é–“. å‰‡ input $x$ å’Œ quantized $x_q$ çš„é—œä¿‚å¦‚ä¸‹åœ– (åœ–ç‰‡è£¡çš„ $m_p=s_{max}$): [ä¾†æº1]æˆ‘å€‘å°‡ quantization error $q=x-x_q$ ç•«å‡ºä¾†å‰‡å¦‚ä¸‹åœ–: [ä¾†æº1]æ‰€ä»¥ quantization error $q:=x-x_q$ æ•¸å€¼ç¯„åœåˆ†å¸ƒåœ¨ $[-\\Delta v/2, \\Delta v/2]$ ä¹‹é–“. åˆ°é€™é‚Šæ‡‰è©²éƒ½æ»¿æ¸…æ¥šçš„.æ­¤æ™‚åšäº†ä¸€å€‹å‡è¨­, å‡è¨­ $q$ çš„åˆ†å¸ƒæ˜¯ uniform distribution, æ‰€ä»¥ power of $q$ çš„æœŸæœ›å€¼ç‚º:$$\\begin{align} P_q=\\int_{-{\\Delta v}/2}^{\\Delta v/2} q^2{1\\over \\Delta v}dq \\\\ = {1\\over\\Delta v}\\left[{q^3\\over3}\\right]_{-{\\Delta v}/2}^{\\Delta v /2}=...= {\\color{orange}{(\\Delta v)^2\\over 12}} \\\\ = \\frac{(s_{\\text max}/2^{B-1})^2}{12} = s_{\\text max}^2\\frac{1}{12\\cdot2^{2(B-1)}} = {\\color{orange}{s_{\\text max}^2\\frac{4^{-B}}{3}}} \\end{align}$$ é–‹é ­é‚£å€‹å¥‡æ€ªçš„å¼å­å°±æ˜¯é€™éº¼ä¾†çš„. å¦å¤– SNR å¯ä»¥é€™éº¼è¡¨ç¤º:$$\\begin{align} \\text{SNR}=\\frac{\\text{Signal Power}}{\\text{Noise Power}} = \\frac{P_s}{P_q}=10\\log_{10}\\left(\\frac{3\\cdot4^B}{s_{max}^2}P_s\\right) \\\\ =10\\log_{10}\\left(3P_s/s_{max}^2\\right) + 20B\\log_{10}(2) \\approx \\alpha + 6B \\end{align}$$ å…¶ä¸­ $\\alpha$ èˆ‡ signal power æœ‰é—œ, å¯ä»¥ç™¼ç¾å¦‚æœå¢åŠ  1 bit çš„è¡¨ç¤ºèƒ½åŠ›, SNR èƒ½æå‡ç´„ 6dB. Non-uniform Quantization å¦å¤–è€ƒæ…®åˆ°ä¸€èˆ¬è¨Šè™Ÿæ•¸å€¼å¤§çš„åªå å°‘éƒ¨åˆ†, $s_{max}$ å®¹æ˜“è¢« outlier å½±éŸ¿, å› æ­¤ quantization error å°±æœƒæ¯”è¼ƒå¤§. å¦‚æœèªªæˆ‘å€‘å…ˆå°‡è¨Šè™Ÿåš nonlinear å£“ç¸® (compresser), i.e. æ•¸å€¼å¤§çš„æœƒè¢«åŠ æ¯”è¼ƒå¤š, æ•¸å€¼å°çš„å£“ä¸€é»å°±å¥½ (è¦‹ä¸‹åœ–), é€™æ¨£æ•¸å€¼é–“çš„å·®ç•°è®Šå°å¾Œ, å†ç¶“é linear quantization çš„è©±, quantization error å°±ä¸æœƒé‚£éº¼å¤§äº†.ç›¸å°çš„è§£ç¢¼çš„æ™‚å€™è¦åšæ“´å±• (expander).ç”±æ–¼åœ¨ transmitter/receiver ç«¯æˆ‘å€‘æœƒåš compress/expand, æ‰€ä»¥æˆ‘å€‘ç¨±ç‚º compander = compresser + expanderTelephone system (åŒ—ç¾å’Œæ—¥æœ¬): $\\mu=100$ for 7-bits (128 levels) $\\mu=255$ for 8-bits (256 levels) è€Œåœ¨æ­æ´²å’Œå…¶ä»–åœ°æ–¹ $A=87.7$ or $87.6$. References Ali Muqaibel: 6.4.1 Quantization, Part I: Uniform Quantization and PCM Generation [YouTube] Ali Muqaibel: 6.4.2 Quantization, part II: Non Uniform Quantization [YouTube] Optimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Training, [arxiv]","tags":[{"name":"Quantization Error","slug":"Quantization-Error","permalink":"https://bobondemon.github.io/tags/Quantization-Error/"},{"name":"Linear Quantization","slug":"Linear-Quantization","permalink":"https://bobondemon.github.io/tags/Linear-Quantization/"},{"name":"Nonlinear Quantization","slug":"Nonlinear-Quantization","permalink":"https://bobondemon.github.io/tags/Nonlinear-Quantization/"}]},{"title":"LoRAPrune, Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning ç­†è¨˜","date":"2023-10-09T09:29:38.000Z","path":"2023/10/09/Pruning-Meets-Low-Rank-Parameter-Efficient-Fine-Tuning-ç­†è¨˜/","text":"æœ¬æ–‡æ˜¯é€™ç¯‡è«–æ–‡ â€œLoRAPrune: Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning [arxiv]â€ çš„ç­†è¨˜. ä¸€èˆ¬ä¾†èªªä½¿ç”¨ first-order Taylor importance çš„ pruning æ–¹æ³• (ä¸‹é¢æœƒä»‹ç´¹æ­¤æ³•) éœ€è¨ˆç®— gradients ä¾†å°æ¯å€‹ weight è¨ˆç®—é‡è¦æ€§, ç„¶å¾Œæ ¹æ“šé‡è¦æ€§å‰ªæ. ä½†æ˜¯ç¾åœ¨æ¨¡å‹å·²ç¶“æ„ˆä¾†æ„ˆå¤§, å°æ‰€æœ‰ weights éƒ½é ˆè¨ˆç®— gradient çš„è² æ“”å¤ªå¤§. å¦ä¸€æ–¹é¢, åœ¨ LLM ä¸­å°æ–¼å¤§æ¨¡å‹çš„ fine tuning ä½¿ç”¨ LoRA (PEFT, Parameter Efficient Fine Tuning, çš„ä¸€ç¨®) ä¾†è¨ˆç®— gradients éå¸¸æœ‰æ•ˆç‡, åŸå› æ˜¯å°åŸä¾†çš„ weights æ˜¯ fixed çš„, åª train LoRA å¤–æ›çš„â€å°‘é‡â€åƒæ•¸, å› æ­¤åªæœ‰å°‘é‡çš„ gradients éœ€è¦è¨ˆç®—. ä¸éæˆ‘å€‘æ€è€ƒä¸€ä¸‹, å¦‚æœè¦å°å·²ç¶“ prune çš„ weights æ—é‚Šå¤–æ› LoRA çš„è©±, LoRA train å®Œå¾Œæ²’è¾¦æ³• merge å›å»åŸä¾†çš„ weights, å› ç‚ºæœ‰å¯èƒ½æ‰“äº‚åŸæœ¬è¦ prune çš„ä½ç½®. ä½†æ˜¯åéä¾†èªª, å¦‚æœå…ˆç”¨ LoRA fine tune å®Œæ‰é€²è¡Œå‰ªæ, åˆå›åˆ°ç•¶æ¨¡å‹å¤ªå¤§è€Œè² æ“”å¤ªå¤§æ²’æ•ˆç‡çš„å•é¡Œ. æ³ä¸”é€™æ¨£åˆ†å…©æ­¥é©Ÿå¯èƒ½ä¸æ˜¯å¾ˆç›´æ¥, å¦‚æœèƒ½åœ¨ LoRA fine tune æ™‚å°±èƒ½ä¸€ä½µè€ƒæ…®æŸäº› weights æœƒè¢« prune çš„æƒ…æ³ä¸‹å» fine tune å¯èƒ½æœƒæ›´å¥½. å¦‚ä½• pruning åŸä¾†çš„åƒæ•¸åˆèƒ½åˆ©ç”¨ä¸Š LoRA çš„æ•ˆç‡å°±æ˜¯æ­¤ç¯‡è«–æ–‡çš„å·¥ä½œ. $$\\begin{array}{|c |c |c |} \\hline &amp; èƒ½å¦å°åŸä¾†çš„åƒæ•¸åšå‰ªæ? &amp; æ˜¯å¦å¾ˆæœ‰æ•ˆç‡? \\\\ \\hline \\text{1st order pruning} &amp; \\text{Yes} &amp; \\text{No} \\\\ \\hline \\text{LoRA} &amp; \\text{No} &amp; \\text{Yes} \\\\ \\hline \\text{LoRAPrune} &amp; \\text{Yes} &amp; \\text{Yes} \\\\ \\hline \\end{array}$$ ä»¥ä¸‹æœƒå…ˆä»‹ç´¹ first-order Taylor importance çš„ pruning æ–¹æ³•, å†ä¾†ä»‹ç´¹ LoRA, æœ€å¾Œèªªæ˜å¦‚ä½•å–å…©è€…ä¹‹å„ªé»å¾—å‡ºæ­¤ç¯‡çš„æ–¹æ³•: LoRAPrune First-order Taylor Importance Pruning å° weight $w_{ij}$ çš„ importance score ä¼°è¨ˆ, æ˜¯ä»¥è©² weight è¢« prune æ‰çš„è©± ($w_{ij}=0$), å° loss æœ‰å¤šå°‘å½±éŸ¿ä¾†ç•¶ä¾æ“š, æ‰€ä»¥: $(W_0)_{ij}$ ç”¨ $w_{ij}$ è¡¨ç¤º $$\\begin{align} \\mathcal{I}_{ij}=(\\mathcal{L}(x,y,W_0)-\\mathcal{L}(x,y,W_0|w_{ij}=0))^2 \\end{align}$$ è¤‡ç¿’ä¸€ä¸‹ Taylor expansion$$f(x)=f(a)+{f&apos;(a)\\over 1!}(x-a)+{f&apos;&apos;(a)\\over 2!}(x-a)^2+{f&apos;&apos;&apos;(a)\\over 3!}(x-a)^3+...$$ æ‰€ä»¥$$\\mathcal{L}(W-\\delta W) = \\mathcal{L}(W) + \\nabla_W \\mathcal{L}^T\\cdot(-\\delta W) + {1\\over2}(-\\delta W)^T\\cdot(\\nabla_W^2 \\mathcal{L})\\cdot(-\\delta W) +... \\\\ \\Longrightarrow \\mathcal{L}(W)-\\mathcal{L}(W-\\delta W)= \\nabla_W \\mathcal{L}^T\\cdot(\\delta W) - {1\\over2}\\delta W^T\\cdot(\\nabla_W^2 \\mathcal{L})\\cdot\\delta W + ...$$ å‡è¨­äºŒæ¬¡é …ä¹‹å¾Œå½±éŸ¿éƒ½æ¯”ä¸€æ¬¡é …å°å¾ˆå¤š, å› æ­¤æˆ‘å€‘å¯ä»¥æŠŠåƒæ•¸ $w_{ij}$ çš„ importance score è¨­å®šæˆä¸€æ¬¡é …çš„ power:(é€™æ™‚çš„ $\\delta W=w_{ij}$)$$\\begin{align} \\mathcal{\\hat I}_{ij}=\\left( {\\partial\\mathcal{L}\\over\\partial w_{ij}}w_{ij} \\right)^2 \\end{align}$$ æˆ‘å€‘å°±æ ¹æ“š $\\mathcal{\\hat I}_{ij}$ ä¾†é€æ­¥å‰ªæä¸è¦çš„åƒæ•¸ LoRA LoRA (Low-Rank Adaptation) å…¬å¼ç‚º:$$\\begin{align} z=xW_0+xBA \\end{align}$$ å…¶ä¸­ $W_0\\in\\mathbf{R}^{d\\times k}$ æ˜¯åŸä¾† model çš„åƒæ•¸, $A\\in\\mathbf{R}^{r\\times k}$ and $B\\in\\mathbf{R}^{d\\times r}$ æ˜¯ LoRA çš„å…©å€‹ learnable low rank (rank $r$) åƒæ•¸.æœƒå°‡ $W_0$ fixed ä½, åªå­¸ $A$ and $B$, ä¸”ç”±æ–¼ rank $r$ é€šå¸¸éƒ½ä¸å¤§, å› æ­¤å¾ˆæœ‰æ•ˆç‡. æ³¨æ„åˆ°ç‚ºäº†ä¿è­‰ initial çš„æ™‚å€™ performance (output) è·ŸåŸä¾†ä¸€æ¨£, æœƒå°‡ $B$ initial æˆ $0$ matrix ($A$ random Guassian å³å¯)å­¸å®Œä¹‹å¾Œ, å¯å°‡ $A,B$ çš„åƒæ•¸ merge å› $W_0$, æ‰€ä»¥ inference ä¸æœƒå¢åŠ é¡å¤–è¨ˆç®—é‡$$\\begin{align} W=W_0+BA \\end{align}$$ LoRAPrune å¦‚æœè¦å°‡ $w_{ij}$ prune æ‰çš„è©±, ç›¸ç•¶æ–¼è¨­å®š $(BA)_{ij}=-w_{ij}$, æ‰€ä»¥ importance score (1) æ”¹å¯«å¦‚ä¸‹:$$\\begin{align} \\mathcal{I}_{ij}=(\\mathcal{L}(x,y,W_0)-\\mathcal{L}(x,y,W_0|(BA)_{ij}=-w_{ij}))^2 \\end{align}$$ å¦‚åŒä¸Šé¢ä¸€æ¨£ first order Taylor approximation ç‚º: $$\\begin{align} \\mathcal{\\hat I}_{ij}=\\left( {\\partial\\mathcal{L}\\over\\partial (BA)_{ij}}((BA)_{ij}+w_{ij}) \\right)^2 \\end{align}$$ æ³¨æ„åˆ° $W_0$ æ˜¯ fixed ä½, è€Œ $A,B$ æ‰æ˜¯ learnable parameters, æ‰€ä»¥æ˜¯å° $(BA)_{ij}$ åå¾®åˆ†å…¶ä¸­ç”±æ–¼ SGD update å…¬å¼çš„é—œä¿‚, (6) çš„åå¾®åˆ†é‚£é …å¯é€™éº¼çœ‹å¾…:$$\\begin{align} {\\partial\\mathcal{L}\\over\\partial(BA)_{ij}}\\propto (BA)_{ij}|_t - (BA)_{ij}|_{t+1} \\end{align}$$ $t$ ç‚ºç•¶ä¸‹çš„ weights, $t+1$ æ˜¯è¦ update çš„ SGD iteration, ç¹¼çºŒæ‹†è§£å¦‚ä¸‹:$$\\begin{align} {\\partial\\mathcal{L}\\over\\partial(BA)_{ij}}\\propto\\left[ B_{i:}A_{:j}- \\left(B_{i:}-\\frac{\\partial\\mathcal{L}}{\\partial B_{i:}}\\right) \\left(A_{:j}-\\frac{\\partial\\mathcal{L}}{\\partial A_{:j}}\\right) \\right] \\\\ =\\left[ \\frac{\\partial\\mathcal{L}}{\\partial B_{i:}}A_{:j} + B_{i:}\\frac{\\partial\\mathcal{L}}{\\partial A_{:j}} - \\frac{\\partial\\mathcal{L}}{\\partial B_{i:}}\\frac{\\partial\\mathcal{L}}{\\partial A_{:j}} \\right] \\end{align}$$ å°‡ (9) ä»£å› (6) å¾—åˆ°:$$\\begin{align} \\mathcal{\\hat I}_{ij}=\\left( (\\nabla B \\cdot A + B\\cdot\\nabla A - \\nabla B\\cdot\\nabla A)\\odot(BA+W_0) \\right)^2 \\end{align}$$ å…¶ä¸­ $\\odot$ è¡¨ç¤º element-wised ç›¸ä¹˜, åˆ°é€™è£¡æˆ‘å€‘ç™¼ç¾åªä½¿ç”¨ $A,B$ çš„ gradients, å› æ­¤ä¿æœ‰äº† LoRA æ•ˆç‡çš„å¥½è™•. ğŸ’¡ ç¸½çµä¸€ä¸‹ç²¾ç¥: åŸä¾†æ‰€æœ‰ weights çš„ first-order Taylor importance scores $\\mathcal{I}_{ij}$ (å¼ 5) åœ¨ fine tune LoRA æ™‚ä½¿ç”¨å®ƒçš„â€å°‘é‡â€åƒæ•¸çš„ gradients ä¾†é€¼è¿‘ $\\mathcal{\\hat I}_{ij}$ (å¼ 10), é€™æ¨£è¨ˆç®— importance score æ²’æ•ˆç‡çš„æƒ…å½¢å°±èƒ½è¢«æ”¹å–„. Progressive LoRAPrune åœ¨è¨ˆç®— forward and backward çš„æ™‚å€™æ˜¯ä½¿ç”¨ masking çš„æ–¹å¼è¨ˆç®—:$$\\begin{align} z=(xW_0+xBA)\\odot M \\end{align}$$ å…¶ä¸­ $M$ æ˜¯ binary mask, æ˜¯æ ¹æ“š importance score $\\mathcal{\\bar I}$ è¨ˆç®—å¾—åˆ°, è€Œ $\\mathcal{\\bar I}$ åªæ˜¯å€‹ smoothed éå¾Œçš„ $\\mathcal{\\hat I}$ (10) è€Œå·²$$\\begin{align} \\mathcal{\\bar I}|_t=\\lambda\\mathcal{\\bar I}|_{t-1}+(1-\\lambda)\\mathcal{\\hat I}|_t \\end{align}$$ æ³¨æ„åˆ°ç”±æ–¼ç›´æ¥ä¹˜ mask $M$, æ²’æœ‰ç‰¹åˆ¥ä½¿ç”¨ STE ä¾†è®“ mask = 0 çš„åœ°æ–¹çš„ gradient æµé€š, å› æ­¤è¢« mask çš„ $i,j$ æœƒæ²’æœ‰ gradients, ä½†å…¶å¯¦ $B_{i:}$ æˆ– $A_{:j}$ é‚„æ˜¯æœ‰æ©Ÿæœƒè¢«å…¶ä»–ä½ç½®çš„ gradients æ›´æ–°åˆ°, ä¾‹å¦‚ $M_{ik}\\neq0$ å‰‡ $B_{i:}$ é‚„æ˜¯æœƒè¢« update, $M_{lj}\\neq0$ å‰‡ $A_{:j}$ ä¹Ÿæœƒè¢« update, ç¶œåˆèµ·ä¾† $(BA)_{ij}$ ä¹Ÿè¢«æ”¹è®Šäº†. ä¹Ÿå› æ­¤å°±ç®— $M_{ij}=0$, $w_{ij}$ é‚„æ˜¯æœ‰æ•—éƒ¨å¾©æ´»çš„æ©Ÿæœƒ. æ‰€ä»¥ progressive LoRAPrune æµç¨‹å¦‚ä¸‹ è«–æ–‡å¾Œé¢æœ‰äº›å¯¦é©—å¾ˆæœ‰æ„æ€, ä¾‹å¦‚ä½¿ç”¨ $\\frac{\\partial\\mathcal{L}}{\\partial w_{ij}}$ ä¾†æ›¿æ› (6) ä¸­çš„ $\\frac{\\partial\\mathcal{L}}{\\partial (BA)_{ij}}$. å†è«‹æœ‰èˆˆè¶£çš„è®€è€…è‡ªè¡Œé–±è®€è«–æ–‡. References LoRAPrune: Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning [arxiv] LoRA: Low-Rank Adaptation of Large Language Models [arxiv]","tags":[{"name":"Pruning","slug":"Pruning","permalink":"https://bobondemon.github.io/tags/Pruning/"},{"name":"LoRA","slug":"LoRA","permalink":"https://bobondemon.github.io/tags/LoRA/"},{"name":"PEFT","slug":"PEFT","permalink":"https://bobondemon.github.io/tags/PEFT/"},{"name":"LoRAPrune","slug":"LoRAPrune","permalink":"https://bobondemon.github.io/tags/LoRAPrune/"}]},{"title":"Movement Pruning Adaptive Sparsity by Fine-Tuning ç­†è¨˜","date":"2023-02-24T14:47:40.000Z","path":"2023/02/24/Movement-Pruning-Adaptive-Sparsity-by-Fine-Tuning-ç­†è¨˜/","text":"å…ˆå¼•ç”¨é€™ç¯‡è«–æ–‡çš„è«–é» Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers [pdf] åŒæ¨£çš„å° model size, å¾é ­è¨“ç·´é‚„ä¸å¦‚å…ˆç”¨å¤§çš„ model size åšå‡ºå¥½æ•ˆæœ, å†å£“ç¸®åˆ°éœ€è¦çš„å¤§å°æ‰€ä»¥ pruning ä¸åƒ…èƒ½å£“å° model size, åŒæ¨£å° performance å¯èƒ½ä¹Ÿæ˜¯å€‹å¥½ç­–ç•¥ Introduction ä½¿ç”¨å–®ç´”çš„ absolutely magnitude pruning å°æ–¼åœ¨ SSL model ä¸å¥½. å› ç‚ºåŸä¾†çš„ weight æ˜¯å° SSL çš„ loss è¨ˆç®—çš„, ä¸¦ä¸èƒ½ä¿è­‰å¾Œä¾†çš„ fine tune (down stream task loss) æœ‰ä¸€æ¨£çš„é‡è¦æ€§é—œè¯.ä¾‹å¦‚å‚³çµ±ä¸Šçš„ magnitude pruning ä½œæ³•, å¦‚é€™ä¸€ç¯‡ 2015 NIPS æ–‡ç«  [Learning both Weights and Connections for Efficient Neural Networks] (cited 5xxx) ä½œæ³•å¾ˆç°¡å–®:&emsp;å…ˆå° model train åˆ°æ”¶æ–‚, ç„¶å¾Œ prune, æ¥è‘—ç¹¼çºŒè¨“ç·´ (prune çš„ weight å°± fix ç‚º $0$), ç„¶ä¾¯å†å¤š prune â€¦ iterative ä¸‹å»åˆ°éœ€è¦çš„ prune æ•¸é‡ä½†ä½œè€…èªç‚º, åªé  magnitude å¤§å°åˆ¤æ–·æ•ˆæœä¸å¥½, å› ç‚ºåœ¨ fine tune éç¨‹ä¸­, å¦‚æœæŸä¸€å€‹ weight é›–ç„¶ magnitude å¾ˆå¤§, ä½† gradient update å¾Œå‚¾å‘æŠŠ magnitude è®Šå°, å°±è¡¨ç¤ºå®ƒé‡è¦æ€§æ‡‰è©²é™ä½æ‰å°, é€™æ˜¯æœ¬ç¯‡çš„ç²¾è¯æ€æƒ³ å› æ­¤æˆ‘å€‘å…ˆå®šç¾©é‡è¦æ€§å°±æ˜¯ä»£è¡¨ weight çš„ magnitude æœƒè®Šå¤§é‚„æ˜¯è®Šå°, è®Šå¤§å°±æ˜¯é‡è¦æ€§å¤§, åä¹‹ å› æ­¤ä½œè€…å°æ¯ä¸€å€‹åƒæ•¸éƒ½å¼•å…¥ä¸€å€‹ score, å‘½ç‚º $S$, å¸Œæœ›èƒ½ä»£è¡¨ weight çš„é‡è¦æ€§. è€Œåœ¨ fine-tune çš„éç¨‹, é™¤äº†å° weight $W$ update ä¹‹å¤–, score $S$ ä¹Ÿæœƒ updateå¦‚æœ score $S$ æ­£å¥½èƒ½åæ˜  weight çš„ gradient å‚¾å‘, å³ $S$ æ„ˆå¤§å‰›å¥½è¡¨ç¤ºè©²å°æ‡‰çš„ weight åœ¨ fine-tune éç¨‹æœƒå‚¾å‘è®“ magnitude è®Šå¤§, åä¹‹äº¦ç„¶, é‚£é€™æ¨£çš„ $S$ æ­£å¥½å°±æ˜¯æˆ‘å€‘è¦æ‰¾çš„. è¦é€™éº¼åšçš„è©±, æˆ‘å€‘é‚„éœ€è¦å›ç­”å…©å€‹å•é¡Œ: æ€éº¼å¼•å…¥ score $S$? Score $S$ æ­£å¥½èƒ½ä»£è¡¨é‡è¦æ€§? æ›å¥è©±èªªèƒ½åæ˜  weight åœ¨ fine tune éç¨‹çš„ magnitude å‚¾å‘å—? æ€éº¼å¼•å…¥ score $S$? é¦–å…ˆ, çœ‹ä¸€ä¸‹ $W$ and $S$ çš„ gradients Forward: $$a=(W\\odot M)x$$ $W$æ˜¯ weight matrix, è€Œ $M$æ˜¯ mask matrix æ¯ä¸€å€‹ element $\\in\\{0,1\\}$, $M$ é€šå¸¸æ˜¯å¾ä¸€å€‹ score matrix $S$ æ­é…ä¸Š masking function e.g. $\\text{Top}_v$ è€Œä¾†:$$M_{ij}=\\text{Top}_v(S)_{ij}=\\left\\{ \\begin{array}{ll} 1, &amp; S_{ij}\\quad\\text{in top }v\\% \\\\ 0, &amp; \\text{o.w.} \\end{array} \\right.$$ è€Œ magnitude based pruning å®šç¾© $S_{ij}=|W_{ij}|$ç®— $W$ çš„ gradients:$$\\begin{align} \\frac{\\partial L}{\\partial W_{ij}}=\\frac{\\partial L}{\\partial a_i}M_{ij}x_{j} \\end{align}$$ è€Œç®— $S$ çš„ gradients æ™‚ç™¼ç¾å› ç‚º $\\text{Top}_v$ ç„¡æ³•å¾®åˆ†æ‰€ä»¥ç”¨ straight-through estimator (STE), i.e. å‡è£æ²’æœ‰ $\\text{Top}_v$ é€™å€‹ function. ä¿®æ”¹ç‚ºå¯å¾®åˆ†çš„ forward: æ”¹æˆè®“ forward å‡è£æ²’æœ‰é $\\text{Top}_v$ (å› ç‚º $\\text{Top}_v$ ç„¡æ³•å¾®åˆ†):$$a=(W\\odot {\\color{orange}S})x$$ æ‰€ä»¥ $S$ çš„ gradients:$$\\begin{align} \\frac{\\partial L}{\\partial S_{ij}} = \\frac{\\partial L}{\\partial a_i}\\frac{\\partial a_i}{\\partial S_{ij}}=\\frac{\\partial L}{\\partial a_i}W_{ij}x_j \\end{align}$$ æ‰€ä»¥ $S$ ä»ç„¶æœƒè¢« update, å°±ç®—å°æ‡‰çš„ weight å·²ç¶“åœ¨ forward è¢« mask äº† é€™ç¨®ä½œæ³•ç¨± Straigth Through Estimator (STE)Appendix A.1 è­‰æ˜ training loss æœƒæ”¶æ–‚ (åŸè«–æ–‡æœ‰å¹¾å€‹æ¨å°ç•¶ä¸‹æ²’çœ‹æ‡‚, å¾Œä¾†è‡ªå·±è£œè¶³äº†ä¸€äº›æ¨å°, è¦‹æœ¬æ–‡æœ€å¾Œé¢æ®µè½) Score $S$ èƒ½ä»£è¡¨é‡è¦æ€§? å…ˆå›é¡§ä¸€å€‹è§€å¿µ$$\\frac{\\partial \\mathcal{L}}{\\partial W_{ij}}&gt;0$$ è¡¨ç¤º loss function $\\mathcal{L}$ èˆ‡ $W_{ij}$ æ–¹å‘ä¸€è‡´, æ›å¥è©±èªª $$W_{ij}\\uparrow \\iff \\mathcal{L}\\uparrow \\\\ W_{ij}\\downarrow \\iff \\mathcal{L}\\downarrow \\\\$$ å¦‚æœ$$\\frac{\\partial \\mathcal{L}}{\\partial W_{ij}}&lt;0$$ å‰‡è¡¨ç¤ºæ–¹å‘ç›¸åæˆ‘å€‘ç¾åœ¨è§€å¯Ÿ $S$ å’Œ $W$ åœ¨ update æ™‚å€™ä¹‹é–“çš„é—œä¿‚, ç”± (1) and (2) çš„é—œä¿‚å¯ä»¥å¯«æˆå¦‚ä¸‹:$$\\begin{align} \\frac{\\partial L}{\\partial S_{ij}} = \\frac{\\partial L}{\\partial W_{ij}}W_{ij} / M_{ij} \\end{align}$$ é¦–å…ˆæˆ‘å€‘æ³¨æ„åˆ°å¦‚æœ $\\partial L / \\partial S_{ij} &lt; 0$, è¡¨ç¤º $L$ å’Œ $S_{ij}$ æ–¹å‘ç›¸å, å› ç‚ºæˆ‘å€‘å¸Œæœ› $L\\downarrow$, æ‰€ä»¥æ­¤æ™‚ $S_{ij}\\uparrow$.è¦è®“ $\\partial L / \\partial S_{ij} &lt; 0$ æ ¹æ“š (3) åªæœƒæœ‰å…©ç¨®æƒ…å½¢ (æˆ‘å€‘ä¸ç®¡ $M_{ij}$, å› ç‚ºå®ƒ $\\geq0$):&emsp;Case 1: $\\partial L / \\partial W_{ij} &lt; 0$ and $W_{ij}&gt;0$. Weight æ˜¯æ­£çš„, ä¸”å®ƒçš„è¡Œç‚ºè·Ÿ $L$ æ–¹å‘ç›¸å. æ‰€ä»¥æ›´æ–°å¾Œ weight æœƒè®Šå¾—æ›´å¤§ (away from zero)&emsp;Case 2: $\\partial L / \\partial W_{ij} &gt; 0$ and $W_{ij}&lt;0$. Weight æ˜¯è² çš„, ä¸”å®ƒçš„è¡Œç‚ºè·Ÿ $L$ æ–¹å‘ç›¸åŒ. æ‰€ä»¥æ›´æ–°å¾Œ weight æœƒè®Šå¾—æ›´å° (close to zero)ä¸Šè¿°å…©ç¨® weight éƒ½æœƒé›¢ $0$ æ„ˆä¾†æ„ˆé  (magnitude æœƒè®Šæ›´å¤§).çµè«–å°±æ˜¯ update éç¨‹å¦‚æœ $S_{ij}\\uparrow$ è¡¨ç¤º $W_{ij}$ é é›¢ $0$.åŒæ¨£çš„æ¨ç†, å¦‚æœ $\\partial L / \\partial S_{ij} &gt; 0$, è¡¨ç¤º $S_{ij}\\downarrow$ çš„æƒ…å½¢ç™¼ç”Ÿåœ¨ $W_{ij}$ æ›´é è¿‘ $0$ äº†.æ‰€ä»¥æˆ‘å€‘å¾—åˆ°ä¸€å€‹çµè«–:&emsp;å› ç‚º $S$ å‡é«˜å°æ‡‰åˆ° $|W|$ è®Šå¤§; $S$ é™ä½å°æ‡‰åˆ° $|W|$ è®Šå°. æ‰€ä»¥åˆç†èªç‚º $S$ ä»£è¡¨çš„æ˜¯é‡è¦æ€§ æœ‰æ„æ€çš„æ˜¯, ä¸Šè¿°çµè«–ä¼¼ä¹è·Ÿ masking function æ˜¯å¦ç”¨ $\\text{Top}_v$ ç„¡é—œæ„æ€æ˜¯å¦‚æœ masking function ç”¨ $\\text{Bottom}_v$ (é¸æœ€å°çš„é‚£ $v\\%$) ä¹Ÿæœƒæœ‰ â€œ$S$ å‡é«˜å°æ‡‰åˆ° $W$ è®Šå¤§; $S$ é™ä½å°æ‡‰åˆ° $W$ è®Šå°, å› æ­¤ $S$ æ˜¯é‡è¦æ€§â€ é€™å€‹çµè«–ä½†æ€éº¼æ„Ÿè¦ºå“ªè£¡æ€ªæ€ªçš„ä¸éå…¶å¯¦é‚è¼¯ä¸Šä¸è¡çª, æˆ‘é€™é‚Šçš„ç†è§£æ˜¯é€™æ¨£çš„:Score $S$ ä»£è¡¨é‡è¦æ€§æ˜¯æ²’å•é¡Œçš„, åªæ˜¯é€™å€‹é‡è¦æ€§ç¾åœ¨åªé‡å° $\\text{Bottom}_v$ çš„é‚£äº› weights å»çœ‹åŒæ™‚, Appendix A.1 è­‰æ˜ loss èƒ½æ”¶æ–‚ä¹Ÿæ˜¯åŸºæ–¼ $\\text{Top}_v$ èƒ½å¾—åˆ°ä¿è­‰, å› æ­¤ç”¨ $\\text{Bottom}_v$ æä¸å¥½æ”¶æ–‚ä¸èµ·ä¾† $S$ çš„æ›´æ–°éç¨‹å¯ä»¥è¦–ç‚º movement (é‡è¦æ€§) çš„ç´¯ç© (åªè¦åˆå§‹çµ¦ $0$ ??) Results åœ¨ low sparsity (more than 70% of remaining weights), magnitude pruning æ¯” movement pruning å¥½åœ¨ high sparsity (less than 15% of remaining weights), å‰‡ movement pruning å¥½å¾—å¾ˆæ˜é¡¯ ç¸½é«”ä¾†èªªåœ¨ high sparsity case, Soft movement pruning (SMvP) &gt; Movement Pruning (MvP) &gt; L0 regularization &gt; Magnitude Pruning (MaP)ä½œè€…å¼·èª¿äº†ä¸€ä¸‹ MvP or SMvP æ¯” L0 ç°¡å–®åˆæ›´å¥½æœ€å¾Œä½œè€…åœ¨ pruning éç¨‹ä¸­åŠ äº† distillation loss, é¡¯ç¤º distillation å°æ‰€æœ‰ pruning methods éƒ½æœ‰å¹«åŠ©. Fig 4(a) ä¸æ„å¤–Fig 4(b) æ¯”è¼ƒæœ‰æ„æ€, score å¤§çš„é‚£äº› weight éƒ½ä¸æœƒ $0$ é è¿‘ (v-shape)ä½œè€…å¯¦é©—äº† global/local NN çš„ pruning, ä¹‹å‰æ˜¯èªª global è®“ NN è‡ªå·±æ±ºå®šæ¯å€‹ layers è¦ prune å¤šå°‘æ¯”ä¾‹, æ‰€ä»¥é€šå¸¸æ¯”è¼ƒå¥½ (å°¤å…¶åœ¨ high sparsity)ä½†ä½œè€…åœ¨è‡ªå·±çš„å¯¦é©—, ç™¼ç¾å…©è€…åœ¨æ•ˆæœä¸Šæ²’å¤ªå¤§å·®ç•°æœ€å¾Œåˆ†æä¸€ä¸‹æ¯å€‹ layer çš„ sparsity, ç™¼ç¾åœ¨æ„ˆå¾Œé¢çš„ layer prune æ„ˆå¤š Codes HuggingFace æœ‰å¯¦ç¾é€™æ®µ codes: 1234567891011121314151617class TopKBinarizer(autograd.Function): @staticmethod def forward(ctx, inputs: torch.tensor, threshold: float): # Get the subnetwork by sorting the inputs and using the top threshold % mask = inputs.clone() _, idx = inputs.flatten().sort(descending=True) j = int(threshold * inputs.numel()) # flat_out and mask access the same memory. flat_out = mask.flatten() flat_out[idx[j:]] = 0 flat_out[idx[:j]] = 1 return mask @staticmethod def backward(ctx, gradOutput): return gradOutput, None æ³¨æ„åˆ°ç¹¼æ‰¿ autograd.Function å°±è¦ implement forward and backward æ–¹æ³•, è®“å®ƒå¯ä»¥å¾®åˆ†æˆ‘å€‘å¯ä»¥çœ‹åˆ° backward ä»€éº¼äº‹éƒ½æ²’åš, é€™æ˜¯å› ç‚º STE (Straight-Through Estimator) çš„é—œä¿‚æ‰€ä»¥åœ¨ forward çš„æ™‚å€™ inputs tensor å°±çµ¦ score matrix $S$, é€™æ¨£å¯ä»¥æ±‚å‡ºå°æ‡‰çš„ mask $M$, åŒæ™‚é€™å€‹ TopK åˆå¯ä»¥å¾®åˆ† Appendix A.1 Guarantees on the decrease of the training loss è£œå……æ¨å°, å…ˆå›é¡§ä¸€ä¸‹ Forward: $$a=(W\\odot M)x$$ é‡å° Backward relaxing çš„ forward: $$a=(W\\odot S)x$$ å…¶ä¸­ $M=\\text{Top}_k(S)$, score matrix ç¶“éé¸æ“‡è®Šæˆ mask matrix. ä¸å¤±ä¸€èˆ¬æ€§, æˆ‘å€‘å®šç¾© score éƒ½ç‚ºæ­£, $S_{ij}&gt;0$.ç®— $W$ çš„ gradients:$$\\frac{\\partial L}{\\partial W_{ij}}=\\frac{\\partial L}{\\partial a_i}M_{ij}x_{j} \\\\ \\frac{\\partial L}{\\partial W_{kl}}=\\frac{\\partial L}{\\partial a_k}M_{kl}x_{l}$$ ç®— $S$ çš„ gradients, ä¸éç”±æ–¼ $\\text{Top}_k$ ç„¡æ³•ç®—å¾®åˆ†, æ‰€ä»¥åªå¥½ç”¨ Backward relaxing çš„æ›¿ä»£æ–¹å¼ $$\\frac{\\partial L}{\\partial S_{ij}} = \\frac{\\partial L}{\\partial a_i}\\frac{\\partial a_i}{\\partial S_{ij}}=\\frac{\\partial L}{\\partial a_i}W_{ij}x_j \\\\ \\frac{\\partial L}{\\partial S_{kl}} = \\frac{\\partial L}{\\partial a_k}\\frac{\\partial a_k}{\\partial S_{kl}}=\\frac{\\partial L}{\\partial a_k}W_{kl}x_l$$ è¦è­‰æ˜, movement pruning ç®—æ³•é€ æˆçš„ $\\text{Top}_k$ è®ŠåŒ–, ä»æœƒä½¿å¾— loss æ„ˆä¾†æ„ˆä½.å…ˆå°‡å•é¡Œç°¡åŒ–ç‚º $\\text{Top}_1$, åœ¨ iteration $t$ æœ€é«˜åˆ†çš„æ˜¯ index $(i,j)$, i.e. $\\forall u,v,S_{uv}^{(t)}\\leq S_{ij}^{(t)}$. ç„¶å¾Œ update ä¸€æ¬¡å¾Œ, è®Šæˆ index $(k,l)$ æ˜¯æœ€å¤§.$$\\left\\{ \\begin{array}{ll} \\text{At } t, &amp; \\forall1\\leq u,v\\leq n,\\quad S_{uv}^{(t)}\\leq S_{ij}^{(t)} \\\\ \\text{At } t+1, &amp; \\forall1\\leq u,v\\leq n,\\quad S_{uv}^{(t+1)}\\leq S_{kl}^{(t+1)} \\end{array} \\right.$$ æ‰€ä»¥æœ‰ $S_{kl}^{(t+1)}-S_{kl}^{(t)} \\geq S_{ij}^{(t+1)}-S_{ij}^{(t)}$.æˆ‘å€‘å¾å®šç¾©å‡ºç™¼:$$\\frac{\\partial L}{\\partial S_{ij}^{(t)}}=\\lim_{|\\Delta|\\rightarrow0}\\frac{L\\left(S^{(t+1)}\\right) - L\\left(S^{(t)}\\right)}{S_{ij}^{(t+1)}-S_{ij}^{(t)}},\\quad\\text{where }\\Delta=S_{ij}^{(t+1)}-S_{ij}^{(t)}$$ $$\\therefore \\quad \\frac{L\\left(S^{(t+1)}\\right)-L\\left(S^{(t)}\\right)}{S_{ij}^{(t+1)}-S_{ij}^{(t)}} \\geq \\frac{L\\left(S^{(t+1)}\\right)-L\\left(S^{(t)}\\right)}{S_{kl}^{(t+1)}-S_{kl}^{(t)}} \\\\ \\text{limit both side}\\Longrightarrow \\frac{\\partial L}{\\partial S_{ij}^{(t)}} \\geq \\frac{\\partial L}{\\partial S_{kl}^{(t)}} \\\\ \\begin{align} \\Longrightarrow \\frac{\\partial L}{\\partial a_i}W_{ij}^{(t)}x_j \\geq \\frac{\\partial L}{\\partial a_k}W_{kl}^{(t)}x_l \\qquad \\ldots \\end{align}$$ é€™å°±æ˜¯è«–æ–‡è£¡ equation (7) çš„æ¨å°,å› æ­¤æˆ‘å€‘è§€å¯Ÿå…©æ¬¡çš„ losses å·®ç•°:$$L(a_i^{(t+1)},a_k^{(t+1)})-L(a_i^{(t)},a_k^{(t)}) \\\\ \\\\ \\approx \\frac{\\partial L}{\\partial a_k}(a_k^{(t+1)}-a_k^{(t)}) + \\frac{\\partial L}{\\partial a_i}(a_i^{(t+1)}-a_i^{(t)}) \\\\ \\\\ =\\frac{\\partial L}{\\partial a_k}W_{kl}^{(t+1)}x_l - \\frac{\\partial L}{\\partial a_i}W_{ij}^{(t)}x_j \\\\ \\\\ = \\frac{\\partial L}{\\partial a_k}W_{kl}^{(t+1)}x_l + (-\\frac{\\partial L}{\\partial a_k}W_{kl}^{(t)}x_l + \\frac{\\partial L}{\\partial a_k}W_{kl}^{(t)}x_l) - \\frac{\\partial L}{\\partial a_i}W_{ij}^{(t)}x_j \\\\ \\\\ = \\frac{\\partial L}{\\partial a_k}(W_{kl}^{(t+1)}x_l-W_{kl}^{(t)}x_l) + (\\frac{\\partial L}{\\partial a_k}W_{kl}^{(t)}x_l - \\frac{\\partial L}{\\partial a_i}W_{ij}^{(t)}x_j) \\\\ \\\\ = \\underbrace{\\frac{\\partial L}{\\partial a_k}x_l(-\\alpha_W\\frac{\\partial L}{\\partial a_k}x_lm(S^{(t)})_{kl})}_{\\text{term1}=0} + \\underbrace{(\\frac{\\partial L}{\\partial a_k}W_{kl}^{(t)}x_l - \\frac{\\partial L}{\\partial a_i}W_{ij}^{(t)}x_j)}_{\\text{term2}&lt;0}$$ ç¬¬äºŒè¡Œçš„ $\\approx$ ä½¿ç”¨æ³°å‹’å±•é–‹å¼ äºŒç¶­çš„æ³°å‹’å±•é–‹å¼$$f(t_n+\\Delta t,x_n+\\Delta x)=f(t_n,x_n)+\\left[\\begin{array}{cc}f_t(t_n,x_n) &amp; f_x(t_n,x_n)\\end{array}\\right]\\left[\\begin{array}{c}\\Delta t \\\\ \\Delta x\\end{array}\\right] + O\\left( \\left\\| \\left[\\begin{array}{c}\\Delta t \\\\ \\Delta x\\end{array}\\right] \\right\\|^2 \\right) \\\\ =f(t_n,x_n)+\\Delta t f_t(t_n,x_n) + \\Delta x f_x(t_n,x_n) + O(\\Delta t^2 + \\Delta x^2)$$ ç¬¬äºŒåˆ°ç¬¬ä¸‰è¡Œçš„æ¨å°, ç”±æ–¼ $a=(W\\odot M)x$, ä¸”å› ç‚º $(t)$ çš„æ™‚å€™ $a_k^{(t+1)}=0$, ä¸” $(t+1)$ çš„æ™‚å€™ $a_i^{(t+1)}=0$ ç™¼ç”Ÿ top 1 switch çš„é—œä¿‚ç„¶å¾Œæœ€å¾Œä¸€è¡Œçš„ term1 ç”±ä¸‹é¢é—œä¿‚å¯ä»¥å¾—åˆ°:$$\\frac{\\partial L}{\\partial W_{kl}}=\\frac{\\partial L}{\\partial a_k}M_{kl}x_{l} \\\\ W_{kl}^{(t+1)} = W_{kl}^{(t)} - \\alpha_W\\frac{\\partial L}{\\partial W_{kl}}$$ æ³¨æ„åˆ° term1 ç‚º $0$, é€™æ˜¯å› ç‚º $m(S^{(t)})_{kl}=0$ (index $(k,l)$ åœ¨ iteration $t$ ä¸æ˜¯æœ€å¤§çš„)è€Œ term2 &lt;0, ç”± (4) å¾—çŸ¥. å› æ­¤ $$L(a_i^{(t+1)},a_k^{(t+1)})-L(a_i^{(t)},a_k^{(t)}) &lt; 0$$ Update å¾Œ loss æœƒä¸‹é™ References In paperswithcode: [link] Codes è«‹åƒè€ƒ paperswithcode è£¡æä¾›çš„é€£çµ, or [github]","tags":[{"name":"Pruning","slug":"Pruning","permalink":"https://bobondemon.github.io/tags/Pruning/"},{"name":"Straight Through Estimator (STE)","slug":"Straight-Through-Estimator-STE","permalink":"https://bobondemon.github.io/tags/Straight-Through-Estimator-STE/"},{"name":"Movement pruning","slug":"Movement-pruning","permalink":"https://bobondemon.github.io/tags/Movement-pruning/"}]},{"title":"L0 Regularization è©³ç´°æ”»ç•¥","date":"2023-01-15T02:50:25.000Z","path":"2023/01/15/L0-Regularization-è©³ç´°æ”»ç•¥/","text":"é€™æ˜¯ä¸€ç¯‡è«–æ–‡Learning Sparse Neural Networks through L0 Regularization çš„è©³ç´°ç­†è¨˜, åŒæ™‚è‡ªå·±å¯¦ä½œåšå¯¦é©— [My Github]ä¸»è¦ä»¥è©³è§£æ¯å€‹éƒ¨åˆ†ä¸¦è‡ªå·±èƒ½å›æ†¶èµ·ç‚ºç›®çš„, æ‰€ä»¥æˆ–è¨±ä¸æ˜¯å¾ˆå¥½é–±è®€ Introduction NN model åƒæ•¸ $\\theta$, æˆ‘å€‘å¸Œæœ›é$0$çš„å€‹æ•¸æ„ˆå°‘æ„ˆå¥½, i.e. $|\\theta|_0$ æ„ˆå°æ„ˆå¥½, æ‰€ä»¥æœƒåŠ å¦‚ä¸‹çš„ regularization term:$$\\mathcal{L}_C^0(\\theta)=\\|\\theta\\|_0=\\sum_{j=1}^{|\\theta|}\\mathbb{I}[\\theta_j\\neq0]$$ æ‰€ä»¥ Loss ç‚º: $$\\mathcal{L}_E(\\theta)=\\frac{1}{N}\\left( \\sum_{i=1}^N\\mathcal{L}(NN(x_i;\\theta),y_i) \\right) \\\\ \\mathcal{L}(\\theta)=\\mathcal{L}_E(\\theta)+\\mathcal{L}_C^0(\\theta)$$ ä½†å¯¦å‹™ä¸Šæˆ‘å€‘æ€éº¼å¯¦ç¾ $\\theta$ é $0$ å‘¢?ä¸€ç¨®æ–¹å¼ç‚ºä½¿ç”¨ä¸€å€‹ mask random variable $Z=\\{Z_1,...,Z_{|\\theta|}\\}$ (~Bernoulli distribution, åƒæ•¸ $q=\\{q_1,...,q_{|\\theta|}\\}$), å› æ­¤ Loss æ”¹å¯«å¦‚ä¸‹: (æ³¨æ„åˆ° $\\mathcal{L}_C^0$ å¯ä»¥æœ‰ closed form ä¸¦ä¸”èˆ‡ $\\theta$ ç„¡é—œäº†) $$\\begin{align} \\mathcal{L}_C^0(\\theta, q)=\\mathbb{E}_{Z\\sim\\text{Bernoulli}(q)}\\left[ \\sum_{j=1}^{|\\theta|}\\mathbb{I}[\\theta_j\\odot Z_j\\neq0] \\right] = \\mathbb{E}_{Z\\sim\\text{Bernoulli}(q)}\\left[ \\sum_{j=1}^{|\\theta|} Z_j \\right] = \\sum_j^{|\\theta|} q_j\\\\ \\mathcal{L}_E(\\theta,q)=\\mathbb{E}_{Z\\sim\\text{Bernoulli}(q)}\\left[ \\frac{1}{N}\\left( \\sum_{i=1}^N\\mathcal{L}(NN(x_i;\\theta\\odot Z_i),y_i) \\right) \\right] \\\\ \\mathcal{L}(\\theta,q)=\\mathcal{L}_E(\\theta,q)+\\lambda\\mathcal{L}_C^0(q) \\end{align}$$ ç¾åœ¨æœ€å¤§çš„éº»ç…©æ˜¯ entropy loss $\\mathcal{L}_E$, åŸå› æ˜¯ Bernoulli æ¡æ¨£æ²’è¾¦æ³•å° $q$ å¾®åˆ†, å› ç‚º $\\nabla_q\\mathcal{L}_E(\\theta,q)$ åœ¨è¨ˆç®—æœŸæœ›å€¼æ™‚, æ¡æ¨£çš„æ©Ÿç‡åˆ†ä½ˆä¹Ÿè·Ÿ $q$ æœ‰é—œ åƒè€ƒ Gumbel-Max Trick é–‹é ­çš„ä»‹ç´¹èªªæ˜ å¥½æ¶ˆæ¯æ˜¯, å¯ä»¥è—‰ç”± reparameterization (Gumbel Softmax) æ–¹æ³•ä½¿å¾—æ¡æ¨£å¾ä¸€å€‹èˆ‡ $q$ ç„¡é—œçš„ r.v. æ¡æ¨£ (æ‰€ä»¥å¯ä»¥å¾®åˆ†äº†), å› æ­¤ä¹Ÿå°±èƒ½åœ¨ NN è¨“ç·´ä½¿ç”¨ backpropagation.ä»¥ä¸‹ä¾åºèªªæ˜: (åƒè€ƒé€™ç¯‡ [L0 normç¨€ç–æ€§: hard concreteé—¨å˜é‡] æ•´ç†çš„é †åº, ä½†è£œè¶³ä¸€äº›å…§å®¹ä»¥åŠåƒè€ƒè«–æ–‡çš„æ±è¥¿)Gumbel max trick $\\Rightarrow$ Gumbel softmax trick (so called concrete distribution)$\\Rightarrow$ Binary Concrete distribution $\\Rightarrow$ Hard (Binary) Concrete distribution $\\Rightarrow$ L0 regularizationæœ€å¾Œè£œä¸Šå° GoogleNet æ¶æ§‹åŠ ä¸Š $L0$ regularization åœ¨ CIFAR10 ä¸Šçš„æ¨¡å‹å£“ç¸®å¯¦é©— æ–‡é•·â€¦ Gumbel Distribution $G\\sim\\text{Gumbel}(\\mu,\\beta)$, å…¶ CDF $F(x)$ ç‚º$$F(x):=P(G\\leq x)=e^{-e^{-(x-\\mu)/\\beta}}$$ ç•¶ $\\mu=0,\\beta=1$ æ™‚ç‚º standard Gumbel r.v., æ‰€ä»¥ CDF ç‚º $\\exp{(-\\exp{(-x)}})$ [wiki] CDF æ˜¯ä¸€å€‹ monotonely increasing function, å­˜åœ¨ inverse function: $$\\begin{align} F^{-1}(F(x))=x \\Rightarrow F^{-1}\\left(e^{-e^{-(x-\\mu)/\\beta}}\\right)=x \\\\ \\Longrightarrow F^{-1}(p)= \\mu-\\beta\\ln(-\\ln(p)) \\end{align}$$ CDF çš„ inverse function åˆç¨± quantile function (Help me understand the quantile (inverse CDF) function) æ‰€ä»¥å¦‚æœ $F^{-1}(U)$ where $U\\sim\\text{Uniform}(0,1)$, ç­‰æ–¼ç…§æ©Ÿç‡åˆ†ä½ˆå– Gumbel random variable. Inverse transform sampling [wiki] å‡è¨­æœ‰ä¸€å€‹ strictly monotone transfromation (æ‰€ä»¥å­˜åœ¨ inverse) $T:[0,1]\\rightarrow\\mathbb{R}$, ä½¿å¾— $T(U)=_dX$, å…¶ä¸­ $U\\sim\\text{Uniform}(0,1)$. é‚£æˆ‘å€‘å°±å¯ä»¥ä½¿ç”¨ $T$ ä¾†åš $X$ çš„æ¡æ¨£ ä»¤ $X$ çš„ CDF ç‚º $F_X(x)$, å‰‡: $$F_X(x)=Pr(X\\leq x)=Pr(T(U)\\leq x) \\\\ =Pr(U\\leq T^{-1}(x))=T^{-1}(x)$$ å‰‡æˆ‘å€‘ç™¼ç¾ $T$ æ˜¯ $F_X^{-1}$. å› æ­¤ $F_X^{-1}(U)$ å°±å¯ä»¥ç”¨ä¾†æ¡æ¨£ $X$. Let $U\\sim\\text{Uniform}(0,1)$, then $F^{-1}(U)=\\mu-\\beta\\ln(-\\ln(U))\\sim\\text{Gumbel}(\\mu,\\beta)$.å¦å¤–, å…©å€‹ Gumbel r.v.s çš„ difference æœå¾ Logistic distribution.If $X\\sim\\text{Gumbel}(\\mu_X,\\beta)$ and $Y\\sim\\text{Gumbel}(\\mu_Y,\\beta)$ are independent, then, $X-Y\\sim\\text{Logistic}(\\mu_X-\\mu_Y, \\beta)$Logistic random variable å…¶ CDF æ˜¯ sigmoid function. Categorical Distribution and Gumbel Max Trick $X\\sim\\text{Categorical}(\\alpha_1,\\alpha_2,...,\\alpha_n)$ è¡¨ç¤ºå–åˆ°ç¬¬ $i$ é¡çš„æ©Ÿç‡æ˜¯ $\\alpha_i$.ä¸¦ä¸”æœ‰å¦‚ä¸‹çš„ reparameterization æ–¹å¼:$$X&apos;\\sim\\arg\\max\\left(G_1+\\ln\\alpha_1,...,G_n+\\ln\\alpha_n\\right)$$ å…¶ä¸­ $(G_1,...,G_n)$ ç‚º $n$ å€‹ç¨ç«‹çš„ Gumbel r.v.s.å‰‡ $X=_dXâ€™$. Concrete Random Variable ç°¡å–®è¬›, å°‡ Gumbel max trick ä¸­çš„ $\\arg\\max$ æ”¹æˆ softmax (with temperature $\\tau$)$$X\\sim\\text{Concrete}((\\alpha_1,\\alpha_2,..,\\alpha_n),\\tau)$$ å…¶ä¸­ $\\tau\\in(0,\\infty)$ and $\\alpha_k\\in(0, \\infty)$.å‰‡ $X$ çš„å–æ³•ç‚º:&emsp;1. Sample $n$ å€‹ç¨ç«‹çš„ Gumbel r.v.s: $(g_1,...,g_n)\\sim(G_1,...,G_n)$, è¦–ç‚º Gumbel noises&emsp;2. å°‡ logits, $\\ln\\alpha_k$, åŠ ä¸Šé€™ $n$ å€‹ Gumbel noises ä¸¦åš softmax (with temperature $\\tau$) æˆç‚º distribution:æ›´å¤šè«‹åƒè€ƒ The Concrete Distribution: A Continuous Relaxation of Discrete Random Variablesç°¡è€Œè¨€ä¹‹, Concrete distirbution æ˜¯å°‡ discrete çš„ categorical r.v. relax æˆ continuous ç‰ˆæœ¬, æ„å³å–å‡ºä¾†çš„ random variable ä¸å†æ˜¯ simplex çš„ one-hot å½¢å¼, è€Œæ˜¯é€£çºŒçš„æ•¸å€¼, è«–æ–‡è£¡çš„åœ–ç¤ºå¾ˆæ¸…æ¥š (åœ–ä¸­çš„ $\\lambda$ ç‚º temperature $\\tau$)ç•¶ $\\tau\\rightarrow 0$, å‰‡ concrete distribution è®Šæˆ categorical distribution. Binary Concrete Distribution Concrete distribution åªå‰©ä¸‹ binary çš„è©±, å¯ä»¥åšåŒ–ç°¡å‰©å…©å€‹åƒæ•¸ $(\\alpha,\\tau)$.$$X=(X_1,X_2)\\sim\\text{Concrete}((\\alpha_1,\\alpha_2),\\tau), \\\\(X_1,X_2)\\sim\\left[\\frac{e^{(G_1+\\ln\\alpha_1)/\\tau}}{e^{(G_1+\\ln\\alpha_1)/\\tau}+e^{(G_2+\\ln\\alpha_2)/\\tau}},\\frac{e^{(G_2+\\ln\\alpha_2)/\\tau}}{e^{(G_1+\\ln\\alpha_1)/\\tau}+e^{(G_2+\\ln\\alpha_2)/\\tau}}\\right] \\\\\\Longrightarrow X_1\\sim\\frac{e^{(G_1+\\ln\\alpha_1)/\\tau}}{e^{(G_1+\\ln\\alpha_1)/\\tau}+e^{(G_2+\\ln\\alpha_2)/\\tau}} = \\frac{1}{1+e^{(G_2-G_1+\\ln\\alpha_2-\\ln\\alpha_1)/\\tau}} \\\\=\\sigma\\left(\\frac{G_1-G_2+\\ln\\alpha_1-\\ln\\alpha_2}{\\tau}\\right) = \\sigma\\left(\\frac{L+\\ln\\alpha_1-\\ln\\alpha_2}{\\tau}\\right)\\\\=\\sigma\\left(\\frac{L+\\ln(\\alpha_1/\\alpha_2)-{\\color{orange}0}}{\\tau}\\right)=\\sigma\\left(\\frac{L+\\ln(\\alpha_1/\\alpha_2)-{\\color{orange}\\ln1}}{\\tau}\\right)$$ å…¶ä¸­ $\\sigma(x)=1/(1+e^{-x})$ ç‚º sigmoid function, ä¸”å·²çŸ¥å…©å€‹ Gumbel r.v.s ç›¸æ¸›, $(G_1-G_2)=L\\sim \\text{Logistic}$, æ˜¯ Logistic, è€Œ $L=\\ln U-\\ln(1-U)$, where $U\\sim\\text{Uniform}(0,1)$. æƒ³æˆ $\\alpha_1&apos;=\\alpha_1/\\alpha_2$, ä¸” $\\alpha_2&apos;=1$, å‰‡ $X=(X_1,1-X_1)\\sim\\text{Concrete}((\\alpha_1&apos;,\\alpha_2&apos;),\\tau)$, ä»£å…¥ $\\alpha_2&apos;=1$ å¾ŒæŠŠä¸‹æ¨™ $1$ å»æ‰å¾—åˆ° Binary Concrete random variable:$$\\begin{align}(X,1-X)\\sim\\text{Concrete}((\\alpha,1),\\tau)\\\\\\Longrightarrow{\\color{orange}{X\\sim\\text{BinConcrete}(\\alpha,\\tau):=\\sigma\\left(\\frac{L+\\ln\\alpha}{\\tau}\\right)=\\sigma\\left(\\frac{\\ln U-\\ln(1-U)+\\ln\\alpha}{\\tau}\\right)}}\\end{align}$$åœ–æ”¹è‡ª The Concrete Distribution: A Continuous Relaxation of Discrete Random Variableså¯ä»¥è§€å¯Ÿåˆ° $\\tau$ æ„ˆæ¥è¿‘ $0$, å‰‡ $X$ çš„å€¼æ„ˆæœ‰å¯èƒ½æ˜¯ $0$ or $1$ çš„ binary case.Binary Concrete çš„ CDF ç‚º ${\\color{orange}{P(X&lt;x)=\\sigma(\\tau(\\ln x-\\ln(1-x))-\\ln\\alpha)}}$ æ¨å°å¦‚ä¸‹:å·²çŸ¥ $L\\sim \\text{Logistic}$, æ‰€ä»¥ $P(L&lt;\\tau(\\ln x-\\ln(1-x))-\\ln\\alpha)=\\sigma(\\tau(\\ln x-\\ln(1-x))-\\ln\\alpha)$ å®˜æ–¹ implementation [codes] Hard (Binary) Concrete Distribution ä¸»è¦å°±æ˜¯å°‡ Binary concrete r.v. æ‹‰ä¼¸å¹³ç§», ä¸¦ clip åœ¨ $(0,1)$ å€é–“Hard binary concrete r.v. å–æ³•ç‚º:&emsp;1. $X\\sim\\text{BinConcrete}(\\alpha,\\tau)=\\sigma\\left((\\ln U-\\ln(1-U)+\\ln\\alpha)/\\tau\\right)$.&emsp;2. Stretch: $\\bar{X}=X(b-a)+a$, å°‡ $X$ æ‹‰ä¼¸å¹³ç§».&emsp;3. Hard-sigmoid to produce Gating r.v.: $Z=\\min(1,\\max(0,\\bar{X}))$.å…¶ä¸­ $a&lt;0&lt;1&lt;b$.ç•¶ $0&lt;X&lt;-a/(b-a)$, å‰‡ $Z=0$,ç•¶ $(1-a)/(b-a)&lt;X&lt;1$, å‰‡ $Z=1$,å¦å‰‡ $(1-a)/(b-a)&lt;X&lt;-a/(b-a)$, $Z=\\bar{X}$. Stretch + hard-sigmoid functions æ˜¯ç‚ºäº†æŠŠ Binary Concrete random variable çœŸçš„æ˜¯ $0$ or $1$ çš„æ©Ÿæœƒå†è®Šæ›´å¤§è«‹åƒè€ƒ â€œBinary Concrete Distributionâ€ æ®µè½è£¡çš„åœ–å°±èƒ½æƒ³åƒ æ‰€ä»¥ $P(Z=0)=P(X&lt;-a/(b-a))$.æˆ‘å€‘ç”± Binary Concrete çš„ CDF ç‚º $P(X&lt;x)=\\sigma(\\tau(\\ln x-\\ln(1-x))-\\ln\\alpha)$ å¯ä»¥å¾—çŸ¥:$${\\color{orange}{P(Z\\neq0)}}=1-P\\left(X&lt;\\frac{-a}{b-a}\\right) \\\\=1-\\sigma\\left(\\tau\\left(\\ln \\frac{-a}{b-a}-\\ln\\left(1-\\frac{-a}{b-a}\\right)\\right)-\\ln\\alpha\\right) \\\\=1-\\sigma\\left(-\\ln\\alpha+\\tau\\ln\\frac{-a}{b}\\right){\\color{orange}{=\\sigma\\left(\\ln\\alpha-\\tau\\ln\\frac{-a}{b}\\right)}}$$ æ‰€ä»¥æœ€å¾Œ Gating random variable $Z\\neq0$ çš„æ©Ÿç‡, $P(Z\\neq0)$, æˆ‘å€‘å¯ä»¥å¾—åˆ° closed form. $\\mathcal{L}_0$ Regularization $P(Z\\neq0)$ å…¶å¯¦é€™å°±æ˜¯ $L_0$ regularization term äº†!$$\\mathcal{L}_C^0(\\phi)=\\sum_j P(Z_j\\neq0|\\phi_j)=\\sum_j \\sigma\\left(\\ln\\alpha_j-\\tau_j\\ln\\frac{-a}{b}\\right)$$ å…¶ä¸­ $\\phi_j=\\{\\alpha_j,\\tau_j\\}$ è¡¨ç¤º Binary Concrete r.v. çš„åƒæ•¸ å¯¦å‹™ä¸Š $\\ln\\alpha_j$ æ˜¯ learnable çš„åƒæ•¸, è€Œ $\\tau_j$ ä¸€èˆ¬ç›´æ¥çµ¦å®š è€ŒåŸæœ¬çš„ loss å°±æ˜¯ weights $\\theta$ ä¹˜ä¸Š gating variable $Z$:æ³¨æ„åˆ° $\\text{BinConcrete}$ å¯ä»¥è—‰ç”± reparameterization trick (è®Šæˆ sample é€™å€‹ operation è·Ÿåƒæ•¸ç„¡é—œ, i.e. åˆ©ç”¨ standard Uniform or Logistic r.v.s å– samples) ä¾†åš backpropagation.Total loss å°±æ˜¯$$\\mathcal{L}(\\theta,\\phi)=\\mathcal{L}_E(\\theta,\\phi)+\\lambda\\mathcal{L}_C^0(\\phi)$$ è«–æ–‡è€ƒæ…®äº†å¦‚æœåŠ å…¥ L2-norm çš„ regularization æ€éº¼æ”¹å‹•.åŸæœ¬çš„ $\\mathcal{L}_2$ regularization åªæ˜¯åƒæ•¸çš„ square: $\\sum_j \\theta_j^2$, ä½†ç‚ºäº†è·Ÿ $\\mathcal{L}_0$ æœ‰å€‹æ¯”è¼ƒå¥½çš„çµåˆ, æ”¹æˆå¦‚ä¸‹: (ç´°ç¯€è«‹åƒè€ƒè«–æ–‡) $$\\mathcal{L}_C^2(\\theta,\\phi)=\\sum_j \\theta_j^2 P(Z_j\\neq0|\\phi_j)$$ æ‰€ä»¥çµåˆå¾Œçš„ regularization term å¦‚ä¸‹:$$\\mathcal{L}_C(\\theta,\\phi)=\\lambda_2\\cdot 0.5\\cdot\\mathcal{L}_C^2(\\theta,\\phi)+\\lambda_0\\cdot\\mathcal{L}_C^0(\\phi) \\\\= \\sum_j \\left( \\lambda_2\\cdot0.5\\cdot\\theta_j^2 + \\lambda_0\\right)P(Z_j\\neq0|\\phi_j)$$ å› æ­¤ Total loss å°±æ˜¯$$\\mathcal{L}(\\theta,\\phi)=\\mathcal{L}_E(\\theta,\\phi)+\\lambda\\mathcal{L}_C(\\theta,\\phi)$$ Experimental Codes and Results Network Structureä½¿ç”¨ GoogleNet åœ¨ CIFAR10 ä¸Šåšå¯¦é©— [Github repo]å…·é«”æ€éº¼åš L0 purning å‘¢? ä»¥ convolution èˆ‰ä¾‹, æˆ‘å€‘å° output channel åš masking, å› æ­¤æ¯å€‹ channel æœƒå°æ‡‰ä¸€å€‹ hard binary concrete r.v. $Z_i$, ç”±æ–¼ hard binary concrete r.v. å‚¾å‘ sample å‡º exactly $0$ or $1$ (ä¸­é–“æ•¸å€¼ä¹Ÿæœ‰å¯èƒ½, åªæ˜¯å¾ˆä½æ©Ÿç‡), å› æ­¤é€ æˆ output dimension æœƒç›´æ¥ä¸‹é™, æ‰€ä»¥çµ¦ä¸‹ä¸€å±¤çš„ layer çš„ channel æ•¸é‡å°±æ¸›å°‘, åœ–ç¤ºå¦‚ä¸‹:æœ‰é—œ hard concrete r.v. çš„ module åƒè€ƒ class L0Gate(nn.Module) [link]å› æ­¤ Inception block æœƒå¤šäº†ä¸€äº› L0Gate layers:æ‰€ä»¥ inception layer çš„ forward() å¤§æ¦‚å°±æ˜¯é•·é€™æ¨£:å†ä¾†å°±æ˜¯ç”¨é€™äº›åŒ…å« L0Gate çš„ inception blocks å»å»ºç«‹æ•´å€‹ GoogleNet çš„ NN äº†. Results Recap ä¸€ä¸‹ Loss:$$\\mathcal{L}(\\theta,\\phi)=\\mathcal{L}_E(\\theta,\\phi)+\\lambda\\mathcal{L}_C^0(\\phi)$$ å…¶ä¸­ $\\phi_j=\\{\\alpha_j,\\tau_j\\}$ è¡¨ç¤º Binary Concrete r.v. çš„åƒæ•¸, ä¸€èˆ¬ä¾†èªªåªæœ‰ $\\ln\\alpha_j$ æ˜¯ learnable, è€Œ $\\lambda$ è¡¨ç¤º L0 regularization çš„æ¯”é‡æˆ‘å€‘å°‡ L0Gate çš„åƒæ•¸, i.e. $\\ln\\alpha_j$, èˆ‡ NN çš„åƒæ•¸ $\\theta$ ä¸€èµ·å¾é ­è¨“ç·´èµ·å°æ¯”æ²’æœ‰ L0 regularization çš„å°±æ˜¯åŸå§‹çš„ GoogleNet GoogleNet Validation Accuracy Test Accuracy Sparsity NO L0 90.12% 89.57% 1.0 with L0, lambda=0.25 88.66% 87.87% 0.94 with L0, lambda=0.5 86.9% 86.56% 0.78 with L0, lambda=1.0 83.2% 82.79% 0.45 å…¶ä¸­ sparsity çš„è¨ˆç®—ç‚ºæ‰€æœ‰å› ç‚º gate ç‚º $0$ è€Œé€ æˆåƒæ•¸ç„¡æ•ˆçš„æ¯”ä¾‹å¯ä»¥è§€å¯Ÿåˆ°éš¨è‘— $\\lambda$ æ„ˆå¤§, æœƒ pruning æ›´å¤š ($\\mathcal{L}_C^0$ çš„æ”¶æ–‚å€¼æœƒæ›´ä½), ä½†ä¹Ÿé€ æˆ accuracy çš„ä¸‹é™å°æ¯”ä¸‹é¢çš„åœ–ä¹Ÿå¯ä»¥çœ‹åˆ° $\\lambda$ å° $\\mathcal{L}_C^0$ çš„æ”¶æ–‚å€¼çš„å½±éŸ¿ å¯¦å‹™ä¸Šä¹˜ gate $0$ ç­‰æ–¼äº‹å…ˆå°‡ weight è®Šæˆ $0$, è€Œå› ç‚ºæˆ‘å€‘ä½¿ç”¨ structure pruning, æ‰€ä»¥å¯ä»¥å°‡ convolution kernel è®Šå°. å¾Œä¾†æˆ‘ç™¼ç¾æ¯”èµ·å°‡ $\\ln\\alpha_j$, èˆ‡ NN çš„åƒæ•¸ $\\theta$ ä¸€èµ·å¾é ­è¨“ç·´èµ·NN $\\theta$ init ä½¿ç”¨ä¹‹å‰ pre-train å¥½çš„ model (æ²’æœ‰ L0), ç„¶å¾Œå†åŠ å…¥ L0 regularization, æ­¤æ™‚å°‡ $\\ln\\alpha$ åˆå§‹æˆæ¯”è¼ƒå¤§çš„å€¼ (æ¥è¿‘ $1$, i.e. è®“ gate æ‰“é–‹), é€™æ¨£åœ¨åŒæ¨£ sparsity æ•ˆæœä¸‹, accuracy æœƒæ¯”è¼ƒé«˜ References L0 normç¨€ç–æ€§: hard concreteé—¨å˜é‡ The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables L0 Regularization Practice [My Github] In paperswithcode: [link] Pruning Filters &amp; Channels in Neural Network Distiller","tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://bobondemon.github.io/tags/PyTorch/"},{"name":"Gumbel distribution","slug":"Gumbel-distribution","permalink":"https://bobondemon.github.io/tags/Gumbel-distribution/"},{"name":"L0 regularization","slug":"L0-regularization","permalink":"https://bobondemon.github.io/tags/L0-regularization/"},{"name":"Concrete distribution","slug":"Concrete-distribution","permalink":"https://bobondemon.github.io/tags/Concrete-distribution/"},{"name":"Hard Concrete distribution","slug":"Hard-Concrete-distribution","permalink":"https://bobondemon.github.io/tags/Hard-Concrete-distribution/"},{"name":"Pruning","slug":"Pruning","permalink":"https://bobondemon.github.io/tags/Pruning/"},{"name":"Straight Through Estimator (STE)","slug":"Straight-Through-Estimator-STE","permalink":"https://bobondemon.github.io/tags/Straight-Through-Estimator-STE/"}]},{"title":"Learning Zero Point and Scale in Quantization Parameters","date":"2022-12-04T13:14:45.000Z","path":"2022/12/04/Learning-Zero-Point-and-Scale-in-Quantization-Parameters/","text":"åœ¨ä¸Šä¸€ç¯‡ ææ‡‚ Quantization Aware Training ä¸­çš„ Fake Quantization æˆ‘å€‘è¨è«–äº† fake quantization ä»¥åŠ QATæåˆ°äº† observer è² è²¬è¨ˆç®— zero point and scale $(z,s)$, ä¸€èˆ¬ä¾†èªªåªéœ€è¦é€éçµ±è¨ˆè§€æ¸¬å€¼çš„ min/max ç¯„åœå°±èƒ½çµ¦å®š, æ‰€ä»¥ä¹Ÿä¸éœ€è¦åƒèˆ‡ backward è¨ˆç®— ç›´è§€ä¸Šæˆ‘å€‘å¸Œæœ›æ‰¾åˆ°çš„ zero/scale ä½¿å¾— quantization error ç›¡é‡å°, ä½†å…¶å¯¦å¦‚æœèƒ½å°ä»»å‹™çš„ loss å„ªåŒ–, æ‡‰è©²æ‰æ˜¯æœ€ä½³çš„é€™å°±å¿…é ˆè®“ $(z,s)$ åƒèˆ‡åˆ° backward çš„è¨ˆç®—, é€™ç¨®å¯ä»¥è¨ˆç®— gradient ä¸¦æ›´æ–°çš„åšæ³•ç¨±ç‚º learnable quantization parameters æœ¬æ–‡ä¸»è¦åƒè€ƒé€™å…©ç¯‡è«–æ–‡:&emsp;1. LSQ: Learned Step Size Quantization&emsp;2. LSQ+: Improving low-bit quantization through learnable offsets and better initialization LSQ åªè¨è«– updating scale, è€Œ LSQ+ æ“´å±•åˆ° zero point ä¹Ÿèƒ½å­¸ç¿’, æœ¬æ–‡åªæ¨å°é—œéµçš„ gradients ä¸èªªæ˜è«–æ–‡è£¡çš„å¯¦é©—çµæœ å¾ˆå¿«å®šç¾©ä¸€ä¸‹ notations:&emsp;- $v$: full precision input value&emsp;- $s$: quantizer step size (scale)&emsp;- $z$: zero point (offset)&emsp;- $Q_P,Q_N$: the number of positive and negative quantization levels&emsp;&emsp;e.g.: for $b$ bits, unsigned $Q_N=0,Q_P=2^b-1$, for signed $Q_N=2^{b-1},Q_P=2^{b-1}-1$&emsp;- $\\lfloor x \\rceil$: round $x$ to nearest integerå°‡ $v$ quantize åˆ° $\\bar{v}$ (1), å†å°‡ $\\bar{v}$ dequantize å› $\\hat{v}$ (2), è€Œ $v-\\hat{v}$ å°±æ˜¯ precision loss$$\\begin{align} \\bar{v}={clip(\\lfloor v/s \\rceil+z,-Q_N,Q_P)} \\\\ \\hat{v}=(\\bar{v}-z)\\times s\\\\ \\end{align}$$ å­¸ç¿’ Scale å› ç‚ºåœ¨ forward çš„æ™‚å€™æ˜¯ $\\hat{v}$ å»åƒèˆ‡ Loss $L$ çš„è¨ˆç®— (ä¸æ˜¯ $v$), æ‰€ä»¥è¨ˆç®— $s$ çš„ gradient æ™‚ Loss $L$ å¿…é ˆå° $\\hat{v}$ å»å¾®åˆ†, å› æ­¤$$\\begin{align} \\frac{\\partial L}{\\partial s}=\\frac{\\partial L}{\\partial \\hat{v}}\\cdot\\frac{\\partial \\hat{v}}{\\partial s} \\end{align}$$ å…¶ä¸­ ${\\partial L}/{\\partial \\hat{v}}$ æ˜¯åš backprop æ™‚æœƒå‚³é€²ä¾†çš„, æ‰€ä»¥éœ€è¦è¨ˆç®— ${\\partial \\hat{v}}/{\\partial s}$$$\\begin{align} \\frac{\\partial \\hat{v}}{\\partial s}=\\frac{\\partial(\\bar{v}-z)s}{\\partial s}=s\\cdot {\\color{orange}{\\frac{\\partial \\bar{v}}{\\partial s}}} +\\bar{v}-z \\\\ =s\\cdot \\left\\{ \\begin{array}{ll} &minus;vs^{-2} &amp; \\text{if }-Q_N&lt;v/s+z&lt;Q_P \\\\ 0 &amp; \\text{otherwise} \\end{array} \\right. +\\bar{v} - z \\end{align}$$ æ©˜è‰²çš„åœ°æ–¹ $\\color{orange}{\\partial\\bar{v}/{\\partial s}}$ å¿…é ˆä½¿ç”¨ STE (Straight Through Estimator) (åƒè€ƒä¸Šä¸€ç¯‡ç­†è¨˜)å°‡ $\\bar{v}$ ç”¨é€™æ¨£è¡¨é”:$$\\begin{align} \\bar{v}= \\left\\{ \\begin{array}{ll} \\lfloor v/s \\rceil + z &amp; \\text{if }-Q_N&lt;v/s+z&lt;Q_P \\\\ -Q_N &amp; \\text{if }v/s+z \\leq -Q_N \\\\ Q_P &amp; \\text{if }Q_P \\leq v/s+z \\end{array} \\right. \\end{align}$$ æ‰€ä»¥ä»£å›å» (5) å¾—åˆ°æˆ‘å€‘è¦çš„ scale çš„ gradients:$$\\begin{align} \\frac{\\partial \\hat{v}}{\\partial s}= \\left\\{ \\begin{array}{ll} &minus;v/s+\\lfloor v/s \\rceil &amp; \\text{if }-Q_N&lt;v/s+z&lt;Q_P \\\\ -Q_N - z &amp; \\text{if }v/s+z\\leq -Q_N \\\\ Q_P - z &amp; \\text{if }v/s+z\\geq Q_P \\end{array} \\right. \\end{align}$$ åœ¨ LSQ é€™ç¯‡çš„ä½œè€…æŠŠ gradients $\\partial\\hat{v}/\\partial s$ ç•«å‡ºä¾†, å¯ä»¥çœ‹åˆ°åœ¨ quantization çš„ transition è™•, LSQ èƒ½é«”ç¾å‡º gradient è®Šå‹•å¾ˆå¤§ (å¦å¤–å…©å€‹æ–¹æ³•æ²’æœ‰) Scale çš„ Gradient è¦åšèª¿æ•´ LSQ ä½œè€…å¯¦é©—èªç‚º weights å’Œ scale çš„ gradients å¤§å°, å†é™¤ä»¥å„è‡ªçš„åƒæ•¸æ•¸é‡å¾Œ, å¦‚æœåœ¨æ¯”ä¾‹ä¸Šä¸€æ¨£çš„è©±æ•ˆæœæ¯”è¼ƒå¥½: $R=\\left.\\left|\\frac{\\nabla_s L}{s}\\right|\\right/\\frac{\\|\\nabla_w L\\|}{\\|w\\|}\\approx 1$ è¦è®“æ›´æ–°çš„ç›¸å°å¤§å°æ˜¯æ¥è¿‘çš„, å› æ­¤æœƒæŠŠ gradients ä¹˜ä¸Šå¦‚ä¸‹çš„ scale å€¼: $g=1/\\sqrt{NQ_P}$, å…¶ä¸­ $N$ æ˜¯é‚£ä¸€å±¤çš„ (pytorch) tensor ç¸½æ•¸é‡ .numel Weight tensor $W$ å°±æ˜¯ W.numel, è€Œå¦‚æœè¦è™•ç† scale $s$ çš„è©±, å‡è¨­è™•ç†çš„æ˜¯ activations $X$, é‚£å°±æ˜¯ X.numel å¯¦ä½œ é€™å€‹ gradient scale çš„æŠ€å·§å¾ˆå¥½, å¯ä»¥ç”¨åœ¨ä»»ä½•ä¸æƒ³æ”¹è®Š output å¤§å°, è€Œåˆå¸Œæœ›æ”¹è®Š gradient å¤§å°çš„å ´åˆä½¿ç”¨ å­¸ç¿’ Zero Point æ¨å° zero point çš„ gradient (å¼å­æ‰“ä¸å‡ºä¾†å¾ˆæ€ª, åªèƒ½ç”¨åœ–ç‰‡): å°ç…§ PyTorch å¯¦ä½œ Pytorch å¯¦ä½œ: _fake_quantize_learnable_per_tensor_affine_backward è£¡é¢è¨»è§£å¯«è‘—å¦‚ä¸‹çš„æ•˜è¿°:The gradients for scale and zero point are calculated as below:Let $X_{fq}$ be the fake quantized version of $X$.Let $X_q$ be the quantized version of $X$ (clamped at $q_\\text{min}$ and $q_\\text{max}$).Let $\\Delta$ and $z$ be the scale and the zero point. å¼å­æ‰“ä¸å‡ºä¾†å¾ˆæ€ª, åªèƒ½ç”¨åœ–ç‰‡: å¯ä»¥ç™¼ç¾èˆ‡ gradient of scale (7) å’Œ gradient of zero point (12) èƒ½å°ç…§èµ·ä¾† ä¸€äº›è¨“ç·´èªªæ˜ æœ‰é—œ initialization å¯ä»¥å¾ post quantization é–‹å§‹, ä¸ä¸€å®šè¦ç…§è«–æ–‡çš„æ–¹å¼å…¶ä¸­ç¬¬ä¸€å’Œæœ€å¾Œä¸€å±¤éƒ½ä½¿ç”¨ 8-bits (æˆ‘è¦ºå¾—ç”šè‡³ç”¨ 32-bits éƒ½å¯ä»¥), é€™å…©å±¤ç”¨é«˜ç²¾åº¦èƒ½ä½¿å¾—æ•ˆæœé¡¯è‘—æå‡, å·²ç¶“æ˜¯å€‹æ¨™æº–åšæ³•äº†å¦ä¸€å€‹æ¨™æº–åšæ³•æ˜¯ intial éƒ½å¾ full precision é–‹å§‹ Reference LSQ: Learned Step Size Quantization LSQ+: Improving low-bit quantization through learnable offsets and better initialization é‡è®­ç»ƒé‡åŒ–Â·å¯å¾®é‡åŒ–å‚æ•°: æœ‰ zero point çš„å¾®åˆ†æ¨å° Pytorch å¯¦ä½œ: _fake_quantize_learnable_per_tensor_affine_backward é‡åŒ–è®­ç»ƒä¹‹å¯å¾®é‡åŒ–å‚æ•°â€”LSQ åˆ¥äººçš„å¯¦ä½œ: lsq-net: https://github.com/zhutmost/lsq-net/blob/master/quan/quantizer/lsq.py","tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://bobondemon.github.io/tags/PyTorch/"},{"name":"Straight Through Estimator (STE)","slug":"Straight-Through-Estimator-STE","permalink":"https://bobondemon.github.io/tags/Straight-Through-Estimator-STE/"},{"name":"Quantization Aware Training (QAT)","slug":"Quantization-Aware-Training-QAT","permalink":"https://bobondemon.github.io/tags/Quantization-Aware-Training-QAT/"},{"name":"Fake Quantization","slug":"Fake-Quantization","permalink":"https://bobondemon.github.io/tags/Fake-Quantization/"},{"name":"LSQ","slug":"LSQ","permalink":"https://bobondemon.github.io/tags/LSQ/"},{"name":"LSQ+","slug":"LSQ","permalink":"https://bobondemon.github.io/tags/LSQ/"}]},{"title":"ææ‡‚ Quantization Aware Training ä¸­çš„ Fake Quantization","date":"2022-11-19T12:09:14.000Z","path":"2022/11/19/ææ‡‚-Quantization-Aware-Training-ä¸­çš„-Fake-Quantization/","text":"çœ‹å®Œæœ¬æ–‡æœƒçŸ¥é“ä»€éº¼æ˜¯ fake quantization ä»¥åŠè·Ÿ QAT (Quantization Aware Training) çš„é—œè¯åŒæ™‚äº†è§£ pytorch çš„ torch.ao.quantization.fake_quantize.FakeQuantize é€™å€‹ class åšäº†ä»€éº¼ Fake quantization æ˜¯ä»€éº¼? æˆ‘å€‘çŸ¥é“çµ¦å®š zero ($z$) and scale ($s$) æƒ…æ³ä¸‹, float æ•¸å€¼ $r$ å’Œ integer æ•¸å€¼ $q$ çš„é—œä¿‚å¦‚ä¸‹: $$\\begin{align} r=s(q-z) \\\\ q=\\text{round_to_int}(r/s)+z \\end{align}$$ å…¶ä¸­ $s$ ç‚º scale value ä¹Ÿæ˜¯ float, è€Œ $z$ ç‚º zero point ä¹Ÿæ˜¯ integer, ä¾‹å¦‚ int8Fake quantization ä¸»è¦æ¦‚å¿µå°±æ˜¯ç”¨ 256 å€‹ float é» (e.g. ç”¨ int8) ä¾†è¡¨ç¤ºæ‰€æœ‰ float values, å› æ­¤ä¸€å€‹ float value å°±ä½¿ç”¨256é»ä¸­æœ€è¿‘çš„ä¸€é» float ä¾†æ›¿æ›å‰‡åŸä¾†çš„ floating training æµç¨‹éƒ½ä¸ç”¨è®Š, åŒæ™‚ä¹Ÿèƒ½æ¨¡æ“¬å› ç‚º quantization é€ æˆçš„ç²¾åº¦æå¤±, é€™ç¨®è¨“ç·´æ–¹å¼ç¨±åš Quantization Aware Training (QAT) (See Quantization çš„é‚£äº›äº‹) ä»¤ä¸€å€‹ tensor x å¦‚ä¸‹, æ•¸å€¼åƒè€ƒ pytorch å®˜æ–¹ç¯„ä¾‹ (link):1234import torchimport numpy as npx = torch.tensor([ 0.0552, 0.9730, 0.3973, -1.0780]).requires_grad_(True) åŒæ™‚ä»¤ zero and scale å’Œ integer ç‚º int812scale, zero = 0.1, 0quant_min, quant_max = 0, 255 å‰‡æˆ‘å€‘å¯ä»¥ä½¿ç”¨ torch.fake_quantize_per_tensor_affine (link) ä¾†æ‰¾å‡ºå“ªä¸€å€‹256é»çš„ float æœ€æ¥è¿‘åŸä¾†çš„ x çš„ float å€¼1234fq_x = torch.fake_quantize_per_tensor_affine(x, scale, zero, quant_min, quant_max)print(f'fake quant of x = &#123;fq_x&#125; by funtion `fake_quantize_per_tensor_affine`')# fake quant of x = tensor([0.1000, 1.0000, 0.4000, 0.0000],# grad_fn=&lt;FakeQuantizePerTensorAffineCachemaskBackward0&gt;) by funtion `fake_quantize_per_tensor_affine` å…¶å¯¦æˆ‘å€‘ä¹Ÿå¯ä»¥ç”¨å¼ (2) å…ˆç®—å‡º quantized çš„å€¼, ç„¶å¾Œå†ç”¨ (1) å›ç®—æœ€é è¿‘çš„ float, é€™æ¨£è¨ˆç®—æ‡‰è©²è¦è·Ÿä¸Šé¢ä½¿ç”¨ torch.fake_quantize_per_tensor_affine çš„çµæœä¸€æ¨£:12345678# We manually check fake quantization resultsx_copy = x.clone().detach().numpy()x_int = np.clip(np.floor(x_copy/scale + 0.5) + zero, quant_min, quant_max)print(f'quantize x to int = &#123;x_int&#125;')# quantize x to int = [1.0, 10.0, 4.0, 0.0]x_back_to_float = (x_int - zero) * scaleprint(f'fake quant of x = &#123;x_back_to_float&#125; by manual calculation')# fake quant of x = [0.1, 1.0, 0.4, 0.0] by manual calculation Fake quantization å¿…é ˆè¦èƒ½å¾®åˆ† æ—¢ç„¶è¦åš QAT, ä¹Ÿå°±æ˜¯èªªåœ¨ back propagation æ™‚, fake quantization é€™å€‹ function ä¹Ÿè¦èƒ½å¾®åˆ†æˆ‘å€‘çœ‹ä¸€ä¸‹ fake quantization function é•·ç›¸:åŸºæœ¬ä¸Šå°±æ˜¯ä¸€å€‹ step function, é™¤äº†åœ¨æœ‰é™çš„ä¸é€£çºŒé»å¤–, å…¶é¤˜å…¨éƒ¨éƒ½æ˜¯å¹³çš„, æ‰€ä»¥ gradient éƒ½æ˜¯ $0$.é€™å°è‡´æ²’æ³•åš back propagation. ç‚ºäº†è®“ gradient æµå›å», æˆ‘å€‘ä½¿ç”¨ identity mapping (å‡è£æ²’æœ‰ fake quantization) çš„ gradient:é‚£è®€è€…å¯èƒ½æœƒå•, é€™æ¨£ gradient ä¸å°±è·Ÿæ²’æœ‰ fake quantization ä¸€æ¨£äº†å—? å¦‚ä½•æ¨¡æ“¬ quantization é€ æˆçš„ç²¾åº¦æå¤±?æˆ‘å€‘ä¾†çœ‹çœ‹åŠ ä¸Š loss å¾Œçš„æƒ…å½¢, å°±å¯ä»¥è§£ç­”é€™å€‹å•é¡Œéš¨ä¾¿å‡è¨­ä¸€å€‹ loss function å¦‚ä¸‹(å¯ä»¥æ˜¯éå¸¸è¤‡é›œçš„å‡½æ•¸, ä¾‹å¦‚è£¡é¢å«æœ‰NN):$$\\begin{align} loss=(x-0.1)^2 \\end{align}$$ åŸä¾†çš„ training flow æ˜¯ä¸Šåœ–ä¸­çš„ä¸Šé¢å­åœ–, loss function ä½¿ç”¨ $x$ ä»£å…¥è¨ˆç®—, è€Œä½¿ç”¨ fake quantization training çš„è©±å¿…é ˆä»£å…¥ $\\text{fq_x}$. é€™æ¨£å°±èƒ½åœ¨è¨ˆç®— loss çš„æ™‚å€™æ¨¡æ“¬ç²¾åº¦æå¤±.æˆ‘å€‘è§€å¯Ÿä¸€ä¸‹ gradient:$$\\begin{align} \\frac{d\\text{loss}}{dx}=\\frac{d\\text{loss}}{d\\text{fq_x}}\\cdot\\frac{d\\text{fq_x}}{d\\text{x}}= 2(\\text{fq_x}-0.1)\\cdot \\{0\\quad\\text{or}\\quad1\\} \\end{align}$$ å› æ­¤ç²¾åº¦æå¤±åæ‡‰åœ¨ $\\frac{d\\text{loss}}{d\\text{fq_x}}$ é€™ä¸€é …ä¸Šæ¥çºŒä¸Šé¢çš„ codes æˆ‘å€‘ä¾†é©—ç®—ä¸€ä¸‹ gradient æ˜¯ä¸æ˜¯å¦‚åŒ (4) é€™æ¨£1234567# Note that x = [0.0552, 0.9730, 0.3973, -1.0780]# and fq_x = [0.1000, 1.0000, 0.4000, 0.0000]loss = torch.sum((fq_x-0.1)**2)# loss = tensor(0.9100)loss.backward()print(f'gradient of x = &#123;x.grad&#125;')# tensor([0.0000, 1.8000, 0.6000, -0.0000]) æ³¨æ„åˆ° x.grad[-1] çš„å€¼æ˜¯ $0$, é€™æ˜¯å› ç‚º x[-1] å·²ç¶“å°æ–¼ quant_min äº†, æ‰€ä»¥ fake quantization çš„ gradient, $\\frac{d\\text{fq_x}}{d\\text{x}}=0$, å…¶ä»–æƒ…æ³éƒ½æ˜¯ $2(\\text{fq_x}-0.1)$. é€™å€‹åšæ³•è·Ÿ so called STE (Straight-Through Estimator) æ˜¯ä¸€æ¨£çš„æ„æ€ [1], ç”¨ä¾†è¨“ç·´ binary NN [6]ä¸€ç¯‡æ˜“æ‡‚çš„æ–‡ç«  â€œIntuitive Explanation of Straight-Through Estimators with PyTorch Implementationâ€œ åŠ å…¥ observer è¦åš fake quantization å¿…é ˆçµ¦å®š zero and scale $(z,s)$, è€Œé€™å€‹å€¼åˆå¿…é ˆå¾ input (æˆ–èªª activation) çš„å€¼åŸŸåˆ†å¸ƒä¾†çµ±è¨ˆå› æ­¤æˆ‘å€‘é€šå¸¸æœƒå®‰æ’ä¸€å€‹ observer ä¾†åšé€™ä»¶äº‹æƒ…pytorch æä¾›äº†ä¸åŒç¨®é¡çš„çµ±è¨ˆæ–¹å¼ä¾†è¨ˆç®— $(z,s)$, ä¾‹å¦‚: MinMaxObserver and MovingAverageMinMaxObserver PerChannelMinMaxObserver and MovingAveragePerChannelMinMaxObserver HistogramObserver FixedQParamsObserver å› æ­¤ä¸€å€‹å®Œæ•´å€‹ fake quantization åŒ…å«äº† observer ä»¥åŠåš fake quantization çš„ function, FakeQuantize é€™å€‹ pytorch class å°±æ˜¯é€™å€‹åŠŸèƒ½: observer åªæ˜¯ç”¨ä¾†çµ¦ $(z,s)$ ä¸éœ€è¦åš back propagationä½†å…¶å¯¦ scale $s$ ä¹Ÿå¯ä»¥ learnable! åƒè€ƒ â€œLearned Step Size Quantizationâ€œ (å¾…è®€) å› æ­¤æˆ‘å€‘å¯ä»¥çœ‹åˆ°è¦ create FakeQuantize æ™‚, å®ƒçš„ init æœ‰åŒ…å«çµ¦ä¸€å€‹ observer:1234567891011121314class FakeQuantize(FakeQuantizeBase): def __init__(self, observer=MovingAverageMinMaxObserver, quant_min=None, quant_max=None, **observer_kwargs): ... def calculate_qparams(self): # ä½¿ç”¨ observer ä¾†è¨ˆç®— zero and scale ... def forward(self, X): if self.observer_enabled[0] == 1: # å‘¼å« `calculate_qparams` è¨ˆç®— zeros and scale ... if self.fake_quant_enabled[0] == 1: # ä½¿ç”¨ `torch.fake_quantize_per_channel_affine` ä¾†åš fake quantization ... return X FakeQuantize é€™å€‹ class æ˜¯ nn.Module, åªè¦ forward è£¡é¢çš„æ¯å€‹ operation éƒ½æœ‰å®šç¾© backward (éƒ½å¯å¾®åˆ†), å°±è‡ªå‹•å¯ä»¥åš back propagation æœ¬æ–‡æœ€é–‹é ­æœ‰å±•ç¤º torch.fake_quantize_per_tensor_affine å¯ä»¥åš backward, æ˜¯å¯ä»¥å¾®åˆ†çš„ op æœ€å¾Œ, åœ¨ä»€éº¼åœ°æ–¹å®‰æ’ FakeQuantize æœƒæ ¹æ“šä¸åŒçš„ module (e.g. CNN, dethwise CNN, LSTM, GRU, â€¦ etc.) è€Œä¸åŒ, åŒæ™‚ä¹Ÿå¿…é ˆè€ƒé‡å¦‚æœæœ‰ batch normalization, concate operation, add operation å‰‡æœƒæœ‰ä¸€äº› fusion, requantize ç‹€æ³è¦æ³¨æ„ Figure Backup fake_quant.drawio Reference Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation: STE paper 2013 Yoshua Bengio Intuitive Explanation of Straight-Through Estimators with PyTorch Implementation: STE ä»‹ç´¹, åŒ…å«ç”¨ Pytorch å¯¦ä½œ torch.ao.quantization.fake_quantize.FakeQuantize (link) torch.fake_quantize_per_tensor_affine (link) Learned Step Size Quantization: scale $s$ ä¹Ÿå¯ä»¥ learnable (å¾…è®€) äºŒå€¼ç½‘ç»œï¼Œå›´ç»•STEçš„é‚£äº›äº‹å„¿","tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://bobondemon.github.io/tags/PyTorch/"},{"name":"Straight Through Estimator (STE)","slug":"Straight-Through-Estimator-STE","permalink":"https://bobondemon.github.io/tags/Straight-Through-Estimator-STE/"},{"name":"Quantization Aware Training (QAT)","slug":"Quantization-Aware-Training-QAT","permalink":"https://bobondemon.github.io/tags/Quantization-Aware-Training-QAT/"},{"name":"Fake Quantization","slug":"Fake-Quantization","permalink":"https://bobondemon.github.io/tags/Fake-Quantization/"},{"name":"Observer","slug":"Observer","permalink":"https://bobondemon.github.io/tags/Observer/"}]},{"title":"Weight Normalization çš„ç­†è¨˜","date":"2022-09-26T13:37:42.000Z","path":"2022/09/26/Weight-Normalization-çš„ç­†è¨˜/","text":"ä½¿ç”¨ SGD åšå„ªåŒ–æ™‚, å¦‚æœ ill-conditioned of Hessian matrix, i.e. $\\sigma_1/\\sigma_n$ æœ€å¤§æœ€å°çš„ eigenvalues ä¹‹æ¯”å€¼, æœƒä½¿å¾—æ”¶æ–‚æ•ˆç‡ä¸å½°(ref zig-zag). å¯ä»¥æƒ³æˆ loss function çš„æ›²é¢æ„ˆä¸åƒæ­£åœ“å‰‡æ„ˆ ill-conditioned (æ„ˆæ‰å¹³). å¸Œæœ›è—‰ç”± re-parameterization ä¾†å°‡ ill-conditioned ç‹€æ³é™ä½.ä¸€èˆ¬ä¾†èªª NN çš„ layer å¯ä»¥é€™éº¼å¯«:$$y=\\phi(w^Tx+b)$$ æŠŠ weight vector $w$ é‡æ–°æ”¹å¯«å¦‚ä¸‹: $$w={g\\over\\|v\\|}v\\quad\\quad(\\star)$$ WN å°±æ˜¯å°‡ $w$ æ‹†æˆç”¨ unit vector $v/||v||$ å’Œ magnitude $g$ å…©å€‹ variables ä¾†è¡¨ç¤º å°å¤§å° $g$ çš„å¾®åˆ† å› æ­¤ loss function $L$ å° $g$ å¾®åˆ†ç‚º:$$\\begin{align} \\frac{dL}{dg}=\\nabla_wL^T\\frac{\\partial w}{\\partial g}=\\nabla_wL^T\\frac{v}{\\|v\\|} \\end{align}$$ é€™è£¡æˆ‘å€‘å¯« gradient vector éƒ½ä»¥ column vector ä¾†å¯«æ‰€ä»¥å¦‚æœ loss function $L$ æ˜¯ scalar çš„è©±, gradient å°±æ˜¯ transpose of Jacobian matrix (å‰›å¥½æ˜¯ 1xn çš„ row vector) å°æ–¹å‘å‘é‡ $v$ çš„å¾®åˆ† Loss function $L$ å° $v$ å¾®åˆ†ç‚º: é€™è£¡è¦åƒè€ƒåˆ° matrix cookbook equation (130) $$\\begin{align} \\nabla_vL^T = \\nabla_wL^T\\left(g\\frac{I}{\\|v\\|}-g\\frac{vv^T}{\\|v\\|^3}\\right)\\quad \\\\ = \\nabla_wL^T\\frac{g}{\\|v\\|}\\left( I-\\frac{vv^T}{\\|v\\|^2} \\right)\\quad \\end{align}$$ $$\\therefore \\quad \\nabla_vL=\\frac{g}{\\|v\\|}M_v\\nabla_wL \\quad\\text{where}\\ M_v:=I-\\frac{vv^T}{\\|v\\|^2}$$ è«–æ–‡è£¡å¼ (3) çš„ gradient æ¨å°å¯è—‰ç”±å°‡ (1) ä»£é€²åˆ° (2) è£¡å¾—åˆ°. $\\nabla_vL$ çš„ç‰©ç†æ„ç¾© æ³¨æ„åˆ°ç”±æ–¼ $v$ è·Ÿ $w$ æ˜¯åŒæ–¹å‘ä½†å¤§å°ä¸åŒè€Œå·². æ‰€ä»¥$$M_v=I-\\frac{vv^T}{\\|v\\|^2}=I-\\frac{ww^T}{\\|w\\|^2}=:M_w$$ $$\\begin{align} \\therefore \\quad \\nabla_vL=\\frac{g}{\\|v\\|}M_w\\nabla_wL \\quad\\text{where}\\ M_w:=I- \\color{orange}{\\frac{ww^T}{\\|w\\|^2}} \\end{align}$$ è§€å¯Ÿä¸€ä¸‹ $M_w$ è£¡çš„ç¬¬äºŒé … ((4) çš„æ©˜è‰²éƒ¨åˆ†) ä¹˜ä¸Šä¸€å€‹ vector $x$ ä»£è¡¨çš„æ„ç¾©:$$\\frac{w}{\\|w\\|}\\cdot\\frac{w^T}{\\|w\\|}\\cdot x$$ å…¶ä¸­ $w/\\|w\\|$ è¡¨ç¤º $w$ æ–¹å‘çš„ unit vector, è€Œ $w^Tx/\\|w\\|$ è¡¨ç¤º $x$ æŠ•å½±åœ¨ $w$ æ–¹å‘ä¸Šçš„é•·åº¦. æ‰€ä»¥ $$M_w\\nabla_wL=\\nabla_wL-\\frac{w}{\\|w\\|}\\cdot\\frac{w^T}{\\|w\\|}\\cdot \\nabla_wL$$ $M_w\\nabla_wL$ å°±æ˜¯å°‡ $\\nabla_wL$ æ‰£æ‰åœ¨ $w$ æ–¹å‘ä¸Šçš„åˆ†é‡, è€Œ $\\nabla_vL$ åªæ˜¯å†å¤šä¹˜ä¸€å€‹ scalar,ä¹Ÿå°±æ˜¯èªª $\\nabla_vL\\perp w$, i.e. $w^T\\nabla_vL=0$ (åªè¦åˆ©ç”¨ (4) è¨ˆç®—å°±å¯çŸ¥é“) SGD æœƒä½¿å¾— $v$ é•·åº¦æ„ˆä¾†æ„ˆå¤§ ç”¨ SGD update $v$ çš„æ™‚å€™å…¬å¼ç‚º:$$v&apos;=v+\\Delta v$$ ä¸” $\\Delta v\\propto\\nabla_vL$ by steepest descent.è€Œå› ç‚º $\\nabla_vL\\perp w$ æ‰€ä»¥ $\\Delta v\\perp w$. (è¦ update çš„å‘é‡èˆ‡ç›®å‰çš„ weight å‚ç›´)ç”±æœ€é–‹å§‹çš„åˆ†è§£ $(\\star)$ æˆ‘å€‘çŸ¥é“ $v$ èˆ‡ weight $w$ åŒæ–¹å‘. æ‰€ä»¥è‡ªç„¶ $\\Delta v\\perp v$.é€™å°±å°è‡´äº† update å¾Œçš„ $vâ€™$ é•·åº¦æœƒæ¯” $v$ ä¾†å¾—å¤§ (ä¸‰è§’ä¸ç­‰å¼), å¦‚ä¸‹åœ–: æ‰€ä»¥ç¶“éå¤šæ¬¡ SGD, $v$ é•·åº¦æœƒæ„ˆä¾†æ„ˆå¤§. èˆ‡ Batch Normalization çš„é—œè¯ BN åœ¨éä¸€å±¤ linear weight $v$ å¾Œç‚º:$$\\begin{align} v^Tf_{BN}(x)= v^T\\left(g\\cdot\\frac{x-\\mu}{\\sigma}+b\\right) \\end{align}$$ å…¶ä¸­ $\\mu,\\sigma$ éƒ½æ˜¯å¾è¨“ç·´æ™‚çš„ mini-batch çµ±è¨ˆçš„, è€Œ $g,b$ æ˜¯ trainable çš„åƒæ•¸è€Œ WN å° weight $w$ ç‚º (ä¸çœ‹ non-linear activation é‚£é …):$$f_{WN}(x;w)= w^Tx = {g\\over\\|v\\|}v^Tx \\\\ = v^T\\left(g\\cdot\\frac{x}{\\|v\\|}\\right) = v^Tf_{BN}(x)$$ å°ç…§ BN å¯ä»¥çŸ¥é“è¨­å®š $\\sigma=\\|v\\|,\\mu=0,b=0$ å°±è®Šæˆ WN!ä½† WN çš„å¥½è™•æ˜¯ä¸ä¾è³´ mini-batch çš„è¨­å®š, é€™åœ¨å¦‚æœ batch size è¼ƒå°çš„æƒ…æ³æœƒæ¯”è¼ƒæœ‰åˆ©. BNåœ¨Convå¾Œæœƒæœ‰Convçš„Weightå…·æœ‰Scale Invariantç‰¹æ€§ WN å°æ–¼ $v$ æœƒæ„ˆ update æ„ˆå¤§, è€ƒæ…® BN æ˜¯å¦ä¹Ÿæœ‰é€™æ¨£çš„ç‹€æ³?ä¸€èˆ¬ä¾†èªª, æˆ‘å€‘æœƒé€™éº¼ä¸²: activation(BN(convolution(x)))å°‡ BN æ”¾åœ¨ convolution å¾Œ activation ä¹‹å‰, é€™æ¨£å¯ä»¥æœ€å¾Œåšå®Œ quantizaiton çš„æ™‚å€™, convolution å’Œ BN çš„ weight åšèåˆ.ä»¤ $w$ ç•¶ä½œ convolution çš„ weights, å¦‚æœ weights åš $\\alpha$ å€çš„ scale: $wâ€™=\\alpha w$, å‰‡å° BN å¾Œçš„çµæœä¸æœƒæœ‰å½±éŸ¿, é€™æ˜¯å› ç‚º $\\muâ€™=\\alpha\\mu$, and $\\sigmaâ€™=\\alpha\\sigma$ ä¹Ÿè·Ÿè‘—ä¸€èµ· scale$$f_{BN}(\\alpha w^Tx)=f_{BN}(w^Tx)$$ æ˜ç¢ºå¯«å‡ºä¾†ä¸€å€‹ function $f$ å° input $w$ æ˜¯ scale invariant:$$f(\\alpha w)=f(w),\\quad \\forall \\alpha\\in\\mathbb{R}$$ å¾®ç©åˆ†æˆ‘å€‘å­¸é gradient vector æœƒè·Ÿ coutour çš„ level curve å‚ç›´æŠŠ scale invariant function çš„ â€œç­‰é«˜ç·šâ€ contour map ç•«å‡ºä¾†, ç¤ºæ„åœ–å¤§æ¦‚é€™æ¨£: å¯ä»¥çœ‹åˆ°åš SGD update çš„æ–¹å‘æœƒè·Ÿ contour å‚ç›´, å°è‡´è·Ÿä¹‹å‰è¨è«– WN $v$ æœƒæ„ˆä¾†æ„ˆå¤§çš„ç‹€æ³ä¸€æ¨£, Convolution çš„ weight $w$ ä¹Ÿæœƒéš¨è‘— SGD update æ„ˆä¾†æ„ˆå¤§.å› æ­¤æˆ‘å€‘åœ¨ä½¿ç”¨ activation(BN(convolution(x))) é€™æ¨£çš„ layer çš„æ™‚å€™å¯èƒ½æœƒè§€å¯Ÿåˆ°é€™æ¨£çš„ç¾è±¡.åˆ°é€™é‚Šæˆ‘å€‘å¯èƒ½æœƒæ“”å¿ƒ, æœƒä¸æœƒè¨“ç·´ä¸‹å» $\\|w\\|_2$ æœƒç™¼æ•£?é€šå¸¸ä¾†èªªä¸ç”¨æ“”å¿ƒ, å› ç‚ºé›¢é›¶é»æ„ˆé å‰‡ gradient æ„ˆå°. é€™æ˜¯å› ç‚º loss surface åªè·Ÿè§’åº¦æœ‰é—œ, é›¢é›¶é»æ„ˆé çš„ loss surface æœƒæ„ˆç¨€ç–ã€å¹³å¦. é€™æ¨£ä¸€ä¾†é›–ç„¶æ¯æ¬¡ update $\\|w\\|_2$ éƒ½æœƒè®Šå¤§, ä½†è®Šå¤§çš„å¹…åº¦æ„ˆä¾†æ„ˆå°. é€™ç¯‡ blog æ–‡ç«  (by inFERENCe) ä¹Ÿæœ‰æè¿°, è£¡é¢çš„åœ–ä¹Ÿè§£é‡‹å¾—å¾ˆå¥½. ğŸ’¡ å¦å¤–ä¹Ÿå¯ä»¥ update å®Œ weight å¾Œ, å†æŠŠ convolution çš„ weight ç›´æ¥ normalized, å› ç‚ºåæ­£æ˜¯ scale invariant function, ä¸å½±éŸ¿è¼¸å‡ºçµæœ. $v$ å’Œ $g$ çš„åˆå§‹åŒ– å¯ä»¥åƒè€ƒ æ¨¡å‹ä¼˜åŒ–ä¹‹Weight Normalization çš„èªªæ˜å°±å¥½.è«–æ–‡æœ‰é¡Œåˆ° WN å°æ–¼ initialization æ¯”è¼ƒæ•æ„Ÿ Pytorch çš„ API torch.nn.utils.weight_normæ³¨æ„ weight normalization æ˜¯é€™ç¨®å½¢å¼:$$y=\\phi(w^Tx+b)$$ (markdownæ¸²æŸ“æ€ªæ€ªçš„, æ”¹ç”¨åœ–) æ³¨æ„åˆ° conv2d ä¸€æ¬¡çš„â€å…§ç©â€ æ˜¯è™•ç† in_channel * kernel_height * kernel_width, æ‰€ä»¥ä¸€å€‹ $w$ çš„ç¶­åº¦ä¹Ÿæ˜¯å¦‚æ­¤.ç¸½å…±æœ‰ out_channel é€™éº¼å¤šå€‹çš„ â€œå…§ç©â€, ä¹Ÿå°±æ˜¯æœ‰é€™éº¼å¤šçš„ $w$.å¦å¤–, æŠŠ stride or dilation æ”¹å‹•ä¸æœƒå½±éŸ¿ weight_g and weight_v çš„ size Summary WN ç›´æ¥å°‡åƒæ•¸æ‹†æˆå¤§å°å’Œæ–¹å‘å‘é‡åˆ†åˆ¥ update. å¸Œæœ›è—‰ç”±é€™æ¨£æ‹†è§£èƒ½æ¸›ç·© ill-conditioned ç‹€æ³, ä½¿æ¨¡å‹æ”¶æ–‚é€Ÿåº¦åŠ å¿«. åŒæ™‚ WN ä¹Ÿä¸ä¾è³´ mini-batch, é€™åœ¨ batch size å¦‚æœæ¯”è¼ƒå°çš„æ™‚å€™ä¸æœƒåƒ BN æ•ˆæœè®Šå·®, æˆ–æ˜¯æ¯”è¼ƒé©ç”¨æ–¼ RNN.ä¸éæ‹†æˆé€™æ¨£åƒæ•¸é‡ä¹Ÿæœƒå¢åŠ , ä½†å…¶å¯¦ BN ä¹Ÿéœ€è¦é¡å¤–çš„ memory ä¾†å­˜ $\\mu,\\sigma$, é€™æ¨£æ¯”å°±è¦çœ‹èª°åˆ’ç®—äº†.å¦å¤–æ¢è¨äº† activation(BN(convolution(x))) æœ‰æ™‚æœƒè§€å¯Ÿåˆ° Convolution çš„ weight $w$ ä¹Ÿæœƒéš¨è‘— SGD update æ„ˆä¾†æ„ˆå¤§.é€™å€‹ç¾è±¡è·Ÿæœ¬æ–‡ WN è£¡é¢è¨è«–åˆ°æ–¹å‘å‘é‡ $v$ çš„å¤§å°ä¹Ÿæœƒæ„ˆ update æ„ˆå¤§é“ç†æ˜¯å¾ˆåƒçš„. ä¸éç›®å‰é‡åˆ°çš„å¯¦å‹™ä¸Š, æ¯”è¼ƒå°‘ä½¿ç”¨ WN, å¤§éƒ¨åˆ†é‚„æ˜¯ç”¨ BN, LN (Layer Normalization).æœ‰æ•ˆæ€§æˆ‘è‡ªå·±é‚„è¦å†å¤šè§€å¯Ÿ æœ€å¾Œé€éçœ‹é€™ç¯‡è«–æ–‡, ä»”ç´°æ¨å°è£¡é¢çš„æ•¸å­¸å’Œç†è§£å…¶ç‰©ç†æ„ç¾©, é€™å°æˆ‘ä¾†èªªé‚„æ˜¯å¾ˆæœ‰å¹«åŠ©çš„. Reference Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks è¯¦è§£æ·±åº¦å­¦ä¹ ä¸­çš„Normalizationï¼ŒBN/LN/WN Weight Normalization ç›¸æ¯”batch Normalization æœ‰ä»€ä¹ˆä¼˜ç‚¹å‘¢ï¼Ÿ torch.nn.utils.weight_norm Exponentially Growing Learning Rate? Implications of Scale Invariance induced by Batch Normalization by inFERENCe","tags":[{"name":"Weight Normalization","slug":"Weight-Normalization","permalink":"https://bobondemon.github.io/tags/Weight-Normalization/"},{"name":"Batch Normalization","slug":"Batch-Normalization","permalink":"https://bobondemon.github.io/tags/Batch-Normalization/"},{"name":"Scale Invariant Function","slug":"Scale-Invariant-Function","permalink":"https://bobondemon.github.io/tags/Scale-Invariant-Function/"}]},{"title":"Why Stochastic Weight Averaging? averaging results V.S. averaging weights","date":"2022-07-20T14:56:34.000Z","path":"2022/07/20/Why-Stochastic-Weight-Averaging-averaging-results-V-S-averaging-weights/","text":"ç”±ä»¥å‰é€™ç¯‡æ–‡ç« çŸ¥é“, å°å¤šé¡†ä¸åŒ models çš„çµæœå–å¹³å‡é€šå¸¸æœƒå¾—åˆ°æ›´å¥½çš„çµæœ.ä½†å¦‚æœå° models çš„åƒæ•¸å…ˆå–å¹³å‡å‘¢? ä¸€æ¨£æœƒå¥½å—?Stochastic Weight Averaging (SWA) çš„é€™ç¯‡æ–‡ç«  â€œAveraging Weights Leads to Wider Optima and Better Generalizationâ€œ å˜—è©¦èªªæ˜é€™æ˜¯æœ‰æ•ˆçš„.è€Œå¯¦å‹™ä¸Š, PyTorch å’Œ PyTorch Lightning ä¹Ÿå·²ç¶“ç›´æ¥å°å…¥äº† SWA çš„ API. ç”šè‡³åœ¨èªéŸ³è¾¨è­˜æ¥­ç•Œè£¡, æœ‰å–ä»£ Kaldi å‹¢é ­çš„ WeNet è£¡é¢ä¹Ÿæœ‰é¡ä¼¼çš„æ©Ÿåˆ¶. æœ¬æ–‡ç›´æ¥æˆªåœ–è‡ªå·±çš„ slides å…§å®¹, è€Œ Pdf æª”æ¡ˆå¯åƒè€ƒ é€™è£¡ æŠ•å½±ç‰‡å…§å®¹ ç›´æ¥ä¸Šåœ–: References Why-Aggregation-Work Averaging Weights Leads to Wider Optima and Better Generalization PyTorch 1.6 now includes Stochastic Weight Averaging Stochastic Weight Averaging in PyTorch Lightning WeNet","tags":[{"name":"Stochastic Weight Averaging","slug":"Stochastic-Weight-Averaging","permalink":"https://bobondemon.github.io/tags/Stochastic-Weight-Averaging/"},{"name":"SWA","slug":"SWA","permalink":"https://bobondemon.github.io/tags/SWA/"}]},{"title":"SGD æ³›åŒ–èƒ½åŠ›çš„ç­†è¨˜","date":"2022-05-28T14:15:58.000Z","path":"2022/05/28/SGD-Ggeneralization-Notes/","text":"Sharp V.S. Flat Local Minimum çš„æ³›åŒ–èƒ½åŠ›å…ˆç°¡å–®ä»‹ç´¹é€™ç¯‡æ–‡ç« :On large-batch training for deep learning: Generalization gap and sharp minimaè€ƒæ…®ä¸‹åœ–å…©å€‹ minimum, å°æ–¼ training loss ä¾†èªªå…¶ losses ä¸€æ¨£. å¾åœ–å¯ä»¥å®¹æ˜“ç†è§£åˆ°, å¦‚æœæ‰¾åˆ°å¤ª sharp çš„é», ç”±æ–¼ test and train çš„ mismatch, æœƒå°è‡´æ¸¬è©¦çš„æ™‚å€™ data ä¸€é»åç§»å°±æœƒå° model output å½±éŸ¿å¾ˆå¤§.è«–æ–‡ç”¨å¯¦é©—çš„æ–¹å¼, å»è©•é‡ä¸€å€‹ local minimum çš„ sharpness ç¨‹åº¦, ç°¡å–®èªªåˆ©ç”¨ random perturb åˆ°é™„è¿‘å…¶ä»–é», ç„¶å¾Œçœ‹çœ‹è©²é» loss è®ŠåŒ–çš„ç¨‹åº¦å¦‚ä½•, è®ŠåŒ–æ„ˆå¤§, ä»£è¡¨è©² local minimum å¯èƒ½æ„ˆ sharp.ç„¶å¾Œæ‰¾å…©å€‹ local minimums, ä¸€å€‹ä¼°å‡ºä¾†æ¯”è¼ƒ sharp å¦ä¸€å€‹æ¯”è¼ƒ flat. æ¥è‘—å°é€™å…©é»é€£æˆçš„ç·š, ç·šä¸Šçš„åƒæ•¸å€¼å°æ‡‰çš„ loss åŠƒå‡ºåœ–ä¾†, é•·ç›¸å¦‚ä¸‹: é€™ä¹Ÿæ˜¯ç›®å‰ä¸€å€‹æ™®éçš„èªçŸ¥: flat çš„ local minimum æ³›åŒ–èƒ½åŠ›è¼ƒå¥½.æ‰€ä»¥å¯ä»¥æƒ³åƒ, step size (learning rate) å¦‚æœæ„ˆå¤§, æ„ˆæœ‰å¯èƒ½è·³å‡º sharp minimum.è€Œ batch size æ„ˆå°, è¡¨ç¤º gradient å› ç‚º mini-batch é€ æˆçš„ noise æ„ˆå¤§, ç›¸ç•¶æ–¼æ„ˆæœ‰å¯èƒ½â€äº‚è·‘â€è·‘å‡º sharp minimum.ä½†é€™ç¯‡æ–‡ç« åƒ…æ­¢æ–¼å¯¦é©—æ€§è³ªä¸Šçš„é©—è­‰. Step size and batch size å°æ–¼æ³›åŒ–èƒ½åŠ›, æˆ–æ˜¯èªªå°æ–¼æ‰¾åˆ°æ¯”è¼ƒ flat optimum çš„æ©Ÿç‡æœƒä¸æœƒæ¯”è¼ƒé«˜? å…©è€…æœ‰ä»€éº¼é—œè¯å‘¢?DeepMind çš„è¿‘æœŸ (2021) å…©ç¯‡æ–‡ç« çµ¦å‡ºäº†å¾ˆæ¼‚äº®çš„ç†è«–åˆ†æ. Full-Batch Gradient (Steepest) Descent å†ä¾†ä»‹ç´¹é€™ç¯‡: Implicit Gradient Regularization, DeepMind å‡ºå“.æƒ³æ¢è¨ç‚ºä»€éº¼ NN çš„æ³›åŒ–èƒ½åŠ›é€™éº¼å¥½? çµè«–å°±æ˜¯è·Ÿ Gradient Descent æœ¬èº«ç®—æ³•ç‰¹æ€§æœ‰é—œ.ä¸€èˆ¬æˆ‘å€‘å° cost (loss) function åš gradient (steepest) descent å…¬å¼å¦‚ä¸‹: $$\\begin{align} \\omega_{n+1}=\\omega_n-h\\nabla C(\\omega_n) \\end{align}$$ å…¶ä¸­ $h$ ç‚º step size (learning rate), $\\omega\\in\\mathbb{R}^d$ è¡¨ç¤º parameters.ç•¶ $h\\rightarrow 0$, $n$ è®Šæˆé€£çºŒçš„æ™‚é–“ $t$, å‰‡å¯è¦–ç‚ºä¸€å€‹ Ordinary Differential Equation (ODE) system, æ•´ç†å¦‚ä¸‹:$$\\begin{align} \\text{Cost Function}: C(\\omega) \\\\ \\text{ODE}: \\dot{\\omega}=f(\\omega)=-\\nabla C(\\omega) \\end{align}$$çµ¦å®š initial point $\\omega_0$, ä¸Šé¢çš„ ODE æ±‚è§£å°±æ˜¯ä¸€æ¢é€£çºŒçš„ trajectory. ğŸ’¡ æˆ‘å€‘åœ¨ Numerical Methods for Ordinary Differential Equations æœ‰ä»‹ç´¹å„ç¨®æ•¸å€¼æ–¹æ³•, å¯ä»¥çŸ¥é“ gradient descent å°±æ˜¯ Euler method, è€Œé€™æ¨£çš„ error æ˜¯ $O(h^2)$. ç”¨å¼ (1) gradient descent ($h$ å›ºå®š) æ±‚è§£, æœƒä½¿å¾— trajectory è·Ÿé€£çºŒçš„ ODE (3) çš„ä¸åŒ. æ³¨æ„åˆ°é€™è£¡æ²’æœ‰ä½¿ç”¨ mini-batch, ç”¨çš„æ˜¯ full-batch, æ‰€ä»¥ä¸æ˜¯ Stochastic gradient descent (SGD). å¦‚æœæˆ‘å€‘èƒ½å° gradient descent çš„ trajectory ç”¨å¦ä¸€å€‹ ODE system çš„ trajectory ä»£è¡¨çš„è©± (æ€éº¼æ‰¾ç­‰ç­‰å†èªª), åˆ†æä¿®æ”¹éå¾Œçš„ ODE å’ŒåŸä¾†çš„ ODE systems èªªä¸å®šèƒ½çœ‹åˆ°ä»€éº¼é—œè¯. é€™æ­£æ˜¯é€™ç¯‡è«–æ–‡çš„é‡è¦ç™¼ç¾.å…ˆä¾†çœ‹çœ‹ä¿®æ”¹éå¾Œçš„ ODE é•·ä»€éº¼æ¨£:$$\\begin{align} \\text{Cost Function}: \\tilde{C}_{gd}(\\omega)=C(\\omega)+\\frac{h}{4}\\|\\nabla C(\\omega)\\|^2 \\\\ \\text{ODE}: \\dot{\\omega}=\\tilde{f}(\\omega)=-\\nabla\\tilde{C}_{gd}(\\omega) \\end{align}$$ æ³¨æ„åˆ°æœ€ä½³è§£èˆ‡åŸä¾†çš„ ODE system ä¸€æ¨£: $C(\\omega)$ å’Œ $\\tilde{C}_{gd}(\\omega)$ æœ€ä½³è§£ç›¸åŒ. (å¾ˆå®¹æ˜“å¯ä»¥çœ‹å‡ºä¾†å› ç‚º minimal points å…¶ gradient å¿…å®šç‚º $0$)å°‡ä¸‰æ¢ trajectories ç”¨åœ–ä¾†è¡¨ç¤ºçš„è©±å¦‚ä¸‹:&emsp;- Gradient descent çš„ trajectory å¼ (1): ç¶ è‰²ç®­è™Ÿç·š&emsp;- ODE çš„ trajectory å¼ (3): é»‘è‰²ç·š&emsp;- ä¿®æ”¹å¾Œçš„ ODE çš„ trajectory å¼ (5): é»ƒè‰²ç·š, å¯ä»¥ç”¨ä¾†ä»£è¡¨ gradient descent çš„ trajectory(åƒè€ƒè‡ª inFERENCe blog æ–‡ç« : Notes on the Origin of Implicit Regularization in SGD)ç‚ºä»€éº¼å¯ä»¥ç”¨ä¿®æ”¹å¾Œçš„ ODE ä»£è¡¨ gradient descent çš„ trajectory å‘¢?å› ç‚ºå…©è€…å·®ç•°å¤ å°, ç‚º $O(h^3)$, æ¯” gradient descent å’ŒåŸæœ¬ ODE ä¹‹é–“çš„ error $O(h^2)$ æ›´å°.(ç¶ è‰²ç®­è™Ÿç·šæ¯”èµ·é»‘è‰²ç·šæ›´æ¥è¿‘é»ƒè‰²ç·š) å†ä¾†æˆ‘å€‘å›ç­”é€™å€‹å•é¡Œ: æ€éº¼æ‰¾åˆ° (4) (5) é€™æ¨£çš„ ODE å¯ä»¥ç”¨ä¾†ä»£è¡¨ gradient descent çš„ trajectory å‘¢?ğŸ’¡ éœ€åˆ©ç”¨ backward error analysis, é€™è£¡ç•¥é, è«‹åƒè€ƒ [ref1] [ref2] å…¶ä¸­ ref2 è£¡çš„äºŒéš Taylor expansion è£œå……æ¨å°:$$\\left.\\frac{d^2}{dt^2}\\tilde{y}(t)\\right|_{t=t_n}=\\left.\\frac{d}{dt}\\left[ f(\\tilde{y}(t))+hf_1(\\tilde{y}(t)) \\right]\\right|_{t=t_n} \\\\ =\\left.\\left[ f&apos;(\\tilde{y}(t))\\frac{d\\tilde{y}(t)}{dt}+hf_1&apos;(\\tilde{y}(t))\\frac{d\\tilde{y}(t)}{dt} \\right]\\right|_{t=t_n} \\\\ =\\left.\\left[ f&apos;(\\tilde{y}(t))\\tilde{f}(\\tilde{y}(t))+hf_1&apos;(\\tilde{y}(t))\\tilde{f}(\\tilde{y}(t)) \\right]\\right|_{t=t_n} \\\\ =\\left.\\left[ \\left( f&apos;(\\tilde{y}(t))+hf_1&apos;(\\tilde{y}(t)) \\right)\\tilde{f}(\\tilde{y}(t)) \\right]\\right|_{t=t_n} \\\\ =(f&apos;(\\tilde{y}_n)+hf_1&apos;(\\tilde{y}_n))\\tilde{f}(\\tilde{y}_n)$$ è§€å¯Ÿ (4) çš„ $\\tilde{C}_{gd}(\\omega)$, å¯ä»¥ç™¼ç¾ç›¸ç•¶æ–¼åœ¨åŸä¾†çš„ cost function $C(\\omega)$ åŠ ä¸Šä¸€å€‹æ­£å‰‡é …. è€Œè©²é …æ­£æ¯”æ–¼ gradient norm çš„å¹³æ–¹.ç™½è©±å°±æ˜¯å¦‚æœ gradient æ„ˆå¤§, penalty æ„ˆå¤§, æ‰€ä»¥å„ªåŒ–çš„æ™‚å€™æœƒå‚¾å‘æ–¼æ‰¾ gradient å°çš„å€åŸŸ. ç›¸ç•¶æ–¼æ‰¾æ¯”è¼ƒ flat çš„å€åŸŸ. é€™æ¨£æœ‰ä»€éº¼å¥½è™•å‘¢? å¦‚åŒä¸€é–‹å§‹èªªçš„, èƒ½æé«˜æ³›åŒ–èƒ½åŠ›!å¦å¤–æ­£å‰‡é …ä¹Ÿæ­£æ¯”æ–¼ step size $h$, æ‰€ä»¥å¦‚æœ step size æ„ˆå¤§, è¡¨ç¤ºå° sharp å€åŸŸçš„ penalty æ„ˆå¤§, å› æ­¤æ›´åŠ å‚¾å‘æ‰¾ flat å€åŸŸ. é€™ä¹Ÿç¬¦åˆæˆ‘å€‘ä¹‹å‰æåˆ°æ„ˆæœ‰å¯èƒ½è·³å‡º sharp minimum çš„è§€é». å¦å¤–ä½œè€…çš„ presentation é–‹é ­ä¹Ÿç”¨ä»¥ä¸‹ä¾‹å­èªªæ˜é€™å€‹ç¾è±¡: å¤§çš„ learning rate å‚¾å‘æ‰¾æ¯”è¼ƒ flat çš„ minimum, ä¹Ÿå°±æ˜¯æ³›åŒ–èƒ½åŠ›è¼ƒå¥½. æ‰€ä»¥å°æ‡‰åˆ°ä¸Šåœ–é¡¯ç¤ºçš„ Test æƒ…æ³ä¸‹æœ€å¥½çš„ learning rate æ¯” training çš„è¦å¤§.ç¸½çµä¾†èªªæä¾›äº†ä¸€å€‹çœ‹æ³•, èªªæ˜ç‚ºä»€éº¼ NN çš„è¡¨ç¾é€™éº¼å¥½, ç‰¹åˆ¥æ˜¯æ³›åŒ–èƒ½åŠ›. å¾ˆæ„å¤–çš„æ˜¯, å…¶å¯¦è·Ÿæˆ‘å€‘ç”¨çš„ gradient descent å¤©ç”Ÿçš„ç‰¹æ€§æœ‰é—œ. Mini-Batch Stochastic Gradient Descent ä¸Šä¸€æ®µéƒ½é‚„æ²’è€ƒæ…® mini-batch çš„æƒ…æ³. å› ç‚ºä¸€æ—¦è®Šæˆ mini-batch ç›¸ç•¶æ–¼ gradient è¢«åŠ ä¸Šäº† random noise è®Šçš„æ›´é›£åˆ†æ. å› æ­¤ DeepMind ä»–å€‘ç™¼äº†ä¸€ç¯‡å¾ŒçºŒæ–‡ç« : On the Origin of Implicit Regularization in Stochastic Gradient Descent, å°‡ mini-batch è€ƒé‡é€²å», ç›¸ç•¶æ–¼åˆ†æ SGD ç®—æ³•.ç”±æ–¼ mini-batches åœ¨ä¸€å€‹ epoch å¯èƒ½çš„é †åºä¸ä¸€æ¨£, æ‰€ä»¥ä¸€æ¢ trajectory å°æ‡‰åˆ°ä¸€å€‹é †åº.(åƒè€ƒè‡ª inFERENCe blog æ–‡ç« : Notes on the Origin of Implicit Regularization in SGD) æˆ‘å€‘è®Šæˆè¦è€ƒé‡çš„æ˜¯ â€œmeanâ€ trajectory. é¡ä¼¼åœ°, mean trajectory ä¸€æ¨£å¯ä»¥ç”¨ä¸€å€‹ä¿®æ”¹å¾Œçš„ ODE system ä¾†ä»£è¡¨å®ƒ:$$\\begin{align} \\text{Mean Trajectory}: \\mathbb{E}(\\omega_m)=\\omega(mh)+O(m^3h^3)\\\\ \\text{Cost Function}:\\tilde{C}_{sgd}(\\omega)= \\tilde{C}_{gd}(\\omega) + \\underbrace{\\frac{h}{4m}\\sum_{i=0}^{m-1}\\|\\nabla \\hat{C}_i(\\omega)-\\nabla C(\\omega)\\|^2}_\\text{additional regularizer} \\\\ \\text{ODE}: \\dot{\\omega}=-\\nabla\\tilde{C}_{sgd}(\\omega) \\end{align}$$å…¶ä¸­ $m$ è¡¨ç¤ºæ•´å€‹ training data å¯ä»¥åˆ†æˆ $m$ å€‹ mini-batches. $\\nabla \\hat{C}_i(\\omega)$ è¡¨ç¤º i-th mini-batch çš„ gradient.å¯ä»¥çœ‹åˆ°å¤šäº†ä¸€é …æ­£å‰‡é …: mini-batches çš„ gradients æ¸›æ‰ full-batch gradient çš„ variance.æˆ‘å€‘å°±å…ˆç•¶ $\\omega$ å·²ç¶“æ˜¯ local minimum å¥½äº† ($\\nabla C(\\omega)=0$). æ‰€ä»¥è©²æ­£å‰‡é …ç°¡åŒ–æˆ mini-batches gradients çš„ variance.ç›¸ç•¶æ–¼å‘Šè¨´æˆ‘å€‘, å¦‚æœ mini-batches çš„é‚£äº› gradients å·®ç•°éƒ½å¾ˆå¤§çš„è©±, penalty æœƒæ¯”è¼ƒå¤§, æ¯”è¼ƒä¸æœƒæ˜¯ SGD æœƒæ‰¾åˆ°çš„è§£.é€™æ¨£çš„ç‰¹æ€§å°æ–¼æ³›åŒ–èƒ½åŠ›æœ‰ä»€éº¼é—œè¯? inFERENCe æ–‡ç« çµ¦äº†ä¸€å€‹å¾ˆæ¸…æ¥šçš„èªªæ˜:x-è»¸æ˜¯ parameter $\\omega$, y-è»¸æ˜¯ loss $C(\\omega)$.Variance of mini-batchesâ€™ gradients å·¦åœ–æ¯”å³åœ–å°, å› è€Œé€ æˆå³åœ–çš„ penalty æ¯”è¼ƒå¤§, æ‰€ä»¥ (8) æœƒå‚¾å‘é¸æ“‡å·¦åœ–. æ˜é¡¯çš„, å°æ–¼ test data ä¾†èªªå·¦åœ–çš„è§£æœƒæ¯”å³åœ– robust, å› ç‚º test data å¯ä»¥çœ‹æˆä¸Šé¢ä¸åŒ batches çš„è¡¨ç¾.å¯ä»¥å¾ (7) çœ‹å‡ºä¾†, ç”±æ–¼ additional regularizer çš„é—œä¿‚, SGD æœ€ä½³è§£æœƒè·ŸåŸä¾† full-batch çš„æœ€ä½³è§£ä¸åŒäº†. é™¤éæ‰€æœ‰ mini-batches çš„ gradients ä¹Ÿéƒ½æ˜¯ $0$.å¦å¤– (7) åœ¨è«–æ–‡ä¸­ä¹Ÿæ¨å°æˆå¦ä¸€å€‹å½¢å¼ (å°æ¯”(7)ç‚º additional regularizer æ”¹å¯«äº†):$$\\mathbb{E}(\\tilde{C}_{sgd}(\\omega))=\\tilde{C}_{gd}(\\omega)+\\frac{N-B}{N-1}\\frac{\\color{orange}{h}}{4\\color{orange}{B}}\\Gamma(\\omega) \\\\ \\Gamma(\\omega)=\\frac{1}{N}\\sum_{i=1}^N \\|\\nabla C_i(\\omega)-\\nabla C(\\omega)\\|^2$$ å¯ä»¥çœ‹å‡º learning rate and batch size çš„é—œä¿‚, $h/B$ å¦‚æœç¶­æŒä¸€å®šæ¯”ä¾‹, å‰‡æ­£å‰‡é …çš„å½±éŸ¿åŠ›å¤§ç´„ç›¸åŒ. ä½œè€… presentation èªª, ç¶“é©—ä¸Š batch size double, learning rate ä¹Ÿè¦ double. [YouTube time]å°æ‡‰åˆ° $h/B$ æ¯”ä¾‹ä¸è®Š, æ‰€ä»¥ performance æ‡‰è©²ä¹Ÿç¶­æŒä¸€æ¨£ (åœ¨ $B$ ä¸å¤§çš„æƒ…æ³ä¸‹). è«–æ–‡åšäº†å¯¦é©—çµæœå¦‚ä¸‹: çµè«– é›–ç„¶å­˜åœ¨ä¸€äº›å‡è¨­æ‰æœƒä½¿ SGD çš„ä¼°è¨ˆæ­£ç¢º âš ï¸ è«–æ–‡æ¨å°çš„å‡è¨­: batch shuffle çš„æ–¹å¼å– data, ä¹Ÿå°±æ˜¯ä¸€å€‹ epoch æœƒä¾åºè·‘å®Œ shuffle å¾Œçš„æ‰€æœ‰ batches learning rate is finite (å°±æ˜¯æœ‰ lower bound) åªåˆ†æ SGD, å…¶ä»–æ›´å¤šè®Šå½¢ä¾‹å¦‚ Adam, Adagrad, RMSProp, ç­‰çš„è¡Œç‚ºä¸çŸ¥é“ $m^3h^3$ å¿…é ˆè¦å¤ å°, SGD çš„ â€œmeanâ€ trajectory æ‰æœƒç¬¦åˆ (7), (8) çš„ ODE çµæœ. ä¸€èˆ¬ dataset éƒ½å¾ˆå¤§ ($m$ å¾ˆå¤§), æ‰€ä»¥è¦æŠŠ $h$ éƒ½è¨­å®šå¾ˆå°, æ„Ÿè¦ºä¹Ÿæœ‰é»é›£ç¬¦åˆ (?). å½±ç‰‡: [here] ä½†ç¸½çµä¾†èªª, åœ¨ full-batch è¨­å®šä¸‹, å¯¦å‹™ä¸Šä½¿ç”¨ steepest descent å¾é€£çºŒè®Šæˆé›¢æ•£çš„è·¯å¾‘, æœ¬èº«å°±æä¾›äº†æ³›åŒ–èƒ½åŠ›çš„å¥½è™•. åŠ ä¸Š mini-batch çš„è¨­å®š, ä½¿å¾—æ³›åŒ–èƒ½åŠ›æ›´å¥½äº†. æ²’æƒ³åˆ°å·²ç¶“ç¿’ä»¥ç‚ºå¸¸çš„ SGD æ–¹æ³•, èƒŒå¾Œç«Ÿç„¶è—äº†é€™æ¨£çš„è§€é», å¤ªå²å®³äº†! References Implicit Gradient Regularization On the Origin of Implicit Regularization in Stochastic Gradient Descent inFERENCe: Notes on the Origin of Implicit Regularization in SGD Numerical Methods for Ordinary Differential Equations On large-batch training for deep learning: Generalization gap and sharp minima Paper presentation by author: On the Origin of Implicit Regularization in Stochastic Gradient Descent","tags":[{"name":"Ordinary Differential Equations","slug":"Ordinary-Differential-Equations","permalink":"https://bobondemon.github.io/tags/Ordinary-Differential-Equations/"},{"name":"ODE","slug":"ODE","permalink":"https://bobondemon.github.io/tags/ODE/"},{"name":"Gradient Descent","slug":"Gradient-Descent","permalink":"https://bobondemon.github.io/tags/Gradient-Descent/"},{"name":"Stochastic Gradient Descent","slug":"Stochastic-Gradient-Descent","permalink":"https://bobondemon.github.io/tags/Stochastic-Gradient-Descent/"},{"name":"SGD","slug":"SGD","permalink":"https://bobondemon.github.io/tags/SGD/"}]},{"title":"Numerical Methods for Ordinary Differential Equations","date":"2022-05-15T15:26:51.000Z","path":"2022/05/15/Numerical-Methods-for-Ordinary-Differential-Equations/","text":"å¦‚æœå°æ–¼ Differential Equation å®Œå…¨æ²’æ¦‚å¿µ, å»ºè­°å…ˆçœ‹ä»¥ä¸‹å…©åˆ†é˜çš„å½±ç‰‡&emsp;- Solving Differential Equations vs. Solving Algebraic Equationsä¸»è¦ç­†è¨˜äº† Prof. Jeffrey Chasnov åœ¨ Coursera çš„å…©é–€èª² é‡å° numerical solution è§£ ODE çš„å…§å®¹:&emsp;1. Differential Equations for Engineers&emsp;2. Numerical Methods for Engineersæœ¬æ–‡ä»‹ç´¹:&emsp;1ï¸âƒ£ Introduction to ODE: linear? ordinary? n-th order?&emsp;2ï¸âƒ£ Euler Method: é›–ç„¶ç°¡å–®, ä½† error å¾ˆå¤§&emsp;3ï¸âƒ£ Modified Euler Method: error $O(\\Delta t^3)$, æ¯” Euler method å°äº†ä¸€å€‹ order&emsp;4ï¸âƒ£ Runge Kutta Methods: Modified Euler æ–¹æ³•æ˜¯ Second-order RK çš„ä¸€å€‹ç‰¹ä¾‹&emsp;5ï¸âƒ£ Higher-order Runge-Kutta Methods: $n$-th order RK çš„ error ç‚º $O(\\Delta t^{n+1})$&emsp;6ï¸âƒ£ Higher-order ODEs and Systems: ä»¥ä¸Šéƒ½åªä»‹ç´¹ first-order ODE é€¼è¿‘æ³•, é‚£ higher-order ODE æ€è§£? ğŸ‘ é‚£å…©é–€èª²çš„è¬›ç¾©æ•™æˆå¾ˆä½›å¿ƒå¾—éƒ½æœ‰é™„ä¸Š:Lecture notes: Differential Equations for EngineersLecture notes: Numerical Methods for Engineers 1ï¸âƒ£ Introduction to differential equations | Lecture 1 | Differential Equations for Engineers [YouTube]$$\\begin{align} L\\frac{d^2q}{dt^2}+R\\frac{dq}{dt}+\\frac{1}{C}q=\\varepsilon_0\\cos wt \\\\ ml\\frac{d^2\\theta}{dt^2}+cl\\frac{d\\theta}{dt}+mg\\sin\\theta=F_0\\cos wt \\\\ \\frac{\\partial u}{\\partial t}=D\\left(\\frac{\\partial^2u}{\\partial x^2}+\\frac{\\partial^2u}{\\partial y^2}+\\frac{\\partial^2u}{\\partial z^2}\\right) \\end{align}$$ å…¶ä¸­ $q=q(t)$, $\\theta=\\theta(t)$, $u=u(x,y,z,t)$å…¨éƒ¨éƒ½æ˜¯ $2^{\\text{nd}}$-order, å› ç‚º independent variable $x,y,z,t$ çš„å¾®åˆ†æœ€é«˜ order ç­‰æ–¼ 2.(1) and (2) æ˜¯ ordinary differential equation (ODE)(3) æ˜¯ partial differential equation (PDE)(1) and (3) æ˜¯ linear, (2) æ˜¯ nonlinear, å› ç‚ºæœ‰ $\\sin\\theta$.Linear æŒ‡çš„æ˜¯è¦å¾®åˆ†çš„é‚£å€‹ function (i.e. $q,\\theta,u$) ä¸ç®¡æœ‰æ²’æœ‰è¦å¾®åˆ†, éƒ½ä¸èƒ½éä¸€å€‹ nonlinear function, ä¾‹å¦‚ $d(q^2)/dt$ é€™æ¨£å°±ä¸è¡Œ (å¹³æ–¹æ˜¯ nonlinear function), æˆ–æ²’æœ‰è¦å¾®åˆ†, ç›´æ¥ $q^2$ ä¹Ÿä¸è¡Œ.Linear N-order ODE/PDE æœ‰è§£æè§£, æ‰€ä»¥ â€œDifferential Equations for Engineersâ€ é€™é–€èª²ä¸»è¦è¬›é€™éƒ¨åˆ†.ä¸éå¦‚æœæ˜¯ non-linear $n^\\text{th}$-order ODE é›–æ²’æœ‰è§£æè§£, ä½†å¯åˆ©ç”¨ä»¥ä¸‹ä»‹ç´¹çš„ numerical methods æ±‚è¿‘ä¼¼è§£.The general linear third-order ode, where $y=y(x)$:$$a_3(x)y&apos;&apos;&apos;+a_2(x)y&apos;&apos;+a_1(x)y&apos;+a_0(x)y=b(x)$$ where the $a$ and $b$ coefficients can be any function of $x$. 2ï¸âƒ£ Euler method | Lecture 2 | Differential Equations for Engineers | Lecture 48 | Numerical Methods for Engineers [YouTube] [YouTube]è¨è«–ä¸€å€‹ first-order ode (ä¸åª linear, ä¹ŸåŒ…å« non-linear, æ‰€ä»¥ä¸€èˆ¬æ²’æœ‰ analytical solution) çš„é€¼è¿‘æ±‚è§£æ–¹æ³•.é€™è£¡èªªåŒ…å« nonlinear æ˜¯å› ç‚º $f(x,y)$ æœ‰å¯èƒ½ä½¿çš„ function $y=y(x)$ æœƒè®Šæˆ nonlinear$$\\frac{dy}{dx}=f(x,y) \\\\ y(x_0)=y_0$$ ç”¨ numerical method å»é€¼è¿‘. Euler method æ˜¯ first order method. 3ï¸âƒ£ Modiï¬ed Euler Method | Lecture 49 | Numerical Methods for Engineers [YouTube]åŸä¾†çš„ Euler method è¦è¨ˆç®— $x_{n+1}$ çš„æ™‚å€™ç”¨ä¸‹å¼é€¼è¿‘$$x_{n+1}=x_n+\\Delta t\\underbrace{f(t_n,x_n)}_\\text{slope}$$ ä½†å¯ä»¥çœ‹åˆ° slope å…¶å¯¦ä¸€ç›´åœ¨è®ŠåŒ–. å¦‚æœèªª slope æ”¹æˆç”¨ $f(t_n,x_n)$ and $f(t_n+\\Delta t,x_{n+1})$ çš„å¹³å‡å‘¢?é€™å°±æ˜¯ Modified Euler Method ä¸»è¦æƒ³æ³•. ğŸ’¡ Modified Euler Method å±¬æ–¼ $2^\\text{nd}$-order Runge-Kutta Methods (RK2) çš„ä¸€ç¨®.ä¸‹æ®µä»‹ç´¹ RK æ–¹æ³•æ™‚æœƒæ¨å°å¯ä»¥çŸ¥é“ç¢ºå¯¦ error order æœƒæ¯”è¼ƒå°æ³¨æ„åˆ° Runge-Kutta èªªçš„ order æŒ‡ error çš„ order, è·Ÿ ODE çš„ order ä»£è¡¨ independent variable çš„æœ€é«˜æ¬¡æ•¸å¾®åˆ†æ„æ€ä¸ä¸€æ¨£. ä½†æˆ‘å€‘ä¸çŸ¥é“ $x_{n+1}$ è¦æ€éº¼ç®— $f(t_n+\\Delta t,x_{n+1})$ å‘¢? æ‰€ä»¥å°±å…ˆç®—ä¸€å€‹ $x_{n+1}$ çš„ prediction. $$\\begin{align} x_{n+1}^p=x_n+\\Delta tf(t_n,x_n) \\\\ x_{n+1}=x_n+\\frac{\\Delta t}{2}\\left[f(t_n,x_n)+f(t_n+\\Delta t,x_{n+1}^p)\\right] \\end{align}$$ å¯ä»¥ç°¡åŒ–ä¸€ä¸‹è®Šæˆä¸‹é¢å¹¾å€‹ stages:$$\\begin{align} K_1=\\Delta t f(t_n,x_n) \\\\ K_2=\\Delta tf(t_n+\\Delta t,x_n+K_1) \\\\ x_{n+1}=x_n+\\frac{1}{2}(K_1+K_2) \\end{align}$$ 4ï¸âƒ£ Runge Kutta Methods | Lecture 50 | Numerical Methods for Engineers [YouTube]å°ä¸€å€‹ first order ODE, ä¸”å·²çŸ¥ $x(t_n)=x_n$ initial value ä¾†èªª$$\\dot{x}=f(t,x)$$ ç¶“éæ™‚é–“ $\\Delta t$ å¾Œçš„ $x(t_n+\\Delta t)$ è¦æ€éº¼ä¼°è¨ˆæ¯”è¼ƒæº–? æˆ‘å€‘å…ˆçœ‹ Taylor expansion:$$\\begin{align} x(t_n+\\Delta t)=x(t_n)+\\Delta tf(t_n,x_n)+\\frac{(\\Delta t)^2}{2}\\left.\\frac{d}{dt}f(t,x(t)) \\right|_{t=t_n} + O(\\Delta t^3) \\end{align}$$ äºŒæ¬¡å¾®åˆ†é …æˆ‘å€‘ç”¨ chain rule ç¹¼çºŒå±•é–‹:$$\\left.\\frac{d}{dt}f(t,x(t))\\right|_{t=t_n}=\\left.\\frac{\\partial}{\\partial t}f(t,x)\\right|_{t=t_n} + \\left.\\frac{\\partial}{\\partial x}f(t,x(t))\\frac{dx}{dt}\\right|_{t=t_n} \\\\ = \\frac{\\partial}{\\partial t}f(t_n,x_n) + \\left.\\frac{\\partial}{\\partial x}f(t,x(t))f(t,x(t))\\right|_{t=t_n} \\\\ = \\frac{\\partial}{\\partial t}f(t_n,x_n) + \\frac{\\partial}{\\partial x}f(t_n,x_n)f(t_n,x_n) \\\\ \\triangleq f_t(t_n,x_n)+f_x(t_n,x_n)f(t_n,x_n)$$ ä»£å›å» (9) å¾—åˆ° $x(t_n+\\Delta t)$ çš„æ³°å‹’å±•é–‹å¼: $$\\begin{align} x(t_n+\\Delta t)=x_n+\\Delta tf(t_n,x_n) + \\frac{(\\Delta t)^2}{2}(f_t(t_n,x_n)+f_x(t_n,x_n)f(t_n,x_n)) + O(\\Delta t^3) \\end{align}$$ Second order Runge-Kutta methods çš„æ­¥é©Ÿå¦‚ä¸‹:$$\\begin{align} K_1=\\Delta tf(t_n,x_n) \\\\ K_2=\\Delta tf(t_n+\\alpha\\Delta t,x_n+\\beta K_1) \\\\ x_{n+1}=x_n+aK_1+bK_2 \\end{align}$$ å…¨éƒ¨åˆæˆä¸€å€‹å¼å­:$$\\begin{align} x_{n+1}=x_n+a\\Delta tf(t_n,x_n)+b\\Delta t \\underbrace{f(t_n+\\alpha\\Delta t,x_n+\\beta \\Delta tf(t_n,x_n))}_\\text{using Taylor expansion} \\\\ =x_n+a\\Delta tf(t_n,x_n)+b\\Delta t \\left[ f(t_n,x_n) + \\alpha\\Delta t f_t(t_n,x_n)+\\beta\\Delta tf(t_n,x_n)f_x(t_n,x_n) + O(\\Delta t^2) \\right] \\\\ = x_n+(a+b)\\Delta tf(t_n,x_n)+(\\Delta t)^2 \\left[ \\alpha b f_t(t_n,x_n) + \\beta bf(t_n,x_n)f_x(t_n,x_n) \\right]+O(\\Delta t^3) \\end{align}$$ ğŸ’¡ è£œå……ä¸€ä¸‹ (14) çš„ Taylor expansion:$$f(t_n+\\Delta t,x_n+\\Delta x)=f(t_n,x_n)+\\left[\\begin{array}{cc}f_t(t_n,x_n) &amp; f_x(t_n,x_n)\\end{array}\\right]\\left[\\begin{array}{c}\\Delta t \\\\ \\Delta x\\end{array}\\right] + O\\left( \\left\\| \\left[\\begin{array}{c}\\Delta t \\\\ \\Delta x\\end{array}\\right] \\right\\|^2 \\right) \\\\ =f(t_n,x_n)+\\Delta t f_t(t_n,x_n) + \\Delta x f_x(t_n,x_n) + O(\\Delta t^2 + \\Delta x^2)$$ ä¸ç®¡ $O(\\Delta t^3)$ é …çš„æƒ…æ³ä¸‹, ä»¤ $x(t_n+\\Delta t)=x_{n+1}$, i.e. (10)=(16) , å¾—åˆ°:$$\\begin{align} a+b=1 \\\\ \\alpha b=\\frac{1}{2}\\\\ \\beta b=\\frac{1}{2} \\end{align}$$ æ‰€ä»¥çµè«–å°±æ˜¯ä½¿ç”¨ Second order Runge-Kutta methods çš„æ­¥é©Ÿ (11)-(13), æ‰€ç”¢ç”Ÿçš„ error order ç‚º $O(\\Delta t^3)$. Check (6)-(8) çš„ Modified Euler method æ­¥é©Ÿå†è·Ÿ Second order Runge-Kutta methods çš„æ­¥é©Ÿ (11)-(13) å°æ¯”.å¾ˆå®¹æ˜“å¯ä»¥ç™¼ç¾é€™æ˜¯ $a=b=1/2,\\alpha=\\beta=1$ çš„æƒ…æ³, åŒæ™‚ä¹Ÿå› ç‚ºæ»¿è¶³ (17)-(19) çš„æ¢ä»¶, æ‰€ä»¥ Modified Euler method æ˜¯ Second order Runge-Kutta methods çš„ä¸€ç¨®æƒ…æ³.å¦ä¸€ç¨® case æ˜¯å« midpoint method: $a=0, b=1, \\alpha=\\beta=1/2$. 5ï¸âƒ£ Higher-order Runge-Kutta Methods | Lecture 52 | Numerical Methods for Engineers [YouTube]Runge-Kutta Methods çš„ order è·Ÿç²¾ç¢ºåº¦æœ‰é—œ, ä¾‹å¦‚ $n^{th}$-order è¡¨ç¤º error term åªæœ‰ $O(\\Delta t^{n+1})$ å¤§å°. ğŸ’¡ çµ¦å®šä¸€å€‹å¯å®¹å¿çš„ error tolerance $\\varepsilon$, æ€éº¼æ±ºå®š step size $\\Delta t$ å¤šå¤§, åœ¨ RK4/5 æ˜¯ ok çš„, é€™æ¨£çš„æ±ºå®šæ–¹æ³•ç¨±ç‚º Adaptive Runge-Kutta methods. é€™é‚Šå°±ä¸ç­†è¨˜äº†. å¤§æ¦‚äº†è§£ä¸€ä¸‹æ„ˆé«˜ order æ‰€éœ€è¦çš„ stages æ„ˆå¤š$4^\\text{th}$-order éœ€è¦ $4$ stages, ä½† $5^\\text{th}$-order è®Šæˆè¦ $6$ stages. æ‰€ä»¥ $4^\\text{th}$-order å¾ˆä¸éŒ¯, ç¨± RK4. 6ï¸âƒ£ Higher-order ODEs and Systems | Lecture 53 | Numerical Methods for Engineers [YouTube]ODE çš„ order æŒ‡çš„æ˜¯ independent variable çš„æœ€é«˜å¾®åˆ†æ¬¡æ•¸.ä¾‹å¦‚ $F=ma$ å°±æ˜¯ $2^\\text{nd}$-order ODE:$$F=m\\frac{d^2x}{dt^2}$$ å»ºè­°ç›´æ¥çœ‹ Lecture 53 Higher-order odes and systems.æ¦‚å¿µå°±æ˜¯ $n^\\text{th}$-order ODE å¯ä»¥æ‹†æˆ $n$ å€‹ $1^\\text{st}$-order ODEs, ç„¶å¾Œç•¶æˆä¸€å€‹ dimension $n$ çš„ vector ä¾†çœ‹, å¥—ç”¨ Runge Kutta Methods (RK2, RD4 éƒ½å¯ä»¥) ä¾†è§£. [Second-order ODE ç¯„ä¾‹]:Write down the second-order Runge-Kutta modified Euler method (predictor-corrector method) for the following system of two first-order odes:$$\\dot{x}=f(t,x,y) \\\\ \\dot{y}=g(t,x,y)$$ [Ans:]æˆ‘å€‘ä»¤ $Z=[x,y]^T$: (ç¬¦è™Ÿæœ‰é»æ¿«ç”¨ï¼Œä¸éçœ‹å¾—æ‡‚å°±å¯ä»¥)$$\\nabla_tZ=[\\dot{x}, \\dot{y}]^T \\\\ \\nabla_tZ(t_n,Z_n)=[f(t_n,x_n,y_n),g(t_n,x_n,y_n)]^T$$ å° $Z$ åš modified Euler method:$$Z_{n+1}^p=Z_n+\\Delta t\\nabla_tZ(t_n,Z_n) \\\\ Z_{n+1}=Z_n+\\frac{\\Delta t}{2}\\left(\\nabla_tZ(t_n,Z_n)+\\nabla_tZ(t_n+\\Delta t,Z_{n+1}^p)\\right)$$ æ•´ç†æˆ Runge-Kutta steps:$$A_1=\\Delta t\\nabla_tZ(t_n,Z_n) \\\\ A_2=\\Delta t\\nabla_tZ(t_n+\\Delta t,Z_n+A_1) \\\\ Z_{n+1}=Z_n+\\frac{1}{2}(A_1+A_2)$$ æ‹†é–‹æ¯å€‹ç¶­åº¦ä¾†çœ‹:$$A_1=\\Delta t[f(t_n,x_n,y_n),g(t_n,x_n,y_n)]^T = [K_1,L_1]^T\\\\ A_2=\\Delta t \\left[\\begin{array}{cc} f(t_n+\\Delta t,x_n+K_1,y_n+L_1) \\\\ g(t_n+\\Delta t,x_n+K_1,y_n+L_1) \\end{array}\\right] =\\left[\\begin{array}{c} K_2\\\\L_2 \\end{array}\\right] \\\\ Z_{n+1}=\\left[\\begin{array}{cc} x_{n+1}\\\\y_{n+1} \\end{array}\\right] =\\left[\\begin{array}{cc} x_n+\\frac{1}{2}(K_1+K_2) \\\\ y_n+\\frac{1}{2}(L_1+L_2) \\end{array}\\right]$$ çµè«–å°±æ˜¯å¯ä»¥æ‹†æˆå…©å€‹ parallel çš„ update æ­¥é©Ÿ, æœ€å¾Œçš„å…¬å¼: ğŸ¤” ä¸€é–‹å§‹ä¸ç¢ºå®šå…©å€‹ parallel çš„ update æ­¥é©Ÿæ˜¯ä¸æ˜¯æ­£ç¢ºçš„, å› ç‚ºæœƒäº’ç›¸åƒç…§. ä½†å¦‚æœç•¶æˆä¸€å€‹ random vector $Z$, å°±å¦‚ä¸Šé¢æ¨å°, æ‹†é–‹çœ‹å„å€‹ç¶­åº¦å°±æ²’éŒ¯äº†.","tags":[{"name":"Ordinary Differential Equations","slug":"Ordinary-Differential-Equations","permalink":"https://bobondemon.github.io/tags/Ordinary-Differential-Equations/"},{"name":"ODE","slug":"ODE","permalink":"https://bobondemon.github.io/tags/ODE/"},{"name":"Euler Method","slug":"Euler-Method","permalink":"https://bobondemon.github.io/tags/Euler-Method/"},{"name":"Modified Euler Method","slug":"Modified-Euler-Method","permalink":"https://bobondemon.github.io/tags/Modified-Euler-Method/"},{"name":"Runge Kutta Methods","slug":"Runge-Kutta-Methods","permalink":"https://bobondemon.github.io/tags/Runge-Kutta-Methods/"}]},{"title":"å¿˜è¨˜ç‰©ç†ä¹Ÿè¦ææ‡‚çš„ Hamiltonian Monte Carlo (HMC) ç­†è¨˜","date":"2022-05-07T10:09:02.000Z","path":"2022/05/07/Hamiltonian-Monte-Carlo/","text":"å…ˆèªªæˆ‘ç‰©ç†ä»€éº¼çš„éƒ½é‚„çµ¦è€å¸«äº†, åªèƒ½ç”¨è‡ªå·±ç†è§£çš„æ–¹å¼, ç­†è¨˜ä¸‹ Hamiltonian dynamic. ğŸ’¡ å¦‚æœé€£æˆ‘éƒ½èƒ½æ‡‚, ç›¸ä¿¡å¤§å®¶éƒ½èƒ½ç†è§£ HMC äº† ä½†é‚„æ˜¯å»ºè­°å…ˆçœ‹ MCMC by Gibbs and Metropolis-Hasting Sampling, å› ç‚ºé€™ç¯‡è¦èªªçš„ Hamiltonian Monte Carlo (HMC) æ˜¯ Metropolis-Hastings (MH) æ–¹æ³•çš„ä¸€ç¨®, åªæ˜¯ proposal distribution å¾ random walk æ”¹æˆä½¿ç”¨ Hamiltonian dynamics ä¾†åš, å› è€Œè®Šçš„éå¸¸æœ‰æ•ˆç‡ (accept rate å¾ˆé«˜), ä¸”å°æ–¼é«˜ç¶­åº¦è³‡æ–™æ¡æ¨£ä¹Ÿå¾ˆæœ‰æ•ˆ. é¦–å…ˆç²—é«”å­—å¦‚ $\\mathbf{x}, \\mathbf{v}, \\mathbf{p}$ éƒ½æ˜¯ column vector, è€Œéç²—é«”å­—è¡¨ scalar, e.g. $m,t$ Hamiltonian dynamic ä¸€ç‰©é«”åœ¨ä½ç½® $\\mathbf{x}$ (é€™è£¡å¯æƒ³æˆæ˜¯é«˜åº¦) çš„é‡åŠ›ä½èƒ½ (potential energy) ç‚º $$\\begin{align} U(\\mathbf{x})=m\\mathbf{g}^T\\mathbf{x} \\end{align}$$ å…¶ä¸­ $m$ è¡¨è³ªé‡, $\\mathbf{g}$ è¡¨é‡åŠ›åŠ é€Ÿåº¦ (æ˜¯å€‹å‘é‡, æ‰€ä»¥æœ‰æ–¹å‘æ€§).åŒæ™‚è©²ç‰©é«”, å…¶æœ¬èº«ä¹Ÿå­˜åœ¨å‹•èƒ½ (kinetic energy) ä¸”å¯è¡¨ç¤ºç‚º: $$\\begin{align} K(\\mathbf{p})=\\frac{\\mathbf{p}^T\\mathbf{p}}{2m}\\left(=\\frac{1}{2}m\\mathbf{v}^2\\right) \\\\ \\mathbf{p}=m\\frac{d\\mathbf{x}}{dt}\\left(=m\\mathbf{v}\\right) \\end{align}$$ $\\mathbf{v}$ è¡¨é€Ÿåº¦ (æ˜¯å€‹å‘é‡, æ‰€ä»¥æœ‰æ–¹å‘æ€§), $\\mathbf{p}$ æˆ‘å€‘ç¨±ç‚ºå‹•é‡ (momentum).æ•´å€‹å°é–‰ç³»çµ± (æ²’æœ‰å¤–ç•Œçš„å…¶ä»–èƒ½é‡ä»‹å…¥) çš„èƒ½é‡ç‚º: $$\\begin{align} H(\\mathbf{x},\\mathbf{p})=U(\\mathbf{x})+K(\\mathbf{p}) \\\\ =m\\mathbf{g}^T\\mathbf{x}+\\frac{\\mathbf{p}^T\\mathbf{p}}{2m} \\end{align}$$ æ ¹æ“šèƒ½é‡å®ˆæ† (energy conservation), ä¸ç®¡æ™‚é–“ $t$ æ˜¯ä»€éº¼, æ•´å€‹ç³»çµ±çš„èƒ½é‡ $H(\\mathbf{x},\\mathbf{p})$ éƒ½ç¶­æŒç›¸åŒ.æ­¤æ™‚å¦‚æœæˆ‘å€‘çŸ¥é“è©²ç‰©é«”çš„åˆå§‹ç‹€æ…‹ $(\\mathbf{x}_0,\\mathbf{p}_0)$ çš„è©±, äº‹å¯¦ä¸Šå¯ä»¥çŸ¥é“ä»»ä½•æ™‚é–“ $t$ ä¸‹çš„ä½ç½®å’Œå‹•é‡ $(\\mathbf{x},\\mathbf{p})$è€Œé€™æ¨£çš„é—œä¿‚å¯ä»¥ç”±ä¸‹é¢çš„ Hamiltonian equations æè¿°å‡ºä¾†: $$\\begin{align} \\frac{dx_i}{dt}=\\frac{\\partial H}{\\partial p_i} \\\\ \\frac{dp_i}{dt}=-\\frac{\\partial H}{\\partial x_i} \\end{align}$$ å…¶ä¸­ $i\\in\\{1,..,d\\}$, $d$ è¡¨ç©ºé–“çš„ç¶­åº¦. åªè¦ä½¿ç”¨ $\\mathbf{p}=m\\mathbf{v}$, é€Ÿåº¦ $\\mathbf{v}$ æ˜¯ $\\mathbf{x}$ å°æ™‚é–“çš„å¾®åˆ†, ä»¥åŠé€Ÿåº¦å°æ™‚é–“çš„å¾®åˆ†ç­‰æ–¼è² åŠ é€Ÿåº¦ $-\\mathbf{g}$ (åº§æ¨™ç³»çµ±å®šç¾©ç‚ºå¾€ä¸Šçš„åº§æ¨™æ˜¯æ­£çš„, è€Œé‡åŠ›åŠ é€Ÿåº¦æ˜¯å‘ä¸‹çš„, æ‰€ä»¥å€¼ç‚ºè² )å°±å¯ä»¥å¾ (5) æ¨å°å‡º (6) å’Œ (7).$$\\frac{\\partial H}{\\partial p_i}=\\frac{\\partial K(\\mathbf{p})}{\\partial p_i}=\\frac{\\partial}{\\partial p_i}\\frac{\\sum_j p_j^2}{2m}=\\frac{p_i}{m}=\\frac{m v_i}{m}=v_i=\\frac{dx_i}{dt} \\\\ \\frac{\\partial H}{\\partial x_i}=\\frac{\\partial U(\\mathbf{x})}{\\partial x_i}=\\frac{\\partial m\\sum_j g_jx_j}{\\partial x_i}=mg_i=m\\frac{d(-v_i)}{dt}=-\\frac{dmv_i}{dt}=-\\frac{dp_i}{dt}$$ æ‰€ä»¥å¦‚æœå·²çŸ¥æ™‚é–“ $t$ çš„ä½ç½® $x_i(t)$, æƒ³é ä¼° $t+\\varepsilon$ çš„ä½ç½® $x_i(t+\\varepsilon)$ çš„è©±, å¯ä»¥é€é (6) çš„æ–¹å¼æ›´æ–°: $$x_i(t+\\varepsilon)\\approx x_i(t)+\\varepsilon\\cdot\\frac{dx_i(t)}{dt}=x_i(t)+\\varepsilon\\cdot\\frac{\\partial K(\\mathbf{p}(t))}{\\partial p_i} \\\\ =x_i(t)+\\varepsilon\\cdot\\frac{\\partial\\left(\\mathbf{p}(t)^T\\mathbf{p}(t)/2m\\right)}{\\partial p_i} = x_i(t)+\\varepsilon\\cdot\\frac{p_i(t)}{m}$$ åªè¦ $\\varepsilon$ å¤ å°çš„è©±, å°±æœƒå¤ æ¥è¿‘.åŒç† $p_i(t+\\varepsilon)$ ä¹Ÿèƒ½ç”¨ (7) ä¼°è¨ˆå‡ºä¾†. ç¸½çµç‚ºä»¥ä¸‹ update æ–¹æ³• (ä»¤ $m=1$), è€Œé€™å€‹æ–¹æ³•ç¨±ç‚º Eulerâ€™s method: $$\\begin{align} x_i(t+\\varepsilon) = x_i(t)+\\varepsilon\\cdot p_i(t) \\\\ p_i(t+\\varepsilon) = p_i(t)-\\varepsilon\\cdot\\frac{\\partial U(\\mathbf{x}(t))}{\\partial x_i} \\end{align}$$ ä½†è‡´å‘½çš„ç¼ºé»æ˜¯ä¸€æ—¦æ™‚é–“é•·äº†, ä¼°è¨ˆå°±æ„ˆä¾†æ„ˆä¸æº–äº†. å› æ­¤å¯¦ä½œä¸Šæœƒæ¡ç”¨ Leapfrog method: pdf ä»‹ç´¹.æˆ‘å€‘å…ˆçœ‹çœ‹å…©ç¨®æ–¹æ³•çš„ç²¾ç¢ºåº¦å·®ç•° (å–è‡ª DeepBayes 2019 Summer School Day 5, MCMC slides): Leapfrog method æè¿°å¦‚ä¸‹: $$\\begin{align} p_i(t+\\varepsilon/2)=p_i(t)-(\\varepsilon/2)\\cdot\\frac{\\partial U(\\mathbf{x}(t))}{\\partial x_i} \\\\ x_i(t+\\varepsilon)=x_i(t)+\\varepsilon \\cdot p_i(t+\\varepsilon/2) \\\\ p_i(t+\\varepsilon)=p_i(t+\\varepsilon/2)-(\\varepsilon/2)\\cdot\\frac{\\partial U(\\mathbf{x}(t+\\varepsilon))}{\\partial x_i} \\end{align}$$ ä¸»è¦çš„æƒ³æ³•æ˜¯, åœ¨ update $x_i(t+\\varepsilon)$ æ™‚ (å¼ (8)), åŸä¾†ä½¿ç”¨ $p_i(t)$ ä¾†æ›´æ–°, æ”¹æˆä½¿ç”¨â€æ›´æº–çš„â€ $p_i(t+\\varepsilon/2)$ ä¾†æ›´æ–°, å¦‚åŒå¼ (11). ç„¶å¾Œ $p_i(t+\\varepsilon)$ åˆ†æˆå…©æ¬¡çš„ $\\varepsilon/2$ steps ä¾†æ›´æ–°. æŠ±æ­‰æ²’æœ‰åš´è¬¹çš„æ•¸å­¸ä¾†è­‰æ˜ error çš„ order. æ³¨æ„åˆ°, æˆ‘å€‘åªéœ€è¦ $\\nabla_\\mathbf{x}U(\\mathbf{x})$ å°±èƒ½æ›´æ–° $(\\mathbf{x},\\mathbf{p})$!ä¹Ÿå°±æ˜¯èªªåªè¦æœ‰ potential energy çš„ gradient å°±å¯ä»¥æ¨¡æ“¬ Hamiltonian dynamic!é€™é»å¾ˆé‡è¦, å› ç‚ºè®Šæˆ sampling æ–¹æ³•å¾Œç­‰åŒæ–¼é€™å¥è©±: åªè¦æœ‰ score function å°±èƒ½æ¡æ¨£! è€Œ score function æ€éº¼ä¼°è¨ˆ, Score Matching æ˜¯å€‹å¥½æ–¹æ³•.Sample codes from (Markov Chain Monte-Carlo Solution.ipynb): 12345678def _leapfrog(self, x, v): self.energy = [] for _ in range(self.n_steps): v -= 0.5 * self.eps * self.dist.grad_log_density(x) x = x + self.eps * v v -= 0.5 * self.eps * self.dist.grad_log_density(x) self.energy.append(self._energy(x, v)) return x, v å½ˆç°§ä¾‹å­ åƒè€ƒè‡ª MCMC: Hamiltonian Monte Carlo (a.k.a. Hybrid Monte Carlo)ä¸çŸ¥é“æ€éº¼ä¾†çš„ä¹Ÿæ²’é—œä¿‚, åæ­£æ­¤æ™‚çš„ç³»çµ±èƒ½é‡ç‚º: $$U(x)=\\frac{x^2}{2} \\\\ K(p)=\\frac{p^2}{2} \\\\ H(x,p)=U(x)+K(p)$$ ä½ç½® $x$ çš„åƒè€ƒåŸé»å®šç¾©åœ¨å½ˆç°§ä¸­å¿ƒ, ä¹Ÿå°±æ˜¯å‰›å¥½ potential energy ç‚º $0$ çš„æ™‚å€™. ä½¿ç”¨ Leapfrog method ä¾†æ¨¡æ“¬ Hamiltonian equations æ›´æ–°ç‹€æ…‹ $(\\mathbf{x},\\mathbf{p})$: å¯ä»¥çœ‹åˆ° Hamiltonian dynamic çš„éç¨‹, èƒ½é‡ä¸Š (å·¦ä¸‹è§’çš„åœ–) åªæ˜¯ potential å’Œ kinetic energy çš„äº’ç›¸äº¤æ› (é»ƒè‰²å’Œé’è‰²äº’ç›¸æ¶ˆé•·), å…¶ç¸½èƒ½é‡æ˜¯ä¸è®Šçš„.å“ä¸å°~ç¸½èƒ½é‡ $H$ çš„é‚£æ¢å…¨é»ƒè‰²çš„ bar æ²’æœ‰å›ºå®šä¸å‹•å•Š, çœ‹èµ·ä¾†é‚„æ˜¯æœƒå°å¹…åº¦ä¸Šä¸Šä¸‹ä¸‹çš„.æ˜¯çš„, ç¸±ä½¿ç”¨äº† Leapfrog method, é‚„æ˜¯æœƒæ¼‚ç§», é€™æ˜¯å› ç‚ºæˆ‘å€‘å°æ™‚é–“é›¢æ•£åŒ–é€ æˆçš„. æƒ³è¦ error æ›´å°, å°±å¿…éœ€åˆ‡æ›´ç´°ç¢çš„æ™‚é–“å»é€¼è¿‘.å¦å¤–éœ€è¦ç‰¹åˆ¥èªªæ˜, å³ä¸‹è§’çš„ â€œPhase Spaceâ€ åœ–, ç•«å‡ºäº† $(x,p)$ ç‹€æ…‹å€¼çš„ç§»å‹•è·¯å¾‘. ç”±æ–¼èƒ½é‡å®ˆæ†, é€™è·¯å¾‘ä»£è¡¨äº†ç›¸åŒçš„ Hamiltonian energy. ç‚ºä»€éº¼è¦ç‰¹åˆ¥èªªæ˜é€™é», åœ¨å¾Œé¢è¬› sampling çš„æ™‚å€™æœƒå†æ¬¡æåˆ°. èƒ½é‡æ€éº¼çœ‹æˆæ©Ÿç‡åˆ†ä½ˆ? æˆ–åéä¾†? çµ¦å®šèƒ½é‡ $E(x)$, ç¸½æ˜¯å¯ä»¥ç”¨ä¸‹å¼è®Šæˆæ©Ÿç‡åˆ†ä½ˆ (Gibbs distribution): $$p(x)=\\frac{1}{Z}e^{-E(x)}$$ $Z$ å°±æ˜¯ä¸€å€‹ normalization constant è®Šæˆæ©Ÿç‡åˆ†ä½ˆç”¨çš„. æ‰€ä»¥èƒ½é‡æ„ˆå¤§è¡¨ç¤ºçš„æ©Ÿç‡å¯†åº¦å°±æ„ˆå°.æˆ‘å€‘ä¾†å°‡ Hamiltonian energy è®Šæ©Ÿç‡åˆ†ä½ˆçœ‹çœ‹: $$p(\\mathbf{x},\\mathbf{p})=\\frac{1}{Z}e^{-H(\\mathbf{x},\\mathbf{p})} \\\\ \\propto e^{-(U(\\mathbf{x})+K(\\mathbf{p}))} =e^{-U(\\mathbf{x})}e^{-K(\\mathbf{p})} =p(\\mathbf{x})p(\\mathbf{p})$$ é€™è£¡å¯ä»¥ç™¼ç¾ $\\mathbf{x}$ èˆ‡ $\\mathbf{p}$ äº’ç›¸ç¨ç«‹.åŸæœ¬å¾ç‰©ç†é‚£é‚Šæˆ‘å€‘æ˜¯å…ˆå®šç¾©äº†èƒ½é‡, å†åˆ©ç”¨ Gibbs distribution è®Šæˆäº†æ©Ÿç‡åˆ†ä½ˆ.ç¾åœ¨æˆ‘å€‘åéä¾†æ“ä½œ: å…ˆå®šç¾©æˆ‘å€‘è¦çš„æ©Ÿç‡åˆ†ä½ˆ, ç„¶å¾Œåæ¨èƒ½é‡é•·ä»€éº¼æ¨£. ğŸ¤” é¡Œå¤–è©±, å¯«åˆ°é€™æˆ‘å°±åœ¨æƒ³, åéä¾†å¾å…ˆå®šç¾©æ©Ÿç‡åˆ†å¸ƒå†æ¨å°èƒ½é‡æ˜¯ä¸æ˜¯ä»ç„¶èƒ½æ»¿è¶³ energy conservation?i.e. èƒ½é‡éš¨æ™‚é–“ä¸è®Š.$$\\begin{align} \\frac{dH(x,p)}{dt}=0 \\end{align}$$ä½†å…¶å¯¦ä¸ç”¨æ“”å¿ƒ, å› ç‚ºåªè¦ç”¨ Hamiltonian equations (6), (7) å»æ›´æ–°ç‹€æ…‹, å°±æœƒæ»¿è¶³ energy conservation.æˆ‘å€‘è€ƒæ…® 1-D case å³å¯, èƒ½é‡ç‚º $H(x(t),p(t))$, æ»¿è¶³ (6) and (7) ä¸¦è§€å¯Ÿ$$\\frac{dH(x(t),p(t))}{dt}=\\frac{dH}{dx}\\frac{dx}{dt}+\\frac{dH}{dp}\\frac{dp}{dt} \\\\ \\text{by }(6)=\\frac{dH}{dx}\\frac{dH}{dp}+\\frac{dH}{dp}\\frac{dp}{dt} \\\\ \\text{by }(7)=\\frac{dH}{dx}\\frac{dH}{dp}-\\frac{dH}{dp}\\frac{dH}{dx}=0$$ å› ç‚ºäº’ç›¸ç¨ç«‹, æˆ‘å€‘å¯ä»¥å…ˆå®šç¾© $\\mathbf{p}$ æ˜¯ normal distribution $\\mathcal{N}(\\mathbf{p}|0,I)$ $$p(\\mathbf{p})=\\frac{1}{Z_\\mathbf{p}}e^{-\\frac{\\mathbf{p}^T\\mathbf{p}}{2}}$$ å¯ä»¥çœ‹å¾—å‡ºä¾†å…¶ (kinetic) energy ç‚º: $$\\begin{align} K(\\mathbf{p})=\\frac{\\mathbf{p}^T\\mathbf{p}}{2} \\end{align}$$ ç„¶å¾Œä¸è¦å¿˜è¨˜æˆ‘å€‘çš„ç›®çš„æ˜¯è¦å¾ä¸€å€‹ç›®æ¨™åˆ†ä½ˆ $p^*(\\mathbf{x})$ å–æ¨£, å› æ­¤ $\\mathbf{x}$ çš„æ©Ÿç‡åˆ†ä½ˆå°±ç›´æ¥å®šç¾©æˆç›®æ¨™åˆ†ä½ˆ. è€Œå…¶ (potential) energy ç‚º: $$\\begin{align} p^*(\\mathbf{x})=\\frac{1}{Z_\\mathbf{x}}e^{-U(\\mathbf{x})} \\\\ \\Longrightarrow U(\\mathbf{x})=-\\log p^*(\\mathbf{x}) + \\text{const.} \\end{align}$$ é‚„è¨˜å¾—æˆ‘å€‘ä¹‹å‰èªªéé€™å¥è©±å—? â€œæˆ‘å€‘åªéœ€è¦ $\\nabla_\\mathbf{x}U(\\mathbf{x})$ å°±èƒ½æ›´æ–° $(\\mathbf{x},\\mathbf{p})$!â€å› æ­¤ (16) çš„ $\\text{const.}$ å°±ä¸é‡è¦äº†, æ‰€ä»¥ potential energy é€™éº¼å®šç¾©å°±å¯ä»¥äº†: $$\\begin{align} U(\\mathbf{x})=-\\log p^*(\\mathbf{x}) \\end{align}$$ MHC æ¡æ¨£éç¨‹ å¥½äº†, åˆ°ç›®å‰ç‚ºæ­¢æˆ‘å€‘è—‰ç”±è¨­å®šå¥½çš„ distribution $p^*(\\mathbf{x}),\\mathcal{N}(\\mathbf{p}|0,I)$, å¯ä»¥æ‰¾åˆ°å°æ‡‰çš„ energy functions $U(\\mathbf{x}),K(\\mathbf{p})$.é‚£å°±å¯ä»¥å¥—ç”¨ Hamiltonian equations (6), (7) ä¾†æ¨¡æ“¬èƒ½é‡ä¸è®Šçš„æƒ…å½¢ä¸‹, $(\\mathbf{x},\\mathbf{p})$ éš¨æ™‚é–“çš„è®ŠåŒ–.çµ¦å®šä¸€å€‹åˆå§‹ç‹€æ…‹ $(\\mathbf{x}_0,\\mathbf{p}_0)$ å¯ä»¥å¾—åˆ°: $$(\\mathbf{x}_0,\\mathbf{p}_0)\\xrightarrow[]{(6)(7)}(\\mathbf{x}_1,\\mathbf{p}_1)\\xrightarrow[]{(6)(7)}(\\mathbf{x}_2,\\mathbf{p}_2)\\xrightarrow[]{(6)(7)}...$$ å…¶ä¸­ $H(\\mathbf{x}_0,\\mathbf{p}_0)=H(\\mathbf{x}_1,\\mathbf{p}_1)=...$å¯¦ä½œä¸Šç”±æ–¼æ¯ä¸€æ¬¡ (6), (7) çš„æ›´æ–°éƒ½æ¡ç”¨å¾ˆå°çš„ $\\varepsilon$ (Leapfrog sample codes è£¡çš„ self.eps), é€™æ¨£æ‰èƒ½ç¢ºä¿å¤ æº–ç¢º.ä½†æˆ‘å€‘ä¹Ÿå¸Œæœ›èƒ½å¤ èµ°é ä¸€äº› (é€™å° multi-modual çš„ distribution å¾ˆæœ‰å¹«åŠ©, å¦‚ä¸‹åœ–æ‰€ç¤º), æ‰€ä»¥æœƒè·‘å€‹ $T$ æ­¥ updates (Leapfrog sample codes è£¡çš„ self.n_steps) ä½†å°±ç®—å¦‚æ­¤, ç”±æ–¼ energy conservation (13) çš„é—œä¿‚, $\\mathbf{x}$ åªæœƒåœ¨ phase space ä¸Šå…·æœ‰ç›¸åŒèƒ½é‡çš„ contour ä¸Šæ¡æ¨£.(Phase space å®šç¾©ç‚º $(\\mathbf{x},\\mathbf{p})$ çš„ç©ºé–“)ç‚ºäº†èƒ½å¤ æ¡æ¨£å‡ºå…¶å®ƒçš„é», æˆ‘å€‘éœ€è¦æ›åˆ°å…¶ä»–èƒ½é‡çš„ contour, å› æ­¤æ”¹è®Š $\\mathbf{p}$, å³å°å®ƒé‡æ–°æ¡æ¨£å³å¯.(follow ä¹‹å‰å®šç¾©å¥½çš„åˆ†ä½ˆ $\\mathcal{N}(\\mathbf{p}|0,I)$).ä½†æ˜¯åˆ¥å¿˜äº†, Hamiltonian MC æ‰€æå‡ºçš„æ¡æ¨£æ˜¯ Metorpolis-Hastings çš„ proposal distribution. æ‰€ä»¥ä¹Ÿéœ€è¦æœ‰ accept/reject, ä½†ä¹Ÿå¾—ç›Šæ–¼ energy conservation æ‰€ä»¥æœƒæœ‰éå¸¸é«˜çš„ accept rate. å› è€Œæ¡æ¨£æ•ˆç‡å¾ˆå¥½.ç¸½çµä¸€ä¸‹ HMC æ–¹æ³• [ref 3]: è€Œ Tuning HMC æœ‰å¹¾å€‹è¦é» [ref 3]: ä¸€èˆ¬ä¾†èªªè¦æ§åˆ¶ rejection rate åœ¨ $[1/4,3/4]$ ä¹‹é–“æœƒæ¯”è¼ƒå¥½. é‚„æœ‰å¤šè·‘å¹¾å€‹ threads ä¾†ç¢ºèªæ”¶æ–‚ç‹€æ³. References é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ç®—æ³• (äºŒ) HMC MCMC: Hamiltonian Monte Carlo (a.k.a. Hybrid Monte Carlo) DeepBayes 2019 Summer School Day 5, MCMC slides MHC sample codes from (https://github.com/bayesgroup/deepbayes-2019/blob/master/seminars/day5/Markov Chain Monte-Carlo Solution.ipynb) Leapfrog method: https://www2.atmos.umd.edu/~ekalnay/syllabi/AOSC614/NWP-CH03-2-2.pdf","tags":[{"name":"MCMC","slug":"MCMC","permalink":"https://bobondemon.github.io/tags/MCMC/"},{"name":"HMC","slug":"HMC","permalink":"https://bobondemon.github.io/tags/HMC/"},{"name":"Metropolis Hastings","slug":"Metropolis-Hastings","permalink":"https://bobondemon.github.io/tags/Metropolis-Hastings/"},{"name":"Hamiltonian Dynamic","slug":"Hamiltonian-Dynamic","permalink":"https://bobondemon.github.io/tags/Hamiltonian-Dynamic/"},{"name":"Hamiltonian Monte Carlo","slug":"Hamiltonian-Monte-Carlo","permalink":"https://bobondemon.github.io/tags/Hamiltonian-Monte-Carlo/"}]},{"title":"Score Matching ç³»åˆ— (äº”) SM åŠ ä¸Š Langevin Dynamics è®Šæˆç”Ÿæˆæ¨¡å‹","date":"2022-03-26T09:31:38.000Z","path":"2022/03/26/Generative-Modeling-by-Estimating-Gradients-of-the-Data-Distribution/","text":"ä¸»è¦å…§å®¹ç‚ºé€™ç¯‡æ–‡ç«  â€œGenerative Modeling by Estimating Gradients of the Data Distributionâ€œ èƒŒæ™¯çŸ¥è­˜ Score-based generative modeling çš„å…©å€‹æ ¸å¿ƒæ¦‚å¿µ: Score matching (SM): ä½¿ç”¨ score matching loss è®“ NN ç›´æ¥å­¸ score function: $\\nabla_x\\log p_{data}(x)$, å…¶ä¸­ $p_{data}(x)$ ç‚º data p.d.f. å› æ­¤æˆ‘å€‘æœ‰ä¸€å€‹ NN: $s_\\theta(x)\\approx \\nabla_x\\log p_{data}(x)$ Score matching åœ¨åšä»€éº¼, è«‹åƒè€ƒç³»åˆ—æ–‡ç« : Score Matching ç³»åˆ— (ä¸€) Non-normalized æ¨¡å‹ä¼°è¨ˆ Score Matching ç³»åˆ— (äºŒ) Denoising Score Matching (DSM) æ”¹å–„æ•ˆç‡ä¸¦å¯ Scalable Score Matching ç³»åˆ— (ä¸‰) Sliced Score Matching (SSM) åŒæ™‚ä¿æŒæ•ˆç‡å’Œæ•ˆæœ Score Matching ç³»åˆ— (å››) SM çš„ Toy Example in PyTorch Langevin dynamics: Langevin dynamics å¯ä»¥ä½¿ç”¨ score function, i.e. $\\nabla_x\\log p_{data}(x)$, ä¾†å– sample, å–å‡ºä¾†çš„ sample å…·æœ‰ $p_{data}(x)$ çš„åˆ†ä½ˆ è€Œæˆ‘å€‘å·²ç¶“ç”¨ä¸€å€‹ NN $s_\\theta(x)$ ä¾†é€¼è¿‘ score function äº†, å› æ­¤å¯ä»¥ç”¨ $s_\\theta(x)$ ä¾†å– sample, æ­¥é©Ÿå¦‚ä¸‹: çµ¦å®šä¸€å€‹å›ºå®šçš„ step size $\\epsilon&gt;0$, initial value $z=\\tilde{x}_0\\sim\\pi(x)$, å…¶ä¸­ $\\pi(x)$ æ˜¯å›ºå®šçš„ prior distribution, and $z_t\\sim\\mathcal{N}(0,I)$ $$\\tilde{x}_t = \\tilde{x}_{t-1}+\\frac{\\epsilon}{2}\\nabla_x\\log p_{data}(\\tilde{x}_{t-1})+\\sqrt{\\epsilon}z_t \\\\ \\approx \\tilde{x}_{t-1}+\\frac{\\epsilon}{2}s_\\theta(\\tilde{x}_{t-1})+\\sqrt{\\epsilon}z_t$$ ç•¶ $\\epsilon\\rightarrow 0$, $T\\rightarrow\\infty$ å‰‡ $\\tilde{x}_T$ ç­‰åŒæ–¼å¾ $p_{data}(x)$ å–æ¨£! è—‰ç”± Score Matching + Langevin Dynamics (SMLD), æˆ‘å€‘ç™¼ç¾å¦‚æœæˆåŠŸå­¸åˆ° score function, å‰‡å¯ä»¥å¾ random noise $z$ ç”¢ç”Ÿç¬¦åˆ data distribution çš„ sample.è€Œé€™æ­£æ˜¯ generative model åœ¨åšçš„äº‹æƒ…, æ­¤ç¨®æ–¹æ³•è«–æ–‡ç¨±ç‚º SMLDä½†æ˜¯ç›´æ¥è¨“ç·´å‡ºä¾†çš„ SMLD åœ¨çœŸå¯¦è³‡æ–™ä¸Šæœƒæœ‰å…©å€‹å•é¡Œå°è‡´åšä¸å¥½, æ¥è‘—è«–æ–‡è£¡èªªæ˜æ˜¯ä»€éº¼åŸå› ä»¥åŠè§£æ±ºæ–¹æ³• å…©å€‹ä¸»è¦å•é¡Œ The manifold hypothesis: Score matching (SM) è¦åšå¾—å¥½æ˜¯åŸºæ–¼è³‡æ–™åˆ†å¸ƒæ˜¯å¸ƒæ»¿æ•´å€‹ space çš„ (æ„æ€æ˜¯ data pdf çš„ rank æ²’æœ‰é™ä½), ç„¶è€ŒçœŸå¯¦è³‡æ–™éƒ½æ˜¯åœ¨ä½ç¶­åº¦çš„ manifold. é€™æœƒè®“ SM åšä¸å¥½ (even using Sliced SM). ä¾‹å¦‚3ç¶­ç©ºé–“ä¸­, è³‡æ–™åˆ†ä½ˆçš„ manifold åªæœ‰ rank 2 (å¹³é¢), æˆ–æ˜¯åªå‰©ä¸‹ rank 1 (ç·š) Low data density regions: åœ¨ density å¯†åº¦ä½çš„åœ°æ–¹, ç”±æ–¼ training data ä¹Ÿå¾ˆå°‘, å°è‡´é€™äº›åœ°æ–¹ SM æ ¹æœ¬ä¼°ä¸æº–. (è¦‹ä¸‹åœ–) å¦ä¸€æ–¹é¢, é€™å€‹å•é¡Œä¹Ÿæœƒå½±éŸ¿ Langevin dynamics çš„æ¡æ¨£: èˆ‰ä¾‹ä¾†èªª, å¦‚æœè³‡æ–™åˆ†å¸ƒæ˜¯ç”±å…©å€‹ disjoint çš„ mode density æ§‹æˆ (e.g. GMM with 2 mixtures), å‰‡ä¸€é–‹å§‹çš„ initial åœ¨å“ªå€‹è³‡æ–™åˆ†å¸ƒå°±å®Œå…¨æ±ºå®šäº†æœƒæ”¶æ–‚åœ¨å“ªé‚Š. é€™ç¨®ç¾è±¡ç¨±ç‚º multi-modal çš„ mixing problem. åŒæ™‚ä¸å¥½çš„ score ä¼°è¨ˆä¹Ÿæœƒå°è‡´ Langevin dynamics ç„¡æ³•æœ‰æ•ˆè·‘åˆ°å°çš„æ–¹å‘, å› è€Œæ”¶æ–‚å¾ˆæ…¢ è§£æ±ºè¾¦æ³• è¦è§£æ±ºç¬¬ä¸€å€‹å•é¡Œ (manifold hypothesis) å¯ä»¥é€éåŠ å…¥ Gaussian noise ç·©è§£, å› ç‚ºæœƒä½¿å¾—åˆ†å¸ƒå……æ»¿æ•´å€‹ç©ºé–“, ä¸å†åªå­˜åœ¨ä½ç¶­åº¦çš„ mainfold.ä¸Šåœ–å·¦æ˜¯ä½¿ç”¨äº† SSM ä½†æ²’åŠ å™ª, å¯ä»¥çœ‹åˆ°è¨“ç·´ä¸èµ·ä¾†. ä¸Šåœ–å³å‰‡åŠ äº†éå¸¸å°çš„å™ªè² (äººçœ¼ç„¡æ³•åˆ†è¾¨), loss å°±èƒ½ç©©å®šä¸‹é™!æ—¢ç„¶åŠ äº†ä¸€é» noise å°±å¯ä»¥ train èµ·ä¾†äº†, é‚£å°±ç”¨æ­¤å­¸å‡ºä¾†çš„ â€œæ¥è¿‘çœŸå¯¦ clean çš„ noisy åˆ†å¸ƒâ€ å»ç”¨ Langevin dynamics æ¡æ¨£çœ‹çœ‹çµæœç™¼ç¾é‚„æ˜¯æ²’æ³•æ¡æ¨£å‡ºæœ‰æ•ˆçš„å½±åƒ:ä¸Šåœ– (a), (b) and (c) çš„æ¯ä¸€å€‹ row å·¦åˆ°å³è¡¨ç¤º Langevin dynamics çš„æ¼”åŒ–éç¨‹. ç™¼ç¾æ¡æ¨£ä¸å‡ºæœ‰æ•ˆ samples. ä¸åŒ rows è¡¨ç¤ºä¸åŒçš„ random noise $z$ çš„çµæœ.æˆ‘å€‘å­¸åˆ°äº†æ¥è¿‘ clean çš„ score function åˆ†ä½ˆäº†, ç‚ºä½•ç„¡æ³•ç”¨ Langevin dynamics æ¡æ¨£å‡ºä¾†å‘¢?åŸå› æ˜¯ä¸Šé¢èªªçš„ç¬¬äºŒå€‹å•é¡Œ: multi-modal çš„ mixing problem. è€Œè¦è§£æ±º, å¯ä»¥å°‡åŠ å…¥çš„ Gaussian noise level åŠ å¤§ (æ›´å»£), é€™æ¨£å¯ä»¥è®“ä½å¯†åº¦çš„åœ°æ–¹è®Šå°‘, å› æ­¤ scores å°±éƒ½æº–äº†.ä½†ä¹Ÿåªèƒ½å­¸åˆ° noisy çš„åˆ†å¸ƒ (è·Ÿ DSM ç¼ºé»ä¸€æ¨£)!å› æ­¤, è«–æ–‡çš„ä½œæ³•å°±æ˜¯å­¸ä¸€å€‹ Noise Conditional Score Networks (NCSN): ä¹Ÿå°±æ˜¯åŸä¾†çš„ä¸åŒ noise level éƒ½æœƒè¨“ç·´å‡ºå°æ‡‰çš„ score networks, ç¾åœ¨ç›´æ¥ç”¨ä¸€å€‹ nework åƒ noise level ç•¶ condition ä¾†è¨“ç·´å°±å¥½. è—‰ç”±é€™æ¨£çš„åšæ³•, å¯ä»¥å°‡ noise å¾å¾ˆå¤§æ¼¸æ¼¸è®Šå°, å¾è€Œé‚„åŸåˆ°çœŸå¯¦çš„è³‡æ–™åˆ†å¸ƒä¹Ÿå› ç‚ºæˆ‘å€‘æœ‰ä¸åŒ noise ç¨‹åº¦çš„ data åˆ†å¸ƒ (NCSN approximates çš„åˆ†ä½ˆ), åŸä¾†çš„ Langevin dynamics éœ€è¦æ”¹æˆ annealed ç‰ˆæœ¬, é€™æ¨£ä¹Ÿèƒ½è§£æ±º multi-modal problem. å› ç‚ºæœ€é–‹å§‹çš„ noisy åˆ†å¸ƒæ˜¯ noise æœ€å¤§çš„æƒ…æ³, æ­¤æ™‚ä¸åŒ modes ä¹‹é–“å€åˆ¥ä¸å¤§, ä¸” low density å€åŸŸä¹Ÿå¾ˆå°‘ Annealed Langevin dynamics ç®—æ³•å¦‚ä¸‹:$\\{\\sigma_i\\}_{i=1}^L$ æ˜¯ä¸€å€‹æ­£çš„ç­‰æ¯”æ•¸åˆ—, è¡¨ç¤ºæ¯ä¸åŒçš„ noise level ç¨‹åº¦, æˆ‘å€‘è®“ $\\sigma_1$è¡¨ç¤ºæœ€å¤§å™ªè²ç­‰ç´š, $\\sigma_L$ ç‚ºæœ€å°å™ªè²ç­‰ç´šä¸”æ¥è¿‘ $0$, è¡¨ç¤ºæ»¿è¶³: $$\\frac{\\sigma_1}{\\sigma_2}=\\dots=\\frac{\\sigma_{L-1}}{\\sigma_L}&gt;1$$ æ ¸å¿ƒæ¦‚å¿µå°±æ˜¯ç”¨ Langevin dynamics å¾ $q_{\\sigma_{i-1}}(x)$ (è¼ƒå¤§å™ªè²çš„ä¼°è¨ˆåˆ†ä½ˆ) æ¡æ¨£, ç„¶å¾Œè©² sample ç•¶æˆåˆå§‹ sample å†å¾ $q_{\\sigma_i}(x)$ (è¼ƒå°å™ªè²çš„ä¼°è¨ˆåˆ†ä½ˆ) ä¸­ç¹¼çºŒç”¨ Langevin dynamics æ¡æ¨£.è—‰ç”±å¾å¤§å™ªè²ä¸€è·¯æ¡æ¨£åˆ°å°å™ªè²çš„åˆ†ä½ˆ, æˆ‘å€‘å°±èƒ½æ¥è¿‘åŸå§‹æƒ…æ³ä¸‹çš„æ¡æ¨£step size $\\alpha_i$ æœƒæ¼¸æ¼¸è®Šå°, å¦‚æ¼”ç®—æ³•çš„ç¬¬3åˆ—é€™å€‹ step size $\\alpha_i$ çš„é¸æ“‡æ˜¯ç‚ºäº†è®“ Langevin dynamics çš„ â€œsignal-to-noiseâ€ ratio:$$\\frac{\\alpha_i s_\\theta(x,\\sigma_i)} {2\\sqrt{\\alpha_i}z}$$ èˆ‡åŠ çš„ noise level $\\sigma_i$ ç„¡é—œ (ä½œè€…åœ¨ç¶“é©—ä¸Šç™¼ç¾ $\\|s_\\theta(x,\\sigma)\\|_2\\propto 1/\\sigma$, ä»£å…¥ä¸Šé¢çš„ SNR ratio æœƒç™¼ç¾èˆ‡ $\\sigma_i$ ç„¡é—œ) çµæœ è—‰ç”± NCSN å’Œ annealed Langevin dynamics æ–¹æ³•, è«–æ–‡å¯ä»¥å¾ˆå¥½çš„ç”¢ç”Ÿå½±åƒFor image Inpainting, sampling ç®—æ³•å¦‚ä¸‹æ²’æœ‰è¢«é®æ“‹çš„åœ°æ–¹å°±æ˜¯åŸæœ¬çš„ image + noise $\\tilde{z}$, é®æ“‹çš„åœ°æ–¹æ˜¯å¾ annealed Langevin dynamics ç”¢ç”Ÿçš„çµæœå¦‚ä¸‹: è¨è«– ä½¿ç”¨ NCSN çš„ network æ¶æ§‹å­¸ç¿’ score function. ä¸€ä½†æœ‰äº† score function, å°±å¯ä»¥ä½¿ç”¨ annealed Langevin dynamics æ¡æ¨£. å› æ­¤ç”Ÿæˆæ¨¡å‹å°±å®Œæˆäº† ğŸ’¡ SMLD = NCSN + annealed Langevin dynamics ä½†é€™æ¨£çš„åšæ³•é‚„æœ‰ä¸€äº›å•é¡Œ, é›–ç„¶ NCSN ä½¿ç”¨ä¸åŒå°ºåº¦çš„ noise è¨“ç·´, ä½† noise çš„å°ºåº¦æ€éº¼é¸? Langevin dynamics çš„ step size åƒæ•¸ $\\epsilon$, ä»¥åŠæ¬¡æ•¸ $T$ æ€éº¼å®š?é€™äº›éƒ½å¿…é ˆä»”ç´°èª¿æ•´, æ‰æœƒæœ‰æ¯”è¼ƒå¥½çš„æ•ˆæœ. ä¹Ÿå› æ­¤åˆ°é€™ç¯‡æ–‡ç« ç‚ºæ­¢ (2019) åªèƒ½ç”¢ç”Ÿè¼ƒå°çš„åœ– (32x32 ä»¥ä¸‹)æ‰€ä»¥åœ¨æ¥ä¸‹ä¾†çš„ä¸€ç¯‡æ–‡ç«  â€œImproved Techniques for Training Score-Based Generative Modelsâ€, 2020, Yang Song å¾ç†è«–ä¸Šæ¢è¨äº†é€™äº›å»ºè­°çš„è¨­å®š, çµæœèƒ½è®“ SMLD çš„ç”Ÿæˆæ¨¡å‹ç©©å®šç”¢ç”Ÿ 64x64, 256x256 çš„çµæœ.æ›´é€²ä¸€æ­¥, Yang Song åœ¨ ICLR 2021 çš„è«–æ–‡ â€œScore-Based Generative Modeling through Stochastic Differential Equationsâ€ å°‡ SMLD èˆ‡ Diffusion Probabilistic Modeling (DPM) çš„ç”Ÿæˆæ¨¡å‹é€é SDE çš„ framework çµ±ä¸€èµ·ä¾†.åœ¨é€™æ¶æ§‹ä¸‹, SMLD èˆ‡ DPM å…¶å¯¦æ˜¯ä¸€é«”å…©é¢, ä¸åŒçš„è§£è®€è€Œå·²! å¤ªè®“äººè®šå˜†äº†! åœ¨è©²ç¯‡çµæœå·²ç¶“èƒ½åšåˆ° 1024x1024 çš„é«˜è§£æåº¦åœ–ç‰‡, é€™è®“äººéå¸¸æœŸå¾… score-based generative modeling æ¥ä¸‹ä¾†çš„ç™¼å±•! ç²¾å½©ç²¾å½©!","tags":[{"name":"Score Matching","slug":"Score-Matching","permalink":"https://bobondemon.github.io/tags/Score-Matching/"},{"name":"Langevin Dynamics","slug":"Langevin-Dynamics","permalink":"https://bobondemon.github.io/tags/Langevin-Dynamics/"},{"name":"Generative Model","slug":"Generative-Model","permalink":"https://bobondemon.github.io/tags/Generative-Model/"}]},{"title":"Score Matching ç³»åˆ— (å››) SM çš„ Toy Example in PyTorch","date":"2022-03-26T06:30:44.000Z","path":"2022/03/26/score-matching-toy-example-in-pytorch/","text":"çœ‹äº†ä¸€äº› score matching çš„è«–æ–‡å¾Œ, å°±åœ¨ç¶²è·¯ä¸Šæ‰¾äº†ä¸€ä¸‹æœ‰æ²’æœ‰ç¯„ä¾‹, ç„¶å¾Œæ‰¾åˆ°äº†é€™å€‹ repo: [toy_gradlogp]éå¸¸æ¸…æ™°æ˜“æ‡‚, é‡é»å¯¦ä½œäº†: Denoising Score Matching (DSM) Deep Energy Estimator Networks (DEEN, æˆ‘æ€éº¼è¦ºå¾—è·Ÿ DSM ç­‰åƒ¹?!) Sliced Score Matching (SSM) Sliced Score Matching with Variance Reduction (SSM-VR) Langevin Dynamics (å¯ä»¥åªæ ¹æ“š score function å– sample) é›–ç„¶ä¸»è¦éƒ½æ˜¯ PyTorch, ä½† data pipeline ä»ç„¶ä½¿ç”¨ tensorflowå› æ­¤æˆ‘å°±æ”¹å¯«äº†ä¸€ä¸‹, è®Šæˆç´” PyTorch, ä¸¦ä¸”ä¹Ÿæ”¹æˆæˆ‘ç¿’æ…£çš„è³‡æ–™å¤¾çµæ§‹å’Œ config ä½¿ç”¨ Hydra æ”¹å¯«å¾Œçš„åœ¨é€™: [Score Matching Practicing in PyTorch] ä»¥ä¸‹æ¥è‘—èªªæ˜å…©å€‹é‡é»: Langevin Dynamics ç°¡ä»‹ æ€éº¼æŠŠ gradient ä¹Ÿç•¶æˆ loss? Langevin Dynamics ç°¡ä»‹ Langevin dynamics å¯ä»¥ä½¿ç”¨ score function, i.e. $\\nabla_x\\log p_{data}(x)$, ä¾†å– sample, å–å‡ºä¾†çš„ sample å…·æœ‰ $p_{data}(x)$ çš„åˆ†ä½ˆè€Œæˆ‘å€‘çŸ¥é“å¯ä»¥ç”¨ SM ä¾†è¨“ç·´ä¸€å€‹ NN $s_\\theta(x)$ é€¼è¿‘ score function, å› æ­¤å°±å¯ä»¥ç”¨ $s_\\theta(x)$ ä¾†å– sample, æ­¥é©Ÿå¦‚ä¸‹:çµ¦å®šä¸€å€‹å›ºå®šçš„ step size $\\epsilon&gt;0$, initial value $z=\\tilde{x}_0\\sim\\pi(x)$, å…¶ä¸­ $\\pi(x)$ æ˜¯å›ºå®šçš„ prior distribution, and $z_t\\sim\\mathcal{N}(0,I)$ $$\\tilde{x}_t = \\tilde{x}_{t-1}+\\frac{\\epsilon}{2}\\nabla_x\\log p_{data}(\\tilde{x}_{t-1})+\\sqrt{\\epsilon}z_t \\\\ \\approx \\tilde{x}_{t-1}+\\frac{\\epsilon}{2}s_\\theta(\\tilde{x}_{t-1})+\\sqrt{\\epsilon}z_t$$ ç•¶ $\\epsilon\\rightarrow 0$, and $T\\rightarrow\\infty$, å‰‡ $\\tilde{x}_T$ ç­‰åŒæ–¼å¾ $p_{data}(x)$ å–æ¨£! åªè¦æˆ‘å€‘èƒ½æŠŠ score function ç”¨ NN å­¸å¾—å¾ˆå¥½, å°±å¯ä»¥åˆ©ç”¨ Langevin dynamics æ¡æ¨£äº†. ç–‘?! é€™æ¨£ä¸å°±å®Œæˆäº†ä¸€å€‹ generative modeling äº†å—?æ²’éŒ¯, é€™å°±æ˜¯æœ€åˆçš„ score-based generative modeling æƒ³ç™¼é–‹é ­. ä½†é€™æœ€ naive çš„æ–¹æ³•äº‹å¯¦ä¸Šæœƒé¢è‡¨åˆ°ä¸€äº›å›°é›£.ä¸‹ä¸€ç¯‡æœƒä»‹ç´¹ Yang Song ä½¿ç”¨é€™ç¨®æ–¹æ³•æ™‚, ä»–æ˜¯å¦‚ä½•è§£æ±ºé€™äº›å›°é›£, ä¸¦æˆåŠŸéŠæˆç”Ÿæˆæ¨¡å‹. æ€éº¼æŠŠ gradient ä¹Ÿç•¶æˆ loss? å…¶å¯¦ç›´æ¥åƒè€ƒé€™ç¯‡æ–‡ç«  retain_graphå’Œcreate_graphå‚æ•° å°±å¯ä»¥äº†, èªªå¾—å¾ˆæ¸…æ¥š.é‡é»æ˜¯åˆ©ç”¨ torch.autograd.grad ä¸¦ä¸”å°‡å…¶ create_graph è¨­å®šç‚º True é€™é‚Šç°¡å–®èªªæ˜ä¸€ä¸‹.ä¸€èˆ¬æˆ‘å€‘è¦å¾—åˆ° gradient æ˜¯å° loss å– loss.backward(), pytorch æœƒåœ¨å…¶ computational graph è£¡åš backprop, ç„¶å¾Œ tensor å¦‚æœ requires_grad ç‚º True çš„è©±, è©² tensor å°±æœƒä¿ç•™ä½ gradient.ä½†ç¾åœ¨å•é¡Œæ˜¯, é€™äº› gradients æœ¬èº«ä¹Ÿæ˜¯ loss çš„ä¸€éƒ¨åˆ†, é€™è©²æ€éº¼è¾¦?åªè¦ä½¿ç”¨ torch.autograd.grad ä¸¦ä¸”å°‡å…¶ create_graph è¨­å®šç‚º True, pytorch å°±æœƒé‡å°é€™äº›æ±‚ gradients çš„ operations ç”Ÿå‡ºå…¶å°æ‡‰çš„ computational graph ä¸¦åŠ é€²åŸä¾†çš„åœ–è£¡. ä¹Ÿå¯ä»¥åˆ©ç”¨æ­¤æ–¹æ³•æ±‚æ›´é«˜éšçš„å°æ•¸ åœ¨ SM è£¡æœƒç”¨åˆ°æ˜¯å› ç‚ºå…¶ loss åŒ…å« score function $\\nabla_x\\log NN(x;\\theta)$, è€Œ score function æ­£æ˜¯æˆ‘å€‘ energy-based model (æ˜¯ä¸€å€‹ NN) çš„å¾®åˆ†ä¸€èˆ¬æˆ‘å€‘å®šç¾© energy-based model $E(x)$ ç‚º:$$E(x)=-\\log q(x)$$å…¶ä¸­ $q(x)$ is non-normalized distribution, i.e. $p(x)=q(x)/Z$ where $Z$ is partition function ä¸éå¦‚æœæˆ‘å€‘çš„ NN ç›´æ¥å°±æ˜¯ä¼°è¨ˆ score function (ä¹Ÿå°±æ˜¯ä¸é€é energy-based model), å°±ä¸éœ€è¦é€™éº¼åš, å¾Œé¢ Yang Song çš„å¾ˆå¤šå·¥ä½œå°±ç›´æ¥é€™æ¨£äº†.","tags":[{"name":"Denoising Score Matching","slug":"Denoising-Score-Matching","permalink":"https://bobondemon.github.io/tags/Denoising-Score-Matching/"},{"name":"Score Matching","slug":"Score-Matching","permalink":"https://bobondemon.github.io/tags/Score-Matching/"},{"name":"Langevin Dynamics","slug":"Langevin-Dynamics","permalink":"https://bobondemon.github.io/tags/Langevin-Dynamics/"},{"name":"Sliced Score Matching","slug":"Sliced-Score-Matching","permalink":"https://bobondemon.github.io/tags/Sliced-Score-Matching/"}]},{"title":"Score Matching ç³»åˆ— (ä¸‰) Sliced Score Matching (SSM) åŒæ™‚ä¿æŒæ•ˆç‡å’Œæ•ˆæœ","date":"2022-03-06T02:06:04.000Z","path":"2022/03/06/Sliced-Score-Matching-A-Scalable-Approach-to-Density-and-Score-Estimation/","text":"é€™æ˜¯ä¸€ç¯‡è«–æ–‡ç­†è¨˜: â€œSliced-Score-Matching-A-Scalable-Approach-to-Density-and-Score-Estimationâ€å»ºè­°çœ‹æœ¬æ–‡å‰è«‹å…ˆåƒå‰å…©ç¯‡: Score Matching ç³»åˆ— (ä¸€) å’Œ Score Matching ç³»åˆ— (äºŒ) é›–ç„¶ DSM (æ–‡ç« åœ¨ç³»åˆ—äºŒ) æ¯”èµ· SM å¯ä»¥éå¸¸æœ‰æ•ˆç‡çš„è¨“ç·´, ä½†æœ€å¤šåªèƒ½é‚„åŸåˆ° noisy çš„åˆ†å¸ƒ, ä¸”åŠ å™ªçš„å¼·åº¦ä¸æ˜“èª¿æ•´.æœ¬ç¯‡ SSM or SSM-VR å‰‡ä¸æœƒæœ‰æ­¤ç¼ºé», ä¸”æ•ˆæœå¯ä»¥æ¥è¿‘åŸä¾†çš„ SM. èƒŒæ™¯å›é¡§çœŸå¯¦è³‡æ–™çš„ pdf $p_d(x)$ å’Œå…¶ score function å®šç¾©å¦‚ä¸‹:$$s_d(x) \\triangleq \\nabla_x \\log p_d(x)$$ Model çš„ non-normalized density $\\tilde{p}_m(x;\\theta)$ å’Œ pdf $p(x;\\theta)$ ä»¥åŠ score function å®šç¾©å¦‚ä¸‹:$$p_m(x;\\theta)=\\frac{\\tilde{p}_m(x;\\theta)}{Z_\\theta}, \\\\ s_m(x;\\theta) \\triangleq \\nabla_x\\log p_m(x;\\theta) = \\nabla_x\\log \\tilde{p}_m(x;\\theta)$$ æœ€åŸå§‹çš„ loss function (Fisher divergence), æˆ–åœ¨æˆ‘å€‘å‰é¢çš„æ–‡ç« ç¨± Explicit Score Matching (ESM):$$\\begin{align} L(\\theta) \\triangleq \\frac{1}{2}\\mathbb{E}_{p_d}\\left[ \\| s_m(x;\\theta) - s_d(x) \\|_2^2 \\right] \\end{align}$$ å…¶ä¸­å¼ (1) ç­‰åƒ¹æ–¼ä¸‹å¼çš„ Implicit Score Matching (ISM) çš„ç›®æ¨™å‡½å¼:$$\\begin{align} J(\\theta)=\\mathbb{E}_{p_d}\\left[ tr(\\nabla_x s_m(x;\\theta))+\\frac{1}{2}\\|s_m(x;\\theta)\\|_2^2 \\right] \\end{align}$$ é›–ç„¶ ISM å¯ä»¥è¨ˆç®—, ä½†éœ€è¦ç”¨åˆ°äºŒæ¬¡å¾®åˆ†, ç•¶ network åƒæ•¸é‡å¤§çš„æ™‚å€™, Hessian matrix æ•ˆç‡å¾ˆä½. åŒæ™‚ $x$ ç¶­åº¦é«˜çš„æ™‚å€™æ•ˆç‡ä¹Ÿæ˜¯å¾ˆä½ (ç„¡æ³•å¾ˆå¥½ scalable)ç‚ºæ­¤, ä¸Šä¸€ç¯‡ DSM åˆ©ç”¨åŠ å…¥ noise çš„æ–¹å¼é¿æ‰é€™å…©å€‹å•é¡Œ, ä½†æœ‰å…©å€‹ç¼ºé» æœ€å¤šåªèƒ½å­¸åˆ°åŠ å™ªè²çš„åˆ†å¸ƒ noise çš„ level, i.e. $\\sigma^2$, å¾ˆé›£èª¿ SSM(-VR) èƒ½æ”¹å–„é€™å…©å€‹ç¼ºé» Sliced Score Matching (SSM) æœ¬ç¯‡ sliced score matching å‰‡åˆ©ç”¨å¦ä¸€ç¨®æƒ³æ³•, ä¸åœ¨é«˜ç¶­åº¦çš„ score function ä¸Šæ¯”è¼ƒ, è€Œæ˜¯å°‡ score function randomly æŠ•å½±åœ¨ä½ç¶­åº¦ä¸Šå†æ¯”è¼ƒ, å› æ­¤ç›®æ¨™å‡½å¼å¾ (1) è®Šæˆä¸‹å¼:$$\\begin{align} L(\\theta;p_v)\\triangleq \\frac{1}{2}\\mathbb{E}_{p_v}\\mathbb{E}_{p_d}\\left[ \\left( v^T s_m(x;\\theta) - v^T s_d(x) \\right)^2 \\right] \\end{align}$$ å…¶ä¸­ $v$ æ˜¯ random direction, $v \\sim p_v$, $x\\sim p_d$ are independent, åŒæ™‚è¦æ±‚$$\\mathbb{E}_{p_v}[vv^T] \\succ 0, \\mathbb{E}_{p_v}[\\|v\\|_2^2]&lt;\\infty$$ å¦‚åŒ ESM æ¨å°æˆç­‰åƒ¹çš„ ISM (å¼ (1) åˆ° (2) å»æ‰ $s_d$), (3) ä¹Ÿå¯ä»¥å°‡ $s_d$ å»æ‰:$$\\begin{align} J(\\theta;p_v) \\triangleq \\mathbb{E}_{p_v}\\mathbb{E}_{p_d} \\left[ v^T\\nabla_x s_m(x;\\theta)v + \\frac{1}{2}(v^Ts_m(x;\\theta))^2 \\right] \\end{align}$$ åŸºæœ¬ä¸Šå°æ¯å€‹ sample å‡ºä¾†çš„ $x_i$, æˆ‘å€‘éƒ½å¯ä»¥ sample å‡º $M$ å€‹æŠ•å½±å‘é‡, æ‰€ä»¥ empirical expecation å¯«æ³•å¦‚ä¸‹:$$\\begin{align} \\hat{J}(\\theta)\\triangleq \\frac{1}{N}\\frac{1}{M}\\sum_{i=1}^N\\sum_{j=1}^M v_{ij}^T\\nabla_x s_m(x_i;\\theta)v_{ij} + \\frac{1}{2}(v_{ij}^T s_m(x_i;\\theta))^2 \\end{align}$$ åŒæ™‚å¦‚æœ $p_v$ æ˜¯ multivariate standard normal or Rademacher distribution, å‰‡å¯ä»¥ç°¡åŒ–ç‚º:$$\\begin{align} \\hat{J}_{vr}(\\theta)\\triangleq \\frac{1}{N}\\frac{1}{M}\\sum_{i=1}^N\\sum_{j=1}^M v_{ij}^T\\nabla_x s_m(x_i;\\theta)v_{ij} + \\frac{1}{2}\\|s_m(x_i;\\theta)\\|_2^2 \\end{align}$$ç¨±ç‚º Sliced Score Matching with Variance Reduction (SSM-VR) æ–‡ç« èªª SSM-VR æ¯” SSM è¡¨ç¾æ›´å¥½, åŒæ™‚æŠ•å½±å‘é‡çš„æ•¸é‡, $M$, é¸æ“‡ 1 å€‹å°±å¾ˆå¥½äº† çœ‹åˆ°é€™å¯èƒ½é‚„æ˜¯æœ‰ç–‘å•, çœ‹èµ·ä¾†é‚„æ˜¯å¾—ç®— Hessian matrix, $\\nabla_x s_m(x;\\theta)$, é˜¿? ä¸æ˜¯èªªè¦å¯ä»¥åŠ é€Ÿæœ‰æ•ˆç‡?å…¶å¯¦æ˜¯é€™æ¨£çš„, å…ˆç®— $v^T s_m(x;\\theta)$ å° $x$ çš„å¾®åˆ†, ç”±æ–¼æ˜¯ scalar çš„ backprob å°±å¿«å¾ˆå¤š, å› æ­¤å¾—åˆ° $v^T\\nabla_x s_m(x;\\theta)$, ç„¶å¾Œå†è·Ÿ $v$ å…§ç©å°±çµæŸäº†å› æ­¤ç®—æ³•å¦‚ä¸‹ Codes å¯ä»¥åƒè€ƒ https://github.com/Ending2015a/toy_gradlogp/blob/master/toy_gradlogp/energy.py#L152 å¯¦é©— è«–æ–‡è£¡ä¸€æ®µå¯¦é©—çµæœå¦‚ä¸‹: SM loss æŒ‡çš„æ˜¯å¼ (1) çš„ loss, SM ç®—æ³•å‰‡æ˜¯å¼ (2) Implicit Score Matching (ISM)DSM æŒ‡çš„æ˜¯ Denosing Score Matching. å…ˆå¿½ç•¥ CP å’Œ Approx BP (å› ç‚ºæˆ‘æ²’çœ‹ XD) å¾ Figure 1 å¯ä»¥çœ‹å‡º SSM(-VR) çš„ performance å¯ä»¥é”åˆ°è·Ÿ SM æ¥è¿‘, ä¹Ÿæ¯” DSM å¥½ä¸Šä¸€æˆª.è€Œ Figure 2 å¯ä»¥çœ‹å‡º SSM(-VR) çš„ scalibility (DSM ä¹Ÿå¾ˆæœ‰æ•ˆç‡), é€™æ˜¯åŸä¾†çš„ SM é”ä¸åˆ°çš„ (å› ç‚ºè¦ç®— Hessian)Table 1 ä¹Ÿå¯ä»¥çœ‹å‡º DSM å°æ–¼ noise çš„å¼·åº¦ ($\\sigma$) è¼ƒæ•æ„Ÿ. ç¸½ä¹‹, SSM(-VR) å¯ä»¥è·Ÿ DSM ä¸€æ¨£ scalable å’Œ efficient, ä¸” performance æ¯” DSM å¥½åˆæ¥è¿‘åŸä¾†çš„ SM.å¦å¤–æä¸€ä¸‹é€™ç¯‡çš„ä½œè€…, Yang Song, å°æ–¼ score matching ä»¥åŠå¾Œä¾†çš„ diffusion probabilistic model éƒ½æœ‰å¾ˆé‡è¦çš„è‘—ä½œå’Œé€²å±•, å€¼å¾—è®€ä»–çš„è«–æ–‡ ğŸ‘","tags":[{"name":"Score Matching","slug":"Score-Matching","permalink":"https://bobondemon.github.io/tags/Score-Matching/"},{"name":"Sliced Score Matching","slug":"Sliced-Score-Matching","permalink":"https://bobondemon.github.io/tags/Sliced-Score-Matching/"}]},{"title":"Score Matching ç³»åˆ— (äºŒ) Denoising Score Matching (DSM) æ”¹å–„æ•ˆç‡ä¸¦å¯ Scalable","date":"2022-03-06T01:30:22.000Z","path":"2022/03/06/A-Connection-Between-Score-Matching-and-Denoising-Autoencoders/","text":"é€™æ˜¯ä¸€ç¯‡è«–æ–‡ç­†è¨˜: â€œA Connection Between Score Matching and Denoising Autoencodersâ€å»ºè­°çœ‹æœ¬æ–‡å‰è«‹å…ˆåƒå‰ä¸€ç¯‡: Score Matching ç³»åˆ— (ä¸€) Non-normalized æ¨¡å‹ä¼°è¨ˆ å‰è¨€åŸºæ–¼ Score Matching, æå‡º Denoising Score Matching (DSM) çš„ç›®æ¨™å‡½å¼, å¥½è™•æ˜¯åœ¨ energy-based model ä¸‹: ä¸ç”¨å°‡ score function çš„ gradients ä¹Ÿç´å…¥ loss å»è¨ˆç®— (é¿å…äºŒæ¬¡å¾®åˆ†åš backprop æé«˜æ•ˆç‡) ç•¶ input $x$ çš„ç¶­åº¦å¾ˆå¤§ä¹Ÿæ²’å•é¡Œ (å¯ä»¥ scalable) ä½†ç¼ºé»æ˜¯: æœ€å¤šåªèƒ½å­¸åˆ°åŠ  noise å¾Œçš„åˆ†å¸ƒ åŠ  noise çš„ level ä¸å¥½èª¿æ•´ é€™å…©å€‹ç¼ºé»åœ¨ä¸‹ä¸€ç¯‡ Sliced Score Matching (SSM) å¯ä»¥å¾—åˆ°æ”¹å–„é€™ç¯‡è«–æ–‡æœ€å¾Œä¹Ÿé»å‡ºäº† denoising autoencoder è·Ÿ score matching çš„é—œä¿‚ (å¯¦éš›ä¸Šå°±æ˜¯ DSM loss) ä»¥ä¸‹æ­£æ–‡é–‹å§‹ æ­£æ–‡ $q(x)$ è¡¨ç¤º data (çœŸå¯¦è³‡æ–™) çš„ pdf, $p(x;\\theta)$ è¡¨ç¤º model åƒæ•¸ç‚º $\\theta$ çš„ pdfExplicit Score Matching (ESM) ç‚º:$$\\begin{align} J_{ESM,q}(\\theta) = \\mathbb{E}_{q(x)}\\left[ \\frac{1}{2}\\left\\| \\psi(x;\\theta)-\\frac{\\partial \\log q(x)}{\\partial x} \\right\\|^2 \\right] \\end{align}$$å¯¦éš›ä¸Šæˆ‘å€‘ä¸çŸ¥é“ $q(x)$, å› æ­¤å¼ (1) çš„ $J_{ESM}$ æˆ‘å€‘ç„¡æ³•ç”¨. ä¸é, æœ€é–‹å§‹çš„ Score Matching è«–æ–‡å·²ç¶“è­‰æ˜ $J_{ESM}$ ç­‰åƒ¹æ–¼å¦‚ä¸‹çš„ $J_{ISM}$, è€Œ $J_{ISM}$ æ˜¯æˆ‘å€‘èƒ½å¯¦ä½œçš„Implicit Score Matching (ISM) ç‚º:$$\\begin{align} J_{ISM,q}(\\theta)=\\mathbb{E}_{q(x)}\\left[ \\frac{1}{2}\\|\\psi(x;\\theta)\\|^2+ tr(\\nabla_x\\psi(x;\\theta)) \\right] \\end{align}$$å¦‚æœæˆ‘å€‘å° $q(x)$ åš pertrub, i.e. æ¯ä¸€å€‹ data point $x$ éƒ½åŠ ä¸Šä¸€å€‹ pdf ç‚º $q_\\sigma(\\tilde{x}|x)$ çš„ random noiseå…¶ä¸­ $\\sigma$ ç‚ºè©² noise pdf çš„åƒæ•¸, å¦‚æœä»¥ isotropic Gaussian pdf ç‚ºä¾‹å­, $\\sigma^2$ å°±æ˜¯ varianceå‰‡ noisy çš„ data pdf $q_\\sigma(\\tilde{x})$ å°±è®Šæˆ:$q_\\sigma(\\tilde{x})=\\int q_\\sigma(\\tilde{x}|x) q(x) dx$ ğŸ’¡ å…©å€‹ independent random variables $x,y$ ç›¸åŠ  $z=x+y$, å‰‡ $z$ çš„ pdf ç‚º $x,y$ çš„ pdfs çš„ convolution ç„¶å¾Œ $\\theta$ è¦å­¸çš„ç›®æ¨™ pdf è®Šæˆ $q_\\sigma(\\tilde{x})$ å¾Œ, å…¶ ESM ç‚º:$$\\begin{align} J_{ESM,q_\\sigma}(\\theta) = \\mathbb{E}_{q_\\sigma(\\tilde{x})}\\left[ \\frac{1}{2}\\left\\| \\psi(\\tilde{x};\\theta)-\\frac{\\partial \\log q_\\sigma(\\tilde{x})}{\\partial \\tilde{x}} \\right\\|^2 \\right] \\end{align}$$ åªæ˜¯å°‡åŸä¾†çš„ ESM data pdf æ›æˆ noisy ç‰ˆæœ¬è€Œå·². å› æ­¤, $J_{ESM,q_\\sigma}$ ä¹Ÿæœƒç­‰åƒ¹ $J_{ISM,q_\\sigma}$ (åªè¦é©ç•¶çš„ noise pdf è®“ $q_\\sigma(\\tilde{x})$ æ»¿è¶³åŸä¾† ESM ç­‰æ–¼ ISM çš„æ¢ä»¶)å…¶ä¸­:$$\\begin{align} J_{ISM,q_\\sigma}(\\theta)=\\mathbb{E}_{q_\\sigma(\\tilde{x})}\\left[ \\frac{1}{2}\\|\\psi(\\tilde{x};\\theta)\\|^2+ tr(\\nabla_x\\psi(\\tilde{x};\\theta)) \\right] \\end{align}$$ âš ï¸ ä¹çœ‹ä¹‹ä¸‹ (4) å¥½åƒè·ŸåŸä¾†çš„ ISM (å¼ (2)) æ²’ä»€éº¼ä¸åŒ, å…¶å¯¦ä¸åŒçš„åœ°æ–¹åœ¨ â€œexpectation on what pdfâ€ ISM çš„ç¼ºé»æ˜¯å¿…é ˆè¦è¨ˆç®—äºŒæ¬¡å¾®åˆ†, ä¸¦ä¸”è¦ç•¶æˆ loss çš„ä¸€éƒ¨åˆ†, é€™æœƒå°è‡´è¨ˆç®—éæ…¢ (å› ç‚ºå¾®åˆ†çš„ operations ä¹ŸæœƒåŠ é€² graph è£¡, å¯ä»¥æƒ³åƒ NN æœ¬ä¾†çš„ graph å°±å¾ˆå¤§äº†, é‚„è¦åŠ ä¸€äºŒæ¬¡å¾®åˆ†çš„ ops é€²å») æœ‰é—œå¦‚ä½•å°‡ä¸€äºŒæ¬¡å¾®åˆ†åŠ å…¥ loss ä¸­å¯åƒè€ƒ [retain_graphå’Œcreate_graphå‚æ•°] å…¶å¯¦æˆ‘å€‘å¯ä»¥ç›´æ¥ç”¨ä¸€å€‹ NN ä¾†è¡¨ç¤º score function $\\psi(x;\\theta)$, é€™æ¨£åŸä¾†çš„äºŒæ¬¡å¾®åˆ†å°±æ˜¯è©² NN çš„ä¸€æ¬¡å¾®åˆ†, é›–ç„¶é€™æ¨£åšæ¯”è¼ƒæœ‰æ•ˆç‡, ä½† Deep Energy Estimator Networks æŒ‡å‡ºæœƒä¸ robust. ä¸éå¦‚æœä½¿ç”¨ Sliced Score Matching (SSM), è©²æ–‡ä½œè€…èªªä¸€æ¨£å¯ä»¥æœ‰æ•ˆçš„ç”¨ NN ç›´æ¥ predict score function. é€™ç¯‡è«–æ–‡æå‡ºçš„ Denoising Score Matching (DSM) çš„ç›®æ¨™å‡½å¼ $J_{DSM,q_\\sigma}(\\theta)$ å¯ä»¥é¿é–‹ä¸Šè¿°å°‡å¾®åˆ†é …ä¹ŸåŠ å…¥ loss è¨ˆç®—å°è‡´ä¸æœ‰æ•ˆç‡çš„ç¼ºé». è©²ç›®æ¨™å‡½å¼ç‚º:$$\\begin{align} J_{DSM,q_\\sigma}(\\theta)=\\mathbb{E}_{q_\\sigma(x,\\tilde{x})}\\left[ \\frac{1}{2} \\left\\| \\psi(\\tilde{x};\\theta) - \\frac{\\partial\\log q_\\sigma(\\tilde{x}|x)}{\\partial\\tilde{x}} \\right\\|^2 \\right] \\end{align}$$æ³¨æ„åˆ°è‹¥ noise pdf ç‚º isotropic Gaussian nosie $\\mathcal{N}(x,\\sigma^2I)$ å‰‡: $$\\frac{\\partial\\log q_\\sigma(\\tilde{x}|x)}{\\partial\\tilde{x}} = \\frac{1}{\\sigma^2}(x-\\tilde{x})$$ å› æ­¤å¼ (5) è®Šå¾—å¾ˆå®¹æ˜“è¨ˆç®—ä¹Ÿæœ‰æ•ˆç‡ ğŸ’¡ é‚„æœ‰ä¸€å€‹ç›´è§€çš„è§£é‡‹, æˆ‘å€‘çµ¦å®šä¸€å€‹ pair $(x,\\tilde{x})$, å¸Œæœ› $\\tilde{x}$ çš„ gradient è·Ÿ noise pdf çš„ gradient æµå‘ä¸€æ¨£, ç›¸ç•¶æ–¼å¸Œæœ›å°‡ nosiey çš„ $\\tilde{x}$ é‚„åŸæˆ clean çš„ $x$ æ–‡ç« ä¸¦è­‰æ˜äº† $J_{DSM_{q_\\sigma}}$ ç­‰åƒ¹æ–¼ $J_{ESM_{q_\\sigma}}$, i.e. (5)=(3) æˆ‘å€‘æ“·å–è«–æ–‡ Appendix çš„è­‰æ˜: æœ€å¾Œæ–‡ç« èªªæ˜äº†ä¸€å€‹æœ‰è¶£çš„ç™¼ç¾æœ€ç°¡å–®çš„ Denoise Autoencoder NN (ä¸€å±¤ linear hidden layer, tied weights) å…¶ reconstruction mse çš„ç›®æ¨™å‡½å¼ç­‰åƒ¹æ–¼ä½¿ç”¨ $J_{DSM_{q_\\sigma}}$è®“æˆ‘å€‘å°‡ Score Matching è·Ÿ Denoise Autoencoder æœ‰äº†é€£çµ","tags":[{"name":"Denoising Score Matching","slug":"Denoising-Score-Matching","permalink":"https://bobondemon.github.io/tags/Denoising-Score-Matching/"},{"name":"Score Matching","slug":"Score-Matching","permalink":"https://bobondemon.github.io/tags/Score-Matching/"}]},{"title":"Score Matching ç³»åˆ— (ä¸€) Non-normalized æ¨¡å‹ä¼°è¨ˆ","date":"2022-01-07T16:01:27.000Z","path":"2022/01/08/Estimation-of-Non-Normalized-Statistical-Models-by-Score-Matching/","text":"é€™æ˜¯ä¸€ç¯‡è«–æ–‡ç­†è¨˜: â€œEstimation of Non-Normalized Statistical Models by Score Matchingâ€, å…¶å¯¦æ¨è–¦ç›´æ¥è®€è«–æ–‡, æ•¸å­¸å¼å¾ˆæ¸…æ¥š, è¡¨é”ä¹Ÿæ˜ç¢º, åªæ˜¯æƒ³é †è‘—è‡ªå·±çš„èªªæ³•åšä¸€ä¸‹ç­†è¨˜ å‹•æ©Ÿä»‹ç´¹åœ¨ Machine Learning ä¸­, æˆ‘å€‘å¸¸å¸¸å¸Œæœ›ç”¨åƒæ•¸ $\\theta$ ä¼°å‡ºä¾†çš„ pdf $p(.;\\theta)$ èƒ½è·ŸçœŸå¯¦ data (training data) çš„ pdf $p_x(.)$ æ„ˆåƒæ„ˆå¥½.ç”±æ–¼æ˜¯ pdf $p(.;\\theta)$, å¿…é ˆæ»¿è¶³æ©Ÿç‡å½¢å¼, i.e. ç©åˆ†æ‰€æœ‰ outcomes ç­‰æ–¼ 1, å› æ­¤å¼•å…¥ä¸€å€‹ normalization term $Z(\\theta)$$$p(\\xi;\\theta)=\\frac{1}{Z(\\theta)}q(\\xi;\\theta)$$å…¶ä¸­ $\\xi\\in\\mathbb{R}^n$ ç‚ºä¸€å€‹ data pointå‡è¨­æˆ‘å€‘æœ‰ $T$ å€‹ observations $\\{x_1,...,x_T\\}$, å¥—ç”¨ empirical expecation ä¸¦å° likelihood estimation æ‰¾å‡ºæœ€ä½³ $\\theta$ (MLE):$$\\theta_{mle}=\\arg\\max_\\theta \\sum_{t=1}^T \\log p(x_t;\\theta)$$è¨ˆç®— gradient, æœƒç™¼ç¾ç”±æ–¼å­˜åœ¨ $Z(\\theta)$ è®Šå¾—å¾ˆé›£è¨ˆç®—, å°è‡´ gradient-based optimization ä¹Ÿå¾ˆå›°é›£. å±±ä¸è½‰è·¯è½‰, å¦‚æœæˆ‘å€‘èƒ½æ›å€‹æƒ³æ³•:ä¸è¦æ±‚æ‰¾åˆ°çš„ $\\theta$ å°æ¯å€‹ data points $x_t$ ä½¿å…¶ $p(x_t;\\theta)$ è·ŸçœŸå¯¦æ©Ÿç‡åˆ†ä½ˆçš„çµæœå¾ˆæ¥è¿‘, i.e. $p(x_t;\\theta)\\approx p_x(x_t)$æ”¹æˆå¸Œæœ›ä½¿å…¶$$\\begin{align} \\nabla_x\\log p_x(x_t) \\approx \\nabla_x\\log p(x_t;\\theta) {\\color{orange}{=\\nabla_x\\log q(x_t;\\theta)}} \\end{align}$$æ„æ€æ˜¯å¸Œæœ›æ¯å€‹ data points ä»–å€‘çš„ (log) gradient éƒ½è·ŸçœŸå¯¦åˆ†å¸ƒçš„ (log) gradient æ¥è¿‘å¯ä»¥æƒ³åƒå…©å€‹ functions çš„è®ŠåŒ–ä¸€è‡´çš„è©±, å®ƒå€‘çš„é•·ç›¸æ‡‰è©²æœƒå¾ˆæ¥è¿‘ (åªå·®åœ¨scaleä¸åŒ)ä»¥ä¸‹åœ–èˆ‰ä¾‹ä¾†èªª (è©²åœ–å¼•ç”¨è‡ª Yang Song: Generative Modeling by Estimating Gradients of the Data Distribution), vector field ç®­è™Ÿè¡¨ç¤ºé‚£äº› (log) gradients, è€Œ contours è¡¨ç¤ºä¸€å€‹ mixture of two Gaussiansæˆ‘å€‘è¦æ±‚ vector field ä¸€è‡´è—‰ç”±é€™æ¨£æ‰¾ $\\theta$ çš„æ–¹æ³•, æˆ‘å€‘å…¶å¯¦æ‰¾åˆ°çš„æ˜¯ non-normalized distribution $q(.;\\theta)$. ç›´è§€çš„ Objective Function (Explicit Score Matching) æˆ‘å€‘ä½¿ç”¨ MSE loss ä¾†è¨ˆç®—å¼ (1), åˆ©ç”¨æ­¤ loss æ‰¾æœ€ä½³ $\\theta$ çš„æ–¹æ³•ç¨±ç‚º Score Matchingå®šç¾© score function, å®ƒå…¶å¯¦å°±æ˜¯ gradient of the log-density with respect to the data vector: Data pdf çš„ score function: $\\psi_x(\\xi)=\\nabla_\\xi\\log p_x(\\xi) \\in \\mathbb{R}^n$ Model pdf çš„ score function: $$\\psi(\\xi;\\theta)= \\left( \\begin{array}{c} \\frac{\\partial\\log p(\\xi;\\theta)}{\\partial\\xi_1} \\\\ \\vdots\\\\ \\frac{\\partial\\log p(\\xi;\\theta)}{\\partial\\xi_n} \\end{array} \\right) =\\left( \\begin{array}{c} \\psi_1(\\xi;\\theta) \\\\ \\vdots \\\\ \\psi_n(\\xi;\\theta) \\end{array} \\right) = \\nabla_\\xi\\log p(\\xi;\\theta) =\\color{orange}{\\nabla_\\xi\\log q(\\xi;\\theta)}$$ å› æ­¤ objective function å°±æ˜¯é€™å…©å€‹ score functions çš„ MSE (åˆç¨±ç‚º Fisher Divergence: Interpretation and Generalization of Score Matching):$$\\begin{align} J(\\theta)=\\frac{1}{2}\\int_{\\xi\\in\\mathbb{R}^n} p_x(\\xi) \\| \\psi(\\xi;\\theta)-\\psi_x(\\xi) \\|^2 d\\xi \\end{align}$$è€Œ score matching estimator çš„åƒæ•¸å°±æ˜¯$$\\hat{\\theta}=\\arg\\min_\\theta J(\\theta)$$è¦ç®—æœŸæœ›å€¼éœ€è¦çŸ¥é“çœŸå¯¦è³‡æ–™çš„ pdf $p_x(.)$, é›–ç„¶æˆ‘å€‘ç„¡æ³•å¾—åˆ°, ä½†å¯ä»¥æ ¹æ“š training data å»è¨ˆç®— empirical æœŸæœ›å€¼.ä¾‹å¦‚æˆ‘å€‘æœ‰ $T$ å€‹ observations $\\{x_1,...,x_T\\}$, å‰‡ empirical expectation ç‚º$$\\tilde{J}(\\theta)=\\frac{1}{T}\\sum_{t=1}^T \\| \\psi(x_t;\\theta) - \\psi(x_t) \\|^2$$ä¸é (2) æœ€éº»ç…©çš„æ˜¯æˆ‘å€‘ä¸çŸ¥é“çœŸå¯¦è³‡æ–™çš„ score function $\\psi_x(.)$, è«–æ–‡çš„å®šç†èªªæ˜äº†åœ¨æŸäº›ç°¡å–®çš„æ¢ä»¶ä¸‹, å¯ä»¥é¿å…æ‰è¨ˆç®—é€™é …. æ¢ä»¶ç‚º: é™¤äº† pdf å¯å¾®, 1st/2nd moment å­˜åœ¨, ä¸€å€‹æ¯”è¼ƒç‰¹æ®Šçš„æ¢ä»¶ç‚º (ä½†ä¹Ÿå®¹æ˜“æ»¿è¶³): $$p_x(\\xi)\\psi(\\xi;\\theta)\\xrightarrow[\\|\\xi\\|\\rightarrow \\infty]{}0$$ æˆ‘å€‘åœ¨ä¸‹é¢æœƒçœ‹å‡ºä¾† Practical Objective Function (Implicit Score Matching) æ“·è‡ªè«–æ–‡. å°‡ Appendix çš„è­‰æ˜æè¿°å¦‚ä¸‹:å°‡ (2) å±•é–‹è®Šæˆ$$J(\\theta)=\\int p_x(\\xi)\\left[ \\frac{1}{2}\\|\\psi_x(\\xi)\\|^2 + \\frac{1}{2}\\|\\psi(\\xi;\\theta)\\|^2 - \\psi_x(\\xi)^T\\psi(\\xi;\\theta) \\right] d\\xi \\\\ =\\int p_x(\\xi)\\left[ \\frac{1}{2}\\|\\psi(\\xi;\\theta)\\|^2 {\\color{orange} {- \\psi_x(\\xi)^T\\psi(\\xi;\\theta)}} \\right]d\\xi + const$$å°‡å‘é‡çš„å…§ç©å±•é–‹, æ”¹å¯«æ©˜è‰²éƒ¨åˆ†ç©åˆ†å¦‚ä¸‹:$$-\\sum_{i=1}^n \\int p_x(\\xi)\\psi_{x,i}(\\xi)\\psi_i(\\xi;\\theta)d\\xi \\\\ \\text{by def. of score function }= -\\sum_{i=1}^n \\int p_x(\\xi) \\frac{\\partial \\log p_x(\\xi)}{\\partial \\xi_i} \\psi_i(\\xi;\\theta) d\\xi \\\\ = -\\sum_{i=1}^n \\int \\frac{p_x(\\xi)}{p_x(\\xi)} \\frac{\\partial p_x(\\xi)}{\\partial \\xi_i} \\psi_i(\\xi;\\theta) d\\xi = \\sum_{i=1}^n {\\color{green}{ -\\int \\frac{\\partial p_x(\\xi)}{\\partial \\xi_i} \\psi_i(\\xi;\\theta) d\\xi}}$$ ä½¿ç”¨åˆ†éƒ¨ç©åˆ† (ç‚ºç°¡åŒ–notation, åªçœ‹ç¬¬ä¸€ç¶­çš„è®Šæ•¸ $\\xi_1$)æ”¹å¯«ç¶ è‰²éƒ¨åˆ†è®Šæˆåªè¦å‡è¨­$$p_x(\\xi)\\psi(\\xi;\\theta)\\xrightarrow[\\|\\xi\\|\\rightarrow \\infty]{}0$$å‰‡æœ€å¾Œåªå‰©ä¸‹$$-\\int\\frac{\\partial p_x(\\xi)}{\\partial\\xi_i}\\psi_i(\\xi;\\theta)d\\xi = \\int\\frac{\\partial\\psi_i(\\xi;\\theta)}{\\partial\\xi_i}p_x(\\xi)d\\xi$$å°‡æ­¤çµæœä¸€è·¯ä»£å›å» (éœ€è¦ä¸€é»è€å¿ƒè€Œä»¥), å°±å¯ä»¥å¾—åˆ°å¼ (3) äº†, é‡è¤‡ä¸€ä¸‹å¼ (3) å¦‚ä¸‹:$$\\begin{align} J(\\theta)=\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)\\sum_{i=1}^n\\left[ \\partial_i\\psi_i(\\xi;\\theta)+\\frac{1}{2}\\psi_i(\\xi;\\theta)^2 \\right]d\\xi + const \\end{align}$$Optimize é€™å€‹ç›®æ¨™å‡½å¼å°±å®¹æ˜“å¾—å¤šäº†, åªè¦ä½¿ç”¨ empirical expecation å°±å¯ä»¥:$$\\begin{align} \\tilde{J}(\\theta)=\\frac{1}{T}\\sum_{t=1}^T\\sum_{i=1}^n\\left[ \\partial_i\\psi_i(x_t;\\theta)+\\frac{1}{2}\\psi_i(x_t;\\theta)^2 \\right] + const \\end{align}$$ æœ€ä½³è§£çš„å­˜åœ¨å”¯ä¸€æ€§ è­‰æ˜:å°ç…§å¼ (2) çš„ç›®æ¨™å‡½æ•¸:$$\\begin{align} J(\\theta)=\\frac{1}{2}\\int_{\\xi\\in\\mathbb{R}^n} p_x(\\xi) \\| \\psi(\\xi;\\theta)-\\psi_x(\\xi) \\|^2 d\\xi \\end{align}$$åªè¦æˆ‘å€‘çš„ parameter space å¤ å¤§èƒ½å¤ åŒ…å«çœŸå¯¦çš„ pdf, ç•¶ç›®æ¨™å‡½å¼é”åˆ°æœ€å°, i.e. $=0$, å‰‡è§£å°±æ˜¯çœŸå¯¦çš„ pdf è¨è«– ç¸½çµæœ€å¾Œçš„ objective function:$$J(\\theta)=\\int_{\\xi\\in\\mathbb{R}^n}p_x(\\xi)\\sum_{i=1}^n\\left[ \\partial_i\\psi_i(\\xi;\\theta)+\\frac{1}{2}\\psi_i(\\xi;\\theta)^2 \\right]d\\xi$$ç°¡åŒ–æ”¹å¯«ä¸€ä¸‹$$\\begin{align} J(\\theta)=\\mathbb{E}_{p_x(\\xi)}\\left[ tr(\\nabla_\\xi\\psi(\\xi;\\theta))+\\frac{1}{2}\\|\\psi(\\xi;\\theta)\\|_2^2 \\right] \\end{align}$$å…¶ä¸­ $\\psi(\\xi;\\theta):\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$, å¯¦å‹™ä¸Šæˆ‘å€‘å°±ç”¨ä¸€å€‹ NN åƒæ•¸ç‚º $\\theta$ è¡¨ç¤º, å› æ­¤åŸæœ¬éœ€è¦äºŒéšå°æ•¸, è®Šæˆåªéœ€è¦ä¸€éšå°æ•¸åœ¨ loss ä¸­. é›–ç„¶é€™æ¨£åšæ¯”è¼ƒæœ‰æ•ˆç‡, ä½† Deep Energy Estimator Networks æŒ‡å‡ºæœƒä¸ robust. å¾ŒçºŒåœ¨é€™ç¯‡æ–‡ç«  â€œA Connection Between Score Matching and Denoising Autoencodersâ€, ä½œè€…æå‡º Denoising Score Matching (DSM) ç›®æ¨™å‡½å¼, å¯ä»¥ä¸éœ€è¦å°‡ gradient ä¹Ÿç´å…¥ loss ä¸­.å…¶æƒ³æ³•å°±æ˜¯å°‡æ¯å€‹ data $x$ æ ¹æ“š Gaussian pdf åšäº›æ“¾å‹•, æ‰€ä»¥ä¸€å€‹å‰¯ä½œç”¨æ˜¯æ°¸é å­¸ä¸åˆ°æœ€æº–çš„ data pdf (é™¤éæ²’æœ‰æ“¾å‹•), ä½†å¯è—‰ç”±åŠ å…¥çš„æ“¾å‹•æ„ˆå°, è®“ä¼°è¨ˆæ„ˆçœŸå¯¦ Score matching çš„ä½œæ³•æ˜¯ 2005 å¹´, è€Œä½œè€… Aapo HyvÂ¨arinen å…¶å¯¦ä¹Ÿæ˜¯ Noise Contrastive Estimation (NCE) çš„ä½œè€…. (åƒè€ƒä¹‹å‰çš„ NCE ç­†è¨˜)NCE ä¹Ÿæ˜¯åœ¨åšä¸€æ¨£çš„äº‹æƒ…: æƒ³è¾¦æ³•é¿é–‹ $Z(\\theta)$ ä¾†ä¼°è¨ˆçœŸå¯¦è³‡æ–™çš„ pdf. ä½†ç™¼è¡¨åœ¨ 2010 å¹´. é€™ä¸€å•é¡Œ, probabilistic model flexibility èˆ‡ tractability çš„ trade-off, åœ¨ Machine Learning æ˜¯è¢«æ¢è¨å¾ˆä¹…çš„å•é¡Œ, é€™ç¯‡ Deep Unsupervised Learning using Nonequilibrium Thermodynamics, (Diffusion Probabilistic Model é–‹å§‹çš„é‡è¦æ–‡ç« ) çš„ introduction æè¿°ä¸€äº›ä¸»è¦æ–¹æ³•, å¯ä»¥ç›¡é‡æ»¿è¶³ flexibility æƒ…æ³ä¸‹, åˆèƒ½ tractable. Score matching å¯ä»¥æ‡‰ç”¨åœ¨ Langevin dynamics, é€éåªä½¿ç”¨ score function $\\nabla_x\\log p(x)$ å°±å¯ä»¥ç”¨ MCMC å– samples, è€Œé€™ä¸€æ­¥é©Ÿåœ¨ Diffusion Probabilistic Model ä¸­æ‰®æ¼”è‘—é‡è¦çš„è§’è‰²åŒæ™‚ NCE åœ¨ Self-supervised Learning åŒæ¨£ä¹Ÿæ˜¯é—œéµ, è¡ç”Ÿäº† infoNCE, CPC, â€¦ é€™ä¸€æ´¾çš„ SSL æ–¹æ³• ğŸ‘çœŸç¥äººä¹ŸğŸ‘","tags":[{"name":"Score Matching","slug":"Score-Matching","permalink":"https://bobondemon.github.io/tags/Score-Matching/"},{"name":"Score Function","slug":"Score-Function","permalink":"https://bobondemon.github.io/tags/Score-Function/"},{"name":"Fisher Divergence","slug":"Fisher-Divergence","permalink":"https://bobondemon.github.io/tags/Fisher-Divergence/"}]},{"title":"Score Function and Fisher Information Matrix","date":"2022-01-07T15:17:40.000Z","path":"2022/01/07/Score-Function-and-Fisher-Information-Matrix/","text":"Bayesian statistics è¦– dataset $\\mathcal{D}=\\{x_1,...,x_n\\}$ ç‚ºå›ºå®š, è€Œ model parameter $\\theta$ ç‚º random variables, é€éå‡è¨­ prior $p(\\theta)$, åˆ©ç”¨ Bayes rule å¯å¾— posterior $p(\\theta|\\mathcal{D})$. è€Œä¼°è¨ˆçš„åƒæ•¸å°±æ˜¯ posterior çš„ mode, i.e. $\\theta_{map}$ (Maximum A Posterior, MAP) é—œæ–¼ Fisher information matrix åœ¨ Bayesian è§€é»çš„ç”¨é€”, å…¶ä¸­ä¸€å€‹ç‚ºå¹«åŠ©å®šç¾©ä¸€å€‹ç‰¹æ®Šçš„ prior distribution (Jeffreys prior), ä½¿å¾—å¦‚æœ parameter $\\theta$ é‡æ–°å®šç¾©æˆ $\\phi$, ä¾‹å¦‚ $\\phi=f(\\theta)$, å‰‡ MAP è§£ä¸æœƒæ”¹è®Š. é—œæ–¼é€™éƒ¨åˆ†é‚„è«‹åƒè€ƒ Machine Learning: a Probabilistic Perspective by Kevin Patrick Murphy. Chapters 5 çš„ Figure 5.2 åœ–å¾ˆæ¸…æ¥š åä¹‹ Frequentist statistics è¦– dataset $\\mathcal{D}=\\{X_1,...,X_n\\}$ ç‚º random variables, é€éçœŸå¯¦ $\\theta^*$ æ¡æ¨£å‡º $K$ çµ„ datasets, æ¯ä¸€çµ„ dataset $\\mathcal{D}^k$ éƒ½å¯ä»¥æ±‚å¾—ä¸€å€‹ $\\theta_{mle}^k$ (MLE è¡¨ç¤º Maximum Likelihood Estimator), å‰‡ $\\theta_{mle}^k$ è·Ÿ $\\theta^*$ çš„é—œä¿‚å¯è—‰ç”± Fisher information matrix çœ‹å‡ºä¾† æœ¬æ–‡æ¢è¨ score function å’Œ Fisher information matrix çš„å®šç¾©, é‡é»æœƒæ”¾åœ¨æ€éº¼ç›´è§€ç†è§£. ç„¶å¾Œæœƒèªªæ˜ Fisher information matrix åœ¨ Frequentist statistics è§’åº¦ä»£è¡¨ä»€éº¼æ„ç¾©. å…ˆå®šç¾©ä¸€æ³¢ Score Function [Score Function Definition]:&emsp;é‡å°æŸä¸€é» data point $x$, åœ¨ $\\hat{\\theta}$ é»çš„ log-likelihood çš„ gradient å®šç¾©ç‚º score function:&emsp;$$\\begin{align} s(x,\\hat{\\theta}) \\triangleq \\nabla_\\theta \\log p(x|\\hat\\theta) \\end{align}$$ æ³¨æ„åˆ°å¦‚æœ $x$ æ˜¯ random variables, $s(x,\\hat{\\theta})$ ä¹Ÿæœƒæ˜¯ random variableåœ¨ Frequentist statistics è§€é»ä¸‹, data $x$ æ˜¯ random variables, æ‰€ä»¥å¯ä»¥å° true parameter $\\theta^*$ çš„ data distribution $p(x|\\theta^*)$ è¨ˆç®—æœŸæœ›å€¼:$$\\begin{align} \\mathbb{E}_{p(x|\\theta^*)}[s(x,\\hat{\\theta})] = \\int p(x|\\theta^*) \\nabla_\\theta \\log p(x|\\hat\\theta) dx \\end{align}$$ æˆ‘å€‘èˆ‰å€‹é›¢æ•£çš„ä¾‹å­ä¾†èªªæ˜å¼ (2): score_function_example.drawio å¯ä»¥çœ‹åˆ° score function ç›¸ç•¶æ–¼åœ¨æè¿° parameter è®ŠåŒ–å°æ–¼ log-likelihood çš„è®ŠåŒ–ç¨‹åº¦.è€Œè©²è®ŠåŒ–ç¨‹åº¦åœ¨çœŸå¯¦ $\\theta^*$ é‚£é»çš„æœŸæœ›å€¼ç‚º $0$, i.e. åœ¨ $\\hat\\theta=\\theta^*$ é€™é»è¨ˆç®— score function çš„æœŸæœ›å€¼:$$\\mathbb{E}_{p(x|\\theta^*)}[s(x,\\theta^*)] = \\int p(x|\\theta^*) \\nabla_\\theta \\log p(x|\\theta^*) dx \\\\ = \\int p(x|\\theta^*)\\frac{\\nabla_\\theta p(x|\\theta^*)}{p(x|\\theta^*)} dx \\\\ = \\int \\nabla_\\theta p(x|\\theta^*) dx \\\\ = \\nabla_\\theta \\int p(x|\\theta^*) dx = \\nabla_\\theta 1 = 0$$ ğŸ’¡ æ³¨æ„åˆ°è¨ˆç®—æœŸæœ›å€¼éƒ½æ˜¯åŸºæ–¼çœŸå¯¦è³‡æ–™åˆ†ä½ˆ, i.e. $p(x|\\theta^*)$. ç‚ºä½•å¼·èª¿é€™ä¸€é», æ˜¯å› ç‚ºæˆ‘å€‘æ‰‹é ­ä¸Šçš„ training data ä¸€èˆ¬ä¾†èªªéƒ½æ˜¯å‡è¨­å¾çœŸå¯¦åˆ†ä½ˆå–æ¨£å‡ºä¾†çš„, ä¹Ÿå°±æ˜¯èªªåªè¦ç”¨ training data è¨ˆç®—æœŸæœ›å€¼, éš±å«çš„å‡è¨­å°±æ˜¯ç”¨ $p(x|\\theta^*)$ ä¾†è¨ˆç®—. å› æ­¤æˆ‘å€‘æœ‰$$\\begin{align} \\mathbb{E}_{p(x|\\theta^*)}[s(x,\\theta^*)] = 0 \\end{align}$$ ğŸ’¡ å…¶å¯¦å°ä»»ä½•å…¶ä»–é» $\\hat{\\theta}$ å¼ (3) ä¹Ÿæˆç«‹, i.e. $\\mathbb{E}_{p(x|\\hat{\\theta})}[s(x,\\hat{\\theta})]=0$. æ³¨æ„åˆ°æœŸæœ›å€¼å¿…é ˆåŸºæ–¼ $p(x|\\hat\\theta)$ è€ŒéçœŸå¯¦è³‡æ–™åˆ†ä½ˆäº†. Fisher Information Matrix ğŸ’¡ $\\mathbb{E}_{p(x|\\theta^*)}[\\cdot]$ æˆ‘å€‘ç°¡å¯«ç‚º $\\mathbb{E}_{p^*}[\\cdot]$ [Fisher Information Matrix Definition]:&emsp;åœ¨ $\\hat{\\theta}$ é»çš„ Fisher information matrix å®šç¾©ç‚º:&emsp;$$I(\\theta^* ; \\hat\\theta) =\\mathbb{E}_{p^*}\\left[ s(x,\\hat\\theta)s(x,\\hat\\theta)^T \\right] \\\\ = \\mathbb{E}_{p^*}\\left[\\nabla_\\theta\\log p(x|\\hat\\theta)\\nabla_\\theta\\log p(x|\\hat\\theta)^T\\right]$$&emsp;å…¶ä¸­ $\\theta^*$ ç‚ºçœŸå¯¦è³‡æ–™çš„åƒæ•¸å…¶å¯¦å°±æ˜¯ score function çš„ second moment. Fisher information matrix åœ¨ $\\hat\\theta=\\theta^*$ æ­¤é»ä¸Šç‚º:$$\\begin{align} I(\\theta^* ; \\theta^*) =\\mathbb{E}_{p^*}\\left[ (s(x,\\theta^*)-0)(s(x,\\theta^*)-0)^T \\right] \\\\ = \\mathbb{E}_{p^*}\\left[ (s(x,\\theta^*)- \\mathbb{E}_{p^*}[s(x,\\theta^*)] )(s(x,\\theta^*)- \\mathbb{E}_{p^*}[s(x,\\theta^*)] )^T \\right] \\\\ = Cov_{p^*}\\left( s(x,\\theta^*),s(x,\\theta^*) \\right) \\end{align}$$ç”±æ–¼æˆ‘å€‘å·²ç¶“çŸ¥é“ score function åœ¨ $\\hat\\theta=\\theta^*$ çš„æœŸæœ›å€¼æ˜¯ $0$ , å› æ­¤ Fisher information matrix è®Šæˆ Covariance matrix of score function ğŸ’¡ åŒæ¨£å°ä»»ä½•å…¶ä»–é» $\\hat{\\theta}$ å¼ (6) ä¹Ÿæˆç«‹, i.e. $I(\\hat\\theta ; \\hat\\theta)=Cov_{\\hat p}(s(x,\\hat\\theta),s(x,\\hat\\theta))$. åŒæ¨£æ³¨æ„åˆ°æœŸæœ›å€¼å¿…é ˆåŸºæ–¼ $p(x|\\hat\\theta)$ è€ŒéçœŸå¯¦è³‡æ–™åˆ†ä½ˆäº†. ç¤ºæ„åœ–ç‚º:score_function_example_on_true_parameters.drawio å¦å¤–å‡å¦‚æˆ‘å€‘æ€è€ƒ score function (gradient) è¨ˆç®—çš„æ˜¯ä¸€æ¬¡å¾®åˆ†, å¯ä»¥æƒ³æˆæ˜¯æ–œç‡. é‚£å¦‚æœè€ƒæ…®äºŒæ¬¡å¾®åˆ† (Hseeian matrix), å‰‡å¯æƒ³æˆæ˜¯ curvature, å› æ­¤ç¤ºæ„åœ–ç‚º:Hessian_example_on_true_parameters.drawiocurvature_example.pptxç´…è‰²çš„é‚£ä¸‰æ¢ curves å°±æ˜¯ 3 å€‹ data points çš„ Hessian matrices. å› æ­¤ Hessian matrix (at $\\theta^*$) çš„æœŸæœ›å€¼ç›´è§€ä¸Šå¯ä»¥æƒ³æˆ log-likelihood çš„ graph åœ¨ $\\theta^*$ çš„å½æ›²ç¨‹åº¦ (curvature).ä»¥ä¸Šé€™å€‹è§€é»å…¶å¯¦è·Ÿ Fisher information matrix æœ‰é—œè¯çš„, æè¿°å¦‚ä¸‹:â€œFisher information matrix = score function çš„ covariance matrixâ€ ç­‰æ–¼ â€œè² çš„ Hessian matrix ä¹‹æœŸæœ›å€¼â€. æ³¨æ„åˆ°é€™æ€§è³ªæˆç«‹åœ¨ $\\theta^\\star$. (æˆ–æ›´ç²¾ç¢ºåœ°èªª, ä»»ä½• $\\hat\\theta$ éƒ½æ»¿è¶³ $I(\\hat\\theta,\\hat\\theta)=-\\mathbb{E}_{\\hat p}[H(x|\\hat\\theta)]$, åªæ˜¯æœŸæœ›å€¼åŸºæ–¼ $p(x|\\hat\\theta)$ è€Œä¸æ˜¯çœŸå¯¦è³‡æ–™åˆ†ä½ˆ, æŠ±æ­‰ç¬¬ä¸‰æ¬¡å›‰å—¦é€™ä¸€é», ä¸å†å¼·èª¿äº† XD) è­‰æ˜å¯åƒè€ƒ Wiki çš„ Fisher information, æˆ–åƒè€ƒ Agustinus Kristiadiâ€™s Blog: Fisher Information Matrix. é€™è£¡å°±ä¸é‡è¤‡.æœ¬ç¯‡ç›®çš„ç‚ºäº†è§£å…¶ç‰©ç†æ„ç¾©. å› æ­¤æˆ‘å€‘æœ‰å¦‚ä¸‹çš„ç­‰å¼:$$\\begin{align} I(\\theta^* ; \\theta^*) = \\mathbb{E}_{p^*}\\left[ \\nabla_\\theta\\log p(x|\\theta^*) \\nabla_\\theta\\log p(x|\\theta^*)^T\\right] = - \\mathbb{E}_{p^*}\\left[ \\nabla_\\theta^2\\log p(x|\\theta^*) \\right] \\end{align}$$ KL-divergence (or relative entropy) èˆ‡ MLE èˆ‡ $I(\\theta^* ; \\theta^*)$ é—œè¯ KL-divergence ç‚º, é€šå¸¸ $p(x)$ è¡¨ç¤º ground truth distribution:$$KL(p(x);q(x))=\\int p(x)\\log\\frac{p(x)}{q(x)}dx$$å‰‡æˆ‘å€‘çŸ¥é“ MLE (maximum log likelihood estimation) ç­‰åŒæ–¼æ±‚è§£æœ€å°åŒ– KL-divergence [ref]$$\\arg\\min_{\\theta} KL(p(x|\\theta^*);p(x|\\theta)) \\\\ =\\arg\\min_{\\theta} \\int p(x|\\theta^*)\\log\\frac{p(x|\\theta^*)}{p(x|\\theta)}dx \\\\ =\\arg\\min_{\\theta} \\int p(x|\\theta^*)\\log\\frac{1}{p(x|\\theta)}dx \\\\ =\\arg\\min_{\\theta} -\\mathbb{E}_{p^*}[\\log p(x|\\theta)] =: \\arg\\min\\text{NLL}\\\\ =\\arg\\max_{\\theta}\\mathbb{E}_{p^*}[\\log p(x|\\theta)] =: \\theta_{mle}$$å…¶ä¸­ NLL è¡¨ç¤º Negative Log-Likelihoodç”±æ–¼æˆ‘å€‘å·²ç¶“çŸ¥é“ $I(\\theta^* ; \\theta^*)$ æè¿°äº† NLL çš„ curvature, ç”±å‰›å‰›çš„æ¨å°çŸ¥é“ NLL (å°±æ˜¯ MLE) è·Ÿ KL ç­‰åƒ¹, æ‰€ä»¥ $I(\\theta^* ; \\theta^*)$ ä¹Ÿæè¿°äº† KL-divergence çš„ curvature, å…·é«”æ¨å°å¦‚ä¸‹:$$\\text{curvature of KL at }\\theta^* = \\nabla_\\theta^2 KL(p(x|\\theta^*); p(x|\\theta^*)) \\\\ =\\left( \\frac{\\partial^2}{\\partial\\theta_i\\partial\\theta_j} KL(p(x|\\theta^*); p(x|\\theta)) \\right)_{\\theta=\\theta^*} \\\\ = -\\int p(x|\\theta^*)\\left( \\frac{\\partial^2}{\\partial\\theta_i\\partial\\theta_j} \\log p(x|\\theta) \\right)_{\\theta=\\theta^*} dx \\\\ =-\\mathbb{E}_{p^*}[\\nabla_\\theta^2\\log p(x|\\theta^*)] \\\\ \\text{by (7) } = I(\\theta^*; \\theta^*)$$ $I(\\theta^* ; \\theta^*)$ åœ¨ Frequentist statistics çš„è§£é‡‹ äº†è§£äº† Fisher information matrix çš„ç‰©ç†æ„ç¾©å¾Œ, é‚„èƒ½çµ¦æˆ‘å€‘ä»€éº¼æ´è¦‹?å›åˆ°æ–‡ç« é–‹é ­èªªçš„: Frequentist statistics è¦– dataset $\\mathcal{D}=\\{X_1,...,X_n\\}$ ç‚º random variables, é€éçœŸå¯¦ $\\theta^*$ æ¡æ¨£å‡º $K$ çµ„ datasets, æ¯ä¸€çµ„ dataset $\\mathcal{D}^k$ (å…± $n$ ç­† data) éƒ½å¯ä»¥æ±‚å¾—ä¸€å€‹ $\\theta_{mle}^k$ (MLE è¡¨ç¤º Maximum Likelihood Estimator) æ‰€ä»¥å¯ä»¥è¦– $\\theta_{mle}$ ç‚ºä¸€å€‹ random variables, å…¶ distribution ç¨±ç‚º sampling distribution.å‰‡ $\\theta_{mle}$ è·Ÿ $\\theta^*$ æœ‰å¦‚ä¸‹é—œä¿‚ (sampling distribution ç‚º Normal distribution) :$$\\begin{align} \\sqrt{n}(\\theta_{mle}-\\theta^*) \\xrightarrow[]{d} \\mathcal{N}\\left( 0,I^{-1}(\\theta^*;\\theta^*) \\right), \\qquad \\text{as }n\\rightarrow\\infty \\end{align}$$å…¶ä¸­ $\\xrightarrow[]{d}$ è¡¨ç¤º converge in distribution. åˆæˆ–è€…é€™éº¼å¯«$$\\begin{align} (\\theta_{mle}-\\theta)\\approx^d \\mathcal{N}\\left( 0, \\frac{1}{nI(\\theta^*;\\theta^*)} \\right) \\end{align}$$ç›´è§€è§£é‡‹ç‚ºå¦‚æœ $I(\\theta^*; \\theta^*)$ æ„ˆå¤§ (or $n$ æ„ˆå¤§) , MLE æ„ˆæœ‰é«˜çš„æ©Ÿç‡æ¥è¿‘ $\\theta^*$å› æ­¤ Fisher information matrix $I(\\theta^*; \\theta^*)$ é‡æ¸¬äº† MLE çš„æº–ç¢ºåº¦ Summary æœ¬æ–‡è¨è«–äº† score function and Fisher information matrix çš„å®šç¾©å’Œç›´è§€è§£é‡‹, åŒæ™‚ä¹Ÿèªªæ˜äº† MLE çš„ä¼°è¨ˆ $\\theta_{mle}$ å…¶è·é›¢çœŸå¯¦åƒæ•¸ $\\theta^*$ å¯è¢« Fisher information matrix $I(\\theta^* ; \\theta^*)$ æè¿°å‡ºä¾† (é›–ç„¶å¯¦å‹™ä¸Šæˆ‘å€‘ç„¡æ³•ç®— $I(\\theta^* ; \\theta^*)$ å› ç‚ºä¸çŸ¥é“ true parameters $\\theta^*$) é—œæ–¼ Fisher information çŸ¥ä¹é€™ç¯‡æ–‡ç« å¾ˆå¥½: è´¹é›ªä¿¡æ¯ (Fisher information) çš„ç›´è§‚æ„ä¹‰æ˜¯ä»€ä¹ˆï¼ŸåŒæ™‚ Fisher information ä¹Ÿèƒ½æè¿°åƒæ•¸ $\\theta$ å’Œ random variable $x$ ä¹‹é–“çš„ä¿¡æ¯é‡ (é€™éƒ¨åˆ†æœ¬æ–‡æ²’æè¿°), å¯åƒè€ƒ Maximum Likelihood Estimation (MLE) and the Fisher Information å’Œ A tutorial on Fisher information åˆ©ç”¨ binomial distribution çš„ä¾‹å­ä¾†èªªæ˜ å¦å¤–èˆ‡ Natural gradient çš„é—œè¯å¯åƒè€ƒ: Natural Gradient by Yuan-Hong Liao (Andrew). å¯«å¾—ä¹Ÿéå¸¸æ£’! åœ¨åŸºæ–¼ç¬¬ $t$ æ¬¡çš„ $\\theta^t$ æ™‚, Natural gradient è¦æ‰¾å¾— optimize æ–¹å‘ $d^*$ ç‚ºå¦‚ä¸‹:$$d^*=\\mathop{\\arg\\min}_{KL(p(x|\\theta^t)\\|p(x|\\theta^t+d))=c} \\mathcal{L}(\\theta^t+d)$$ ä¹Ÿå°±æ˜¯èªªå¸Œæœ› distribution è®ŠåŒ–ä¹Ÿä¸è¦å¤ªå¤§. çµè«–æœƒç™¼ç¾ $d^*$ çš„è¿‘ä¼¼è§£:$$d^*\\propto-I(\\theta^t;\\theta^t)^{-1}\\nabla_\\theta\\mathcal{L}(\\theta)|_{\\theta=\\theta^t}$$ æ­£å¥½è·Ÿ optimization çš„ Newtonâ€™s method æ–¹æ³•ä¸€æ¨£. æœ€å¾Œæä¸€ä¸‹, æœ¬æ–‡å®šç¾©çš„ score function æ˜¯åŸºæ–¼ $\\theta$ çš„ gradient, ä½†åŒæ™‚æœ‰å¦ä¸€ç¨®æ–¹æ³•ç¨± Score Matching [ref 9], å…¶å®šç¾©çš„ score function æ˜¯åŸºæ–¼ data point $x$ çš„ gradient:$$\\nabla_x\\log p(x;\\theta)$$ å› æ­¤çœ‹é€™ score function å°±ä¸æ˜¯åœ¨ parameter space ä¸Šè§€å¯Ÿ, è€Œæ˜¯åœ¨ input space ä¸Š. Reference Machine Learning: a Probabilistic Perspective by Kevin Patrick Murphy. Chapters 5 and 6 Agustinus Kristiadiâ€™s Blog: **Fisher Information Matrix Wiki Fisher information A tutorial on Fisher information [pdf] Maximizing likelihood is equivalent to minimizing KL-Divergence è´¹é›ªä¿¡æ¯ (Fisher information) çš„ç›´è§‚æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ Maximum Likelihood Estimation (MLE) and the Fisher Information by Xichu Zhang Yang Song: Generative Modeling by Estimating Gradients of the Data Distribution Estimation of Non-Normalized Statistical Models by Score Matching Natural Gradient by Yuan-Hong Liao (Andrew)","tags":[{"name":"Score Function","slug":"Score-Function","permalink":"https://bobondemon.github.io/tags/Score-Function/"},{"name":"Fisher Information Matrix","slug":"Fisher-Information-Matrix","permalink":"https://bobondemon.github.io/tags/Fisher-Information-Matrix/"}]},{"title":"Stochastic Processes Week 8 LÃ©vy processes","date":"2021-12-12T15:17:32.000Z","path":"2021/12/12/Stochastic-Processes-Week-8-Levy-processes/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes (æœ¬æ–‡) Week 8.1: Definition of a LÃ©vy process. Stochastic continuity and cÃ dlÃ g paths$N_t,W_t,L_t$ åˆ†åˆ¥è¡¨ç¤º Poisson process, Brownian motion, and Levy process$$\\begin{array}{|c | c |c |} \\hline N_t &amp; W_t &amp; L_t \\\\ \\hline N_0=0\\text{ a.s.} &amp; W_0=0\\text{ a.s.} &amp; L_0=0\\text{ a.s.} \\\\ \\hline \\text{indep. increments} &amp; \\text{indep. increments} &amp; \\text{indep. increments} \\\\ \\hline \\text{stationary increments} &amp; \\text{stationary increments} &amp; \\text{stationary increments} \\\\ \\hline N_t-N_s\\sim Pois(\\lambda(t-s)) &amp; W_t-W_s\\sim\\mathcal{N}(0,t-s) &amp; {L_t-L_s\\sim\\mathcal{P}(t-s),\\mathcal{P}\\text{ is }\\color{orange}{idd}} \\\\ \\hline \\end{array}$$&emsp;- Independent increments:&emsp;&emsp;$\\forall t_0&lt;t_1&lt;\\ldots&lt;t_n$, we have the following random variables jointly independent (æ‰€ä»¥ä¸€å®šä¹Ÿæ˜¯ pairwise indep.)&emsp;&emsp;$X_{t_n}-X_{t_{n-1}},\\ldots,X_1-X_0$&emsp;- Stationary increments:&emsp;&emsp;$\\forall t,s\\geq0$, and $h&gt;0$, we have&emsp;&emsp;$X_{t+h}-X_{s+h} =^d X_t-X_s$&emsp;&emsp;æ³¨æ„åˆ°æ˜¯ in distribution sense (æœ€ weak çš„é‚£å€‹ sense)&emsp;&emsp;æˆ‘å€‘çŸ¥é“ â€œalmost surelyâ€, â€œin probabilityâ€, or â€œin mean squareâ€ senses éƒ½æœƒå°è‡´ in distribution sense.&emsp;- $iid$ stands for Infinitely divisible distribution: will be discussed in next section æ³¨æ„åˆ°å°æ‰€æœ‰çš„ Levy process $L_t$, å…¶ covariance function æœ‰å¦‚ä¸‹é—œä¿‚:$$K(t,s)=Cov(L_t,L_s)\\\\ \\text{assume } t&gt;s \\text{ } =Cov(L_t-L_s+L_s,L_s) = Cov(L_t-L_s,L_s) + Var(L_s) = Var(L_s)\\\\ \\therefore K(t,s)=Var(L_{\\min(t,s)})$$ [Cadlag Function Def]:&emsp;ä¸­æ–‡ç¨± â€œå³é€£å·¦æ¥µå‡½æ•¸â€&emsp;We say $f$ is a Cadlag function, if å·¦å³ limit éƒ½å­˜åœ¨ä¸”å®šç¾© $f$ ç‚ºå³ limit çš„å€¼&emsp;$$\\exists\\lim_{s\\rightarrow t,s&lt;t} f(s) =: f(t^-) \\\\ \\exists\\lim_{s\\rightarrow t,s&gt;t} f(s) =: f(t^+) = f(t)$$ Wiki çš„ä»‹ç´¹å¾ˆæ¸…æ¥š è¨˜å¾—åœ¨ Brownian motion æ™‚æœ‰è¬›åˆ° Kolmogorov continuity theorem: ä¸€å®šå­˜åœ¨ä¸€å€‹ continuous modification of a Brownian motion é¡ä¼¼.æ‰€ä»¥çœ‹åˆ° Brownian motion å¯ä»¥åªè€ƒæ…®å…¶ almost surely continuous trajectories çš„ç‰ˆæœ¬ [Proposition, Cadlag Trajectories of Levy Process]:&emsp;åœ¨ Levy process ä¹Ÿæœ‰é¡ä¼¼çš„æƒ…æ³. çµ¦å®šä¸€å€‹ Levy process $L_t$&emsp;å­˜åœ¨å¦ä¸€å€‹ process $L_tâ€™$ such that æ‰€æœ‰ trajectories éƒ½æ˜¯ almost surely Cadlag function. Week 8.2: Examples of LÃ©vy processes. Calculation of the characteristic function in particular cases[Infinitely Divisible Distributions Def]:&emsp;$\\xi$ is a infinitely divisible distribution if $\\forall n\\geq2$, $\\exists Y_1,\\ldots,Y_n$ - i.i.d. such that&emsp;$\\xi=^d Y_1+\\dots+Y_n$&emsp;Note that it is equals in distribution sense. It is equivalent to saying:&emsp;$$\\Phi_\\xi(u)=\\left(\\Phi_{Y_1}(u)\\right)^n, \\qquad \\forall n \\\\ \\Longleftrightarrow \\left(\\Phi_\\xi(u)\\right)^{1/n} \\text{ is a characteristic function}, \\qquad\\forall n$$&emsp;where $\\Phi_\\xi(u)$ is the characteristic function of random variable $\\xi$ [Levy Process can be Characterized by an I.D.D.]:&emsp;1. $\\forall$ Levy process $L_t$ at $\\forall$ time $t^*$, $L_{t^*}$ has an infinitely divisible distribution&emsp;2. $\\forall$ infinitely divisible distribution, $\\exists$ a Levy process $L_t$ such that $L_1$ has this distribution[Proof]:&emsp;åªè­‰æ˜ç¬¬ä¸€æ¢. $L_t$ å¯ä»¥æ”¹å¯«å¦‚ä¸‹: $\\forall n$ éƒ½æ»¿è¶³&emsp;$L_t=\\sum_{k=1}^n\\left(L_{t\\cdot\\frac{k}{n}} - L_{t\\cdot\\frac{k-1}{n}}\\right)$&emsp;ç”±æ–¼ stationary increments ç‰¹æ€§&emsp;$\\left(L_{t\\cdot\\frac{k}{n}} - L_{t\\cdot\\frac{k-1}{n}} \\right) =^d L_{\\frac{t}{n}}$&emsp;å†ç”±æ–¼ independent increments ç‰¹æ€§, è®Šæˆ $n$ å€‹ i.i.d. random variables ç›¸åŠ . Q.E.D. [Normal Distribution is an i.d.d.]:&emsp;æ‰€ä»¥å¯ä»¥ç™¼ç¾ $L_t$ is a Levy process ($W_t$ is a Brownian motion)&emsp;$L_t=\\mu t+\\sigma W_t$; ä¸” $L_1\\sim\\mathcal{N}(\\mu,\\sigma^2)$ [Cauchy Distribution is an i.d.d.]:&emsp;Cauchy distribution çš„ p.d.f. ç‚º:&emsp;$p(x)=\\frac{1}{\\pi\\gamma\\left[1+\\left(\\frac{x-x_0}{\\gamma}\\right)^2\\right]}$&emsp;å…¶ä¸­ $x_0$ ç¨±ç‚º location parameter, $\\gamma$ ç¨±ç‚º scale parameter&emsp;è§€å¯Ÿç‰¹å¾µå‡½æ•¸å¯ä»¥ç™¼ç¾æ˜¯ i.d.d. [Gamma Distribution is an i.d.d.] Distributions that are infinitely divisible distributions: [Stable Distribution Def]:&emsp;We say that $\\xi$ is stable distribution if $\\forall n\\geq2$, $\\exists$ $a_n&gt;0,b_n\\in\\mathbb{R}$&emsp;$\\xi,\\xi_1,\\ldots,\\xi_n$ - are i.i.d. such that&emsp;$\\xi_1+\\ldots+\\xi_n =^d a_n\\xi+b_n$ æ˜¯ stable distribution ä¸€å®šæ˜¯ infinitely divisible, å¾ˆå®¹æ˜“çœ‹å‡ºä¾†, åªè¦æ”¹å¯«æˆ$\\left(\\frac{\\xi_1}{a_n}-\\frac{b_n}{n\\cdot a_n}\\right) + \\ldots + \\left(\\frac{\\xi_n}{a_n}-\\frac{b_n}{n\\cdot a_n}\\right) =^d \\xi$åä¹‹ä¸æˆç«‹æ‰€ä»¥ä¸Šè¿°çš„ i.d.d. ä¸­, åªæœ‰ Normal and Cauch distributions æ˜¯ stable Week 8.3: Relation to the infinitely divisible distributions[Properties of Infinitely Divisible Distributions]:&emsp;Let $\\xi$ is a i.d.d. then&emsp;1. $\\Phi_\\xi(u)=0$ doesnâ€™t have any $\\mathbb{R}$ solution&emsp;&emsp;i.e. all solutions are imaginary numbers. ç‰¹å¾µæ–¹ç¨‹å¼çš„ roots æ²’æœ‰å¯¦æ•¸è§£&emsp;2. Support set of $\\xi$, $Supp(\\xi)$, is unbounded Random variable $\\xi$ ç‚ºä¸€å€‹ measurable function $\\Omega\\rightarrow\\mathbb{R}$. è€Œ support of a measurable function $\\mu$ å®šç¾©ç‚º:$Supp(\\mu):=\\left\\{x:\\forall\\text{ open set }G\\text{ containing }x\\text{ s.t. }\\mu(G)&gt;0\\right\\}$ åƒè€ƒ wiki çš„å®šç¾©): ç™½è©±æ˜¯ä»»ä½• $x$ çš„ open neighbourhood çš„ measure éƒ½ $&gt;0$, å‰‡ $x$ å±¬æ–¼ support set å› æ­¤ random variable çš„ support set å°±ç”¨ measurable function çš„æ–¹å¼å»æƒ³ [Uniform Distribution is NOT i.d.d.]:&emsp;Let $\\xi$ is uniform distribution $\\mathcal{U}(a,b)$, then the characteristic function is&emsp;$\\Phi_\\xi(u)=\\int_a^b e^{iux}\\frac{1}{b-a}dx=\\frac{1}{b-a}\\cdot\\frac{e^{iua}}{iu}\\cdot\\left(e^{iu(b-a)}-1\\right)$&emsp;We have $\\Phi_\\xi(u)=0$ if and only if&emsp;$e^{iu(b-a)}=1 \\Longleftrightarrow u=\\frac{2\\pi k}{b-a},\\qquad k\\in\\mathbb{Z}/\\{0\\}$&emsp;æ‰€ä»¥å­˜åœ¨ $\\mathbb{R}$ çš„ root, å› æ­¤ä¸æ˜¯ infinitely divisible distributions [Bernoulli Distribution is NOT i.d.d.]:&emsp;Let $\\xi$ is Bernoulli random variable&emsp;$$\\xi=\\left\\{ \\begin{array}{rl} 1, &amp; p\\\\ 0, &amp; 1-p \\end{array} \\right.$$&emsp;then $Supp(\\xi)=\\{0,1\\}$, so is not bounded and hence NOT infinitely divisible distributions æˆ‘å€‘å¸¸çœ‹åˆ°çš„ distribution å¤§éƒ¨åˆ†éƒ½æ˜¯ infinitely divisible distribution, å¦‚Gaussian, Cauchy, Gamma, Poisson, Compound Poissonä½†æ˜¯ uniform and Bernoulli distributions ä¸æ˜¯ i.d.d. æœ€å¾Œè©¦é¡Œè¨ˆç®—ä¸€ä¸‹ binomial distribution $Bin(n,p)$ çš„ç‰¹å¾µå‡½æ•¸:$$\\Phi_X(u)=\\mathbb{E}\\left[e^{iuX}\\right]=\\sum_{k=0}^n e^{iuk}\\mathcal{P}(X=k) \\\\ = \\sum_{k=0}^n e^{iuk}\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k} \\\\ = \\sum_{k=0}^n\\frac{n!}{k!(n-k)!}(e^{iu}p)^k(1-p)^{n-k} = (e^{iu}p+(1-p))^n$$ Week 8.4: Characteristic exponent[Characteristic Exponent Def with Proposition]:&emsp;$\\forall$ Levy process $L_t$, $\\exists \\Psi:\\mathbb{R}\\rightarrow\\mathbb{C}$ call characteristic exponent, such that&emsp;$\\Phi_{L_t}(u)=\\mathbb{E}[e^{iuL_t}]=e^{t\\cdot\\Psi(u)}$ [Example 1]:&emsp;$L_t=\\mu\\cdot t$, å…¶ characteristic function is $\\Phi_{L_t}(u)=\\mathbb{E}[e^{iu\\mu t}]$, æ‰€ä»¥ $\\Psi(u)=iu\\mu$ [Brownian Motion Example 2]:&emsp;$L_t=\\sigma W_t$, where $W_t$ is a Brownian motion. æ‰€ä»¥ $L_t\\sim\\mathcal{N}(0,\\sigma^2t)$.&emsp;æˆ‘å€‘çŸ¥é“ $X\\sim\\mathcal{N}(\\mu,\\sigma^2)$ çš„ç‰¹å¾µæ–¹ç¨‹å¼ç‚º:&emsp;$\\Phi_X(u)=e^{i\\mu u-\\frac{1}{2}\\sigma^2u^2}$&emsp;æ‰€ä»¥&emsp;$\\Phi_{L_t}(u)=e^{-\\frac{1}{2}\\sigma^2t u^2}\\Longrightarrow \\Psi(u)=-\\frac{1}{2}\\sigma^2u^2$ [Compound Poisson processes Example 3]:&emsp;Let $X_t$ is a Compound Poisson processes. We have itâ€™s characteristic function of increments as:&emsp;$\\Phi_{X_t-X_s}(u)=e^{\\lambda(t-s)(\\Phi_{\\xi_1}(u)-1)}$&emsp;Therefore, characteristic function of $L_t=X_t$:&emsp;$\\Phi_{L_t}(u)=e^{\\lambda t(\\Phi_{\\xi_1}(u)-1)}$&emsp;and hence&emsp;$$\\Psi(u)=\\lambda(\\Phi_{\\xi_1}(u)-1) \\\\ =\\lambda\\left( \\int e^{iux}\\mathcal{P}_{\\xi_1}(x)dx - \\int\\mathcal{P}_{\\xi_1}(x)dx \\right) \\\\ = \\int (e^{iux}-1)\\lambda \\mathcal{P}_{\\xi_1}(x)dx =\\int (e^{iux}-1)\\lambda F_{\\xi_1}(dx)$$ [Linear Brownian Motion Plus Compound Poisson processes Example 4]:&emsp;Let $L_t$ is&emsp;$L_t=\\mu t+\\sigma W_t + C.P.P.$&emsp;then we have&emsp;$\\Psi(u)=iu\\mu-\\frac{1}{2}\\sigma^2u^2 + \\int (e^{iux}-1)\\lambda F_\\xi(dx)$ é€™å€‹å½¢å¼å¾ˆé‡è¦, for such Levy process, å…¶ç‰¹å¾µæ–¹ç¨‹å¼å¯ä»¥ explicitly å¯«å‡ºä¾† [Corollaries]:&emsp;1. The distribution of $L_t$ is determined by $L_1$&emsp;&emsp;$\\Phi_{L_1}(u)=e^{\\Psi(u)}$&emsp;&emsp;æ‰€ä»¥å¯ä»¥ç”± $L_1$ æ±ºå®šå‡º characteristic exponent $\\Psi(u)$&emsp;&emsp;è€ŒçŸ¥é“ $\\Psi(u)$ æˆ‘å€‘å°±çŸ¥é“ä»»ä½•æ™‚é–“é»çš„ characteristic function, ä¹Ÿå°±æ±ºå®šäº† distribution&emsp;2. Expectation and variance of $L_t$&emsp;&emsp;$$\\mathbb{E}L_t=t\\cdot\\mathbb{E}L_1 \\\\ Var(L_t)=t\\cdot Var(L_1) \\\\ K(t,s) =Var(L_{\\min(t,s)}) = \\min(t,s)\\cdot Var(L_1)$$ ç”±æ­¤ $K(t,s)$ å¯çŸ¥, Levy process is NOT stationary (in any sense). å› ç‚º WSS å¿…é ˆæ»¿è¶³ $K(t,s)=K(t+h,s+h)$, ç„¶è€Œ $\\min(t,s)\\neq \\min(t+h,s+h)$ æ³¨æ„åˆ°, Levy process is NOT stationary but is stationary increment Week 8.5: Properties of a LÃ©vy process, which directly follow from the existence of characteristic exponent[Levy Measure Def]:&emsp;Levy measure of a Levy process $X_t$ is defined as&emsp;$$\\nu(B)=\\mathbb{E}\\left[ \\# t\\in[0,1]: \\triangle X_t \\in B \\right], \\qquad \\forall B\\subset\\mathbb{R} \\setminus\\{0\\}$$&emsp;where $\\triangle X_t=X_t-X_{t^-}$ (size of jump), also reference to definition of Cadlag function $B$ å®šç¾©äº†æˆ‘å€‘è¦é—œæ³¨çš„é‚£äº› jump å€¼, è€Œ measure å°±æ˜¯: æœ‰å¤šå°‘ (ä»¥æœŸæœ›å€¼ä¾†çœ‹) random variables ä»–å€‘çš„ jump å€¼å±¬æ–¼ $B$, ä¸” random variables åªé™åˆ¶åœ¨ $t\\in[0,1]$åˆæˆ–è€…é€™éº¼èªª, å°æ–¼ $X_t,\\forall t\\in[0,1]$ é€™äº› random variables ä¾†èªª, measure å°±æ˜¯ç™¼ç”Ÿ jump æ¬¡æ•¸çš„æœŸæœ›å€¼ (constrained on jump çš„å€¼æ˜¯æˆ‘å€‘è¦çš„, i.e. in $B$)æ­¤æ®µèª²ç¨‹å¾Œé¢æœƒæä¾›ä¸€å€‹ Levy measure çš„å……è¦æ¢ä»¶, å¯¦åœ¨å¾ˆç¥å¥‡ é€™å®šç¾©æ˜¯å¦ç¬¦åˆ measure ä¹‹å®šç¾©? æª¢æŸ¥å¦‚ä¸‹ç‰¹æ€§&emsp;1. Non-negativity: $\\nu(B)\\geq 0$&emsp;2. Null empty set: $\\nu(\\phi) = 0$&emsp;3. Countable additivity:&emsp;&emsp;For all countable collections ${B_k}$ of pairwise disjoint sets&emsp;&emsp;$\\nu\\left(\\bigcup_{k=1}^\\infty B_k \\right) = \\bigcup_{k=1}^\\infty \\nu(B_k)$å¯ç™¼ç¾ $\\nu$ ç¬¦åˆ measure å®šç¾©, æ‰€ä»¥æ˜¯å€‹ measure Brownain motion is continuous a.e. æ‰€ä»¥ $\\nu(B)=0$Poisson process å¦‚åœ–æ‰€ç¤º è€ƒæ…® Compound Poisson process, let $N_t$ is Poisson process, and $\\xi_1,\\xi_2,â€¦$ are i.i.d. then C.P.P. $X_t$ is defined as$X_t=\\sum_{k=1}^{N_t} \\xi_k$å…¶ Levy measure å¦‚ä¸‹:$$\\nu(B)=\\lambda\\cdot\\mathcal{P}(\\xi_1\\in B) \\\\ = \\int_B \\lambda \\mathcal{P}_\\xi(x)dx := \\int_B s(x)dx$$where $s(x)$ is called Levy density$s(x):=\\lambda \\mathcal{P}_\\xi(x)$and we have $\\nu(dx)=s(x)dx$ å¯ä»¥é€™éº¼æƒ³, åœ¨åŸä¾†çš„ Poisson process, æ¯ä¸€æ¬¡çš„ jump éƒ½å›ºå®šæ˜¯ $1$, ä½†åœ¨ C.P.P. jump çš„å€¼æ˜¯æ ¹æ“š $\\xi_k$ ä¾†æ±ºå®šçš„. æ‰€ä»¥èƒ½ä¸èƒ½ç®—é€²ä¸€æ¬¡ jump è¦çœ‹ jump çš„å€¼æ˜¯ä¸æ˜¯åœ¨ $B$ ä¸­ [Sufficient and Necessary Condition of Levy Measure]:&emsp;If $\\nu$ is a Levy measure for some Levy process $L_t$, if and only if satisfying&emsp;$$\\int_{|x|&lt;1} x^2\\nu(dx) =\\int_{|x|&lt;1} x^2s(x)dx&lt;\\infty \\\\ \\int_{|x|\\geq1} \\nu(dx)=\\int_{|x|\\geq1} s(x)dx&lt;\\infty$$ Week 8.6: LÃ©vy-Khintchine representation and LÃ©vy-Khintchine triplet-1 ğŸ’¡ èª²ç¨‹è€å¸«èªªé€™æ˜¯æ•´å€‹èª²ç¨‹æœ€é‡è¦çš„å®šç† [Levy-Khintchine Theorem]:&emsp;The characteristic exponent $\\Psi(u)$ of a Levy process $L_t$ can be represented as follows:&emsp;$$\\color{orange}{ \\Psi(u)=iu\\mu-\\frac{1}{2}u^2\\sigma^2 + \\int_{\\mathbb{R}}\\left( e^{iux}-1-iux\\cdot\\mathbf{1}\\{|x|&lt;1\\} \\right)\\nu(dx) }$$&emsp;where $\\mu\\in\\mathbb{R},\\sigma\\geq0$, and $\\nu$ is a Levy measure. $(\\mu,\\sigma,\\nu)$ is called Levy triplet&emsp;which completely determined the distribution of Levy process at any time moment $t$ å¯ä»¥è­‰æ˜ $\\forall L_t$ - Levy process, å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹$X_t = \\underbrace{\\mu t + \\sigma W_t}_\\text{continuous part} + \\underbrace{\\mathcal{J}_t}_{\\text{jump part}}$ æ‰€ä»¥ Levy process çš„ continuous part å¯ä»¥è¦–ç‚º Brownian motionè€Œ jump part $\\mathcal{J}_t$:$$\\mathcal{J}_t \\approx \\overbrace{ \\left( \\sum_{0&lt;s&lt;t,|\\triangle X_s|&gt;1} \\triangle X_s \\right) }^{\\text{C.P.P.}} + \\left( \\lim_{\\varepsilon\\rightarrow0} \\overbrace{ \\sum_{0&lt;s&lt;t,\\varepsilon&lt;|\\triangle X_s|\\leq1} \\triangle X_s }^{\\text{C.P.P.}} \\right)$$ æˆ‘å€‘å¯ä»¥å°‡ Levy process çš„ trajectory ç•«å‡ºä¾† trajectory_of_Levy_process.pptx æ¥ä¸‹ä¾†ä¸‹ä¸€ç¯€èª²ç¨‹æœƒä»‹ç´¹ä¸€å€‹ sufficient condition ä½¿æˆ‘å€‘å¯ä»¥æŠŠ jump process çš„ limit é‚£æ®µæ‹¿æ‰, ä½¿å¾— jump process å®Œå…¨å¯ä»¥ç”±ä¸€å€‹ C.P.P. æ›¿ä»£ Week 8.7: LÃ©vy-Khintchine representation and LÃ©vy-Khintchine triplet-2é‡è¤‡ä¸€æ¬¡ Levy process çš„ characteristic exponent:$$\\Psi(u)=iu\\mu-\\frac{1}{2}u^2\\sigma^2 + \\int_{\\mathbb{R}}\\left( e^{iux}-1- \\color{orange}{ iux\\cdot\\mathbf{1}\\{|x|&lt;1\\} } \\right)\\nu(dx)$$æœ‰äº›æƒ…æ³ä¸‹å¯ä»¥ç°¡åŒ–ä¸Šå¼, å°¤å…¶æ©˜è‰²éƒ¨åˆ†. é¦–å…ˆå›é¡§ä¸€ä¸‹ä»€éº¼æ˜¯ bounded variation [Bounded Variation of a Stochastic Processes]:&emsp;å°æ–¼ä¸€å€‹ process $X_t$, è€ƒæ…®ä¸€å€‹ partition $\\bigtriangleup:0=t_0&lt;t_1&lt;...&lt;t_n=t$&emsp;å¦‚æœæ»¿è¶³ä»¥ä¸‹æ¢ä»¶, å‰‡ç¨± $X_t$ is bounded variation:&emsp;$\\lim_{|\\bigtriangleup|\\rightarrow0} \\sum_{k=1}^n | X_{t_k}-X_{t_{k-1}} | &lt; \\infty$&emsp;$|\\bigtriangleup|\\rightarrow0$ è¡¨ç¤º:&emsp;$\\max_{k=0,...,n}\\{|t_k-t_{k-1}|\\}\\rightarrow0, \\text{ for }n\\rightarrow0$ æ³¨æ„åˆ° Brownian motion $W_t$ ä¸æ˜¯ bounded variation [When Levy Process is Bounded Variation]:&emsp;ä¸€å€‹ Levy process $L_t$ æ˜¯ bounded variation è‹¥ä¸”ç‚ºè‹¥&emsp;$$\\begin{align} \\sigma=0 \\\\ \\int_{|x|&lt;1} x\\nu(dx) &lt; \\infty \\end{align}$$&emsp;æ¢ä»¶ $(2)$ æœƒæœ‰å¦‚ä¸‹çµæœ&emsp;$\\int_\\mathbb{R}iux\\cdot\\mathbf{1}\\{|x|&lt;1\\}\\nu(dx) = iu\\int_{|x|&lt;1}x\\nu(dx)&lt;\\infty$&emsp;å› æ­¤ characteristic exponent è®Šæˆ:&emsp;$$\\Psi(u)=iu\\mu-\\frac{1}{2}u^2\\sigma^2 + \\int_{\\mathbb{R}}\\left( e^{iux}-1- iux\\cdot\\mathbf{1}\\{|x|&lt;1\\} \\right)\\nu(dx) \\\\ =iu\\mu + \\int_{\\mathbb{R}}(e^{iux}-1)\\nu(dx)-iu\\int_{|x|&lt;1}x\\nu(dx) \\\\ = iu\\left(\\mu-\\int_{|x|&lt;1}x\\nu(dx)\\right) + \\int_{\\mathbb{R}}(e^{iux}-1)\\nu(dx)$$&emsp;æ‰€ä»¥ characteristic function: $\\Phi(u)=\\exp\\{t\\cdot\\Psi(u)\\}$ é‡å¯«ä¸€é, é€™å¾ˆé‡è¦$$\\color{orange}{ \\Psi(u) = iu \\underbrace{\\left(\\mu-\\int_{|x|&lt;1}x\\nu(dx)\\right)}_{=\\tilde{\\mu}} + \\int_{\\mathbb{R}}(e^{iux}-1)\\nu(dx) }$$or$$\\color{orange}{ \\Psi(u) = iu \\underbrace{\\left(\\mu-\\int_{|x|&lt;1}x\\cdot s(x)dx\\right)}_{\\tilde{\\mu}} + \\int_{\\mathbb{R}}(e^{iux}-1)\\cdot s(x)dx }$$where $s(x)$ is Levy density [When Levy Process is C.P.P.]&emsp;ä¸€å€‹ Levy process $L_t$ æ˜¯ C.P.P. è‹¥ä¸”ç‚ºè‹¥&emsp;$$\\begin{align} \\sigma=0, \\\\ \\int_{\\mathbb{R}}\\nu(dx)=\\nu(\\mathbb{R})&lt;\\infty \\end{align}$$&emsp;å¯ä»¥ç™¼ç¾é€™æ¨£çš„ $L_t$ ä¹Ÿæ˜¯ bounded variation, æ‰€ä»¥ä¹Ÿå¯ä»¥ç°¡åŒ– [When Levy Process is Subordinator]:&emsp;ä¸€å€‹ Levy process $L_t$ ç¨±ç‚º subordinator å¦‚æœæ»¿è¶³&emsp;$$\\begin{align} X_t\\geq0\\text{ a.s. }\\Longleftrightarrow X_t\\geq X_s\\text{ a.s. }, \\forall t\\geq s \\end{align}$$&emsp;ä¸Šå¼æœƒç­‰åƒ¹æ˜¯å› ç‚º Levy process çš„ stationary increment. i.e.&emsp;$X_t-X_s =^d X_{t-s}, \\qquad \\forall t\\geq s$&emsp;è€Œ Levy process $L_t$ ç‚º subordinator è‹¥ä¸”ç‚ºè‹¥&emsp;$$\\begin{align} \\sigma=0 \\\\ \\nu(\\mathbb{R}^-)=0 \\\\ \\int_0^1 x\\nu(dx)&lt;\\infty \\end{align}$$ å¼ (7) çš„ Levy measure è¡¨ç¤º jump çš„å€¼ä¸€å®šéƒ½æ˜¯æ­£çš„ (ç‚ºè² çš„æ¬¡æ•¸å…¶ measure ç‚º 0) ä¸€æ¨£å¯ä»¥ç™¼ç¾é€™æ¨£çš„ $L_t$ ä¹Ÿæ˜¯ bounded variation, æ‰€ä»¥ä¹Ÿå¯ä»¥ç°¡åŒ–æœ€å¾Œä¸€å€‹å•é¡Œæ˜¯å› ç‚º $\\sigma&gt;0$ è¡¨ç¤ºæœ‰ Brownian motion, æ‰€ä»¥ variation ä¸æœƒ bounded Week 8.8: LÃ©vy-Khintchine representation and LÃ©vy-Khintchine triplet-3RecapLevy process å¸¸ç”¨ä¾†æè¿° jumps, recap Levy process $L_t$å…¶ characteristic exponent ç‚º$$\\Psi(u)=iu\\mu-\\frac{1}{2}u^2\\sigma^2 + \\int_{\\mathbb{R}}\\left( e^{iux}-1- iux\\cdot\\mathbf{1}\\{|x|&lt;1\\} \\right)\\nu(dx)$$ç„¶å¾Œ characteristic function ç‚º$\\Phi_{L_t}(u)=\\exp\\{t\\cdot \\Psi(u)\\}$è€Œ $\\nu(x)$ æ˜¯ Levy measure$\\nu(B)=\\int_B s(x)dx$ç¨± $s(x)$ ç‚º Levy density, æ»¿è¶³$$\\begin{align} \\int_{|x|&lt;1} x^2\\nu(dx) =\\int_{|x|&lt;1} x^2s(x)dx&lt;\\infty \\\\ \\int_{|x|\\geq1} \\nu(dx)=\\int_{|x|\\geq1} s(x)dx&lt;\\infty \\end{align}$$ Recap çµæŸç”± Levy measure and density å¼å­ (9) and (10) çŸ¥é“, characteristic exponent çš„ç©åˆ†é …å­˜åœ¨, åˆ†æå¦‚ä¸‹$$\\int_{\\mathbb{R}}\\left( e^{iux}-1- iux\\cdot\\mathbf{1}\\{|x|&lt;1\\} \\right)\\nu(dx) \\\\ = \\int_{|x|&lt;1}\\left(e^{iux}-1-iux\\right)\\nu(dx) + \\int_{|x|\\geq1}(e^{iux}-1)\\nu(dx) \\\\ \\leq \\int_{|x|&lt;1}\\left(O(x^2)\\cdot u^2\\right)\\nu(dx) + \\int_{|x|\\geq1}2\\nu(dx)&lt;\\infty$$æˆ‘å€‘å¯ä»¥åˆ†æ $r$ æœ€å°å¯ä»¥å¤šå°, ä½¿å¾—ä¸‹å¼ä»æ»¿è¶³$\\int_{|x|&lt;1}x^r\\nu(dx)&lt;\\infty$æˆ‘å€‘çŸ¥é“å¦‚æœ $r$ æ»¿è¶³çš„è©±, å‰‡ $\\forall s, $\\alpha\\in(0,2]$, such that&emsp;$$\\left\\{ S_{at}\\right\\}_{t\\geq0} =^d \\left\\{ a^{1/\\alpha}S_t+b(t)\\right\\}_{t\\geq0}$$ Brownian motion is a stable process, å› ç‚º $\\alpha=2$, $b(t)=0$ æ»¿è¶³ä¸Šå¼$W_{at}\\sim\\mathcal{N}(0,at)\\sim\\sqrt{2}\\cdot\\mathcal{N}(0,t)\\sim\\sqrt{2}\\cdot W_t$ For stable processes, $BG(\\nu)=\\alpha$ å¦‚æœ $\\alpha\\approx0$, å‰‡ trajectories æœƒå¾ˆæ¥è¿‘ C.P.P., è€Œå¦‚æœ $\\alpha\\approx2$, å‰‡ trajectories æœƒå¾ˆæ¥è¿‘ Brownian motion, å…¶ä»–å‰‡ä»‹æ–¼ä¸­é–“çš„å…©è€…æ··åˆ Week 8.9: Modelling of jump-type dynamics. LÃ©vy-based modelsé€™ç¯€ä¸»è¦è¬›å¦‚ä½•å¾ data å» estimate å‡ºå°æ‡‰çš„ Levy process$X_t$ is a Levy process with bounded variation, æ‰€ä»¥ç‰¹å¾µæ–¹ç¨‹å¼ç‚º:$$\\Phi_{X_\\Delta}(u) = \\exp\\left\\{ \\Delta\\cdot\\left( iu\\tilde\\mu+\\int_\\mathbb{R}(e^{iux}-1)s(x)dx \\right) \\right\\}$$å°å…¶ä¸€æ¬¡å’ŒäºŒæ¬¡å¾®åˆ†: æ³¨æ„åˆ°äºŒæ¬¡å¾®åˆ†è·‘å‡ºäº†ä¸€å€‹ Fourier transform é …, æ‰€ä»¥æ”¹å¯«ä¸€ä¸‹è®Šæˆ$$\\begin{align} \\mathcal{F}[x^2s(x)](u)=\\frac{-1}{\\Delta}\\cdot\\left( \\frac{\\Phi_{X_\\Delta}&apos;&apos;(u)}{\\Phi_{X_\\Delta}(u)} - \\left(\\frac{\\Phi_{X_\\Delta}&apos;(u)}{\\Phi_{X_\\Delta}(u)}\\right)^2 \\right) \\end{align}$$ æ‰€ä»¥å¦‚æœæˆ‘å€‘æœ‰å¦‚ä¸‹çš„ data:$X_\\Delta,X_{2\\Delta},...,X_{n\\Delta}$ æˆ‘å€‘å¯ä»¥ä¼°è¨ˆå‡º $\\Phi$ å¦‚ä¸‹:$$\\hat{\\Phi}_{X_\\Delta}(u)=\\frac{1}{n}\\sum_{k=1}^n \\exp\\left\\{iu\\left(X_{k\\Delta}-X_{(k-1)\\Delta}\\right) \\right\\}$$ æˆ‘ä¸æ˜¯å¾ˆæ‡‚ç‚ºä½•å¯ä»¥é€™éº¼ä¼°è¨ˆ, ç™¼å•é¡Œåˆ°è«–å£‡äº†. å› æ­¤å°å…¶å¾®åˆ†ä¹Ÿå°±å¾—åˆ°ä¼°è¨ˆçš„ $\\hat\\Phiâ€™,\\hat\\Phiâ€™â€™$, ç„¶å¾Œå¯ä»¥å¾—åˆ°å¼ (11) çš„çµæœ, å†å°å…¶æ±‚ inverse Fourier transform å¯ä»¥å¾—åˆ° Levy density $s(x)$ è€å¯¦èªªæ²’æœ‰ä¾‹å­å¾ˆé›£æƒ³åƒæ€éº¼åšâ€¦. ğŸ™ Week 8.10: Time-changed stochastic processes. Monroe theoremæœ‰å§‹æœ‰çµ‚å§, æœ€å¾Œä¸€èª²äº†!!èªªæ˜ä¸€äº› Levy-based modelèª²ç¨‹èªªå–®ç´”çš„ Levy process å°æ–¼çœŸå¯¦æƒ…æ³ä»éæ–¼ç°¡åŒ–, å› æ­¤è¦æœ‰ä¸€äº›è®Šå½¢, å…¶ä¸­ä¸€å€‹ä¾‹å­æ˜¯ stochastic time change model [Stochastic Time Change Model]:&emsp;$X_t$ is a Levy process, å…¶ä¸­ $t=T(s)$, $T(s)$ æ˜¯ä¸€å€‹ subordinator Levy process, æ‰€ä»¥è®Šæˆ $X_{T(s)}$&emsp;åŒæ™‚å¦‚æœ $X_t\\perp T(s)$ å‰‡ $X_{T(s)}$ ä¹Ÿæœƒæ˜¯ Levy process ä¸€å€‹ä¾‹å­å¦‚ä¸‹åœ–, $t$ æœ‰æ™‚å¾ˆå¯†é›†, æœ‰æ™‚å¾ˆé¬†æ•£ $T(s)$ æ˜¯ cumulative amount of transactions in time interval $[0,s]$ ç¬¬äºŒå€‹ä¾‹å­çœŸçš„è½ä¸æ‡‚â€¦ èª²ç¨‹çµæŸ! æœ€å¾Œå‰© Quiz and Final Exam! ğŸ‘","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"LÃ©vy Processes","slug":"Levy-Processes","permalink":"https://bobondemon.github.io/tags/Levy-Processes/"},{"name":"Characteristic Exponent","slug":"Characteristic-Exponent","permalink":"https://bobondemon.github.io/tags/Characteristic-Exponent/"}]},{"title":"Stochastic Processes Week 7 Stochastic integration & ItÃ´ formula","date":"2021-12-12T13:17:41.000Z","path":"2021/12/12/Stochastic-Processes-Week-7-Stochastic-integration-Ito-formula/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula (æœ¬æ–‡) Week 8: LÃ©vy processes å››ç¨® types çš„ stochastic integration, where $X_t,H_t$ are stochastic processes, $f(t)\\in L^2([a,b])$ is a deterministic function, $W_t$ is a Brownian motion, and $a,b\\in\\mathbb{R}$$$\\begin{align} \\int_a^b X_t dt \\\\ \\int_a^b f(t)dW_t \\\\ \\int_a^b X_t dW_t \\\\ \\int_a^b X_t dH_t \\end{align}$$ åœ¨ stochastic integral è·Ÿä»¥å¾€çš„ integral å¾ˆä¸ä¸€æ¨£çš„ä¸€é»æ˜¯, æˆ‘å€‘ç™¼ç¾ integral çš„çµæœä»ç„¶æ˜¯ä¸€å€‹ random variableé–±è®€ä»¥ä¸‹å…§å®¹æ™‚å¯ä»¥çœ‹å‡ºé€™ä¸€é» Week 7.1: Different types of stochastic integrals. Integrals of the type $âˆ« X_t dt$Given a Stochastic process $X_t:\\Omega\\times\\mathbb{R}_+\\rightarrow\\mathbb{R}$å¦‚æœæˆ‘å€‘å›ºå®šä¸€å€‹ outcome $\\omega$, å‰‡ $X_t(\\omega):\\mathbb{R}_+\\rightarrow\\mathbb{R}$, å› æ­¤æˆ‘å€‘å°±å¯ä»¥è€ƒæ…® Riemann integral:$\\int_a^b X_t(\\omega)dt=\\color{orange}{\\lim_{|\\Delta|\\rightarrow0}}\\sum_{k=1}^n X_{t_{k-1}}(\\omega)\\cdot(t_k-t_{k-1})$For partition $\\Delta:a=t_0\\leq t_1\\leq â€¦\\leq t_n=b$, $|\\Delta|=\\max\\{t_k-t_{k-1}\\},k=1,...,n$è‹¥è€ƒæ…® stochastic process, ä¸Šè¿°çš„ limit å¿…é ˆä»¥ mean square sense ä¾†è€ƒæ…®, å› æ­¤æ­£å¼å®šç¾©å¦‚ä¸‹: [Stochastic Integrals of Simplest Type $âˆ« X_t dt$]:&emsp;Given a Stochastic process $X_t:\\Omega\\times\\mathbb{R}_+\\rightarrow\\mathbb{R}$&emsp;Given partition $\\Delta:a=t_0\\leq t_1\\leq ...\\leq t_n=b$, $|\\Delta|=\\max\\{t_k-t_{k-1}\\},k=1,...,n$&emsp;If the following expectation converges to some value $A$ in mean square sense:&emsp;$$\\mathbb{E}\\left[ \\left( A - \\sum_{k=1}^n X_{t_{k-1}}(t_k-t_{k-1}) \\right)^2 \\right] \\xrightarrow[|\\Delta|\\longrightarrow0]{} 0$$&emsp;Then we denote(define) the converged value $A$ as: $\\int_a^b X_t dt$ [Existence of the Simplest Type of Stochastic Integral]:&emsp;$X_t:\\mathbb{E}[X_t^2]&lt;\\infty$, if&emsp;1. $m(t)$ continuous&emsp;2. $K(t,s)$ continuous&emsp;Then the stochastic integral exists, i.e. $\\int_a^b X_tdt&lt;\\infty$ æœ‰ä¸Šè¿°å®šç†å¥½è™•å¦‚ä¸‹We assume integral is taken in an bounded interval $[a,b]$&emsp;1. Expectation of stochastic integral:&emsp;&emsp;$\\mathbb{E}\\left[ \\int X_tdt \\right] = \\int \\mathbb{E}[X_t]dt$&emsp;&emsp;èª²ç¨‹è€å¸«èªª apply Frobenius theorem å¯å¾—æ­¤çµæœ. çœ‹ä¸æ‡‚ Frobenius theorem&emsp;2. Expectation of squared stochastic integral:&emsp;&emsp;$$\\mathbb{E}\\left[ \\left(\\int X_t dt\\right)^2 \\right] = \\mathbb{E}\\left[ \\int\\int X_t X_s dtds \\right] \\\\ = \\int\\int\\mathbb{E}[X_tX_s]dtds$$&emsp;3. Variance of stochastic integral:&emsp;&emsp;$$Var\\left[ \\int X_t dt \\right] = \\mathbb{E}\\left[ \\left(\\int X_t dt\\right)^2 \\right] - \\left(\\mathbb{E}\\left[ \\int X_tdt \\right]\\right)^2 \\\\ = \\int\\int \\mathbb{E}[X_tX_s]dtds - \\mathbb{E}\\left[ \\int X_tdt \\right]\\mathbb{E}\\left[ \\int X_sds \\right]\\\\ = \\int\\int \\mathbb{E}[X_tX_s]dtds - \\int\\mathbb{E}[X_t]dt\\cdot\\int\\mathbb{E}[X_s]ds \\\\ = \\int_a^b\\int_a^b K(t,s) dtds \\\\ \\because\\text{symmetric}= 2\\int_a^b \\int_a^s K(t,s) dtds$$ æ³¨æ„åˆ° $W_t\\sim\\mathcal{N}(0,t)$, æ‰€ä»¥ $Var(W_t)=\\mathbb{E}W_t^2=t$ Week 7.2-3: Integrals of the type $âˆ« f(t) dW_t$ç¬¬äºŒç¨® type çš„ integral æˆ‘å€‘ç¨±ç‚º Wiener integral$\\int_a^b f(t)dW_t$where $f(t)\\in L^2([a,b])$ is a deterministic function, $W_t$ is a Brownian motion, and $a,b\\in\\mathbb{R}$ [Inner Product in Function Space]:&emsp;Define inner product between real valued functions $f,g$ in $[a,b]$&emsp;$&lt;f,g&gt;=\\int_a^b f(x)g(x)dx$&emsp;Having properties:&emsp;1. $&lt;f,g&gt;=&lt;g,f&gt;$&emsp;2. $&lt;a_1f_1+a_2f_2,g&gt;=a_1&lt;f_1,g&gt;+a_2&lt;f_2,g&gt;$&emsp;3. $&lt;f,f&gt;\\geq0$, and $=0\\Longleftrightarrow f=0$ [Informal Def of $L^2$ Space]:&emsp;å®šç¾© norm ç‚º $\\|f\\|_2 = \\sqrt{&lt;f,f&gt;}$, å‰‡æ‰€æœ‰ $\\|f\\|_2\\leq\\infty$ æ‰€å½¢æˆçš„ç©ºé–“&emsp;(æ­é… $\\|\\cdot\\|_2$ å‰‡ç‚º Banach space, æ­é… $&lt;\\cdot,\\cdot&gt;$ å‰‡ç‚º Helbert sapce) æˆ‘å€‘ç¨±ç‚º $L^2$ space æ¯”è¼ƒåš´è¬¹çš„å®šç¾©åƒè€ƒæ•¸å­¸èª²æœ¬ å› æ­¤æˆ‘å€‘å¯ä»¥èªªåœ¨ $L^2$ space ä¸Šçš„æ”¶æ–‚, è¦–ç‚ºè©² normed (Banach) space ä¸Šçš„æ”¶æ–‚, i.e.$$f_n\\xrightarrow[]{L^2}f\\Longleftrightarrow \\|f_n-f\\|_2\\xrightarrow[n\\rightarrow\\infty]{}0 \\\\ \\text{, or } \\Longleftrightarrow \\int_a^b \\left( f_n(x)-f(x) \\right)^2 dx \\xrightarrow[n\\rightarrow\\infty]{}0$$ æˆ‘å€‘å…ˆå®šç¾© Wiener integral of a step function [Wiener Integral of a Step Function]:&emsp;Let $a=t_0\\leq t_1\\leq â€¦\\leq t_n=b$, $\\alpha_i\\in\\mathbb{R}$, and step function $f(x)$ defined as:&emsp;$f(x)=\\sum_{i=1}^n \\alpha_i\\cdot\\mathbf{1}\\{t_{i-1}\\leq x&lt;t_i\\}$&emsp;Then Wiener integral of $f(x)$ is:&emsp;$\\int_a^b f(x)dW_t = \\sum_{i=1}^n \\alpha_i\\cdot(W_{t_i}-W_{t_{i-1}})$ [Example]:&emsp;æˆ‘å€‘å¯ä»¥ç™¼ç¾ integral çš„çµæœéƒ½æ˜¯ normal distribution [Distribution of Wiener Integral of a Step Function]:&emsp;Let $f(x)$ is a step function, and Wiener integral as:&emsp;$I(f):=\\int_a^b f(t)dW_t$&emsp;then&emsp;$I(f)\\sim\\mathcal{N}\\left(0,\\int_a^bf^2(x)dx\\right)$ [Proof]:&emsp;æ ¹æ“š Wiener integral çš„å®šç¾©, æˆ‘å€‘å¯ä»¥çŸ¥é“&emsp;$\\int_a^b f(x)dW_t = \\sum_{i=1}^n \\alpha_i\\cdot(W_{t_i}-W_{t_{i-1}})$&emsp;è€Œå› ç‚º $W_t$ is Brownian motion, å…·æœ‰ independent increment æ€§è³ª&emsp;å› æ­¤ç­‰æ–¼æ˜¯äº’ç›¸ç¨ç«‹çš„ normal distribution ç·šæ€§çµ„åˆçš„çµæœ, æ‰€ä»¥ä¹Ÿæ˜¯ normal. å› æ­¤æˆ‘å€‘åªéœ€è¨ˆç®— mean and variance [Wiener Integral of a Deterministic $L^2$ Function]:&emsp;Let $f(x)\\in L^2([a,b])$, and if we can find a sequence of step functions $(f_n)_n$&emsp;such that converges to $f$ in $L^2$ space, i.e.:&emsp;$f_n\\xrightarrow[]{L^2}f\\Longleftrightarrow \\int_a^b\\left( f_n(t)-f(t) \\right)^2 dt \\xrightarrow[n\\rightarrow\\infty]{}0$&emsp;then we define $I(f)$ as the limit of $I(f_n)$ as $n\\rightarrow\\infty$, i.e.:&emsp;$I(f):=\\lim_{n\\rightarrow\\infty} I(f_n)$&emsp;Where the limit should be understood by mean square sense:&emsp;$$\\mathbb{E}\\left[ (I(f_n)-I(f))^2 \\right] \\xrightarrow[n\\rightarrow\\infty]{}0$$ è§€å¯Ÿä»¥ä¸Šçš„å®šç¾©, æœ‰ 3 å€‹é‡è¦çš„å•é¡Œéœ€è¦å›ç­”: Why $I(f)$ doesnâ€™t depend on $(f_n)_n$? Properties of $I(f)$? How to counstruct $(f_n)_n$? Will be answered in Week 7.4-5 [Theorem Explian Why $I(f)$ doesnâ€™t depend on $(f_n)_n$]:&emsp;$(f_n)_n,(\\tilde{f}_n)_n$ sequences of step functions in $L^2$ space and both converges to $f$, i.e.&emsp;$f_n\\xrightarrow[]{L^2}f, \\tilde{f}_n\\xrightarrow[]{L^2}f$&emsp;Then&emsp;$\\lim_{n\\rightarrow\\infty} I(f_n) = \\lim_{n\\rightarrow\\infty} I(\\tilde{f_n})$&emsp;The limit is understood as mean square sense, that is:&emsp;$$\\mathbb{E}\\left[ (I(f_n)-I(\\tilde{f}_n))^2 \\right] \\xrightarrow[n\\rightarrow\\infty]{}0$$ Note that the Wiener integral of a step function $f$ is defined as:$I(f):=\\int_a^b f(t)dW_t$and $W_t$ is Brownian motion [Proof]:&emsp;$I(f_n)-I(\\tilde{f}_n)=I(f_n-\\tilde{f}_n)$ also is a step function&emsp;æ‰€ä»¥é€™å€‹ step function çš„ Wiener integral æœƒ follow normal distribution:&emsp;$I(f_n-\\tilde{f}_n)\\sim\\mathcal{N}\\left(0,\\int_a^b (f_n(x)-\\tilde{f}_n(x))^2 dx\\right)$&emsp;æ‰€ä»¥ Variance:&emsp;$$Var(I(f_n-\\tilde{f}_n)) = \\mathbb{E}\\left[ (I(f_n-\\tilde{f}_n))^2 \\right] \\\\ = \\int_a^b (f_n(x)-\\tilde{f}_n(x))^2 dx \\xrightarrow[n\\rightarrow\\infty]{} 0$$&emsp;æœ€å¾Œæœƒ approach to $0$ æ˜¯å› ç‚º both converges to $f$.&emsp;æ‰€ä»¥é¦¬ä¸Šå°±ç™¼ç¾ limit converges in mean square sense:&emsp;$$\\because \\mathbb{E}\\left[ (I(f_n)-I(\\tilde{f}_n))^2 \\right] = \\mathbb{E}\\left[ (I(f_n-\\tilde{f}_n))^2 \\right] \\\\ = Var(I(f_n-\\tilde{f}_n)) \\xrightarrow[n\\rightarrow\\infty]{}0 \\\\ \\therefore\\lim_{n\\rightarrow\\infty} I(f_n) = \\lim_{n\\rightarrow\\infty} I(\\tilde{f_n})$$ [The Wiener Integral of Function in $L^2$ Space]:&emsp;$\\forall f\\in L^2([a,b])$, The Wiener integral:&emsp;$I(f)\\sim\\mathcal{N}\\left(0,\\int_a^b f^2(x)dx\\right)$[Proof]:&emsp;For any $(f_n)_n$ converges to $f$ in $L^2$, we have&emsp;$$I(f)=\\lim_{n\\rightarrow\\infty} I(f_n)\\\\ I(f_n)\\sim\\mathcal{N}\\left( 0, \\int_a^b f^2_n(x)dx \\right)$$&emsp;Normal distribution çš„ limit ä»æ˜¯ normal, å…¶çµæœç‚º mean and variance çš„ limit, æ‰€ä»¥&emsp;$$I(f)\\sim\\mathcal{N}\\left( 0, \\lim_{n\\rightarrow\\infty}\\int_a^b f^2_n(x)dx \\right) = \\mathcal{N}\\left( 0, \\int_a^b f^2(x)dx \\right)$$&emsp;Q.E.D. Week 7.4-5: Integrals of the type $âˆ« X_t dW_t$è¦å®šç¾©é€™æ¨£çš„ integral, $X_t$ å¿…é ˆå®šç¾©åœ¨ filtered probability space ä¸Š.[Filteration Def]: from Wiki [Filteration Def]:&emsp;Filtration is a sequence of $\\sigma$-algebras $\\mathcal{F}_t$ defined on the same probability space $(\\Omega,\\mathcal{F},\\mathcal{P})$&emsp;such that, $\\mathcal{F}_t$ is a sub-$\\sigma$-algebra of $\\mathcal{F}_s$ if $t\\leq s$, i.e.:&emsp;$\\mathcal{F}_t \\subseteq \\mathcal{F}_s, \\forall t\\leq s$ [$L^2$ Space of Stochastic Processes]:&emsp;çµ¦å®šä¸€å€‹ filtered probability space $(\\Omega,\\mathcal{F}, \\{\\mathcal{F}_t\\} ,\\mathcal{P})$&emsp;æˆ‘å€‘å¯ä»¥å®šç¾© $X_t$ æ˜¯å¾å¦‚ä¸‹çš„ stochastic process çš„ space ä¾†çš„, ($ad$ è¡¨ç¤º adapted)&emsp;$L^2_{ad}([a,b],\\Omega)$&emsp;é€™å€‹ space æœ‰å¦‚ä¸‹å…©å€‹ properties:&emsp;1. ç”±æ–¼æˆ‘å€‘çŸ¥é“ random variable $X_t$ å…¶å¯¦æ˜¯ä¸€å€‹ measurable function&emsp;&emsp;å¾ measurable space $(\\Omega,\\mathcal{F}_t)$ mapping åˆ°å¦ä¸€å€‹ measurable space $(\\mathbb{R},B(\\mathbb{R}))$, where $B(\\mathbb{R})$ è¡¨ç¤º Borel set of $\\mathbb{R}$&emsp;&emsp;ç”± measurable function çš„å®šç¾©çŸ¥é“ pre-image is still in $\\sigma$-algebra&emsp;&emsp;i.e., $\\{\\omega:X_t(\\omega)\\in B\\}\\in\\mathcal{F}_t$, $\\forall B\\in B(\\mathbb{R})$&emsp;&emsp;æˆ‘å€‘ç¨± $X_t$ is $\\mathcal{F}_t$ measurable æˆ–ç¨± $X_t$ is $\\mathcal{F}_t$-adapted&emsp;&emsp;æˆ‘å€‘æœ‰ $X_t$ is $\\mathcal{F}_t$-adapted, $\\forall t$&emsp;2. æ»¿è¶³å¦‚ä¸‹ç‰¹æ€§&emsp;&emsp;$\\int_a^b \\mathbb{E}X_t^2 dt &lt; \\infty$ è‹¥è¦ç©åˆ†$\\int_a^b X_tdW_t$Brownian motion $W_t$ ä¹Ÿå¿…é ˆåœ¨ç›¸åŒçš„ filtered space ä¸Š. [$\\mathcal{F}_t$-Brownian Motion Def]:&emsp;æˆ‘å€‘ç¨± $W_t$ is $\\mathcal{F}_t$-Brownian motion, if&emsp;1. $W_t$ is $\\mathcal{F}_t$-adapted&emsp;2. $(W_t-W_s)\\perp\\mathcal{F}_s,\\forall t&gt;s$ [Wiener Integral of a $L^2$-adapted Stochastic Process $X_t$]:&emsp;$X_t\\in L_{ad}^2$, $W_t$ is a $\\mathcal{F}_t$-Brownian motion, consider defining&emsp;$\\int_a^b X_t dW_t$&emsp;(Stage 1): Let $\\xi_i,\\forall i=0,â€¦,n-1$ are random variables. If $X_t$ is a step processes, i.e.&emsp;&emsp;$X_t=\\sum_{i=1}^n\\xi_{i-1}\\cdot\\mathbf{1}\\{t_{i-1}\\leq t&lt;t_i\\}$&emsp;&emsp;then we define Wiener integral of this type is&emsp;&emsp;$I(X_t)=\\sum_{i=1}^n \\xi_{i-1}(W_{t_i}-W_{t_{i-1}})$&emsp;(Stage 2): For any $X_t\\in L_{ad}^2$, we can find a sequence of step processes $(X_t^n)_n$ which converges in $L_{ad}^2$ sense, i.e.:&emsp;&emsp;$\\int_a^b\\mathbb{E}\\left(X_t^n-X_t\\right)^2dt\\xrightarrow[n\\rightarrow\\infty]{}0$&emsp;&emsp;Such $X_t^n$ can be difined as:&emsp;&emsp;$X_t^n:=\\sum_{i=1}^nX_{t_{i-1}}\\cdot\\mathbf{1}\\{t_{i-1}\\leq t&lt;t_i\\}$&emsp;&emsp;and will be proved later that this construction is converges in $L_{ad}^2$ sense.&emsp;&emsp;then we can define the integral as follows:&emsp;&emsp;$I(X_t):=\\lim_{n\\rightarrow\\infty}I(X_t^n)$&emsp;&emsp;and the limit is understood in mean square sense, i.e.:&emsp;&emsp;$$\\mathbb{E}\\left[ (I(X_t^n)-I(X_t))^2 \\right]\\xrightarrow[n\\rightarrow0]{}0$$ åŒæ¨£çš„, é€™å€‹ integration doesnâ€™t depend on æ€éº¼é¸ sequence of step processes $(X_t^n)_n$ ğŸ’¡ æ‰€ä»¥æ‰¾å‡ºä¸€å€‹ sequence of step processes converges (in $L_{ad}^2$ sense) to $X_t$ å¾Œ, ç”±æ–¼æ¯ä¸€å€‹ step process çš„ Wiener integral éƒ½å¯ä»¥æ±‚å¾—, æ‰€ä»¥è©² Wiener integral çš„ limit (in m.sq. sense) æˆ‘å€‘å°±å¯ä»¥å®šç¾©ç‚º $X_t$ çš„ Wiener integral ä»¥ä¸‹å®šç†èªªæ˜æ€éº¼æ‰¾åˆ°é€™å€‹ step process $(X_t^n)_n$ such that converge to $X_t$ in $L_{ad}^2$ sense [Convergence of Step Processes]:&emsp;Let stochastic process $X_t$ be such that $m(t)$ and $K(t,s)$ are continuous, then define&emsp;$X_t^n:=\\sum_{i=1}^nX_{t_{i-1}}\\cdot\\mathbf{1}\\{t_{i-1}\\leq t&lt;t_i\\}$&emsp;then we have&emsp;$X_t^n\\xrightarrow[]{L^2_{ad}} X_t \\Longleftrightarrow \\int_a^b\\mathbb{E}\\left(X_t^n-X_t\\right)^2dt\\xrightarrow[n\\rightarrow\\infty]{}0$[Proof]:&emsp;é¦–å…ˆè­‰æ˜ $X_t$ is continuous in mean square sense, i.e.&emsp;$\\mathbb{E}(X_t-X_s)^2\\xrightarrow[s\\rightarrow t]{}0$&emsp;å±•é–‹ä¾†ä¸¦å…¨éƒ¨ç”¨ $m(t),K(t,s)$ æ›¿æ›:&emsp;$$\\mathbb{E}(X_t-X_s)^2 = \\mathbb{E}X_t^2 - 2\\mathbb{E}X_tX_s + \\mathbb{E}X_s^2 \\\\ = (K(t,t)+m^2(t))-2(K(t,s)+m(t)m(s))+(K(s,s)+m^2(s)) \\\\ \\xrightarrow[s\\rightarrow t]{}0 \\Longrightarrow X_t^n\\xrightarrow[n\\rightarrow\\infty]{m.sq.}X_t \\text{ (for a given }t) \\\\ \\text{i.e. }\\lim_{n\\rightarrow\\infty}\\mathbb{E}\\left(X_t^n-X_t\\right)^2=0$$&emsp;å…¶ä¸­ $X_t^n$ converges to $X_t$ in m.sq. sense å¯ä»¥åƒè€ƒ link&emsp;æ‰€ä»¥&emsp;$$\\lim_{n\\rightarrow\\infty}\\int_a^b\\mathbb{E}\\left(X_t^n-X_t\\right)^2dt \\\\ (\\text{by Lebesgue&apos;s dominated convergence theorem})\\\\ = \\int_a^b \\lim_{n\\rightarrow\\infty}\\mathbb{E}\\left(X_t^n-X_t\\right)^2dt = 0\\ldots(\\star)$$&emsp;åƒè€ƒ Lebesgueâ€™s dominated convergence theorem&emsp;If $\\exists M(t)$ such that&emsp;$$|f(n,t)|\\leq M(t),\\forall n,t \\\\ \\int M(t)dt&lt;\\infty$$&emsp;then&emsp;$\\int\\lim_{n\\rightarrow\\infty} f(n,t)dt = \\lim_{n\\rightarrow\\infty}\\int f(n,t)dt$&emsp;ç”±æ–¼æœ‰ä»¥ä¸‹é—œä¿‚&emsp;$$\\mathbb{E}(X_t^n-X_t)^2 \\leq 2\\mathbb{E}(X_t^n)^2 + 2\\mathbb{E}(X_t)^2 \\\\ \\leq 4\\max_{t\\in[a,b]}\\mathbb{E}X_t^2=4\\max_{t\\in[a,b]}(K(t,t)+m^2(t))$$&emsp;ç”±æ–¼ $m,K$ continuous æ‰€ä»¥è©² maximum å­˜åœ¨æ˜¯ finite, å› æ­¤æˆ‘å€‘æ‰¾åˆ°äº† bounded function $M(t)$&emsp;æ‰€ä»¥ limit and integral å¯äº’æ›.&emsp;çµæœ $(\\star)$ æˆç«‹, Q.E.D. [Quadratic Variation of a Brownian Motion]:&emsp;Assume $W_t$ is a Brownian motion. The interval from $0$ to $t$ is divided into $n$ parts by points $0=t_0,t_1,â€¦,t_n=t$. Prove&emsp;$t=\\lim_{n\\rightarrow\\infty}\\sum_{i=1}^n (W_{t_i}-W_{t_{i-1}})^2$[Sol]: [Example]: Quiz ç¬¬ä¸ƒé¡Œæœ‰è¨ˆç®—é€™å€‹ stochastic integral ç”¢ç”Ÿçš„ process ä¹‹ mean and variance é€™æ®µèª²ç¨‹çš„çµèª, ä½¿ç”¨å®šç¾©çš„æ–¹å¼ä¾†è¨ˆç®—å‡º Wiener integral of process in $L_{ad}^2$ å¾ˆå¤šæ™‚å€™ä»ç„¶å¾ˆå›°é›£ä½†æ¥ä¸‹ä¾†è¦ä»‹ç´¹çš„ Ito formula å¯ä»¥å¹«åŠ©æˆ‘å€‘è¨ˆç®—å¤§éƒ¨åˆ†çš„æƒ…æ³ Week 7.6: Integrals of the type $âˆ« X_t dY_t$, where $Y_t$ is an ItÃ´ process[Ito Process Def]:&emsp;Let $\\mathcal{F}_t$ is a filtration, $b_t,\\sigma_t$ are processes $\\mathcal{F}_t$-adapted, $W_t$ is $\\mathcal{F}_t$ Brownian motion&emsp;and $H_0$ is a random variable which is a measurable function w.r.t. $\\mathcal{F}_0$&emsp;$H_t$ is a Ito process:&emsp;$H_t=H_0+\\int_0^t b_sds + \\int_0^t\\sigma_sdW_s$&emsp;or equivalently&emsp;$dH_t=b_tdt+\\sigma_tdW_t$ $H_t$ çš„è®ŠåŒ– (ä¹Ÿé‚„æ˜¯ä¸€å€‹ random process) ç­‰æ–¼ $b_t$ ä¹˜ä¸Šæ™‚é–“çš„è®ŠåŒ– $dt$, å†åŠ ä¸Š $\\sigma_t$ ä¹˜ä¸Š Brownian motion çš„è®ŠåŒ– $dW_t$ [Stochastic Integral with Ito Process]:&emsp;Let $\\mathcal{F}_t$ be some filtration, $X_t$ is $\\mathcal{F}_t$-adapted and $H_t$ is a Ito process which is also $\\mathcal{F}_t$-adapted.&emsp;If $X_t$ fulfilled&emsp;$\\int_a^b|X_sb_s|+X_s^2\\sigma_s^2ds&lt;\\infty$&emsp;then the integral is defined as&emsp;$\\int_a^b X_tdH_t:=\\int_a^bb_sX_xds + \\int_a^b\\sigma_sX_sdW_s$ r.h.s. çš„ç¬¬ä¸€é …å’Œç¬¬äºŒé … integrals ä¹‹å‰éƒ½è¨è«–é [Ito Lemma or Ito Formula]:&emsp;Let $H_t$ is a Ito process, i.e.&emsp;$dH_t=b_tdt+\\sigma_tdW_t$&emsp;where $b_t,\\sigma_t$ are processes $\\mathcal{F}_t$-adapted, $W_t$ is $\\mathcal{F}_t$ Brownian motion.&emsp;If $f(t,x)$ is twice continuously differentiable, then $f(t,H_t)$ be a Ito process with the following equation:&emsp;$$\\color{orange}{ f(t,H_t)=f(0,H_0)+\\int_0^tf_1&apos;(s,H_s)ds + \\int_0^tf_2&apos;(s,H_s)dH_s + \\frac{1}{2}\\int_0^tf_{22}&apos;&apos;(s,H_s)\\sigma_s^2ds }$$&emsp;where&emsp;$$f_1&apos;(t,x)=\\frac{\\partial}{\\partial t}f(t,x) \\\\ f_2&apos;(t,x)=\\frac{\\partial}{\\partial x}f(t,x) \\\\ f_{22}&apos;&apos;(t,x)=\\frac{\\partial^2}{\\partial t\\partial t}f(t,x)$$&emsp;or equivalently,&emsp;$$\\color{orange}{ df(t,H_t)=f_1&apos;(t,H_t)dt + f_2&apos;(t,H_t)dH_t + \\frac{1}{2}f_{22}&apos;&apos;(t,H_t)\\sigma_t^2dt }$$ Week 7.7: ItÃ´â€™s formulaè‹¥ $H_t$ ç‚º Ito-process, i.e.: $b_t,\\sigma_t$ are processes $\\mathcal{F}_t$-adapted, $W_t$ is $\\mathcal{F}_t$ Brownian motion.$dH_t=b_tdt+\\sigma_tdW_t$ If $f(t,x)$ is twice continuously differentiable, then $f(t,H_t)$ be a Ito process with the following equation:$$f(t,H_t)\\\\ =f(0,H_0)+\\int_0^tf_1&apos;(s,H_s)ds + \\int_0^tf_2&apos;(s,H_s)dH_s + \\frac{1}{2}\\int_0^tf_{22}&apos;&apos;(s,H_s)\\sigma_s^2ds$$ Ito formula å¯ä»¥ç”¨ä¾†å¹«åŠ©è¨ˆç®—ä»¥ä¸‹å½¢å¼çš„ç©åˆ†, å‡è¨­ $g(t,x)$ is twice continuously differentiable:$\\int_0^t g(s,W_s)dW_s$ å°ç…§ Ito formula æˆ‘å€‘åœ¨ Week 7.5 æœ‰åˆ©ç”¨ Wiener process Integral çš„å®šç¾©ä¾†è¨ˆç®—é $\\int W_sdW_s$, æ­¤æ™‚ $g(s,W_s)=W_s$, ä½†å¦‚æœ $g(.,.)$ è¤‡é›œä¸€é»å°±æœƒå¾ˆé›£è¨ˆç®—. ä¸éæˆ‘å€‘å¯ä»¥å€Ÿç”¨ Ito formula ä¾†å¹«å¿™ æˆ‘å€‘ä»¤ $f$-antiderivative of $g$ w.r.t. 2nd-argument, i.e., $f_2â€™=g$, æ³¨æ„åˆ° $f(t,x)$ å¦‚æœåŠ ä¸Š $h(t)$ ä¹Ÿæ»¿è¶³ $f_2â€™=g$, ä¸”ä¸å½±éŸ¿ä»¥ä¸‹æ¨å°, å¯è‡ªè¡Œå¸¶å…¥å¤šäº†ä¸€å€‹ $h(t)$ æœƒç™¼ç¾ä¸å½±éŸ¿çµæœç”±æ–¼ Brownian motion ä¹Ÿæ˜¯ Ito process, æ‰€ä»¥æ­¤æ™‚ $H_t=W_t$ and $\\sigma_s=1$, é‡æ–°æ”¹å¯« Ito formula è®Šæˆ:$f(t,W_t)=f(0,0)+\\int_0^tf_1&apos;(s,W_s)ds + \\int_0^t g(s,W_s)dW_s + \\frac{1}{2}\\int_0^t g_2&apos;(s,W_s)ds$ ç§»é …ä¸€ä¸‹:$$\\color{orange}{ \\int_0^t g(s,W_s)dW_s=f(t,W_t)-f(0,0) - \\int_0^t\\left( f_1&apos;(s,W_s)+\\frac{1}{2}g_2&apos;(s,W_s) \\right)ds }\\ldots(\\square)$$ [Example]:&emsp;è¨ˆç®— $\\int_0^t W_sdW_s$[Sol]:&emsp;$g(t,x)=x$, æ‰€ä»¥ $f(t,x)=\\frac{1}{2}x^2$. åˆ©ç”¨ $(\\square)$ å‰‡&emsp;$\\int_0^t W_sdW_s = \\frac{1}{2}W_t^2-\\int_0^t\\frac{1}{2}ds=\\frac{1}{2}W_t^2-\\frac{1}{2}t$ [Example]:&emsp;è¨ˆç®— $\\int_0^t \\frac{W_s}{1+W_s^2}dW_s$[Sol]: Week 7.8: Calculation of stochastic integrals using the ItÃ´ formula. Black-Scholes modelé‡è¤‡ä¸€æ¬¡ Ito formula (in derivative form)$df(t,H_t)=f_1&apos;(t,H_t)dt + f_2&apos;(t,H_t)dH_t + \\frac{1}{2}f_{22}&apos;&apos;(t,H_t)\\sigma_t^2dt$å…¶ä¸­ $H_t$ ç‚º Ito-process$dH_t=b_tdt+\\sigma_tdW_t$ [Black-Scholes model Def]:&emsp;$X_t$ ç‚ºä»¥ä¸‹ Stochastic Differential Equation (SDE) çš„è§£:&emsp;$dX_t = X_t\\mu dt+X_t\\sigma dW_t$&emsp;where $\\mu,\\sigma\\in\\mathbb{R},\\sigma&gt;0$, $W_t$ is $\\mathcal{F}_t$ Brownian motion. å°æ¯” Ito-process çš„å®šç¾©æœƒç™¼ç¾ $X_t$ æ˜¯ Ito-process &emsp;ä¸Šå¼ç­‰åŒæ–¼&emsp;$X_t=X_0+\\mu\\int_0^t X_sds+\\sigma\\int_0^tX_sdW_s$&emsp;è­‰æ˜å…¶è§£ç‚º:&emsp;$X_t=X_0\\cdot\\exp\\left\\{(\\mu-\\frac{\\sigma^2}{2})t+\\sigma W_t\\right\\}$[Proof]:&emsp;Let $f(t,x)=\\ln x$, $H_t=X_t$ ä¸¦ä»£å…¥ Ito formula: èª²ç¨‹æ•™æˆèªªé€™å¸¸ç”¨åœ¨ modeling stock prices Week 7.9: Vasicek model. Application of the ItÃ´ formula to stochastic modellingé‡è¤‡ä¸€æ¬¡ Ito formula (in derivative)$df(t,H_t)=f_1&apos;(t,H_t)dt + f_2&apos;(t,H_t)dH_t + \\frac{1}{2}f_{22}&apos;&apos;(t,H_t)\\sigma_t^2dt$å…¶ä¸­ $H_t$ ç‚º Ito-process$dH_t=b_tdt+\\sigma_tdW_t$ [Vasicek model Def]:&emsp;$X_t$ ç‚ºä»¥ä¸‹ Stochastic Differential Equation (SDE) çš„è§£:&emsp;$dX_t=(a-bX_t)dt+cdW_t,\\qquad b,c&gt;0$ å°æ¯” Ito-process çš„å®šç¾©æœƒç™¼ç¾ $X_t$ æ˜¯ Ito-process &emsp;è­‰æ˜å…¶è§£ç‚º:&emsp;$X_t=e^{-bt}X_0 + \\frac{a}{b}(1-e^{-bt})+c\\int_0^te^{b(s-t)}dW_s$[Proof]:&emsp;ä½¿ç”¨ Ito formula, ä¸¦å®šç¾© $H_t=X_t$, and $f(t,x)=xe^{bt}$&emsp;å¾—åˆ°&emsp;$$d\\left(X_te^{bt}\\right)=bX_te^{bt}dt+e^{bt}\\left((a-bX_t)dt+cdW_t\\right) \\\\ = ae^{bt}dt+ce^{bt}dW_t$$&emsp;æ‰€ä»¥&emsp;$X_t=e^{-bt}X_0 + \\frac{a}{b}(1-e^{-bt})+c\\int_0^te^{b(s-t)}dW_s$ SDE æ”¹å¯«æˆ$dX_t=b\\left(\\frac{a}{b}-X_t\\right)dt+cdW_t,\\qquad b,c&gt;0$ å¦‚æœ $X_t&gt;a/b$, $dX_t&lt;0$, ä¹Ÿå°±æ˜¯èªª $X_t$ çš„æ–œç‡ç‚ºè² , $X_t$ æœƒè®Šå°. åä¹‹æ–œç‡ç‚ºæ­£, å€¼è®Šå¤§. æ‰€ä»¥è§€å¯Ÿ trajectory ç‚ºä¸‹åœ–: $b$ ç¨±ç‚º speed of reversion Week 7.10: Ornstein-Uhlenbeck process. Application of the ItÃ´ formula to stochastic modelling.ç¹¼çºŒé‡è¤‡ Ito formula (in derivative)$df(t,H_t)=f_1&apos;(t,H_t)dt + f_2&apos;(t,H_t)dH_t + \\frac{1}{2}f_{22}&apos;&apos;(t,H_t)\\sigma_t^2dt$å…¶ä¸­ $H_t$ ç‚º Ito-process$dH_t=b_tdt+\\sigma_tdW_t$ [Ornstein-Uhlenbeck process Def]:&emsp;$V_t$ ç‚ºä»¥ä¸‹ Stochastic Differential Equation (SDE) çš„è§£:&emsp;$mdV_t=dW_t-\\lambda\\cdot V_tdt$&emsp;where $m$ is mass (è³ªé‡), $V_t$ è¡¨ç¤ºé€Ÿåº¦, $W_t$ is Brownian motion. $\\lambda$ is called friction coefficient&emsp;è­‰æ˜å…¶è§£ç‚º:&emsp;$$V_t=e^{-\\frac{\\lambda}{m}t} \\left( V_0+\\frac{1}{m}\\int_0^t e^{\\frac{\\lambda}{m}s}dW_s \\right)$$[Proof]:&emsp;ä½¿ç”¨ Ito formula, ä¸¦å®šç¾© $H_t=X_t$, and&emsp;$f(t,x)=xe^{\\frac{\\lambda}{m}t}$&emsp;å‰‡è§£ç‚º&emsp;$$V_t=e^{-\\frac{\\lambda}{m}t} \\left( V_0+\\frac{1}{m}\\int_0^t e^{\\frac{\\lambda}{m}s}dW_s \\right)$$ å¦‚æœ$V_0\\sim\\mathcal{N}\\left(0,\\frac{1}{2\\lambda m}\\right) \\perp W_t$then $V_t$ is a Gaussian process with $m(t)=0$$K(t,s)=\\frac{m}{2\\lambda}e^{-\\frac{\\lambda}{m}|t-s|}$ä¸”çœ‹çš„å‡ºåªèˆ‡ $t-s$ æœ‰é—œ, å› æ­¤ auto-covariance å­˜åœ¨ $\\gamma(t-s)=K(t,s)$å› æ­¤æ˜¯ WSS, åŠ ä¸Šæ˜¯ Gaussian process, æ‰€ä»¥ä¹Ÿæ˜¯ strictly stationary","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Stochastic Integration","slug":"Stochastic-Integration","permalink":"https://bobondemon.github.io/tags/Stochastic-Integration/"},{"name":"ItÃ´ formula","slug":"Ito-formula","permalink":"https://bobondemon.github.io/tags/Ito-formula/"}]},{"title":"Stochastic Processes Week 6 Ergodicity, differentiability, continuity","date":"2021-12-12T12:16:36.000Z","path":"2021/12/12/Stochastic-Processes-Week-6-Ergodicity-differentiability-continuity/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity (æœ¬æ–‡) Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes Self Study: Convergence of random variablesä¸»è¦åƒè€ƒ wikipedia çš„è³‡æ–™ç­†è¨˜ Convergence of random variables[Converge in distribution Def]:&emsp;è¨˜åš $X_n \\xrightarrow[]{d}X$ Converge in distribution æ˜¯æœ€ weak çš„, ä¹Ÿå°±æ˜¯æ»¿è¶³ converge in distribution ä¸ä¸€å®šæœƒæ»¿è¶³ converge in probability æˆ–æ»¿è¶³ almost surely æˆ–æ»¿è¶³ converge in mean[æ©Ÿç‡è«–] å…©éš¨æ©Ÿè®Šæ•¸ç›¸ç­‰è¡¨ç¤ºå…©è€…æœ‰ç›¸åŒåˆ†å¸ƒä½†åä¹‹ä¸ç„¶, é€™ç¯‡æ–‡ç« æœ€å¾Œçµ¦äº†ä¸€å€‹ä¾‹å­:è€ƒæ…®å‡å‹»åˆ†å¸ƒ $X$ ç‚ºéš¨æ©Ÿè®Šæ•¸æœå¾å‡å‹»åˆ†å¸ƒ $\\mathcal{U}[-1,1]$ ç¾åœ¨å–å¦ä¸€éš¨æ©Ÿè®Šæ•¸ $Y:=-X$ å‰‡ $Y$ äº¦ç‚ºåœ¨ $[-1,1]$ ä¸Šå‡å‹»åˆ†å¸ƒï¼Œäº¦å³ $X$ èˆ‡ $Y$ å…·æœ‰åŒåˆ†å¸ƒã€‚ç„¶è€Œ$\\mathcal{P}(X=Y)=0$ Converge in distribution çš„å…¶ä»–ç­‰åƒ¹å®šç¾© [Converge in probability Def]:&emsp;è¨˜åš $X_n \\xrightarrow[]{p}X$ [Properties]: è‡ªå·±çš„æƒ³æ³•: $X_n$ èˆ‡ $X$ çš„ sample spaces å¯ä»¥ä¸åŒ, åªè¦ mapping åˆ° $\\mathbb{R}$ ä¹‹å¾Œç›¸æ¸›å°±å¥½, æ‰€ä»¥è€ƒé‡çš„æ˜¯ joint distributionFor a random process $X_t$ converges to a constant in probability sense$X_t\\xrightarrow[t\\rightarrow\\infty]{p} c \\text{ (is const.)}$å‰‡è¡¨ç¤ºä¸€å®šæœƒ (å¿…è¦æ¢ä»¶)$$\\mathbb{E}X_t\\xrightarrow[t\\rightarrow\\infty]{}c \\\\ Var(X_t)\\xrightarrow[t\\rightarrow\\infty]{}0$$ [Almost sure convergence Def]:&emsp;è¨˜åš $X_n \\xrightarrow[]{a.s.} X$ å¯åƒè€ƒ: è¬å®—ç¿°çš„éš¨ç­† [æ©Ÿç‡è«–] Almost Sure Convergence è‡ªå·±çš„æƒ³æ³•: éœ€è¦ sample space ä¸€æ¨£, ä¸”éƒ½æ˜¯å°å€‹åˆ¥ outcome å»æ¯”è¼ƒçš„. æŠŠæ‰€æœ‰é€™äº›ç¬¦åˆçš„ outcomes è’é›†èµ·ä¾†çš„é›†åˆ, å…¶ probability measure ç‚º $1$.é€™æ˜¯ä¸€å€‹å¾ˆå¼·çš„æ¢ä»¶, å¹¾ä¹é‡å°æ¯ä¸€å€‹ outcome éƒ½è¦ç¬¦åˆ. [Convergence in mean Def]:&emsp;è¨˜åš $X_n \\xrightarrow[]{L^r} X$. Convergence in the $r$-th mean, for $r\\geq1$, implies convergence in probability (by Markovâ€™s inequality). Furthermore, if $r&gt;s\\geq1$, convergence in $r$-th mean implies convergence in $s$-th mean. Hence, convergence in mean square implies convergence in mean.It is also worth noticing that if $$X_n\\xrightarrow[]{L^r}X$$ then $$\\lim_{n\\rightarrow\\infty}\\mathbb{E}[|X_n|^r]=\\mathbb{E}[|X|^r]$$ [Relation btw Stochastic Convergences]: å„ç¨® convergence çš„ proofs:https://en.wikipedia.org/wiki/Proofs_of_convergence_of_random_variables#propA2 è£œä¸Šèª²ç¨‹é‡å°ä»¥ä¸Šå››å€‹ convergences çš„å®šç¾© Week 6.1: Notion of ergodicity. ExamplesMotivated by LLN (Law of Large Number)[LLN Thm]:&emsp;$\\xi_1,\\xi_2,â€¦$ - i.i.d. and $\\mathbb{E}\\xi_1&lt;\\infty$, then&emsp;$\\frac{1}{N}\\sum_{n=1}^N \\xi_n \\xrightarrow[N\\rightarrow\\infty]{p} \\mathbb{E}\\xi_1$&emsp;ä¸Šå¼ $\\xrightarrow[]{p}$ è¡¨ç¤º convergence in probability&emsp;ä½†ä¹Ÿæ»¿è¶³ $\\xrightarrow[]{a.s.}$ almost sure convergence (Strong LLN) Ergodicity å˜—è©¦å°‡ LLN æ¦‚å¿µå»¶ä¼¸åˆ° stochastic process [Ergodicity Def]:&emsp;$X_t$ is a stochastic process, where $t=1,2,3,â€¦$&emsp;$X_t$ is said ergodic if $\\exists c$ constant such that&emsp;$$M_T:=\\frac{1}{T}\\sum_{t=1}^T X_t \\xrightarrow[T\\rightarrow\\infty]{p} c$$&emsp;where $c$ is some constant. $T$ is called horizon.&emsp;And we consider convergence in probability sense. æ‰€ä»¥è¦è­‰æ˜ ergodic å¯ä»¥ $\\xrightarrow[]{p}$, or $\\xrightarrow[]{a.s.}$, or $\\xrightarrow[]{m.sq.}$, or $\\xrightarrow[]{d}c$ [Example 1]:&emsp;$X_t=\\xi\\sim\\mathcal{N}(0,1)$, trajectory ç‚º constant for all $t$&emsp;$m(t)=0,K(t,s)=Var\\xi=1$&emsp;æ‰€ä»¥æ˜¯ weak stationary, æˆ‘å€‘è€ƒæ…® ergodicity&emsp;$\\frac{1}{T}\\sum_{t=1}^T X_t=\\xi\\neq c$&emsp;ä¸å­˜åœ¨ä¸€å€‹ constant for $T\\rightarrow \\infty$, æ‰€ä»¥ non-ergodic [Example 2]:&emsp;$X_t$ stochastic process defined as:&emsp;$X_t=\\varepsilon_t+a\\cos\\frac{\\pi t}{6}$&emsp;where $a\\neq0$ and $\\varepsilon_1, \\varepsilon_2, â€¦$ i.i.d. $\\mathcal{N}(0,1)$ å…¶ trajectory ç‚ºä¸‹åœ–æ›²ç·š, ä¸¦å°è©²æ›²ç·šæ¯å€‹ä½ç½®éƒ½æœ‰ std normal noise$m(t)=a\\cos\\frac{\\pi t}{6}\\neq const$, æ‰€ä»¥ä¸æ˜¯ stationary. è€ƒæ…® ergodicity:$\\frac{1}{T}\\sum_{t=1}^T X_t\\sim\\mathcal{N}\\left(\\frac{a}{T}\\sum_{t=1}^T \\cos\\frac{\\pi t}{6},\\frac{1}{T}\\right)$äº’ç›¸ç¨ç«‹ä¹‹ normal distributions ç›¸åŠ ä»ç‚º normal, mean and variance éƒ½ç‚ºç›¸åŠ variance æ”¶æ–‚åˆ° $0$, è§€å¯Ÿ mean:ç”±æ–¼ trajectory æ˜¯ä»¥ 12 ç‚ºä¸€å€‹é€±æœŸ, æ‰€ä»¥æœ€å¤šåªæœƒæœ‰ 12 å€‹é 0 çš„å€¼, è€Œæ¯ä¸€å€‹éƒ½å°æ–¼ç­‰æ–¼ 1çµè«–æ˜¯ mean ä¹Ÿæ”¶æ–‚åˆ° $0$ (å› ç‚ºä¸ç®¡å“ªä¸€å€‹ outcome, å…¶ trajectory æœ€å¾Œéƒ½åˆ° $0$, æ‰€ä»¥æ”¶æ–‚çš„ random variable ç‚º contant $0$)æ‰€ä»¥$\\frac{1}{T}\\sum_{t=1}^T X_t\\sim\\mathcal{N}\\left(0,0\\right) \\text{ for }T\\rightarrow\\infty$æ‰€ä»¥ $=0$ a.s. å› æ­¤æ˜¯ ergodicExample 1 æ˜¯ (weak) stationary but non-ergodicExample 2 æ˜¯ non-stationary but erogodicå› æ­¤ stationary è·Ÿ ergodic æ˜¯ä¸åŒæ¦‚å¿µ Week 6.2: Ergodicity of wide-sense stationary processes[Proposition]:For $X_t$ is a discrete time stochastic process. Define&emsp;$$M_T=\\frac{1}{T}\\sum_{t=1}^TX_t\\\\ C(T)=Cov(X_T,M_T)$$&emsp;If $\\exists\\alpha$ such that the covariance function is bounded by $\\alpha$, i.e.&emsp;$|K(s,t)|\\leq\\alpha;\\forall s,t$&emsp;Then&emsp;$$Var(M_T)\\xrightarrow[T\\rightarrow\\infty]{}0 \\Longleftrightarrow C(T)\\xrightarrow[T\\rightarrow\\infty]{}0$$ [Stolz-Cesaro Thm]:&emsp; For $a_n,b_n\\in\\mathbb{R}$, $b_n$ is strictly increasing and unbounded, we have:&emsp;$\\lim_{n\\rightarrow\\infty}\\frac{a_n-a_{n-1}}{b_n-b_{n-1}}=q\\Longrightarrow \\frac{a_n}{b_n}\\xrightarrow[n\\rightarrow\\infty]{}q$ See wiki for more detials and proof ç•¶ stationary æ™‚, æœ‰å…©å€‹ sufficient conditions æ»¿è¶³å‰‡ä¿è­‰ ergodic[Sufficient Conditions of Ergodicity when WSS]:&emsp;$X_t$ is weakly stationary and $\\gamma(\\cdot)$ is its auto-covariance function with $|\\gamma(\\cdot)|&lt;\\infty$.&emsp;1. Sufficient condition: If&emsp;&emsp;$\\frac{1}{T}\\sum_{r=0}^{T-1}\\gamma(r) \\xrightarrow[T\\rightarrow\\infty]{}0$&emsp;&emsp;Then $X_t$ is ergodic&emsp;2. Sufficient condition: If&emsp;&emsp;$\\gamma(r) \\xrightarrow[r\\rightarrow\\infty]{}0$&emsp;&emsp;Then $X_t$ is ergodic[Proof 1]:&emsp;è€ƒæ…® $C(T)$&emsp;$$C(T)=Cov\\left(X_T,\\frac{1}{T}\\sum_{t=1}^TX_t\\right) =\\frac{1}{T}\\sum_{t=1}^T Cov(X_T,X_t) \\\\ =\\frac{1}{T}\\sum_{t=1}^T \\gamma(T-t) =\\frac{1}{T}\\sum_{r=0}^{T-1}\\gamma(r) \\longrightarrow0\\text{ (by assumption)}$$&emsp;ç”± proposition çŸ¥é“ $Var(M_T)\\rightarrow0$, as $T\\rightarrow\\infty$&emsp;åˆå› ç‚ºå·²çŸ¥ $X_t$ is weakly stationary, æ‰€ä»¥ $\\exists c$ constant, s.t.&emsp;$\\mathbb{E}X_t=c\\Rightarrow\\mathbb{E}M_t=c$&emsp;å‰‡ variance converge to $0$ as $T\\rightarrow\\infty$ è¡¨ç¤º&emsp;$VarM_T=\\mathbb{E}\\left[(M_T-c)^2\\right]\\xrightarrow[T\\rightarrow\\infty]{}0$&emsp;å‰‡&emsp;$M_T \\xrightarrow[]{L^2} c \\Longrightarrow M_T \\xrightarrow[]{p} c$&emsp;æ ¹æ“šå®šç¾© $X_t$ is ergodic. Q.E.D. [Proof 2]:&emsp;æˆ‘å€‘åˆ©ç”¨ proof 1 çš„çµæœå’Œ Stolz-Cesaro thm, å®šç¾©&emsp;$$a_n:=\\sum_{r=0}^{n-1}\\gamma(r)\\\\ b_n:=n$$&emsp;å‰‡&emsp;$$\\frac{a_n-a_{n-1}}{b_n-b_{n-1}}=\\frac{\\gamma(n-1)}{1}\\xrightarrow[n\\rightarrow\\infty]{}0=q \\\\ \\Longrightarrow \\frac{a_n}{b_n} = \\frac{1}{n}\\sum_{r=0}^{n-1}\\gamma(r)\\xrightarrow[n\\rightarrow\\infty]{}0=q \\\\ \\Longrightarrow X_t \\text{ ergodic}$$ [Example 1]:&emsp;$N_t$ is Poisson process with $\\lambda$. çµ¦å®š $p&gt;0$, ä¸¦å®šç¾©&emsp;$X_t:=N_{t+p}-N_t$&emsp;å‰‡æˆ‘å€‘å¯å¾—çŸ¥ $X_t$ is ergodic You can use the independent increment property of Poisson Process to get this formula.$\\gamma(t-s) = Cov(N_{t+p}-N_t,N_{s+p}-N_s)$If $|s-t|&gt;p$, then $N_{t+p}-N_t$ is independent of $N_{s+p}-N_s$, so $\\gamma(t-s)=0$If $t&lt;s&lt;t+p$, then $N_t$ is independent of $N_{s+p}-N_s$, so$$Cov(N_{t+p}-N_t,N_{s+p}-N_s) = Cov(N_{t+p},N_{s+p}-N_s) \\\\ = Cov(N_{t+p},N_{s+p}) - Cov(N_{t+p},N_s) \\\\ = Cov(N_{t+p},N_{s+p} - N_{t+p} + N_{t+p}) - Cov(N_{t+p} - N_s + N_s,N_s) \\\\ = Var(N_{t+p}) - Var(N_s) = \\lambda(t+p-s)$$For $s&lt;t&lt;s+p$. you can deal with it similarly. [Example 2]:&emsp;$A,B$ éƒ½æ˜¯ r.v.s æœ‰å¦‚ä¸‹åœ–çš„ expectation and uncorrelated relation&emsp;$\\omega$ æ˜¯ä»»æ„çµ¦å®šçš„ fixed value&emsp;å‰‡æˆ‘å€‘ç™¼ç¾ $X_t$ is weakly stationary and ergodic Week 6.3: Definition of a stochastic derivative[Stochastic Derivative Def]:&emsp;We say that a random process $X_t$ is differentiable at $t=t_0$&emsp;if the following limit converges in m.sq. sense to some random variable $\\eta$&emsp;$\\frac{X_{t+h}-X_t}{h} \\xrightarrow[h\\rightarrow0]{L^2}\\eta:=X_{t_0}&apos;$&emsp;equivalently we can write as follows&emsp;$\\mathbb{E}\\left[\\left(\\frac{X_{t+h}-X_t}{h}-\\eta\\right)^2\\right] \\xrightarrow[h\\rightarrow0]{}0$ [Proposition, Differentiability of Stochastic Process]:&emsp;Let $X_t$ is a stochastic process and $\\mathbb{E}X_t^2&lt;\\infty$.&emsp;Then $X_t$ is differentiable at $t=t_0$ if and only if&emsp;$$\\exists\\frac{dm(t)}{dt}\\text{, at }t=t_0 \\\\ \\exists\\frac{\\partial}{\\partial t\\partial s}K(t,s)\\text{, at }(t_0,t_0)$$ [Brownian Motion is NOT differentiable at any time $t$]: [Differentiability of Independent Increments]:&emsp;$X_t$ is independent increments and $X_0=0$ a.s. å‰‡æˆ‘å€‘çŸ¥é“&emsp;$K(t,s)=Var(X_{\\min(t,s)})$&emsp;å› æ­¤å¤§éƒ¨åˆ†çš„ stochastic process with independent increments éƒ½ä¸æ˜¯å¯å¾®çš„.&emsp;æˆ‘å€‘å¯«ä¸€ä¸‹ covariance function çš„æ¨å°:&emsp;$$K(t,s)=Cov(X_t,X_s) \\\\ \\text{(for t&gt;s) }=Cov(X_t-X_s,X_s-X_0)+Cov(X_s,X_s) \\\\ = 0+Var(X_s)\\\\ \\text{(consider t&gt;s and t&lt;s) }= Var(X_{\\min(t,s)})$$ [Differentiability of Weakly Stationary]:&emsp;$X_t$ is weakly stationary. æ‰€ä»¥ $m(t)$ is constant $\\Rightarrow$ differentiable at all $t$.&emsp;æˆ‘å€‘çŸ¥é“ $K(t,s)=\\gamma(t-s)$, è¨ˆç®— partial derivatives:&emsp;$$\\left.\\frac{\\partial^2K(t,s)}{\\partial t\\partial s} \\right\\vert_{(t_0,t_0)} = \\frac{\\partial^2 \\gamma(t-s) }{\\partial t\\partial s} \\\\ = \\left.\\frac{\\partial}{\\partial t} \\left(-\\gamma&apos;(t-s)\\right)\\right|_{(t_0,t_0)} = \\left.-\\gamma&apos;&apos;(t-s)\\right|_{(t_0,t_0)} \\\\ = -\\gamma&apos;&apos;(0)$$&emsp;æ‰€ä»¥ $X_t$ is differentiable (at any time $t$) if and only if $-\\gammaâ€™â€™(0)$ å­˜åœ¨ [Example 1]:&emsp;æ‰¿ä¸Š weakly stationary differentiable. å¦‚æœ $\\gamma(r)=e^{-\\alpha|r|}$&emsp;å‰‡ $X_t$ is not differentiable, å› ç‚º $-\\gammaâ€™â€™(0)$ ä¸å­˜åœ¨ ($\\gammaâ€™(0)$ å°±ä¸å­˜åœ¨äº†). $\\gamma(t)$ å¦‚ä¸‹: [Example 2]:&emsp;æ‰¿ä¸Š weakly stationary differentiable. å¦‚æœ $\\gamma(r)=\\cos(\\alpha r)$&emsp;å‰‡ $X_t$ is differentiable Week 6.4: Continuity in the mean-squared sense[Continuity in the probability sense Def]:&emsp;$X_t\\xrightarrow[t\\rightarrow t_0]{p}X_{t_0} \\Longleftrightarrow \\mathcal{P}(|X_t-X_{t_0}|&gt;\\varepsilon)\\xrightarrow[t\\rightarrow t_0]{}0, \\qquad \\forall\\varepsilon&gt;0$ Converges in mean-squared sense ç¢ºä¿äº† converges in probability, ä¸” in m.sq. sense æ¯”è¼ƒå®¹æ˜“ç¢ºèª, å› æ­¤ä»¥ä¸‹è‘—é‡åœ¨ in m.sq. sense [Continuity in the mean-squared sense Def]:&emsp;$X_t\\xrightarrow[t\\rightarrow t_0]{L^2}X_{t_0} \\Longleftrightarrow \\mathbb{E}(X_t-X_{t_0})^2\\xrightarrow[t\\rightarrow t_0]{}0$ [Proposition, Continuity of Stochastic Process]:&emsp;$X_t$ stochastic process and $\\mathbb{E}X_t=0$&emsp;1. If $K(t,s)$ is continuous at $(t_0, t_0)$, then $X_t$ is continuous in the m.sq. sense at $t=t_0$&emsp;2. If $X_t$ is continuous in the m.sq. sense at $t=t_0,s_0$, then $K(t,s)$ is continuous at $(t_0,s_0)$ [Proof 1]:&emsp;proved by definition of m.sq. sense&emsp;$$\\mathbb{E}(X_t-X_{t_0})^2 = \\mathbb{E}X_t^2-2\\mathbb{E}X_tX_{t_0} + \\mathbb{E}X_{t_0}^2 \\\\ =K(t,t)-2K(t,t_0)+K(t_0,t_0)\\xrightarrow[t\\rightarrow t_0]{}0$$[Proof 2]:&emsp;$$K(t,s)-K(t_0,s_0) \\\\ = (K(t,s)-K(t_0,s)) + (K(t_0,s) - K(t_0,s_0))$$&emsp;ä½¿ç”¨ $\\mathbb{E}X_t=0$ and ç§‘è¥¿ä¸ç­‰å¼, è€ƒæ…®ç¬¬ä¸€é … $K(t,s)-K(t_0,s)$&emsp;$$|K(t,s)-K(t_0,s)|=|\\mathbb{E}[(X_t-X_{t_0})X_s]| \\\\ \\leq \\sqrt{\\mathbb{E}(X_t-X_{t_0})^2}\\cdot\\sqrt{\\mathbb{E}X_s^2}\\\\ \\text{by assumption }\\xrightarrow[t\\rightarrow t_0]{}0$$&emsp;ç¬¬äºŒé … $K(t_0,s) - K(t_0,s_0)$ ä¹Ÿä¸€æ¨£. Q.E.D. Differentiability è¦é—œæ³¨ $m(t)$ and $K(t,s)$ çš„å¾®åˆ†æ€§, è€Œ continuity åªé—œæ³¨ $K(t,s)$ çš„é€£çºŒæ€§å¦å¤–å°æ–¼ simplest type of stochastic integral $\\int X_tdx$ ä¾†èªª, é—œæ³¨çš„æ˜¯ $m(t)$ and $K(t,s)$ çš„é€£çºŒæ€§ [Corollary]:&emsp;Covariance function $K(t,s)$ is continuous at $(t_0,s_0),\\forall t_0,s_0$ if and only if&emsp;$K(t,s)$ is continuous at diagonal, i.e. $(t_0,t_0),\\forall t_0$ [Proof]:&emsp;åªéœ€è­‰æ˜ $\\Longleftarrow$&emsp;$K(t,s)$ is continuous at $(t_0,t_0)$, $\\forall t_0$. ç”± proposition 1 çŸ¥é“ $X_t$ is continuous in m.sq. sense $\\forall t$&emsp;å› æ­¤ $X_t$ is continuous in the m.sq. sense at $t=t_0,s_0$ for all points&emsp;ç”± proposition 2 çŸ¥é“ $K(t,s)$ is continuous at $(t_0,s_0),\\forall t_0,s_0$&emsp;Q.E.D.","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Stochastic Convergences","slug":"Stochastic-Convergences","permalink":"https://bobondemon.github.io/tags/Stochastic-Convergences/"},{"name":"Ergodicity","slug":"Ergodicity","permalink":"https://bobondemon.github.io/tags/Ergodicity/"},{"name":"Continuity","slug":"Continuity","permalink":"https://bobondemon.github.io/tags/Continuity/"}]},{"title":"Stochastic Processes Week 5 Stationarity and Linear filters","date":"2021-12-12T11:11:51.000Z","path":"2021/12/12/Stochastic-Processes-Week-5-Stationarity-and-Linear-filters/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters (æœ¬æ–‡) Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes Week 5.1-2: Two types of stationarity[Strictly Stationary Def]:&emsp;$X_t$ is (strictly) stationary if $\\forall(t_1,...,t_n)\\in\\mathbb{R}_+^n,\\forall h&gt;0$&emsp;$(X_{t_1+h},...,X_{t_n+h})=^d (X_{t_1},...,X_{t_n})$ Finite dimenstional distributions are invariant in shift in time [Weakly Stationary Def]:&emsp;$X_t$ is (weakly) stationary, if $\\forall t,s\\in \\mathbb{R}_+,\\forall h&gt;0$&emsp;$$m(t)=\\mathbb{E}X_t=const \\\\ K(t,s)=Cov(X_t,X_s)=K(t+h,s+h)$$&emsp;å­˜åœ¨ function $\\gamma:\\mathbb{R}\\rightarrow\\mathbb{R}$ (auto-covariance function) such that&emsp;$K(t,s)=\\gamma(t-s)$ Shift in time ä¸è®Šçš„åªæœ‰ mean å’Œ covarianceWeak stationarity ä¹Ÿç¨± second order stationarity æˆ– wide sense stationarity (WSS) [Properties of Auto-covariance $\\gamma(\\cdot)$]:&emsp;1. $\\gamma(0)\\geq0$&emsp;&emsp;$\\gamma(0)=Cov(X_t,X_t)=Var(X_t)\\geq0,\\forall t\\geq0$&emsp;2. $|\\gamma(t)|\\leq\\gamma(0)$&emsp;&emsp;$$|\\gamma(t)|=|Cov(X_t,X_0)|\\leq\\sqrt{Var(X_t)}\\sqrt{Var(X_0)} \\\\ = \\sqrt{Cov(X_t,X_t)}\\sqrt{Cov(X_0,X_0)} \\\\ = \\sqrt{\\gamma(t-t)}\\sqrt{\\gamma(0-0)}=\\gamma(0)$$&emsp;3. $\\gamma$ is even&emsp;&emsp;$\\gamma(t)=Cov(X_t,X_0)=Cov(X_0,X_t)=\\gamma(-t)$ [Statements btw Strictly and Weakly Stationarity]:&emsp;1. We assume $\\mathbb{E}X_t^2&lt;\\infty$, then $X_t$ is strictly stationary $\\Longrightarrow$ $X_t$ is weakly stationary&emsp;2. $X_t$ is Gaussian process, then $X_t$ is strictly stationary $\\Longleftrightarrow$ $X_t$ is weakly stationary [Stationary of White Noise Process? Is Weak]:&emsp;$X_t,t=\\pm1,\\pm2,â€¦$ is called white noise process, $WN(0,\\sigma^2)$, if&emsp;$$\\mathbb{E}X_t=0, Var(X_t)=\\sigma^2 \\\\ Cov(X_t,X_s)=0,\\forall t\\neq s$$&emsp;i.e.&emsp;$m(t)=0,\\gamma(0)=\\sigma^2,\\gamma(t)=0,\\forall t&gt;0$&emsp;or&emsp;$$\\mathbb{E}X_t=0\\\\ K(t,s)=\\sigma^2\\mathbf{1}\\{t=s\\}=\\gamma(t-s) \\\\ \\therefore\\gamma(x)=\\sigma^2\\mathbf{1}\\{x=0\\}$$&emsp;ä»¥ä¸Šéƒ½æ˜¯ç›¸åŒæ„æ€ $WN(0,\\sigma^2)$ å¯ä»¥çœ‹å‡ºæ˜¯ weakly stationary, é€šå¸¸æƒ…æ³ä¸‹ä¸ä¸€å®šæ˜¯ strictly stationary, å› ç‚ºæ ¹æ“šå®šç¾©åªçœ‹ mean and covariance. ä½†æœ‰äº›æƒ…æ³æœƒæ˜¯ strict, å¦‚: $X_1,X_2,â€¦$ are i.i.d. noise $X_t$ is a Gaussian process (å› ç‚ºæ­¤æ™‚ strictly if and only if weakly) [Stationary of Random Walk Process? Not Weak/Strict]:&emsp;$S_n=S_{n-1}+\\xi_n$ where $\\xi_1,\\xi_2,...$ are i.i.d. with&emsp;$$\\xi=\\left\\{ \\begin{array}{rl} 1, &amp; p \\\\ -1, &amp; 1-p \\end{array} \\right.$$&emsp;Also assume $S_0=0$&emsp;çŸ¥é“ $S_n=\\xi_1+â€¦+\\xi_n$, è¨ˆç®—ä¸€ä¸‹ expectation&emsp;$\\mathbb{E}S_n=n\\mathbb{E}\\xi_1=n(2p-1)$&emsp;æ‰€ä»¥å¦‚æœ $p\\neq\\frac{1}{2}$, å‰‡ $\\mathbb{E}S_n$ depends on $n$&emsp;æ‰€ä»¥ $S_n$ ä¸æ˜¯ weakly stationary (å› æ­¤ä¹Ÿä¸€å®šä¸æ˜¯ strictly)&emsp;æ‰€ä»¥æˆ‘å€‘ focus åœ¨ $p=\\frac{1}{2}$, æ¥è‘—è¨ˆç®— covariance, for $n&gt;m$&emsp;$$K(n,m)=Cov(S_m+\\xi_{m+1}+...+\\xi_n, S_m) \\\\ = Cov(S_m,S_m)+Cov(\\xi_{m+1}+...+\\xi_n,S_m) \\\\ =m\\cdot Var(\\xi_1)+0=\\min\\{n,m\\}Var(\\xi_1)$$&emsp;æ‰€ä»¥ $K(n,m)$ ç„¡æ³•åªç”¨ $n-m$ ä¾†è¡¨ç¤º, å› æ­¤ Random walk ä¸æ˜¯ strictly/weakly stationary [Stationary of Brownian Motion? Not Weak/Strict]:&emsp;$\\mathbb{E}B_t=0$, and $Var(B_t)=t$. ä¸”çŸ¥é“ $B_t-B_s\\sim\\mathcal{N}(0,t-s)$&emsp;$K(t,t)=Cov(B_t,B_t)=Var(B_t)=t$, $\\because B_t\\sim\\mathcal{N}(0,t)$&emsp;æ‰€ä»¥ä¸å­˜åœ¨ $\\gamma(t-s)=K(t,s)$, å› ç‚ºæˆ‘å€‘çœ‹ $\\gamma(0)$ å°±çŸ¥é“ä¸å›ºå®š, $\\gamma$ ä¸ç¬¦åˆ function å®šç¾©&emsp;æˆ–å¯ä»¥å¾ $K(t+h,s+h)=?K(t,s)$ è§€å¯Ÿ, å·²çŸ¥ Brownian motion $K(t,s)=\\min\\{t,s\\}$&emsp;å‰‡ $K(t+h,s+h)\\neq K(t,s)$&emsp;çµè«– Brownian motion is not weakly stationary (å› æ­¤ä¸€å®šä¹Ÿä¸æ˜¯ strictly) [Stationary of Moving Average Process? Is Weak]:&emsp;$X_t\\sim WN(0,\\sigma^2)$. Given $a_1,â€¦,a_q\\in\\mathbb{R};a_0=1$. Moving average $Y_t$ defined as:&emsp;$Y_t=X_t+a_1X_{t-1}+...+a_qX_{t-q}$&emsp;ç”¨ $MA(q)$ è¡¨ç¤º&emsp;$\\mathbb{E}Y_t=\\mathbb{E}[X_t]+a_1\\mathbb{E}[X_{t-1}]+...+a_q\\mathbb{E}[X_{t-q}]=0$&emsp;$$K(t,s)=Cov\\left(\\sum_{j=0}^qa_jX_{t-j},\\sum_{k=0}^qa_kX_{s-k}\\right) \\\\ = \\sum_{j=0}^q \\sum_{k=0}^q a_ja_kCov(X_{t-j},X_{s-k}) \\\\ = \\sum_{j=0}^q \\sum_{k=0}^q a_ja_k \\sigma^2\\mathbf{1}\\{t-s=j-k\\}$$&emsp;å› æ­¤å¯ä»¥çœ‹å‡º $K(t,s)$ åªè·Ÿ $t-s$ æœ‰é—œ&emsp;MA(1):&emsp;æ‰€ä»¥æ˜¯ Weakly stationary é€™å€‹ moving average æ˜¯ FIR (linear), input $X_t$ æ˜¯ white noise, æ‰€ä»¥ç‚º weakly stationary. ç”± weakly stationary ç¶“é linear filter å…¶ output ä»ç‚º weakly stationary å¯å¾—åˆ°çµè«–. [Stationary of Autoregressive Model? Weak in Constraint]:&emsp;$\\xi_t\\sim WN(0,\\sigma^2)$, we say that $Y_t$ is autoregressive model, $AR(p)$, if:&emsp;$Y_t=b_1Y_{t-1}+...+b_pY_{t-p}+\\xi_t$&emsp;Also we assume $Cov(\\xi_t,Y_s)=0,\\forall t&gt;s$&emsp;è€ƒæ…® $AR(1)$:&emsp;$$Y_t=bY_{t-1}+\\xi_t \\\\ =b(bY_{t-2}+\\xi_{t-1})+\\xi_t \\\\ = ... = \\sum_{j=0}^\\infty b^j\\xi_{t-j}$$&emsp;æ˜é¡¯å¯ä»¥çœ‹å‡º $\\mathbb{E}Y_t=0$, æ¥è‘—è¨ˆç®— covariance:&emsp;$$K(t,s)=Cov(Y_t,Y_s)=\\sum_{j,k=0}^\\infty b^{j+k}\\cdot Cov(\\xi_{t-j},\\xi_{s-k}) \\\\ = \\sum_{j,k=0}^\\infty b^{j+k} \\cdot \\sigma^2\\cdot\\mathbf{1}\\{t-s=j-k\\}$$&emsp;çœ‹èµ·ä¾† covariance åªè·Ÿ $t-s$ æœ‰é—œ, ä½†æˆ‘å€‘è¨ˆç®—ä¸€ä¸‹ $\\gamma(0)=K(t,t)$:&emsp;$$t-s=0\\Rightarrow K(t,t)=\\sum_{k=0}^\\infty b^{2k}\\cdot \\sigma^2 \\\\ \\therefore K(t,t)&lt;\\infty\\Leftrightarrow |b|&lt;1$$&emsp;åªæœ‰åœ¨ $|b|&lt;1$ çš„æƒ…æ³ variance æ‰æ”¶æ–‚, å› æ­¤ weakly stationary æ‰æˆç«‹&emsp;è€ƒæ…® $AR(p)$, èª²ç¨‹èªª $Y_t$ ä¸€æ¨£å¯ä»¥å¯«å‡º $\\xi_t$ çš„å’Œ, æ‰¾å‡ºæ‰€æœ‰æ ¹ä¸¦åœ¨ norm&lt;1 æ‰æ”¶æ–‚ é€™å°±æ˜¯ IIR çš„ poles è¦åœ¨å–®ä½åœ“å…§ &emsp;ç¸½ä¹‹, autoregressive model æœ‰æ¢ä»¶åœ°æˆç‚º weakly stationary Week 5.3-4: Spectral density of a wide-sense stationary process[Bochnerâ€“Khinchin Theorem]:&emsp;$\\Phi:\\mathbb{R}\\rightarrow\\mathbb{C}$, and $\\Phi(u)$ is a characteristic function, i.e.&emsp;$\\exists\\xi$ random variable such that $\\Phi(u)=\\mathbb{E}[e^{iu\\xi}]$&emsp;$\\Longleftrightarrow$&emsp;1. $\\Phi$ is continuous&emsp;2. $\\Phi$ is positive semi-definite&emsp;&emsp;$$\\forall(z_1,...,z_n)\\in\\mathbb{C}^n,\\forall(u_1,...,u_n)\\in\\mathbb{R}^n \\\\ \\sum_{j,k=1}^n z_j\\overline{z_k}\\Phi(u_j-u_k)\\geq0$$&emsp;3. $\\Phi(0)=1$ [Bochnerâ€“Khinchin Theorem Alternative 1]:&emsp;å¦‚æœåªæ»¿è¶³ 1. and 2. å‰‡å¯ä»¥å¾—åˆ° $\\exists\\mu$ is some measure such that&emsp;$\\Phi(u)=\\int e^{iux}\\mu(dx)$&emsp;$\\mu$ å¯ä»¥ä¸å¿…æ˜¯ probability measure (ä½†æˆ‘å€‘çŸ¥é“ä¸€å®šæœƒæœ‰å€‹ measure æ»¿è¶³ä¸Šå¼) [Bochnerâ€“Khinchin Theorem Alternative 2]:&emsp;å¦‚æœæ»¿è¶³ 1. and 2. and å¦‚ä¸‹æ¢ä»¶&emsp;$\\int|\\Phi(u)|du&lt;\\infty$&emsp;å‰‡ $\\Phi:\\mathbb{R}\\rightarrow\\mathbb{C}$, and $\\Phi(u)$ is a characteristic function&emsp;i.e. æŸå€‹ r.v. $\\xi$ çš„ p.d.f. ç‚º $s(x)$ çš„ Fourier transform&emsp;ç›¸æ¯” alternative 1, æ­¤æ™‚ measure $\\mu$ æœ‰ density $s(x)$&emsp;$\\Phi(u)=\\int e^{iux}s(x)dx$ ğŸ’¡ æ³¨æ„åˆ°èª²ç¨‹çš„ Fourier transform è·Ÿæˆ‘å€‘ä¸€èˆ¬åœ¨è¨Šè™Ÿè™•ç†çš„æœ‰é»ä¸åŒ, èª²ç¨‹çš„å®šç¾©ç‚º:$\\mathcal{F}[g](u)=\\int e^{iux}g(x)dx$ä¸”èª²ç¨‹çš„ spectral density åœ¨è¨Šè™Ÿè™•ç†æˆ‘å€‘ç¨± â€œpowerâ€ spectral density [Spectral Density of Weakly Stationary Def]:&emsp;Let $X_t$ is weakly stationary ä¸” $\\gamma:K(t,s)=\\gamma(t-s)$&emsp;If $\\gamma$ is continuous (æœ¬èº«å·²ç¶“æ˜¯åŠæ­£å®š) and $\\int|\\gamma(u)|du&lt;\\infty$&emsp;ä½¿ç”¨ Bochnerâ€“Khinchin Theorem Alternative 2 å‰‡ $\\exists g(x)$ a density such that&emsp;$$\\color{orange}{ \\gamma(u)=\\int_\\mathbb{R} e^{iux}g(x)dx }\\\\ = \\mathcal{F}[g](u) \\text{ (i.e. Fourier transform of }g)$$&emsp;ä¹Ÿç­‰æ–¼&emsp;$$\\color{orange}{ g(x)=\\frac{1}{2\\pi}\\int_\\mathbb{R} e^{-iux}\\gamma(u)du }\\\\ = \\frac{1}{2\\pi}\\mathcal{F}[\\gamma](-x)$$&emsp;æ­¤æ™‚ $g(x)$ ç¨±ç‚º $X_t$ çš„ spectral density&emsp;åœ¨ discrete case ç‚º&emsp;$$\\color{orange}{ g(x)=\\frac{1}{2\\pi}\\sum_{h=-\\infty}^\\infty e^{-ihx}\\gamma(h) }$$ åœ¨ WSS æ¢ä»¶ä¸‹, auto-covariance $\\gamma$ å°±ç­‰åŒæ–¼ç‰¹å¾µæ–¹ç¨‹å¼äº†(æ³¨æ„åˆ°ç‰¹å¾µæ–¹ç¨‹å¼ç‚º pdf çš„ Fourier transform) [Examples]:&emsp;White noise, $WN(0,\\sigma^2)$, $\\gamma(u)=\\sigma^2\\cdot\\mathbf{1}\\{u=0\\}$, æ‰€ä»¥&emsp;$g(x)=\\frac{\\sigma^2}{2\\pi}$&emsp;Moving average, $MA(1)$&emsp;$$\\gamma(u)=\\left\\{ \\begin{array}{rl} 0, &amp; |u|&gt;1 \\\\ a\\sigma^2, &amp; |u|=1 \\\\ (1+a^2)\\sigma^2, &amp; u=0 \\end{array} \\right. \\\\ g(x)=\\frac{\\sigma^2}{2\\pi}\\left(1+a^2+a\\cdot2\\cos(x)\\right)$$ [Sufficient and Necessary Condition for a Function is a Spectral Density]:&emsp;A real-valued function $g(x)$ defined on $(-\\pi,\\pi]$&emsp;is a spectral density of a stochastic process $X_t$&emsp;if and only if&emsp;1. $g(x)\\geq0$&emsp;2. $g(x)$ is even&emsp;3. $\\int_{-\\pi}^\\pi g(x)dx&lt;\\infty$ ç”¨ â€œpowerâ€ spectral density ä¾†è¨˜æ†¶, å› ç‚ºæ˜¯ power æ‰€ä»¥ 1. 2. åˆç†ä¸€å®šè¦ Week 5.5: Stochastic integration of the simplest type[Stochastic Integrals Def]:&emsp;Given a Stochastic process $X_t$&emsp;Given partition $\\Delta:a=t_0\\leq t_1\\leq ...\\leq t_n=b$, $|\\Delta|=\\max\\{t_k-t_{k-1}\\},k=1,...,n$&emsp;If the following expectation converges to some value $A$ in mean square sense:&emsp;$$\\mathbb{E}\\left[ \\left( A - \\sum_{k=1}^n X_{t_{k-1}}(t_k-t_{k-1}) \\right)^2 \\right] \\xrightarrow[|\\Delta|\\longrightarrow0]{} 0$$&emsp;Then we denote(define) the converged value $A$ as:&emsp;$\\int_a^b X_t dt$ ğŸ’¡ åƒè€ƒèª²ç¨‹ Week 7.1: Different types of stochastic integrals. Integrals of the type $âˆ« X_t dt$ [Existence of Stochastic Integral]:&emsp;$X_t:\\mathbb{E}[X_t^2]&lt;\\infty$, if&emsp;1. $m(t)$ continuous&emsp;2. $K(t,s)$ continuous&emsp;Then the stochastic integral exists&emsp;$\\int_a^b X_tdt&lt;\\infty$ è¦è­‰æ˜ $K(t,s)$ continuous, å…¶å¯¦åªéœ€è¦ check diagonal é …å°±å¯ä»¥ ğŸ’¡ åªå° covariance function $K(t,s)$ æœ‰é€™æ¨£çš„ç‰¹æ€§, æˆ‘å€‘å† Week 6.4 æœƒè­‰æ˜ [Lemma]:&emsp;1. Stochastic process $X_t$. If $K(t,s)$ is continuous at $(t_0, t_0)$&emsp;&emsp;then $X_t$ is continuous at $t_0$ (in mean square sense), that is&emsp;&emsp;$\\mathbb{E}[(X_t-X_{t_0})^2]\\rightarrow0,\\text{ as }t\\rightarrow t_0$&emsp;2. On the other side, if $X_t$ is continuous at $t_0$ and $s_0$&emsp;&emsp;then $K(t,s)$ is continuous at $(t_0,s_0)$, that is $K(t_0,s_0)$ is continuous [Covariance Function is Continuous when Continuous on Diagonal]:&emsp;Covariance function $K(t,s)$ is continuous $\\forall(t_0,s_0)$ $\\Longleftrightarrow$&emsp;$K(t,s)$ is continuous $\\forall(t_0,t_0)$[Proof]:&emsp;$(\\Longrightarrow)$: of course&emsp;$(\\Longleftarrow)$:&emsp;$K(t,s)$ is continuous $\\forall(t_0,t_0)$, ç”± Lemma 1 çŸ¥é“ $X_t$ is countinuous $\\forall t_0$&emsp;å› æ­¤ $X_t$ is continuous $\\forall t_0,s_0$, ç”± Lemma 2 çŸ¥é“ $K(t_0,s_0)$ is countinuous $\\forall t_0,s_0$ [Properties of Stochastic Integral]: assume integral exists&emsp;We assume integral is taken in an bounded interval $[a,b]$&emsp;1. Expectation of stochastic integral:&emsp;&emsp;$\\mathbb{E}\\left[ \\int X_tdt \\right] = \\int \\mathbb{E}[X_t]dt$&emsp;&emsp;èª²ç¨‹è€å¸«èªª apply Frobenius theorem å¯å¾—æ­¤çµæœ. çœ‹ä¸æ‡‚ Frobenius theorem&emsp;2. Expectation of squared stochastic integral:&emsp;&emsp;$$\\mathbb{E}\\left[ \\left(\\int X_t dt\\right)^2 \\right] = \\mathbb{E}\\left[ \\int\\int X_t X_s dtds \\right] \\\\ = \\int\\int\\mathbb{E}[X_tX_s]dtds$$&emsp;3. Variance of stochastic integral:&emsp;&emsp;$$Var\\left[ \\int X_t dt \\right] = \\mathbb{E}\\left[ \\left(\\int X_t dt\\right)^2 \\right] - \\left(\\mathbb{E}\\left[ \\int X_tdt \\right]\\right)^2 \\\\ = \\int_a^b\\int_a^b K(t,s) dtds \\\\ \\because\\text{symmetric}= 2\\int_a^b \\int_a^s K(t,s) dtds$$ èª²ç¨‹ pop up quiz Week 5.6-8: Moving-average filtersFilter å°±æ˜¯æŠŠæŸå€‹ stochastic process $X_t$ transform åˆ°å¦ä¸€å€‹ $Y_t$Filter æœ‰ linearity and time-invariant å…©å€‹é‡è¦ propertiesèª²ç¨‹èˆ‰å…©å€‹ filter çš„ä¾‹å­ (ç¬¬ä¸€å€‹ç‚º FIR, ç¬¬äºŒå€‹ç‚º simplest stochastic integral)$$\\begin{align} Y_t=a_0X_t+a_1X_{t-1}+...+a_nX_{t-n} \\\\ Y_t=\\int_\\mathbb{R} e^{-\\beta(t-s)}X_sds \\end{align}$$ éƒ½å…·æœ‰ä¸Šè¿° properties, ä¹Ÿå¾ˆå®¹æ˜“è­‰ç„¶å¾Œä¸Šåœ–å³ä¸‹è§’å¯«å‡º filtering çš„ continuous and discrete çš„æ•¸å­¸å¼, é¡¯ç„¶é€™æ˜¯ convolution$$Y_t=\\int_\\mathbb{R}\\rho(s)X_{t-s}ds \\\\ Y_t=\\sum_{h=-\\infty}^\\infty \\rho(h)X_{t-h}$$ [Spectral Density and Weakly Stationary by Linear Filter]:&emsp;$X_t$ is weakly stationary with $\\mathbb{E}X_t=0$ and some spectral density $g(x)$.&emsp;$Y_t$ is linear filtered by $\\rho(x)$ from $X_t$:&emsp;$Y_t=\\int_\\mathbb{R} \\rho(s)X_{t-s}ds$&emsp;Then,&emsp;1. $Y_t$ is weakly stationary&emsp;2. Spectral density of $Y_t$:&emsp;&emsp;$$\\color{orange}{ g_Y(u)=g_X(u)\\cdot|\\mathcal{F}[\\rho](u)|^2 }$$&emsp;here the Fourier transform of $\\rho$ is:&emsp;$\\mathcal{F}[\\rho](u)=\\int_\\mathbb{R} e^{-iux}\\rho(x)dx$[Proof 1. weakly stationary]:&emsp;è§€å¯Ÿ expectation and covariance functions æ˜¯å¦ç¬¦åˆ weakly stationary&emsp;$\\mathbb{E}[Y_t]=\\int_\\mathbb{R}\\rho(s)\\mathbb{E}[X_{t-s}]ds=0$&emsp;å› ç‚º $\\mathbb{E}[Y_t]=0$, æ‰€ä»¥ $K(t,s)=Cov(Y_t,Y_s)=\\mathbb{E}[Y_tY_s]$, then&emsp;$$K_Y(t_1,t_2)=\\mathbb{E}\\left[ \\int_\\mathbb{R}\\rho(s_1)X_{t_1-s_1}ds_1 \\cdot \\int_\\mathbb{R}\\rho(s_2)X_{t_2-s_2}ds_2 \\right] \\\\ =\\int_\\mathbb{R}\\int_\\mathbb{R} \\rho(s_1)\\rho(s_2)\\mathbb{E}[X_{t_1-s_1}X_{t_2-s_2}] ds_1ds_2 \\\\ =\\int_\\mathbb{R}\\int_\\mathbb{R} \\rho(s_1)\\rho(s_2)\\gamma( \\color{orange}{t_2-t_1} -(s_2-s_1)) ds_1ds_2 \\\\$$&emsp;æ‰€ä»¥åª depends on $t_2-t_1$, æ‰€ä»¥ auto-covariance of $Y_t$ å­˜åœ¨å¦‚ä¸‹:&emsp;$$\\gamma_Y(x)=\\int_\\mathbb{R}\\int_\\mathbb{R} \\rho(s_1)\\rho(s_2)\\gamma( x -(s_2-s_1)) ds_1ds_2$$&emsp;Q.E.D.[Proof 2. Spectral density of $Y_t$]:&emsp;ç”± proof 1 çŸ¥é“ $\\gamma_Y(x)$ æ”¹å¯«å¦‚ä¸‹:&emsp;$$\\gamma_Y(x)=\\int_\\mathbb{R}\\rho(s_1) \\color{orange}{\\int_\\mathbb{R}\\rho(s_2)\\gamma((x+s_1)-s_2)ds_2} ds_1 \\\\ =\\int_\\mathbb{R}\\rho(s_1) \\color{orange}{[\\gamma_X*\\rho](x+s_1)} ds_1 \\ldots(\\star)\\\\$$&emsp;å®šç¾© $\\rho^o(x)=\\rho(-x)$, åœ¨æŠŠ $s_1$ æ”¹å¯«æˆ $-s_1$, å‰‡ $(\\star)$ è®Šæˆ:&emsp;$$\\gamma_Y(x)=(\\star)=\\int_\\mathbb{R}\\rho^o(s_1) [\\gamma_X*\\rho](x-s_1) ds_1 \\\\ =[\\gamma_X*\\rho*\\rho^o](x)\\ldots(\\square)$$&emsp;æ³¨æ„åˆ° spectral density è·Ÿ auto-covariance çš„é—œä¿‚ç‚º Fourier transform çš„é—œä¿‚:&emsp;$g_Y(u)=\\frac{1}{2\\pi}\\mathcal{F}[\\gamma_Y](-u)$&emsp;æ‰€ä»¥å° $(\\square)$ å…©é‚Šå– Fourier transform æˆ‘å€‘å¾—åˆ°:&emsp;$$g_Y(u)= \\frac{1}{2\\pi}\\mathcal{F}[\\gamma_Y](-u)=\\frac{1}{2\\pi}\\mathcal{F}[\\gamma_X](-u)\\cdot\\mathcal{F}[\\rho](-u)\\cdot\\mathcal{F}[\\rho^o](-u) \\\\ =g_X(u)\\cdot|\\mathcal{F}[\\rho](u)|^2$$&emsp;Q.E.D. Let $X_t$ is weakly stationary, and itâ€™s spectral density is $g_X(u)$. æˆ‘å€‘æƒ³ç”¨ moving average $MA(2)$ ä¾†é æ¸¬ç•¶ä¸‹é€™å€‹æ™‚é–“é»çš„ $X_t$:$Y_n=a_1X_{n-1}+a_2X_{n-2}$å¦‚ä½•æ±ºå®š $a_1,a_2$ ä¾†ä½¿å¾—é æ¸¬æœ€æº– (in least square error sense):$\\mathbb{E}[(X_n-Y_n)^2]\\rightarrow \\min$æˆ‘å€‘çŸ¥é“ $Z_n=X_n-Y_n=X_n-a_1X_{n-1}-a_2X_{n-2}$ ä¹Ÿæ˜¯ weakly stationary, å› ç‚ºéä¸€å€‹ linear filter $\\rho(x)$:$\\rho(x)=\\mathbf{1}\\{x=0\\}-a_1\\mathbf{1}\\{x=1\\}-a_2\\mathbf{1}\\{x=2\\}$å…¶ Fourier transform ç‚º: $\\mathcal{F}[\\rho](u)=1-a_1e^{iu}-a_2e^{2iu}$å‰‡ spectral density of $Z$ ç‚º: $g_Z(u)=g_X(u)\\cdot|\\mathcal{F}[\\rho](u)|^2$æ‰€ä»¥å•é¡Œç­‰åŒæ–¼è¨ˆç®—$\\arg\\min_{a_1,a_2} VarZ_n$è¨ˆç®— $Var Z_n$ å¦‚ä¸‹$$Var(Z_n)=K_Z(n,n)=\\gamma_Z(0)\\\\ =\\int e^{i\\cdot u\\cdot 0}g_Z(u)du \\\\ =\\int g_X(u)\\cdot|1-a_1e^{iu}-a_2e^{2iu}|^2 du \\\\ =\\int g_X(u)\\cdot(1-a_1e^{iu}-a_2e^{2iu})\\cdot(1-a_1e^{-iu}-a_2e^{-2iu}) du \\\\ =...=\\sum_{i,j=1}^2 B_{ij}a_ia_j + \\sum_{i=1}^2 C_ia_i + D$$æ‰€ä»¥æœ€å°åŒ–ä¸€å€‹äºŒæ¬¡å¼å³å¯æ±‚å¾—æœ€ä½³è§£ $a_1,a_2$ [Pop up Quiz]: æœ‰é»é›£ç®— XD å®¹æ˜“ç®—éŒ¯","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Spectral Density","slug":"Spectral-Density","permalink":"https://bobondemon.github.io/tags/Spectral-Density/"},{"name":"Wide-Sense Stationary","slug":"Wide-Sense-Stationary","permalink":"https://bobondemon.github.io/tags/Wide-Sense-Stationary/"},{"name":"Stochastic Integration","slug":"Stochastic-Integration","permalink":"https://bobondemon.github.io/tags/Stochastic-Integration/"}]},{"title":"Stochastic Processes Week 4 Gaussian Processes","date":"2021-12-12T09:55:59.000Z","path":"2021/12/12/Stochastic-Processes-Week-4-Gaussian-Processes/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes (æœ¬æ–‡) Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes Week 4.1: Random vector. Definition and main propertiesNormal distribution of one r.v.$$X\\sim\\mathcal{N}(\\mu,\\sigma^2), \\text{ for }\\sigma&gt;0,\\mu\\in\\mathbb{R} \\\\ p(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$The characteristic function of normal distribution is:$\\Phi(u)=e^{iu\\mu-\\frac{1}{2}u^2\\sigma^2}$æˆ‘å€‘å¯ä»¥èªªä¸€å€‹ random variable $X$ almost surely constant $=\\mu$ è¡¨ç¤ºå¦‚ä¸‹:$\\mathcal{P}\\{X=\\mu\\}=1$å¦‚æœæ­¤æ™‚ä¹Ÿå®šç¾© $\\sigma=0$, æˆ‘å€‘å¯å°‡å…¶ä¹Ÿè¦–ç‚º normal distribution $\\mathcal{N}(\\mu,0)$ ç­‰æ–¼æŠŠ constant ä¹ŸåŠ å…¥ normal distribution çš„å®šç¾© [Gaussian Vector Def]:&emsp;A random vector $\\vec{X}=(X_1,...,X_n)$ is Gaussian if and only if&emsp;$$(\\star):\\sum_{k=1}^n \\lambda_k X_k \\sim \\mathcal{N}\\\\ \\forall(\\lambda_1,...,\\lambda_n)\\in\\mathbb{R}$$ Week 4.2: Gaussian vector. Definition and main propertiesDefinition of multivariate characteristic function, ref from wikiæˆ‘å€‘èªªæ˜ä¸€ä¸‹ç‚ºä½• $C$ (covariance matrix) is positive semi-definite, æª¢æŸ¥ $\\vec{u}^TC\\vec{u},\\forall \\vec{u}$$$\\vec{u}^TC\\vec{u} = \\sum_{k,j=1}^n u_k c_{kj} u_j = \\sum_{k,j=1}^n u_k Cov(X_j,X_k) u_j \\\\ = Cov\\left(\\sum_{j=1}^n u_jX_j,\\sum_{k=1}^n u_kX_k\\right) = Var\\left(\\sum_{j=1}^n u_jX_j\\right) \\geq 0$$ [Gaussian Vector Thm]:&emsp;$\\vec{X}$ is Gaussian vector if and only if any of the following conditions holds:&emsp;1. Characteristic function of Gaussian vector:&emsp;$$(\\square): \\Phi_{\\vec{X}}(\\vec{u})=\\mathbb{E}\\left[ e^{i\\cdot \\vec{u}^T\\vec{X}} \\right] = \\exp\\left\\{ i\\cdot \\vec{u}^T\\vec{\\mu} - \\frac{1}{2}\\vec{u}^TC\\vec{u} \\right\\} \\\\ \\text{where }\\vec{\\mu}\\in\\mathbb{R}^n; C\\in\\mathbb{R}^{n\\times n}\\text{-positive semi-definite}$$&emsp;&emsp;åŒæ™‚ $\\vec{\\mu}$ and $C$ ç‚º&emsp;$$\\vec{\\mu}=(\\mathbb{E}X_1,...,\\mathbb{E}X_n) \\\\ C=\\left(c_{jk}\\right)_{j,k=1}^n; c_{jk}=Cov(X_j,X_k)$$&emsp;2. Can be represented by Standard Gaussian vector $\\vec{X^o}$&emsp;$$(\\blacksquare):\\vec{X}=A\\cdot \\vec{X^o}+\\vec{\\mu} \\\\ \\text{where }A\\in\\mathbb{R}^{n\\times n},\\vec{X^o}\\text{ is standard Gaussin vector}$$&emsp;&emsp;åŒæ™‚ $A=C^{1/2}$, i.e. $AA=C$ è¦å¯«å‡º $A$ åªè¦å°‡ $C$ å°è§’åŒ–, ç„¶å¾Œå°ä¸­é–“çš„ diagonal matrix (eigenvalues çµ„æˆçš„) å– sqrt å³å¯ [Proof]:&emsp;æˆ‘å€‘å…ˆè­‰æ˜ Definition $(\\star)\\Rightarrow 1.(\\square)$&emsp;Let $\\xi=\\vec{u}^T\\vec{X}=\\sum_{k=1}^n u_kX_k$ æ ¹æ“šå®šç¾© $\\xi\\sim\\mathcal{N}$&emsp;æˆ‘å€‘å°‡ $\\vec{X}$ çš„ç‰¹å¾µæ–¹ç¨‹å¼å¯«å‡ºä¾†:&emsp;$\\Phi_{\\vec{X}}(\\vec{u})=\\mathbb{E} [e^{i\\vec{u}^T\\vec{X}}]=\\mathbb{E}[e^{i\\xi\\cdot1}]=\\Phi_\\xi(1)$&emsp;å› ç‚º $\\xi\\sim\\mathcal{N}$, æ‰€ä»¥ç‰¹å¾µæ–¹ç¨‹å¼æ˜¯çŸ¥é“çš„:&emsp;$\\Phi_\\xi(1)=\\exp\\left(i\\mu_\\xi-\\frac{1}{2}\\sigma_\\xi^2\\right)$&emsp;æ‰€ä»¥æˆ‘å€‘åªéœ€è¨ˆç®—å‡º $\\mu_\\xi,\\sigma_\\xi^2$ åœ¨ä»£å›å»å³å¯&emsp;$\\mu_\\xi=\\mathbb{E}\\left[\\sum_{k=1}^n u_kX_k\\right] = \\sum_{k=1}^n u_k \\mu_k = \\vec{u}^T \\vec{\\mu}$&emsp;$$\\sigma_\\xi^2 = cov\\left( \\sum_{k=1}^n u_k X_k, \\sum_{j=1}^n u_j X_j \\right) \\\\ = \\sum_{k,j=1}^n u_k\\cdot cov(X_k,X_j) \\cdot u_j = \\vec{u}^TC\\vec{u}$$&emsp;ä»£å›å»å³å¯ç™¼ç¾ $=(\\square)$&emsp;Q.E.D.&emsp;æˆ‘å€‘å†è­‰æ˜ $1.(\\square)\\Rightarrow$ Definition $(\\star)$&emsp;å› ç‚ºç‰¹å¾µå‡½æ•¸è·Ÿ P.D.F. æ˜¯ä¸€å°ä¸€å°æ‡‰çš„, æ‰€ä»¥çŸ¥é“ $\\vec{X}$ çš„ç‰¹å¾µå‡½æ•¸ç‚º $(\\square)$&emsp;å¾ˆé¡¯ç„¶é€™æ˜¯ Gaussian çš„ç‰¹å¾µå‡½æ•¸, æ‰€ä»¥ $\\vec{X}$ æ˜¯ Gaussian vector&emsp;è­‰æ˜ $2. (\\blacksquare) \\Rightarrow 1. (\\square)$&emsp;$\\vec{X}^o$ is standard Gaussian vector, æˆ‘å€‘å°‡å®ƒçš„ç‰¹å¾µå‡½æ•¸å¯«ä¸‹ä¾†:&emsp;$\\Phi_{\\vec{X}^o}(\\vec{u}) = \\exp\\{-\\frac{1}{2}\\vec{u}^T\\vec{u}\\}$&emsp;è¨ˆç®— $\\vec{X}$ çš„ç‰¹å¾µå‡½æ•¸:&emsp;$$\\text{from }(\\blacksquare) \\text{ we know that } \\Phi_{\\vec{X}}(\\vec{u})=\\mathbb{E}\\left[ e^{i\\vec{u}^T(A\\vec{X}^o+\\vec{\\mu})} \\right] \\\\ = e^{i\\vec{u}^T\\vec{\\mu}} \\cdot \\Phi_{\\vec{X}^o}(A^T\\vec{u}) \\\\ = e^{i\\vec{u}^T\\vec{\\mu}} \\cdot e^{-\\frac{1}{2}\\vec{u}^TAA^T\\vec{u}} \\\\ = e^{i\\vec{u}^T\\vec{\\mu}} \\cdot e^{-\\frac{1}{2}\\vec{u}^TC\\vec{u}} = (\\square)$$&emsp;Q.E.D.&emsp;è­‰æ˜ $1. (\\square) \\Rightarrow 2. (\\blacksquare)$&emsp;æˆ‘å€‘å®šç¾© $A:=C^{1/2}$, å‰‡ä»£å…¥ $(\\square)$ å†æ•´ç†ä¸€ä¸‹å¯ä»¥å¾—åˆ°é€™æ˜¯ä¸€å€‹ $\\vec{X}=A\\cdot \\vec{X^o}+\\vec{\\mu}$ çš„ç‰¹å¾µå‡½æ•¸&emsp;Q.E.D. Week 4.3: Connection between independence of normal random variables and absence of correlation[Thm]:&emsp;Let $X_1,X_2\\sim\\mathcal{N}(0,1)$ and $corr(X_1,X_2)=0$, å‰‡&emsp;$X_1 \\perp X_2 \\Longleftrightarrow (X_1,X_2) \\text{ is Gaussian vector}$[Proof]:&emsp;è­‰æ˜ $(\\Rightarrow)$&emsp;$\\lambda_1 X_1+\\lambda_2 X_2 \\sim \\mathcal{N} \\Longrightarrow (X_1,X_2) \\text{ is Gaussian vector}$&emsp;å¯ä»¥å¾ç‰¹å¾µæ–¹ç¨‹å¼å°æ–¼ç¨ç«‹ r.v.s çš„ç·šæ€§çµ„åˆ, ä»¥åŠ Gaussian çš„ç‰¹å¾µæ–¹ç¨‹å¼çœ‹å‡ºä¾†&emsp;è­‰æ˜ $(\\Leftarrow)$&emsp;å› ç‚º uncorrelated&emsp;$$\\therefore C=\\left[ \\begin{array}{c} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{array} \\right] \\Rightarrow A=\\left[ \\begin{array}{c} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{array} \\right]=C^{1/2}$$&emsp;å®šç† $2. (\\blacksquare)$ å‘Šè¨´æˆ‘å€‘ $(X_1,X_2)$ å¯ä»¥æ”¹å¯«å¦‚ä¸‹:&emsp;$$\\left[ \\begin{array}{c} X_1 \\\\ X_2 \\end{array} \\right] =^d \\left[ \\begin{array}{c} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{array} \\right] \\left[ \\begin{array}{c} \\xi_1 \\\\ \\xi_2 \\end{array} \\right] + \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right]$$&emsp;$=^d$ è¡¨ç¤ºç›¸åŒåˆ†å¸ƒ, $\\xi_1,\\xi_2\\sim\\mathcal{N}(0,1)$&emsp;ä¹˜é–‹ä¾†å°±ç™¼ç¾ $X_1 =^d \\xi_1$ and $X_2 =^d \\xi_2$, å› æ­¤ $X_1 \\perp X_2$&emsp;Q.E.D. [Exercise1]:&emsp;Given $X_1\\sim\\mathcal{N}(0,1)$, $\\mathcal{P}\\{\\xi=1\\}=0.5; \\mathcal{P}\\{\\xi=-1\\}=0.5$,&emsp;and $\\xi\\perp X_1$&emsp;è€ƒæ…® $X_2 = |X_1|\\cdot \\xi$, è­‰æ˜ $X_2 \\sim \\mathcal{N}(0,1)$[Proof]:&emsp;$$\\mathcal{P}\\{X_2\\leq x\\},\\forall x&gt;0\\\\ = \\mathcal{P}\\{|X_1|\\leq x | \\xi=1\\}\\mathcal{P}\\{\\xi=1\\} + \\mathcal{P}\\{|X_1|\\geq -x | \\xi=-1\\}\\mathcal{P}\\{\\xi=-1\\} \\\\ \\text{Note }(X_1\\perp\\xi\\text){ }= \\mathcal{P}\\{|X_1|\\leq x\\}/2 + \\mathcal{P}\\{|X_1|\\geq -x\\}/2 \\\\ \\text{Note }(\\mathcal{P}\\{|X_1|\\geq-x\\}=1) = \\frac{1}{2}\\left( 1+\\mathcal{P}\\{|X_1|\\leq x\\} \\right)\\\\ \\text{by std normal} = \\mathcal{P}\\{X_1\\leq x\\}$$&emsp;æ³¨æ„åˆ° Standard normal $\\mathcal{P}\\{X_1\\geq x\\}=\\mathcal{P}\\{X_1\\leq -x\\}$, æ‰€ä»¥&emsp;$$\\frac{1}{2}\\left( 1+\\mathcal{P}\\{|X_1|\\leq x\\}\\right) = \\frac{1}{2}\\left( 1 +\\mathcal{P}\\{X_1\\leq x\\}-\\mathcal{P}\\{X_1\\leq -x\\}\\right) \\\\ = \\frac{1}{2}\\left( {\\color{orange}1} +\\mathcal{P}\\{X_1\\leq x\\}-\\mathcal{P}\\{X_1\\geq x\\}\\right) \\\\ = \\frac{1}{2}\\left( \\color{orange}{\\mathcal{P}\\{X_1\\leq x\\}+\\mathcal{P}\\{X_1\\geq x\\}} +\\mathcal{P}\\{X_1\\leq x\\}-\\mathcal{P}\\{X_1\\geq x\\}\\right) \\\\ = \\mathcal{P}\\{X_1\\leq x\\}$$&emsp;Q.E.D. [Exercise2]:&emsp;Given $X_1\\sim\\mathcal{N}(0,1)$, $\\mathcal{P}\\{\\xi=1\\}=0.5; \\mathcal{P}\\{\\xi=-1\\}=0.5$, and $\\xi\\perp X_1$&emsp;è€ƒæ…® $X_2 = |X_1|\\cdot \\xi$, è­‰æ˜ $cov(X_1,X_2)=0$[Proof]:&emsp;$$cov(X_1,X_2)=\\mathbb{E}[X_1X_2]-\\mathbb{E}[X_1]\\mathbb{E}[X_2] \\\\ =\\mathbb{E}[X_1\\cdot|X_1|\\cdot\\xi]-0\\cdot \\mathbb{E}[X_2] \\\\ =\\mathbb{E}[X_1\\cdot|X_1|] \\mathbb{E}[\\xi] = \\mathbb{E}[X_1\\cdot|X_1|]\\cdot 0=0$$&emsp;Q.E.D. [Exercise3]:&emsp;Given $X_1\\sim\\mathcal{N}(0,1)$, $\\mathcal{P}\\{\\xi=1\\}=0.5; \\mathcal{P}\\{\\xi=-1\\}=0.5$, and $\\xi\\perp X_1$&emsp;è€ƒæ…® $X_2 = |X_1|\\cdot \\xi$, è­‰æ˜ $X_1$ and $X_2$ are dependent[Proof]:&emsp;ç”± Exercise 1 &amp; 2 æˆ‘å€‘çŸ¥é“ $X_1,X_2\\sim\\mathcal{N}(0,1)$ and $corr(X_1,X_2)=0$&emsp;å‰‡å¦‚æœ $X_1\\perp X_2$, ç­‰åƒ¹æ–¼èªªæ˜ $(X_1,X_2)$ æ˜¯ Gaussian vector.&emsp;åˆ©ç”¨åè­‰æ³•, å¦‚æœæ˜¯ Gaussian vector å‰‡æ»¿è¶³ linear combination ä»æ˜¯ normal distribution:&emsp;$Z=X_1-X_2=X_1-|X_1|\\xi \\sim \\mathcal{N}$&emsp;è€ƒæ…®&emsp;$$(a)\\ldots \\mathcal{P}\\{Z&gt;0\\} \\geq \\mathcal{P}\\{X_1&gt;0,\\xi=-1\\} \\\\ = \\mathcal{P}\\{X_1&gt;0\\}\\mathcal{P}\\{\\xi=-1\\}=1/4 \\\\ (b)\\ldots \\mathcal{P}\\{Z=0\\} \\geq \\mathcal{P}\\{X_1&gt;0,\\xi=1\\} \\\\ =\\mathcal{P}\\{X_1&gt;0\\}\\mathcal{P}\\{\\xi=1\\}=1/4$$&emsp;æ¢ä»¶ $(a),(b)$ ä¸å¯èƒ½åŒæ™‚æ»¿è¶³, å› ç‚ºå¦‚æœ $\\sigma^2&gt;0$ å‰‡ $\\mathcal{P}\\{Z=0\\}=0$ çŸ›ç›¾ $(b)$&emsp;å¦å‰‡å°±æ˜¯ $\\sigma^2=0$, i.e. constant, æ˜é¡¯çŸ›ç›¾&emsp;Q.E.D. Exercise 1, 2, &amp; 3 å‘Šè¨´æˆ‘å€‘, å¯ä»¥æœ‰å…©å€‹ normal r.v.s æ˜¯ uncorrelated ä½†ä¸æ˜¯ independet Week 4.4-5: Definition of a Gaussian process. Covariance function[Gaussian Processes Def]:&emsp;A Gaussian process $X_t$ is a stochastic process if&emsp;$\\forall t_1, ..., t_n: (X_{t_1},...,X_{t_n})$ is a Gaussian vector Denotes two terms $m(t)$ and $K(t,s)$:$m(t)=\\mathbb{E}X_t$, mathmetical expectation, $\\mathbb{R}_+\\rightarrow\\mathbb{R}$$K(t,s)=Cov(X_t,X_s)$, covariance function, $\\mathbb{R}_+\\times\\mathbb{R}_+\\rightarrow \\mathbb{R}$ $K(t,t)=Var[X_t]$$K(t,s)=K(s,t)$ [Covariance function $K(t,s)$ is positive semi-definite]:&emsp;For a Gaussian process $X_t$, $K(t,s)$ is positive semi-definite[Proof]:&emsp;è€ƒæ…® $\\forall(t_1,...,t_n)\\in\\mathbb{R}_+^n$ and $\\forall(u_1,â€¦,u_n)\\in\\mathbb{R}^n$, å‰‡&emsp;$$\\sum_{k,j=1}^n u_k u_j K(t_k,t_j) = Cov\\left(\\sum_{k=1}^n u_k X_{t_k}, \\sum_{j=1}^n u_j X_{t_j}\\right) \\\\ = Var\\left(\\sum_{k=1}^n u_k X_{t_k}\\right) \\geq 0$$&emsp;Q.E.D. [Gaussian Processes Thm]:&emsp;è‹¥ $m:\\mathbb{R}_+\\rightarrow\\mathbb{R}$ å’Œ $K:\\mathbb{R}_+\\times\\mathbb{R}_+\\rightarrow\\mathbb{R}$ ç‚ºä»»æ„ functions æ»¿è¶³&emsp;$K$ is symmetric positive semi-definite, å‰‡&emsp;$\\exists$ Gaussian process $X_t:$&emsp;$$\\begin{align} \\mathbb{E}X_t=m(t) \\\\ Cov(X_t,X_s)=K(t,s) \\end{align}$$ è¨è«–ä¸€ä¸‹ sufficient statistics&emsp;- Gaussian random variable: $\\mu\\in\\mathbb{R}$, and $\\sigma\\in\\mathbb{R}_+$&emsp;- Gaussian vector: $\\vec{\\mu}\\in\\mathbb{R}^n$, and $C\\in\\mathbb{R}^{n\\times n}$ and is symmetric positive semi-definite&emsp;- Gaussian process: $m:\\mathbb{R}_+\\rightarrow\\mathbb{R}$, and $K:\\mathbb{R}_+\\times\\mathbb{R}_+\\rightarrow\\mathbb{R}$ and is symmetric positive semi-definite [Example1]: $K(t,s)=|t-s|$, è­‰æ˜ä¸æ˜¯ positive semi-definite[Proof]:&emsp;å¦‚æœ $K$ æ˜¯åŠæ­£å®š, å‰‡å­˜åœ¨ Gaussian process $X_t$ such that&emsp;$Cov(X_t,X_s)=|t-s|$&emsp;å‰‡å¯ç™¼ç¾ $Var(X_t)=0$, å› æ­¤ $X_t=f(t)$ æ˜¯ deterministic function, i.e. constat&emsp;å› æ­¤&emsp;$Cov(X_t,X_s)=\\mathbb{E}[X_tX_s]-\\mathbb{E}[X_t]\\mathbb{E}[X_s]=0$&emsp;æ˜é¡¯ä¸æ˜¯åŠæ­£å®š, Q.E.D. [Example2]: $K(t,s)=\\min(t,s)$, è­‰æ˜æ˜¯åŠæ­£å®š[Proof]:&emsp;èƒ½å¦è­‰æ˜&emsp;$(\\star)\\ldots\\sum_{j,k=1}^n u_j u_k \\min(t_j,t_k) \\geq 0$&emsp;æˆ‘å€‘å°å…¥ $f_t(x)$ å¹«å¿™æ¨å°&emsp;$f_t(x)=\\mathbf{1}\\{x\\in[0,t]\\}, \\text{ where }\\mathbf{1}\\{\\cdot\\} \\text{ is indicator function} \\\\$&emsp;å‰‡&emsp;$\\min(t,s)=\\int_0^\\infty f_t(x)f_s(x) dx$&emsp;ä»£å…¥ $(\\star)$ å¾—åˆ°&emsp;$$\\sum_{j,k=1}^n u_j u_k \\int_0^\\infty f_{t_j}(x)f_{t_k}(x)dx \\\\ = \\int_0^\\infty \\left(\\sum_{j=1}^n u_j f_{t_j}(x) \\right) \\left(\\sum_{k=1}^n u_k f_{t_k}(x) \\right) dx \\\\ =\\int_0^\\infty \\left(\\sum_{j=1}^n u_j f_{t_j}(x) \\right)^2 dx \\geq 0$$&emsp;Q.E.D. Week 4.6: Two definitions of a Brownian motionBrownian Motion åˆç¨± Wiener process[Brownian Motion Def1]:&emsp;We say that $B_t$ is Brownian motion if and only if&emsp;$B_t$ is a Gaussin process with $m(t)=0$ and $K(t,s)=\\min(t,s)$ [Brownian Motion Def2]:&emsp;We say that $B_t$ is Brownian motion if and only if&emsp;$(0)$ $B_0=0$ almost surely (a.s.)&emsp;$(1)$ $B_t$ is independent increaments, i.e.&emsp;&emsp;$\\forall t_0&lt;t_1&lt;...&lt;t_n$, we have $B_{t_1}-B_{t_0}, ..., B_{t_n}-B_{t_{n-1}}$ are independent&emsp;$(2)$ $B_t-B_s\\sim\\mathcal{N}(0,t-s)$, $\\forall t&gt;s\\geq0$ [è­‰æ˜ Def1 $\\Rightarrow$ Def2]:&emsp;å…ˆè­‰æ˜ $(0)$, æˆ‘å€‘çŸ¥é“ $\\mathbb{E}B_0 = m(0)=0$, $Var(B_0)=K(B_0, B_0)=0$&emsp;æ‰€ä»¥ $B_0=0$ a.s.&emsp;å†ä¾†è­‰æ˜ $(1)$: $B_b-B_a \\perp B_d-B_c, \\forall 0\\leq a\\leq b\\leq c\\leq d$&emsp;æˆ‘å€‘å…ˆè­‰æ˜å®ƒå€‘æ˜¯ uncorrelated&emsp;$$Cov(B_b-B_a, B_d-B_c) \\\\ =Cov(B_b,B_d) - Cov(Ba,B_d) - Cov(B_b,B_c) + Cov(B_a,B_c) \\\\ = b-a-b+a = 0$$&emsp;æ‰€ä»¥ $B_b-B_a$ uncorrelated with $B_d-B_c$&emsp;ä¹‹å‰æˆ‘å€‘å­¸é, å¦‚æœ $(B_b-B_a, B_d-B_c)$ æ˜¯ Gaussian vector çš„è©±&emsp;uncorrelated ç­‰åŒæ–¼ independent&emsp;æ‰€ä»¥æˆ‘å€‘ç”¨ Gaussian vector çš„å®šç¾©ä¾†è­‰æ˜:&emsp;$$\\lambda_1(B_b-B_a)+\\lambda_2(B_d-B_c) \\\\ = \\lambda_1B_b-\\lambda_1B_a+\\lambda_2B_d-\\lambda_2B_c \\\\ \\text{by Def1 }\\sim \\mathcal{N}$$&emsp;è­‰å¾— $(B_b-B_a, B_d-B_c)$ æ˜¯ Gaussian vector ä¸”å·²è­‰é uncorrelated, æ‰€ä»¥ independent&emsp;æœ€å¾Œè­‰æ˜ $(2)$:&emsp;é¦–å…ˆ $B_t-B_s\\sim\\mathcal{N}$, å› ç‚º by Def1 $B_t$ is Gaussian process, æ‰€ä»¥ç·šæ€§çµ„åˆä¹Ÿæ˜¯ Gaussian&emsp;$\\mathbb{E}[B_t-B_s]=\\mathbb{E}[B_t]-\\mathbb{E}[B_s]=m(t)-m(s)=0$&emsp;$$Var[B_t-B_s]=Cov(B_t-B_s,B_t-B_s) \\\\ = Cov(B_t,B_t)-2Cov(B_t,B_s)+Cov(B_s,B_s) \\\\ = t-s$$&emsp;Q.E.D. [è­‰æ˜ Def2 $\\Rightarrow$ Def1]:&emsp;æˆ‘å€‘å…ˆè­‰æ˜æ˜¯ Gaussian process, $\\forall t_1&lt;t_2&lt;...&lt;t_n$ è€ƒæ…®&emsp;$$\\sum_{k=1}^n \\lambda_k B_{t_k} = \\lambda_n(B_{t_n}-B_{t_{n-1}}) + (\\lambda_n+\\lambda_{n-1})B_{t_{n-1}} + \\sum_{k=1}^{n-2} \\lambda_k B_{t_k} \\\\ = \\sum_{k=1}^n d_k(B_{t_n}-B_{t_{n-1}}) \\\\ \\text{by sum of independent Guassian is also Gaussian} \\sim \\mathcal{N}$$&emsp;æ‰€ä»¥ $(B_{t_1},...,B_{t_n})$ æ˜¯ Gaussian vector implies that $B_t$ æ˜¯ Gaussian process&emsp;æ˜¯ Gaussian process å¾Œ, æˆ‘å€‘æ‰¾ä¸€ä¸‹ $m(t),K(t,s)$&emsp;é¦–å…ˆæ³¨æ„åˆ°æˆ‘å€‘æœ‰ $B_t=B_t-B_0\\sim\\mathcal{N}(0,t)$&emsp;æ‰€ä»¥ $m(t)=\\mathbb{E}B_t=0$&emsp;æ¥è‘—è¨ˆç®— $K(t,s)$, for $t&gt;s$&emsp;$$K(t,s)=Cov(B_t,B_s) \\\\ = Cov(B_t-B_s+B_s,B_s) \\\\ = Cov(B_t-B_s, B_s) + Cov(B_s,B_s) \\\\ = Cov(B_t-B_s, B_s-B_0) + s \\\\ \\text{by indep. increment }= 0 + s = s$$&emsp;å¦‚æœ $t&lt;s$ å‰‡ $K(t,s)=t$, å› æ­¤&emsp;$K(t,s)=\\min(t,s)$&emsp;Q.E.D. ç”± Brownian motion çš„ Def2 æˆ‘å€‘å¯ä»¥æ¨å‡ºä¸€äº›æ±è¥¿:For $t&gt;s\\geq0$, $B_t\\sim\\mathcal{N}(0,t)$, $B_s\\sim\\mathcal{N}(0,s)$, $B_{t-s}\\sim\\mathcal{N}(0,t-s)$ç”± independent increament çŸ¥é“ $B_{t-s}\\perp B_s$, åˆå› ç‚ºç¨ç«‹ normal r.v.s ç›¸åŠ ä¹Ÿä»æ˜¯ normal, ä¸”å…¶ mean and variance ç‚ºç›´æ¥ç›¸åŠ æ‰€ä»¥$(B_{t-s}+B_s)\\sim\\mathcal{N}(0,t-s+s)=\\mathcal{N}(0,t)=^d B_t \\\\$$B_t(x)=B_{t-s}(x)+B_s(x)$ Week 4.7: Modification of a process. Kolmogorov continuity theorem[Stochastically Equivalent Def]:&emsp;$X_t,Y_t$ are called stochastically equivalent if&emsp;$\\mathcal{P}\\{X_t=Y_t\\}=1,\\forall t\\geq0$ [Example]: stochastically equivalent ä½†è¡Œç‚ºå»ä¸ä¸€æ¨£çš„ r.v.s&emsp;$X_t=0,\\forall t\\in[0,1]$. And $Y_t=\\mathbf{1}\\{\\tau=t\\},\\tau\\sim Unif(0,1)$&emsp;åœ¨çœ‹ $Y_t$ é€™å€‹ random variable çš„æ™‚å€™, $t$ æ˜¯çµ¦å®šçš„ (fixed), è€Œå®ƒçš„å€¼åªæœ‰å¯èƒ½æ˜¯ $0$ or $1$&emsp;å‰‡å¾ˆé¡¯ç„¶ $X_t$ å’Œ $Y_t$ æ˜¯ stochastically equivalent:&emsp;$\\mathcal{P}\\{X_t=Y_t\\}=\\mathcal{P}\\{Y_t=0\\}=\\mathcal{P}\\{t\\neq\\tau\\}=1$&emsp;æˆ‘å€‘åŠƒå‡º $X_t$ å’Œ $Y_t$ çš„ trajectory:&emsp;Stochastic process $X_t:\\Omega\\times\\mathbb{R}_+\\rightarrow\\mathbb{R}$&emsp;Trajectory of an given outcome $\\omega$, $X_t(\\omega):\\mathbb{R}_+\\rightarrow\\mathbb{R}$&emsp;ä¸Šåœ–é¡¯ç¤ºäº†çµ¦å®šæŸä¸€å€‹ $t$, $X_t$ å’Œ $Y_t$ çš„ä¸€æ¢ trajectory&emsp;å°æ–¼æ‰€æœ‰çš„ $t$, $X_t$ éƒ½é•·ä¸€å€‹æ¨£, è€Œ $Y_t$ éƒ½é•·ä¸ä¸€æ¨£, ä¸”éƒ½ä¸é€£çºŒ æ‰€ä»¥ $X_t$ å’Œ $Y_t$ æ˜¯ stochastically equivalent ä½†æ˜¯ $X_t$ trajectory æ˜¯ continuous è€Œ $Y_t$ ä¸æ˜¯æœ‰æ²’æœ‰å¯èƒ½æŠŠä¸€å€‹ trajectory ä¸é€£çºŒçš„ stochastic process æ‰¾é“å…¶å°æ‡‰ stochastically equivalent çš„ process å‘¢ ? [Kolmogorov continuity Theorem]:&emsp;Let $X_t$ be a stochastic process, if $\\exists C,\\alpha,\\beta&gt;0$ such that&emsp;$\\mathbb{E}\\left[ |X_t-X_s|^\\alpha \\right] \\leq C\\cdot |t-s|^{1+\\beta},\\forall t,s\\in[a,b]$&emsp;then $\\exists Y_t$ is stochastically equivalent to $X_t$ and $Y_t$ has continuous trajectories&emsp;We can say that the process $X_t$ has a continuous modification. [Brownian motion has continuous modification]:&emsp;Let $B_t$ be a Brownian motion&emsp;We know that $B_t-B_s\\sim\\mathcal{N}(0,t-s)$, which also means&emsp;$B_t-B_s=^d\\sqrt{t-s}\\cdot\\xi,\\xi\\sim\\mathcal{N}(0,1)$&emsp;Then (using the 4-th moment of normal distribution)&emsp;$\\mathbb{E}\\left[ |B_t-B_s|^4 \\right] = (t-s)^2\\mathbb{E}\\xi^4= (t-s)^2\\cdot3$&emsp;We can see that it fullfilled Kolmogorov continuity Theorem&emsp;Conclude that Brownian motion has continuous modification. ä¸€èˆ¬æˆ‘å€‘ç¨± Brownian motion éƒ½é è¨­ç¨±é€™å€‹ continuous modification Week 4.8: Main properties of Brownian motion[Quadratic Variation Def]: wiki&emsp;$X_{t}$ is a stochastic process. Itâ€™s quadratic variation is the process, written as $[X_t]$, defined as&emsp;$[X_t]=\\lim_{|\\Delta|\\rightarrow0}\\sum_{k=1}^n (X_{t_k}-X_{t_{k-1}})^2$&emsp;where $\\Delta:0=t_0&lt;t_1&lt;...&lt;t_n=t$, is a partition, and $|\\Delta|=\\max_{i=1,...,n}\\{t_i-t_{i-1}\\}$&emsp;This limit, if it exists, is defined using convergence in probability (See Week 6 çš„é–‹é ­). èª²ç¨‹æ²’æä¾›è­‰æ˜, èªªåœ¨å¾ˆå¤š stochastic çš„æ›¸éƒ½æœ‰æä¾›äº† [Quadratic Variation of Brownian Motion]:&emsp;çµ¦ä¸€å€‹ Brownian motion $B_t$, è€ƒæ…®ä¸€å€‹ partition $\\bigtriangleup:0=t_0&lt;t_1&lt;...&lt;t_n=t$&emsp;æˆ‘å€‘ç¨±è©² partition çš„ quadratic variation ç‚ºä»¥ä¸‹ limit:&emsp;$\\lim_{|\\bigtriangleup|\\rightarrow0} \\sum_{k=1}^n\\left( B_{t_k}-B_{t_{k-1}} \\right)^2 = t$&emsp;$|\\bigtriangleup|\\rightarrow0$ è¡¨ç¤º:$\\max_{k=0,...,n}\\{|t_k-t_{k-1}|\\}\\rightarrow0, \\text{ for }n\\rightarrow0$&emsp;å¾ä¸Šé¢å¯ä»¥çœ‹å‡º Brownian motion çš„ quadratic variation æ¥µé™å€¼å­˜åœ¨ä¸”ç­‰æ–¼ $t$[Proof]:&emsp;ä½¿ç”¨ convergence in mean square sense è­‰æ˜.&emsp;å› ç‚ºæˆ‘å€‘çŸ¥é“ m.sq. sense æˆç«‹å‰‡ converges in probability&emsp;(quadratic variation çš„ limit å®šç¾©) ä¹Ÿæˆç«‹. æ›´å¤šåƒè€ƒ Week 6 é–‹é ­. å¦‚æœæˆ‘å€‘ä»¤:$S_n=\\sum_{k=1}^n\\left( B_{t_k}-B_{t_{k-1}} \\right)^2$å‰‡ quadratic variation å‘Šè¨´æˆ‘å€‘$\\mathbb{E}(S_n-t)^2\\rightarrow0, \\text{ for }n\\rightarrow\\infty$ [Variation of Brownian Motion]:&emsp;çµ¦ä¸€å€‹ Brownian motion $B_t$, è€ƒæ…®ä¸€å€‹ partition $\\bigtriangleup:0=t_0&lt;t_1&lt;...&lt;t_n=t$&emsp;æˆ‘å€‘ç¨±è©² partition çš„ variation ç‚ºä»¥ä¸‹ limit:&emsp;$\\lim_{|\\bigtriangleup|\\rightarrow0} \\sum_{k=1}^n | B_{t_k}-B_{t_{k-1}} | = \\infty$&emsp;å¾ä¸Šé¢å¯ä»¥çœ‹å‡º Brownian motion çš„ variation æ¥µé™å€¼ä¸å­˜åœ¨ èª²ç¨‹èªª variation ä¸å­˜åœ¨çš„è­‰æ˜æœƒç”¨åˆ° quadratic variation å­˜åœ¨çš„å®šç†, ä½†æ²’çµ¦è­‰æ˜ ç¸½çµä¾†èªª, Brownian motion æ˜¯ quadratic variation, ä½†ä¸æ˜¯ bounded variation [Brownian Motion Continuity and Differentiability]:&emsp;Brownian motion is everywhere continuous but nonwhere differentiable.&emsp;æˆ‘å€‘èªª stochastic process æ˜¯ continuous at time $t$ æ„æ€ç‚º:&emsp;$$B_{t+h}\\xrightarrow[h\\rightarrow0]{p}B_t \\\\ \\Longleftrightarrow\\mathcal{P}\\{|B_{t+h}-B_t|&gt;\\varepsilon\\}=0, \\text{ for }h\\rightarrow0, \\forall\\varepsilon&gt;0$$&emsp;è€Œ differentiable æœƒåœ¨ week6 æåˆ°. æ¥ä¸‹ä¾†çš„å®šç†å¯ä»¥ç”¨ä¾†äº†è§£ Brownian motion $B_t$ è·‘å‘ $\\infty$ çš„é€Ÿåº¦æœ‰å¤šå¿«.$$\\begin{align} \\begin{array}{rl} \\lim_{t\\rightarrow\\infty}\\frac{B_t}{t}=0, &amp;a.s. \\\\ \\lim\\sup_{t\\rightarrow\\infty}\\frac{B_t}{\\sqrt{t}}=\\infty, &amp;a.s. \\end{array} \\end{align}$$ èª²ç¨‹èªªå¾ˆå®¹æ˜“è­‰æ˜â€¦ ä½†å°æˆ‘ä¾†èªªä¸æ˜¯ (Law of the iterated logarithm) ç›´è§€ç†è§£ç‚º: Brownian motion è·‘å¾—æ¯” $t$ é‚„æ…¢, ä½†æ˜¯æ¯” $\\sqrt{t}$ é‚„å¿«ä½†æº–ç¢ºä¾†èªª Brownian motion çš„é€Ÿåº¦æ‡‰è©²æ˜¯ä»€éº¼? Law of the Iterated Logarithm å‘Šè¨´äº†æˆ‘å€‘ç­”æ¡ˆ [Law of the Iterated Logarithm]:&emsp;Brownian motion $B_t$, we have&emsp;$\\lim\\sup_{t\\rightarrow\\infty} \\frac{B_t}{\\sqrt{2t\\log(\\log t)}}=1$ ç„¡æ³•å¤ªæ·±å…¥ç†è§£é€™äº›å®šç†çš„ç”¨è™•å’Œæ„ç¾©, åŒæ„èª²ç¨‹è¦çµ¦æ›´å¤šç¯„ä¾‹èªªæ˜ æœ€å¾Œä¸€å€‹å•é¡Œå¯ä»¥ç”± $\\lim_{h\\rightarrow0} B_{t+h}-B_t \\sim \\lim_{h\\rightarrow0}\\mathcal{N}(0,h)$ çœ‹å‡º, ç‚º constant $0$ a.s. END OF CLASS","tags":[{"name":"Gaussian Process","slug":"Gaussian-Process","permalink":"https://bobondemon.github.io/tags/Gaussian-Process/"},{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Gaussian Vector","slug":"Gaussian-Vector","permalink":"https://bobondemon.github.io/tags/Gaussian-Vector/"},{"name":"Brownian Motion","slug":"Brownian-Motion","permalink":"https://bobondemon.github.io/tags/Brownian-Motion/"}]},{"title":"Stochastic Processes Week 3 Markov Chains","date":"2021-12-12T09:15:30.000Z","path":"2021/12/12/Stochastic-Processes-Week-3-Markov-Chains/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains (æœ¬æ–‡) Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes Week 3.1: Definition of a Markov chain. Some examples[Markov Chain Def]:&emsp;ä»¤ State space $\\mathcal{S}$ which is countable. å‰‡ $S_n$, $n=0,1,2,â€¦$ ç¨±ç‚º Markov chain éœ€æ»¿è¶³ Markov property å¦‚ä¸‹:&emsp;$\\mathcal{P}\\{S_n=j | S_{n-1}=i_{n-1},...,S_0=i_0\\} = \\mathcal{P}\\{S_n=j | S_{n-1}=i_{n-1}\\}$&emsp;å…¶ä¸­ $i_0,...,i_{n-1},j\\in\\mathcal{S}$, and $\\mathcal{P}\\{S_{n-1}=i_{n-1},...,S_0=i_0\\}\\neq0$ å¦‚æœæ»¿è¶³ Markov property, å‰‡æˆ‘å€‘ç™¼ç¾:$$\\mathcal{P}\\{S_n=i_n,S_{n-1}=i_{n-1},...,S_0=i_0\\} \\\\ = \\mathcal{P}\\{ S_n=i_n | S_{n-1}=i_{n-1},...,S_0=i_0 \\}\\cdot \\mathcal{P}\\{ S_{n-1}=i_{n-1},...,S_0=i_0 \\} \\\\ = \\mathcal{P}\\{ S_n=i_n | S_{n-1}=i_{n-1} \\}\\cdot \\mathcal{P}\\{ S_{n-1}=i_{n-1},...,S_0=i_0 \\} \\\\ =...\\\\ = \\mathcal{P}\\{ S_n=i_n | S_{n-1}=i_{n-1} \\} \\mathcal{P}\\{ S_{n-1}=i_{n-1} | S_{n-2}=i_{n-2} \\} ... \\mathcal{P}\\{ S_1=i_1 | S_0=i_0 \\} \\mathcal{P}\\{S_0=i_0\\}$$ æ‰€ä»¥æ˜¯ pairwise independent Any renewal process is also a Markov chain [Random Walk Example]:&emsp;è€ƒæ…®&emsp;$$\\mathcal{P}\\{ S_n=j | S_{n-1}=i_{n-1} \\} = \\left\\{ \\begin{array}{rl} p, &amp; j=i_{n-1}+1 \\\\ 1-p, &amp; j=i_{n-1}-1 \\\\ 0, &amp; \\text{otherwise} \\end{array} \\right.$$&emsp;ç™¼ç¾åªæœƒè·Ÿå‰ä¸€å€‹ state æœ‰é—œ æ³¨æ„åˆ° random walk ä¸æ˜¯ renewal process, å› ç‚º $\\xi$ å¯ä»¥ç”¢ç”Ÿè² çš„å€¼. è€Œåœ¨ renewal process, $\\xi$ ç‚º inter-arrival time $\\geq0$ [Taxis in the airport Example]:&emsp;$1$ taxi at $n$ moment, $n=1,2,3,â€¦$&emsp;å¦‚æœç•¶ä¸‹æ²’æœ‰ä¹˜å®¢, taxi å°±é›¢é–‹. å¦‚æœæœ‰ä¹˜å®¢, taxi ç•¶å ´è¼‰èµ°ä¸€åä¸¦é¦¬ä¸Šå°±é›¢é–‹.&emsp;$X_k$: # people waiting for taxi at time $k$&emsp;$Y_k$: # people arriving at time $k$&emsp;ç¾åœ¨èªªæ˜ $X_k$ æ˜¯ Markov chain&emsp;$$X_k=Y_k+(X_{k-1}-1)_+= \\left\\{ \\begin{array}{rl} Y_k, &amp; \\text{if }X_{k-1}=0 \\\\ Y_k+X_{k-1}-1, &amp; \\text{if }X_{k-1}\\geq0 \\\\ \\end{array} \\right.$$&emsp;æ‰€ä»¥ $X_k$ åªè·Ÿ $X_{k-1}$ æœ‰é—œ [Example]:&emsp;è€ƒæ…®ä»¥ä¸‹ $X_n$, for some fixed $m\\in\\mathbb{N}$&emsp;$\\mathcal{P}\\{ X_n | X_{n-1},...,X_0 \\} = \\mathcal{P}\\{ X_n | X_{n-1},...,X_{n-m} \\}$&emsp;ç•¶ä¸‹çš„ state è·Ÿå‰ $m$ å€‹ states æœ‰é—œ, è€ŒåŸæœ¬ Markov property æ˜¯åªèƒ½èˆ‡å‰ $1$ å€‹ state æœ‰é—œ.&emsp;æˆ‘å€‘å®šç¾© $S_n$ (a vector of $X_n$) å¦‚ä¸‹:&emsp;$S_n=(X_n,...,X_{n-m+1}),\\text{ where } n=m-1,m,...$&emsp;å‰‡æˆ‘å€‘ç™¼ç¾:&emsp;$$\\mathcal{P}\\{ X_n | X_{n-1},...,X_0 \\} = \\frac{\\mathcal{P}\\{ X_n,X_{n-1},...,X_0\\}}{\\mathcal{P}\\{ X_{n-1},...,X_0\\}} \\\\ = \\frac { \\mathcal{P}\\{ (X_n,...,X_{n-m+1}), (X_{n-1},...,X_{n-m}),...,(X_{m-1},...,X_0) \\} } { \\mathcal{P}\\{ (X_{n-1},...,X_{n-m}),...,(X_{m-1},...,X_0) } \\\\ = \\frac {\\mathcal{P}\\{S_n,S_{n-1},...,S_{m-1}\\}} {\\mathcal{P}\\{S_{n-1},...,S_{m-1}\\}} = \\mathcal{P}\\{S_n | S_{n-1},...,S_{m-1}\\} \\ldots(\\star) \\\\ \\mathcal{P}\\{ X_n | X_{n-1},...,X_{n-m} \\} = \\frac{\\mathcal{P}\\{ X_n,X_{n-1},...,X_{n-m}\\}}{\\mathcal{P}\\{ X_{n-1},...,X_{n-m}\\}} \\\\ = \\frac { \\mathcal{P}\\{ (X_n,...,X_{n-m+1}), (X_{n-1},...,X_{n-m}) \\} } { \\mathcal{P}\\{ (X_{n-1},...,X_{n-m}) } \\\\ = \\frac {\\mathcal{P}\\{S_n,S_{n-1}\\}} {\\mathcal{P}\\{S_{n-1}\\}} = \\mathcal{P}\\{S_n | S_{n-1}\\}\\ldots(\\square)$$&emsp;å› ç‚º $X_n$ æ˜¯ Markov chain, æ‰€ä»¥ $(\\star)=(\\square)$, å¾—çŸ¥ $S_n$ ç‚º Markov chain Week 3.2: Matrix representation of a Markov chain. Transition matrix. Chapman-Kolmogorov equationMatrix representation å¦‚èª²ç¨‹ä¸Šåœ–çš„èªªæ˜, é€™è£¡å¾ˆå®¹æ˜“çœ‹ä¸Šåœ–å³å¯. [Thm]:&emsp;Define $p_{ij}^{(m)} = \\mathcal{P}\\{X_{n+m}=j | X_n=i\\}$, å³ step $n$ æ™‚åœ¨ state $i$, ä¸”èµ°äº† $m$ steps, i.e. step $n+m$, æ™‚åœ¨ state $j$ çš„æ©Ÿç‡.&emsp;ä¸¦å®šç¾© $P^{(m)}=\\left( p_{ij}^{(m)} \\right)$ è¡¨ç¤º m-step çš„ transition matrix. å‰‡æˆ‘å€‘æœ‰:&emsp;$P^{(m)}= P^m=\\underbrace{PP\\cdots P}_{m\\text{-times}}$ å®šç¾©äº† stationary distribution $\\vec\\pi^*=\\vec\\pi^*P$ Week 3.3-5: Graphic representation. Classification of stateså®šç¾©äº† $i\\rightarrow j$ è¡¨ç¤ºæœ‰ä¸€æ¢ walk (å¤šæ¢ arcs é€£çµ) from $i$ to $j$. ç¨± $j$ is accesible from $i$å®šç¾©äº† $i\\leftrightarrow j$ è¡¨ç¤ºæœ‰ä¸€æ¢é›™å‘ walk é€£çµ $i$ and $j$. ç¨± $i$ and $j$ communicate [Equivalence Relation Def]:&emsp;çµ¦å®š set $A$, è‹¥æœ‰ä¸€å€‹ binary operation $\\sim$ æ»¿è¶³ä»¥ä¸‹é—œä¿‚å‰‡ç¨± $\\sim$ ç‚º equivalence relation:&emsp;$$\\begin{array}{rl} a\\sim a, a\\in A &amp; \\text{reflectivity} \\\\ a\\sim b\\Rightarrow b\\sim a, \\forall a,b\\in A &amp; \\text{symmetry} \\\\ a\\sim b, b\\sim c \\Rightarrow a\\sim c &amp; \\text{transtivity} \\end{array}$$ çµ¦å®š set $A$ å’Œå®ƒçš„ä¸€å€‹ equivalence relation $\\sim$, å‰‡æˆ‘å€‘å¯ä»¥å®šç¾©å‡º equivalence class The equivalence class of an element $a$ is often denoted $[a]$ or $[a]_\\sim$ and is defined as the set ${ x\\in A: a\\sim x}$ of elements that are related to $a$ by $\\sim$. æˆ‘å€‘å° Markov chain çš„åœ–å¯ä»¥å®šç¾©ä¸€å€‹ equivalence relation (by communicate $\\leftrightarrow$) $B_1,B_2,â€¦$ ç‚º states çš„ equivalence classes by definition below$$\\forall j\\in B_i, \\forall k \\in \\mathcal{S} \\left\\{ \\begin{array}{rl} k\\in B_i, &amp;k\\leftrightarrow j \\\\ k \\notin B_i, &amp; k \\nleftrightarrow j \\end{array} \\right.$$ç°¡å–®è¬›å°±æ˜¯æ‹¿å…©å€‹ states $j$ and $k$ å‡ºä¾†, å¦‚æœä»–å€‘ $\\leftrightarrow$ å‰‡å±¬æ–¼åŒä¸€å€‹ set. é€™æ¨£æœƒä½¿å¾— state space $\\mathcal{S}$ å½¢æˆ equivalence classes èª²ç¨‹è£¡çš„ state $4$ åªæœ‰ out going arcs, æ‰€ä»¥ $4 \\nleftrightarrow 4$, å› æ­¤ä¸æ‡‰è©²æœ‰ä¸€å€‹ equivalence class $\\{4\\}$ æ‰å°å•Š ? æˆ‘çŒœæ‡‰è©²è¦å¤šè£œä¸Šé€™æ¢: è‡ªå·±è·Ÿè‡ªå·±ä¸€å®šå±¬æ–¼åŒä¸€å€‹ equivalence class. [Recurrent and Transient Def]:&emsp;$i$ is recurrent if $\\forall j:i\\rightarrow j \\Rightarrow j\\rightarrow i$&emsp;$i$ is transient if $\\exist j: i\\rightarrow j, j\\nrightarrow i$ æˆ‘å€‘èªªä¸€å€‹ state $i$ æ˜¯ recurrent å¿…é ˆæ»¿è¶³å°â€æ‰€æœ‰â€å…¶ä»– states éƒ½æ»¿è¶³ â€œå¦‚æœ $i$ åˆ°çš„äº†è©² state, é‚£è©² state ä¹Ÿåˆ°çš„äº† $i$â€è€Œ transient åªéœ€æ»¿è¶³ â€œå­˜åœ¨â€ ä¸€å€‹ state ä½¿å¾— $i$ åˆ°çš„äº†ä½†å›ä¸ä¾† [Thm, Nodes are ALL Recurrent or ALL Transient in An Equivalence Class]: å› æ­¤ equivalence classes:$$\\begin{array}{rl} \\{1\\}, &amp; \\text{transient} \\\\ \\{2,3\\}, &amp; \\text{recurrent} \\\\ \\{4\\}, &amp; \\text{transient} \\\\ \\{5,6\\}, &amp; \\text{transient} \\end{array}$$ å…¶å¯¦æˆ‘å€‘å¯ä»¥æŠŠ equivalence class æƒ³æˆæ˜¯ä¸€å€‹ state å°±å¯ä»¥. ç„¶å¾Œå¦‚æœæœ‰å‡ºå»çš„ arc å°±æ˜¯ transient. åä¹‹æ²’æœ‰å‡ºå»çš„ arcs å°±æœƒæ˜¯ recurrent. [Period of a State $i$ Def]:&emsp;çµ¦å®šä¸€å€‹ Markov chain (discrete time and countable state space $\\mathcal{S}$), å®šç¾© peroid of a state $i$:&emsp;$d(i):=GCD\\{n:p_{ii}^{(n)}\\neq0\\}$&emsp;å…¶ä¸­ $GCD$ ç‚º greates common divisor, è‹¥ $d(i)=1$ æˆ‘å€‘ç¨± $i$ ç‚º aperiodic å‡è¨­ $n$ ç‚ºèµ°å›è‡ªå·±è¦èŠ±çš„æ­¥æ•¸, æ‰€æœ‰é‚£äº› $n$ çš„æœ€å¤§å…¬å› æ•¸å°±æ˜¯ period [ç¯„ä¾‹]: åŒæ¨£ç”¨èª²ç¨‹çš„åœ–&emsp;$d(1)=1$&emsp;$d(2)=d(3)=2$&emsp;$d(4)=1$, èµ°ä¸å›è‡ªå·± period å®šç¾©ç‚º $1$&emsp;$d(5)=GCD{2,3,â€¦}=1$, å…¶ä¸­ $2$ æ˜¯å› ç‚º $5\\rightarrow6\\rightarrow5$, $3$ æ˜¯å› ç‚º $5\\rightarrow6\\rightarrow6\\rightarrow5$&emsp;$d(6)=1$ $a\\vdots b$ è¡¨ç¤º $a$ èƒ½è¢« $b$ æ•´é™¤ [Thm]: All elements in 1 equivalence class have the same period[Proof]:&emsp;é¸å®š states $i$ and $j$ åœ¨åŒä¸€å€‹ equivalence class, ä¸¦ä»¤ $i\\rightarrow j$ èµ° $n$ æ­¥, $j\\rightarrow i$ èµ° $m$ æ­¥.&emsp;å‡å®š for some $k$ æ»¿è¶³:&emsp;$p_{jj}^{(k)}\\neq 0 \\Longrightarrow k\\vdots d(j) \\ldots (\\star)$&emsp;è¡¨ç¤º $j\\rightarrow j$ å¯ä»¥èµ° $k$ æ­¥, å› æ­¤ $k$ ä¸€å®šæœƒè¢« $d(j)$ æ•´é™¤.&emsp;å¦‚åœ–:&emsp;æˆ‘å€‘æœ‰å¦‚ä¸‹çš„é—œä¿‚:&emsp;$$\\left. \\begin{array}{r} p_{ii}^{(n+m)}\\neq0 \\Longrightarrow (n+m) \\vdots d(i) \\\\ p_{jj}^{(k)}\\neq0 \\Longrightarrow p_{ii}^{(n+m+k)}\\neq0 \\Longrightarrow (n+m+k) \\vdots d(i) \\end{array} \\right\\} \\Longrightarrow k\\vdots d(i)$$&emsp;å› ç‚º $j$ å¯ä»¥èµ° $k$ æ­¥å›åˆ°è‡ªå·±, æ‰€ä»¥ $i$ å¯ä»¥èµ° $n+m+k$ æ­¥ä¹Ÿå›åˆ°è‡ªå·±. å¾—åˆ° $k$ å¯ä»¥è¢« $d(i)$ æ•´é™¤çš„çµè«–.&emsp;å› æ­¤å°æ‰€æœ‰å¯èƒ½çš„ $k$ (é‚£äº›æ»¿è¶³ $(\\star)$ çš„ $k$) æˆ‘å€‘éƒ½å¯ä»¥å¾—åˆ°è¢« $d(i)$ æ•´é™¤çš„çµè«–.&emsp;è¡¨ç¤º $d(i)$ æ˜¯é€™äº›æ‰€æœ‰å¯èƒ½çš„ $k$ çš„ â€œå…¬å› æ•¸â€&emsp;æ ¹æ“šå®šç¾©, $d(j)$ æ˜¯é€™äº›æ‰€æœ‰å¯èƒ½çš„ $k$ çš„ â€œæœ€å¤§å…¬å› æ•¸â€&emsp;å› æ­¤ $d(j)\\geq d(i)$&emsp;åŒæ¨£çš„æµç¨‹æˆ‘å€‘ $i$ and $j$ çš„è…³è‰²äº’æ›, ä¹Ÿå¯ä»¥å¾—åˆ° $d(i)\\geq d(j)$&emsp;å¾—åˆ°çµè«– $d(i)=d(j)$&emsp;Q.E.D.&emsp;èª²ç¨‹çš„èªªæ˜æˆ‘è¦ºå¾—æœ‰é»å•é¡Œ, ä»¥ä¸‹ç‚ºèª²ç¨‹çš„è§£é‡‹: æ³¨æ„åˆ° $d(i)$ æ˜¯â€æŸä¸€å€‹â€ $k$ çš„å› æ•¸, ä½†æ˜¯ $d(j)$ æ˜¯æ‰€æœ‰å¯èƒ½çš„ $k$ çš„æœ€å¤§å…¬å› æ•¸. å› æ­¤ $d(i)$ ä¸€å®šå¯ä»¥è¢« $d(j)$ æ•´é™¤ (??) :$$d(i) \\vdots d(j)$$åŒæ¨£çš„æµç¨‹æˆ‘å€‘ $i$ and $j$ çš„è…³è‰²äº’æ›, ä¹Ÿå¯ä»¥å¾—åˆ° $d(j)$ æœƒè¢« $d(i)$ æ•´é™¤å¾—åˆ°çµè«– $d(i)=d(j)$ Week 3.6-7: Ergodic chains. Ergodic theorem[Ergodic Markov Chain using Graphic Representation]:&emsp;æˆ‘å€‘èªªä¸€å€‹ Markov chain is ergodic, éœ€æ»¿è¶³ä»¥ä¸‹æ¢ä»¶&emsp;1. åªæœ‰ä¸€å€‹ class of equivalence&emsp;2. æ‰€æœ‰ nodes are recurrent&emsp;3. $d(i)=1,\\forall i\\in\\mathcal{S}$. æ‰€æœ‰ nodes are aperiodic [Example]:&emsp;å¦‚æœåªæœ‰å¯¦ç·šçš„ arcs, å‰‡æ»¿è¶³ 1. åªæœ‰ä¸€å€‹ equivalence class, 2. æ‰€æœ‰ nodes are recurrent. ä½†æ˜¯ $d(i)=6$.&emsp;ä½†å¦‚æœåŒ…å«è™›ç·šçš„ arc å‰‡ $d(i)=GCD(\\{5,6\\})=1$&emsp;ç®—å‡º equivalence class è£¡çš„ä¸€å€‹ node, å°±ç­‰æ–¼ç®—å‡ºäº†å…¨éƒ¨ nodes [Thm of Connection between Graphic and Matrix Representation in Ergodic Markov Chain]:&emsp;Markov chain is ergodic (defined in graphic representation)&emsp;$\\Longleftrightarrow \\exists m\\in \\mathbb{N}:p_{ij}^{(m)}\\neq0, \\forall i,j \\in \\mathcal{S} \\ldots (\\star)$ æˆ‘å€‘èˆ‰å€‹ä¾‹å­ $(\\star)$ æ¢ä»¶ä¸æˆç«‹. æˆ‘å€‘ç™¼ç¾$$\\left\\{m=5,11,17,...:p_{ij}^{(m)}\\neq0\\right\\} \\\\ \\left\\{m=1,7,13,...:p_{ji}^{(m)}\\neq0\\right\\}$$ ä¸å­˜åœ¨ä¸€å€‹ $m$ èƒ½åŒæ™‚æ»¿è¶³æ‰€æœ‰ nodes åˆ©ç”¨ä»¥ä¸Šå®šç†æˆ‘å€‘å¯ä»¥å¯«å‡º matrix representation for ergodic Markov chain[Ergodic Markov Chain using Matrix Representation]:&emsp;æˆ‘å€‘ç¨±ä¸€å€‹ Markov chain æ˜¯ ergodic, å¦‚æœæ»¿è¶³:&emsp;$p_{ij}^{(m)}\\neq0, \\forall i,j \\in \\mathcal{S}, \\forall m\\geq(M-1)^2+1$&emsp;å…¶ä¸­ $M$ æ˜¯ states æ•¸é‡, i.e. $|\\mathcal{S}|$ èª²ç¨‹è©¦é¡Œ:å°‡ graph åœ–ç•«å‡ºä¾†, å¯ä»¥ç™¼ç¾æ»¿è¶³ graphic representation of ergodic Markov chain çš„ä¸‰å€‹æ¢ä»¶ ç”¨ matrix çš„å®šç¾©ç›®å‰é‚„ä¸çŸ¥é“æ€éº¼é©—è­‰ $\\forall m\\geq26$ éƒ½æ»¿è¶³ [Ergodic Theorem]:&emsp;ä»¤ $X_t$ ç‚ºä¸€å€‹ ergodic Markov chain, (i.e. 1-class equivalence, recurrent, and aperiodic.), å‰‡æ¥µé™å€¼å­˜åœ¨:&emsp;$\\exists \\lim_{n\\rightarrow\\infty}p_{ij}^{(n)} = \\pi_j^* &gt; 0$&emsp;æ³¨æ„åˆ°å·²ç¶“è·Ÿå‡ºç™¼é»çš„ state $i$ ç„¡é—œäº†, ä¸” strictly positive. å¦å¤– $\\vec\\pi$ çš„å®šç¾©å¦‚ä¸‹:&emsp;$\\vec{\\pi}^* = (\\vec{\\pi}_1^*,...,\\vec{\\pi}_M^*), \\text{ with } \\sum_{j=1}^M \\pi_j^* = 1$ $i$ transition $n$ æ­¥åˆ° $j$ çš„æ©Ÿç‡, ç•¶ $n\\rightarrow\\infty$ æ™‚æœƒæ”¶æ–‚, ä¸¦ä¸” $&gt;0$ [Corollary]:&emsp;ä»¤ $X_t$ ç‚ºä¸€å€‹ ergodic Markov chain, å‰‡ Ergodic theorem æˆç«‹, å‰‡æˆ‘å€‘æœ‰:&emsp;1. $\\vec{\\pi}^*$ is stationary distribution, i.e. $\\vec{\\pi}^*=\\vec{\\pi}^*P$&emsp;2. $\\lim_{n\\rightarrow\\infty}\\mathcal{P}\\{X_n=j\\}=\\pi_j^*$[Proof]: [Example]: Applications of the Markov ChainsApplications of the Markov Chains.pdf","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Markov Chains","slug":"Markov-Chains","permalink":"https://bobondemon.github.io/tags/Markov-Chains/"},{"name":"Ergodic Markov Chains","slug":"Ergodic-Markov-Chains","permalink":"https://bobondemon.github.io/tags/Ergodic-Markov-Chains/"}]},{"title":"Stochastic Processes Week 2 Poisson Processes","date":"2021-12-12T00:42:36.000Z","path":"2021/12/12/Stochastic-Processes-Week-2-Poisson-Processes/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes (æœ¬æ–‡) Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes Week 2.1-4: Definition of a Poisson process as a special example of renewal process. Exact forms of the distributions of the renewal process and the counting processJust a recapä»¤æˆ‘å€‘æœ‰å¦‚ä¸Šé¢æ‰€è¿°çš„ renewal process[Poisson Processes Def1]:&emsp;A Poisson process æ˜¯ä¸€å€‹ renewal process, ä¸” $\\xi_i\\sim p(x)=\\lambda e^{-\\lambda x}\\cdot \\mathbf{1}(x&gt;0)$ which is exponential density function&emsp;æ­¤æ™‚ $\\mathbf{1}(\\cdot)$ ç‚º indicator function, è€Œ $\\lambda$ ç¨±ç‚º intensity parameter, æˆ– rate of Poisson process ç°¡å–®èªªå°±æ˜¯ exponential random variables çš„ renewal processæ­¤æ™‚çš„ renewal process çš„ $S_n$ (arrival time process) and $N_t$ (counting process) æœ‰ closed form [Thm] Arrival time process $S_n$ çš„ distribution and density functions:&emsp;$$F_{S_n}(x)=\\left\\{ \\begin{array} {rl} 1-e^{-\\lambda x} \\sum_{k=0}^{n-1}\\frac{(\\lambda x)^k}{k!}, &amp; x&gt;0 \\\\ 0, &amp; x&lt;0 \\end{array} \\right. \\\\ \\mathcal{P}_{S_n}(x)=\\lambda\\frac{(\\lambda x)^{n-1}}{(n-1)!}e^{-\\lambda x}\\cdot \\mathbf{1}(x&gt;0)$$ [Proof]:&emsp;æˆ‘å€‘è­‰æ˜ p.d.f., ä½¿ç”¨æ•¸å­¸æ­¸ç´æ³•&emsp;è€ƒæ…® $n=1$ æ™‚ $\\mathcal{P}_{S_1}=?$&emsp;$S_1=\\xi_1\\sim \\lambda e^{-\\lambda x}\\cdot \\mathbf{1}(x&gt;0)$&emsp;å‡è¨­ $n$ æˆç«‹, è€ƒæ…® $n+1$&emsp;$$\\mathcal{P}_{S_{n+1}}(x) = \\int_{y=0}^x \\mathcal{P}_{S_n}(x-y) \\cdot \\mathcal{P}_{\\xi_{n+1}}(y) dy \\\\ = \\int_{y=0}^x \\frac{\\lambda^n(x-y)^{n-1}}{(n-1)!}e^{-\\lambda (x-y)} \\lambda e^{-\\lambda y} dy \\\\ = \\int_{y=0}^x \\frac{\\lambda^{n+1}(x-y)^{n-1}}{(n-1)!}e^{-\\lambda x} dy \\\\ = \\frac{\\lambda^{n+1}}{(n-1)!}e^{-\\lambda x} \\int_{y=0}^x (x-y)^{n-1}dy \\\\ = \\frac{\\lambda^{n+1}}{(n-1)!} e^{-\\lambda x} \\cdot \\frac{x^n}{n} = \\lambda\\frac{(\\lambda x)^n}{n!} e^{-\\lambda x}$$ [Thm] Counting process $N_t$ æ˜¯ Poisson distribution, $\\mathcal{P}{N_t=n}\\sim Pois(\\lambda t)$:&emsp;$${\\color{orange} { \\mathcal{P}\\{N_t=n\\} \\sim Pois(\\lambda t)=e^{-\\lambda t}\\frac{(\\lambda t)^n}{n!} } }$$[Proof]:&emsp;æˆ‘å€‘æœ‰ $\\mathcal{P}\\{N_t=n\\}=\\mathcal{P}\\{ S_n\\leq t\\} - \\mathcal{P}\\{ S_{n+1}\\leq t\\}\\ldots(\\star)$&emsp;L.H.S. æ„æ€æ˜¯, åˆ°æ™‚é–“ $t$ ç‚ºæ­¢æ­£å¥½ç™¼ç”Ÿ $n$ æ¬¡äº‹ä»¶çš„æ©Ÿç‡&emsp;R.H.S. ä»¥ä¸‹å…©ç¨®éƒ½å¯ä»¥è§£é‡‹:&emsp;1. åˆ°æ™‚é–“ $t$ ç‚ºæ­¢å·²ç™¼ç”Ÿè‡³å°‘ $n$ æ¬¡äº‹ä»¶çš„æ©Ÿç‡, æ‰£æ‰, åˆ°æ™‚é–“ $t$ ç‚ºæ­¢å·²ç™¼ç”Ÿè‡³å°‘ $n+1$ æ¬¡äº‹ä»¶çš„æ©Ÿç‡&emsp;&emsp;â€”&gt; å¾ˆé¡¯ç„¶åªæœƒå‰©ä¸‹åˆ°æ™‚é–“ $t$ ç‚ºæ­¢æ­£å¥½ç™¼ç”Ÿ $n$ æ¬¡äº‹ä»¶çš„æ©Ÿç‡&emsp;2. ç¬¬ $n$ å€‹äº‹ä»¶ç™¼ç”Ÿçš„æ™‚é–“æ¯” $t$ å°çš„æ©Ÿç‡, æ‰£æ‰, ç¬¬ $n+1$ å€‹äº‹ä»¶ç™¼ç”Ÿçš„æ™‚é–“æ¯” $t$ å°çš„æ©Ÿç‡.&emsp;&emsp;$\\{N_t=n\\}=\\{S_n\\leq t\\} \\cap \\{S_{n+1}&gt;t\\}$ ç”¨ $A \\cap B$ è¡¨ç¤º, ç”±æ–¼&emsp;$$\\left. \\begin{array}{r} A\\cap B=A\\backslash B^c \\\\ B^c\\subset A \\end{array} \\right\\} \\Rightarrow \\mathcal{P}(A\\cap B)=\\mathcal{P}(A)-\\mathcal{P}(B^c)$$&emsp;å› æ­¤&emsp;$$(\\star) = \\left( 1-e^{-\\lambda t} \\sum_{k=0}^{n-1}\\frac{(\\lambda t)^k}{k!} \\right) - \\left( 1-e^{-\\lambda t} \\sum_{k=0}^{n}\\frac{(\\lambda t)^k}{k!} \\right) \\\\ = e^{-\\lambda t}\\frac{(\\lambda t)^n}{n!}$$ Week 2.5: Memoryless property[Def] Memoryless Property:&emsp;A random variable $X$ possesses the memoryless property, $iff$&emsp;$\\mathcal{P}\\{X&gt;u+v\\} = \\mathcal{P}\\{X&gt;u\\} \\mathcal{P}\\{X&gt;v\\}$ If $\\mathcal{P}\\{x&gt;v\\}&gt;0$, then$\\mathcal{P}\\{ X&gt;u+v \\vert X&gt;v \\} = \\mathcal{P}\\{ X&gt;u \\}\\ldots(\\square)$é€™æ˜¯å› ç‚º$$\\mathcal{P}\\{X&gt;u+v\\} = \\mathcal{P}\\{X&gt;u+v , X&gt;v\\}=\\mathcal{P}\\{X&gt;u+v \\vert X&gt;v\\}\\mathcal{P}\\{X&gt;v\\} \\\\ \\text{mem.less prop.}\\Rightarrow \\mathcal{P}\\{X&gt;u\\} \\mathcal{P}\\{X&gt;v\\} = \\mathcal{P}\\{X&gt;u+v \\vert X&gt;v\\}\\mathcal{P}\\{X&gt;v\\} \\\\ \\Rightarrow \\mathcal{P}\\{X&gt;u\\} = \\mathcal{P}\\{X&gt;u+v \\vert X&gt;v\\}$$ å¾é€™å°±å¯ä»¥çœ‹å‡ºç‚ºä½•ç¨± memoryless. é€™æ˜¯å› ç‚º å·²ç¶“ç­‰äº† $v$ çš„æ™‚é–“, è¦å†å¤šç­‰ $u$ çš„æ™‚é–“, è·Ÿä¸€é–‹å§‹å°±ç­‰ $u$ çš„æ™‚é–“çš„æ©Ÿç‡æ˜¯ä¸€æ¨£çš„ å†ä¾†æœ‰ä¸€å€‹å®šç†å¯ä»¥çœ‹å‡º Poisson process é©ä¸é©åˆç”¨ä¾† model ä¸€å€‹å•é¡Œ [Thm] Memoryless is exactly exponential distribution:&emsp;Let $X$ be a random variable with density $p(x)$, å‰‡&emsp;$X\\text{ memoryless } \\Longleftrightarrow p(x)=\\lambda e^{-\\lambda x}\\text{, }X\\sim\\text{ exponential p.d.f.}$ ç¯„ä¾‹: å…¬è»Šæ¯ $20 \\pm 2$ åˆ†é˜ä¾†ä¸€ç­, ä¹Ÿå°±æ˜¯èªª $X$ æ˜¯å…¬è»Šåˆ°çš„æ™‚é–“çš„ r.v. å€¼åœ¨ $20 \\pm 2$. é€™å€‹å•é¡Œæ˜¯å¦å¯ä»¥ç”¨ Poisson process ä¾† model ? (æª¢å¯Ÿ r.v. $X$ æ˜¯å¦å…·æœ‰ memoryless property)ä»¤ $v=19$, $u=10$, å‰‡è€ƒæ…® $(\\square)$L.H.S. ç‚º $\\mathcal{P}\\{X&gt;29|X&gt;19\\}=0$R.H.S. ç‚º $\\mathcal{P}\\{ X&gt;10 \\}=1$å…©è€…ä¸ç›¸ç­‰, æ‰€ä»¥ä¸å…·æœ‰ memoryless property, å› æ­¤æ­¤ random variable ä¸èƒ½ç”¨åœ¨ renewal process è®“å®ƒæˆç‚º Poisson process [Quiz]: Week 2.6-7: Other definitions of Poisson processesä¹‹å‰å®šç¾© Poisson process æ˜¯ renewal process çš„ä¸€å€‹ç‰¹ä¾‹ (ç•¶ $\\xi$ æ˜¯ exponential distribution)ç¾åœ¨çµ¦å‡ºå¦ä¸€ç¨®å®šç¾©, é€™ç¨®å®šç¾©è·Ÿ Poisson process èˆ‡ Levy precess çš„é—œè¯æœ‰å¾ˆå¤§çš„é—œä¿‚. (ä¹‹å¾Œæ‰æœƒçŸ¥é“) [Poisson Processes Def2] from Levy precess:&emsp;Poisson process is an integer-valued process, $N_t$, with $N_0=0$ a.s. (almost surely), such that&emsp;1. $N_t$ has independent increments&emsp;&emsp;$\\forall t_0&lt;t_1&lt;...&lt;t_n$, we have $N_{t_1}-N_{t_0}, ..., N_{t_n}-N_{t_{n-1}}$ are independent&emsp;2. $N_t$ has stationary increments&emsp;&emsp;$N_t-N_s$ èˆ‡ $N_{t-s}$ å…·æœ‰ç›¸åŒçš„ distribution&emsp;3. $N_t-N_s\\sim Pois(\\lambda(t-s))$&emsp;&emsp;$${\\color{orange} { \\mathcal{P}\\{N_t=n\\} \\sim Pois(\\lambda t)=e^{-\\lambda t}\\frac{(\\lambda t)^n}{n!} } }$$ ç‰¹æ€§ 3 å¯ä»¥æ¨å°å‡ºç‰¹æ€§ 2$X \\sim Pois(\\mu)$ has $\\mathbb{E}[X]=Var[X]=\\mu$ æˆ‘å€‘å†ä¾†æ¨å°ä¸€å€‹å®šç†, è©²å®šç†è®“æˆ‘å€‘æœ‰ç¬¬ä¸‰ç¨® Poisson process çš„å®šç¾©. ä¸”è·Ÿ queueing theory æœ‰é—œè¯.ç•¶åœ¨ä¸€å€‹æ¥µçŸ­çš„æ™‚é–“æ®µä¹‹å…§, Poisson process èƒ½åˆ†æˆä¸‰ç¨®æƒ…æ³:&emsp;1. æ²’æœ‰äº‹ä»¶ç™¼ç”Ÿ&emsp;2. äº‹ä»¶ç™¼ç”Ÿ $1$ æ¬¡&emsp;3. äº‹ä»¶ç™¼ç”Ÿ $\\geq 2$ æ¬¡ å®šç¾© $f(h)=o(g(h))$ ç‚º$\\lim_{h\\rightarrow0}\\frac{f(h)}{g(h)}=0$ ç›´è§€ç†è§£ç‚º $f(h)$ æ¯” $g(h)$ å°çš„æ›´å¿«. [Thm] Poisson process åœ¨æ¥µå°æ™‚é–“æ®µçš„è¡Œç‚º:&emsp;$$\\left\\{ \\begin{array}{rl} \\mathcal{P}\\{N_{t+h}-N_t=0\\} = 1 -\\lambda h + o(h), &amp; h\\rightarrow0 \\\\ \\mathcal{P}\\{N_{t+h}-N_t=1\\} = \\lambda h + o(h), &amp; h\\rightarrow0 \\\\ \\mathcal{P}\\{N_{t+h}-N_t\\geq2\\} = o(h), &amp; h\\rightarrow0 \\end{array} \\right.$$[Proof]:&emsp;æˆ‘å€‘å…ˆè­‰æ˜ $=0$ çš„æƒ…æ³&emsp;æ ¹æ“šä¹‹å‰çš„ å®šç¾©2 æˆ‘å€‘çŸ¥é“ $\\mathcal{P}\\{N_{t+h}-N_t=0\\}=e^{-\\lambda h}$, å‰‡&emsp;$$\\lim_{h\\rightarrow0}\\frac{1-\\mathcal{P}\\{N_{t+h}-N_t=0\\}}{h} = \\lim_{h\\rightarrow0}\\frac{1-e^{-\\lambda h}}{h}\\\\ \\text{by L&apos;Hospital&apos;s rule} = \\lim_{h\\rightarrow0}\\frac{\\lambda e^{-\\lambda h}}{1} = \\lambda$$&emsp;i.e., as $h\\rightarrow0$,&emsp;$$\\frac{1-\\mathcal{P}\\{N_{t+h}-N_t=0\\}}{h} = \\lambda + o(1) \\\\ \\Rightarrow \\mathcal{P}\\{N_{t+h}-N_t=0\\} = 1-\\lambda h + ho(1) \\\\ = 1-\\lambda h + o(h)$$&emsp;$o(h)$ çš„æ­£è² è™Ÿä¸é‡è¦, Q.E.D.&emsp;è€Œ $\\mathcal{P}\\{N_{t+h}-N_t=1\\} = \\lambda h + o(h), h\\rightarrow0$ é€™ä¸€æ¢å¯ä»¥è—‰ç”±è¨ˆç®—&emsp;$$\\lim_{h\\rightarrow0}\\frac{\\mathcal{P}\\{N_{t+h}-N_t=1\\}}{h} = \\lim_{h\\rightarrow0}\\frac{e^{-\\lambda h}\\lambda h}{h}\\\\ \\text{by L&apos;Hospital&apos;s rule} = \\lim_{h\\rightarrow0}\\frac{-\\lambda e^{-\\lambda h}\\lambda h + \\lambda e^{-\\lambda h}}{1} = \\lambda$$&emsp;i.e., as $h\\rightarrow0$,&emsp;$$\\frac{\\mathcal{P}\\{N_{t+h}-N_t=1\\}}{h} = \\lambda + o(1) \\\\ \\Rightarrow \\mathcal{P}\\{N_{t+h}-N_t=1\\} = \\lambda h + o(h)$$&emsp;Q.E.D. &emsp;æœ€å¾Œ, $\\mathcal{P}\\{N_{t+h}-N_t\\geq2\\}=1-\\mathcal{P}\\{N_{t+h}-N_t=0\\} - \\mathcal{P}\\{N_{t+h}-N_t=1\\}$ å¯ä»¥è¨ˆç®—å¾—åˆ°&emsp;æ³¨æ„åˆ° $-o(h)=o(h)$, $2o(h)=o(h)$&emsp;Q.E.D. [Poisson Processes Def3] from queueing process:&emsp;Poisson process is an integer-valued process, $N_t$, with $N_0=0$ a.s. (almost surely), such that&emsp;1. $N_t$ has independent increments&emsp;&emsp; $\\forall t_0&lt;t_1&lt;...&lt;t_n$, we have $N_{t_1}-N_{t_0}, ..., N_{t_n}-N_{t_{n-1}}$ are independent&emsp;2. $N_t$ has stationary increments&emsp;&emsp;$N_t-N_s$ èˆ‡ $N_{t-s}$ å…·æœ‰ç›¸åŒçš„ distribution&emsp;3. æ»¿è¶³:&emsp;&emsp;$\\lim_{h\\rightarrow0} \\frac{\\mathcal{P}\\{N_{t+h} - N_t\\geq2\\}}{\\mathcal{P}\\{N_{t+h}-N_t=1\\}}=0$ å®šç¾© 2 å’Œå®šç¾© 3 çš„å·®åˆ¥åªåœ¨ç¬¬ 3 é»çš„æ¢ä»¶. ç„¶è€Œå…©ç¨®å®šç¾©ç­‰åƒ¹.æˆ‘å€‘å…¶å¯¦å·²ç¶“è­‰æ˜äº† (å®šç¾© 2 $\\Rightarrow$ å®šç¾© 3), ä½†å¦ä¸€å€‹æ–¹å‘é‚„æ²’æœ‰ Week 2.8-9: Non-homogeneous Poisson processesä¹Ÿå¯ä»¥åƒè€ƒ https://www.randomservices.org/random/poisson/Nonhomogeneous.html, ä½†å°æˆ‘ä¾†èªªæœ‰é»é›£æ‡‚ [Non-homogeneous Poisson Processes Def1]:&emsp;Let $\\Lambda(t)$ be a differentiable increasing function, and $\\Lambda(0)=0$,&emsp;$N_t$ is a N.H.P.P. (Non-Homogeneous Poisson Processes), if&emsp;1. $N_0=0$&emsp;2. $N_t$ has independent increments&emsp;3. $N_t-N_s \\sim Pois(\\Lambda(t)-\\Lambda(s))$&emsp;&emsp;$${\\color{orange} { \\mathcal{P}\\{N_t=n\\} \\sim Pois(\\Lambda(t))=e^{-\\Lambda(t)}\\frac{\\Lambda(t)^n}{n!} } }$$&emsp;å®šç¾© $\\lambda(t) = \\Lambdaâ€™(t)$, ç¨± intensity function åœ¨ P.P. çš„å®šç¾© 2, æˆ‘å€‘çŸ¥é“ $N_t-N_s\\sim Pois(\\lambda(t-s))$, æ‰€ä»¥ç•¶ $\\Lambda(t)=\\lambda t$ çš„è©±, non-homogeneous P.P. ç­‰æ–¼ P.P. æˆ‘å€‘å¯ä»¥ç™¼ç¾ non-homogeneous å»æ‰ stationary increment ç‰¹æ€§, ä¹Ÿå°±æ˜¯ Poisson distribution çš„ rate $\\lambda$ åœ¨æ¯å€‹æ™‚é–“æ®µè½ä¸ä¸€å®šæœƒéƒ½ä¸€æ¨£, depends on $\\Lambda(t)$ [Properties of N.H.P.P.]:&emsp;1. $\\mathbb{E}[N_t]=\\Lambda(t)$&emsp;&emsp;æˆ‘å€‘ç®—ä¸€ä¸‹ $\\mathbb{E}[N_t]$ for N.H.P.P.:&emsp;&emsp;$N_t = N_t - N_0 \\sim Pois(\\Lambda(t)-\\Lambda(0))=Pois(\\Lambda(t))$&emsp;&emsp;$\\therefore \\mathbb{E}[N_t]=\\Lambda(t)$&emsp;2. å¦‚æœ $\\lambda(t)=\\text{const} \\Rightarrow \\Lambda(t) = \\text{const}\\cdot t$, å›é€€åˆ°åŸä¾†çš„ (homogeneous) P.P.&emsp;3. å› ç‚º $\\Lambda(t)$ is differentialble and increasing, æ‰€ä»¥ $\\Lambda^{-1}(t)$ å­˜åœ¨&emsp;&emsp;è®“æˆ‘å€‘å‡è¨­ $\\text{Image}(\\Lambda(t))=\\mathbb{R}^+$, æ‰€ä»¥ $\\Lambda^{-1}(t)$ å°æ–¼ $t\\in\\mathbb{R}^+$ éƒ½æ˜¯ well defined&emsp;&emsp;å°æ–¼ä¸€å€‹ N.H.P.P. çš„ $N_t$ ä¾†èªª, è€ƒæ…® $N_{\\Lambda^{-1}(t)}$ é€™äº› r.v.s çš„è©±, æœƒç™¼ç¾è®Šæˆäº† homogeneous P.P. äº†! ç¬¬ä¸‰é»æä¾›äº†ä¸€å€‹ N.H.P.P. èˆ‡ P.P. çš„å°æ‡‰æ–¹æ³•ä½†å…·é«”ä¾†èªª, å¦‚æœä¸€å€‹ N.H.P.P. å‰›å¥½æ˜¯ P.P. çš„è©±, iff ä»–ä¹Ÿæ˜¯å€‹ renewal process, ä¸‹ä¸€ç¯€è­‰æ˜ Week 2.10-12: Relation between renewal theory and non-homogeneous Poisson processesæˆ‘å€‘è©¦è‘—å¾ä¸€å€‹ $N_t$ æ˜¯ N.H.P.P. å»å»ºæ§‹ renewal process çœ‹çœ‹, æˆ‘å€‘æœ‰å¦‚ä¸‹çš„ N.H.P.P.Renewal process çš„ arrival time $S_n$ å¯ä»¥é€™éº¼æ§‹å»º$S_n=\\arg\\min_t\\{N_t=n\\}$ $\\{N_t=n\\}$ è¡¨ç¤ºç™¼ç”Ÿ $n$ æ¬¡äº‹ä»¶çš„æ™‚é–“çš„é›†åˆ, æ‰€ä»¥å¾ˆé¡¯ç„¶çš„å–æœ€å°é‚£å€‹å°±æ˜¯å‰›å‰›å¥½ç¬¬ $n$ å€‹äº‹ä»¶ç™¼ç”Ÿçš„æ™‚é–“, i.e. $=S_n$æœ‰ $S_n$ å°±å¯ä»¥å¾—åˆ° interarrival time $\\xi_n=S_n-S_{n-1}$ é€™æ¨£å­çš„ arrival times $S_n$ and interarrival times $\\xi_n$ æ˜¯ä¸€å€‹ renewal process å—?é¦–å…ˆæˆ‘å€‘çŸ¥é“è‹¥è¦æˆç‚ºä¸€å€‹ renewal process, $\\xi_1, \\xi_2, â€¦$ å¿…é ˆæ˜¯ i.i.d. æ‰è¡ŒNote that:$${ \\mathcal{P}\\{N_t=n\\} \\sim Pois(\\Lambda(t))=e^{-\\Lambda(t)}\\frac{\\Lambda(t)^n}{n!} }$$ å…ˆè­‰æ˜ä»¥ä¸‹å…©å€‹ç­‰å¼: $\\mathcal{P}_{\\xi_1}(x)=\\lambda(x)e^{-\\Lambda(x)}$:[Proof]:&emsp;$$\\mathcal{P}\\{\\xi_1\\leq x\\}=\\mathcal{P}\\{S_1\\leq x\\}=\\mathcal{P}\\{N_x\\geq 1\\} = 1 - \\mathcal{P}\\{N_x=0\\} \\\\ = 1- Pois(\\Lambda(x)) = 1-e^{-\\Lambda(x)}$$&emsp;ç”¨åˆ° $\\{S_n\\leq t\\}=\\{N_t\\geq n\\}$, ç„¶å¾Œå·¦å³ç­‰å¼å¾®åˆ†å¾—åˆ°:&emsp;$\\mathcal{P}_{\\xi_1}(x)=\\lambda(x)e^{-\\Lambda(x)}$&emsp;å…¶ä¸­ $\\lambda=\\Lambdaâ€™$, Q.E.D. $\\mathcal{P}_{(\\xi_2|\\xi_1)}(t|s)=\\lambda(t+s)e^{-\\Lambda(t+s)+\\Lambda(s)}$:[Proof]:&emsp;å…ˆè¨ˆç®—ä¸€ä¸‹å…©å€‹ r.v.s $\\xi_1,\\xi_2$ çš„ joint C.D.F. $\\mathcal{F}_{\\xi_1,\\xi_2}(s,t)$ &emsp;$$\\mathcal{F}_{(\\xi_1,\\xi_2)}(\\xi_1=s,\\xi_2=t)=\\mathcal{P}\\{\\xi_1\\leq s, \\xi_2\\leq t\\} \\\\ =\\int_{y=0}^s \\mathcal{P}\\{ \\xi_1\\leq s, \\xi_2\\leq t \\vert \\xi_1=y \\} \\mathcal{P}_{\\xi_1}(y)dy$$&emsp;$\\because y\\leq s$&emsp;$$=\\int_{y=0}^s \\mathcal{P}\\{ \\xi_2\\leq t \\vert \\xi_1=y \\} \\mathcal{P}_{\\xi_1}(y) dy \\\\ = \\int_{y=0}^s \\mathcal{P}\\{ N_{t+y} - N_y \\geq 1 \\vert \\xi_1 = y \\} \\mathcal{P}_{\\xi_1}(y) dy \\ldots(\\star)$$&emsp;ç”± N.H.P.P. çš„ independent increments ç‰¹æ€§çŸ¥é“ $(N_{t+y} - N_y),(N_y-N_0)$ é€™å…©å€‹ r.v.s ç‚º independent. å› æ­¤&emsp;$$\\mathcal{P}\\{N_{t+y} - N_y \\geq 1 | \\xi_1=y\\} = \\mathcal{P}\\{ N_{t+y} - N_y \\geq 1 | N_y-N_0=1 \\} \\\\ = \\mathcal{P}\\{N_{t+y} - N_y \\geq 1 \\}$$&emsp;æ¥çºŒ $(\\star)$&emsp;$$(\\star) = \\int_{y=0}^s \\mathcal{P}\\{ N_{t+y}-N_y \\geq 1 \\} \\cdot \\mathcal{P}_{\\xi_1}(y) dy \\\\ = \\int_{y=0}^s (1 - \\mathcal{P}\\{ N_{t+y}-N_y = 0 \\}) \\cdot \\mathcal{P}_{\\xi_1}(y) dy \\\\ = \\int_{y=0}^s (1 - e^{-\\Lambda(t+y)+\\Lambda(y)}) \\cdot \\lambda(y)e^{-\\Lambda(y)} dy$$&emsp;æ‰€ä»¥å…©å€‹ r.v.s $\\xi_1,\\xi_2$ çš„ joint C.D.F.&emsp;$\\mathcal{F}_{(\\xi_1,\\xi_2)}(s,t) = \\int_{y=0}^s (1 - e^{-\\Lambda(t+y)+\\Lambda(y)}) \\cdot \\lambda(y)e^{-\\Lambda(y)} dy$&emsp;å¾®åˆ†å¯ä»¥è¨ˆç®— P.D.F.&emsp;$$\\mathcal{P}_{(\\xi_1,\\xi_2)}(s,t) = \\frac{\\partial}{\\partial t} \\left( \\frac{\\partial}{\\partial s} \\mathcal{F}_{(\\xi_1,\\xi_2)}(s,t) \\right) \\\\ \\text{replace y by s} = \\frac{\\partial}{\\partial t} \\left( (1 - e^{-\\Lambda(t+s)+\\Lambda(s)}) \\cdot \\lambda(s)e^{-\\Lambda(s)} \\right) \\\\ = \\lambda(t+s) e^{-\\Lambda(t+s)+\\Lambda(s)}\\cdot \\lambda(s) e^{-\\Lambda(s)} \\\\ = \\lambda(t+s) e^{-\\Lambda(t+s)+\\Lambda(s)} \\cdot \\mathcal{P}_{\\xi_1}(s)$$&emsp;æ‰€ä»¥&emsp;$$\\mathcal{P}_{(\\xi_2|\\xi_1)}(t|s) = \\frac{\\mathcal{P}_{(\\xi_1,\\xi_2)}(s,t)}{\\mathcal{P}_{\\xi_1}(s)} \\\\ =\\lambda(t+s)e^{-\\Lambda(t+s)+\\Lambda(s)}$$&emsp;Q.E.D. å›åˆ°è€ƒæ…®ä»€éº¼æƒ…æ³ä¸‹çš„ N.H.P.P. çš„ $\\xi_1, \\xi_2, â€¦$ æ˜¯ i.i.d. é€™å€‹å•é¡Œæˆ‘å€‘å…ˆå‡è¨­ $\\xi_1, \\xi_2, â€¦$ æ˜¯ i.i.d., i.e. å‡è¨­ N.H.P.P. æ˜¯ renewal process, å‰‡$$\\mathcal{P}_{\\xi_2 | \\xi_1}(t|s)=\\mathcal{P}_{\\xi_2}(t) \\\\ \\because\\text{i.i.d.}=\\mathcal{P}_{\\xi_1}(t), \\forall t,s&gt;0$$å¸¶å…¥æˆ‘å€‘èŠ±å¾ˆå¤šåŠ›æ°£æ¨å°çš„ä¸Šè¿°å…©å€‹çµæœå¾—åˆ°:$\\lambda(t+s)e^{-\\Lambda(t+s)+\\Lambda(s)} = \\lambda(t)e^{-\\Lambda(t)}$ç„¶å¾Œå°å…©é‚Šéƒ½åšç©åˆ† $\\int_0^T\\lambda(t+s)e^{-\\Lambda(t+s)+\\Lambda(s)} dt = \\int_0^T \\lambda(t)e^{-\\Lambda(t)} dt \\ldots (\\square)$ $(\\square)$ R.H.S.:$$\\int_0^T \\lambda(t)e^{-\\Lambda(t)} dt = \\int_0^T e^{-\\Lambda(t)}d\\Lambda(t) \\left(= \\int_0^Te^{-y}dy\\right) \\\\ = -e^{-\\Lambda(T)}+e^{-\\Lambda(0)} = 1 -e^{-\\Lambda(T)}$$ $(\\square)$ L.H.S. åŒç†$$\\int_0^T\\lambda(t+s)e^{-\\Lambda(t+s)+\\Lambda(s)} dt = e^{\\Lambda(s)}\\int_0^T e^{-\\Lambda(t+s)} d\\Lambda(t+s) \\\\ \\left(\\text{this as: }e^{\\Lambda(s)}\\int e^{-y}dy\\right) \\\\ = e^{\\Lambda(s)} \\left[\\left. -e^{\\Lambda(t+s)}\\right|_{t=0}^T \\right] = e^{\\Lambda(s)}\\left[-e^{-\\Lambda(T+s)}+e^{-\\Lambda(s)}\\right] = -e^{-\\Lambda(T+s)+\\Lambda(s)}+e^0$$ æ‰€ä»¥ L.H.S = R.H.S.$$\\Rightarrow e^0-e^{-\\Lambda(T+s)+\\Lambda(s)} = 1 - e^{-\\Lambda(T)} \\\\ \\Rightarrow \\Lambda(T+s) - \\Lambda(s) = \\Lambda(T), \\forall T,s&gt;0$$ å› ç‚º $\\Lambda$ is increasing function, ä¸Šå¼çŸ¥é“æ˜¯ linear function, æ‰€ä»¥æœƒå¾—åˆ° $\\Lambda(t)=\\text{const}\\cdot t$è€Œé€™æ­£å¥½è¡¨æ˜äº† N.H.P.P. è®Šæˆäº† homogeneous P.P. äº† çµè«–æ˜¯:N.H.P.P. is a renewal process $\\Longleftrightarrow$ $\\Lambda (t)=\\lambda t$ (i.e. æ­¤æ™‚çš„ N.H.P.P. ä¹Ÿè®Šæˆ homogenous äº†) $(\\Longleftarrow)$ è­‰æ˜å¾ˆå®¹æ˜“, å› ç‚º homogeneous P.P. æ˜¯ renewal process æ›å¥è©±èªª N.H.P.P. is a renewal process $\\Longleftrightarrow$ it is homogenous P.P. Week 2.13: Elements of the queueing theory. M/G/k systems-1æˆ‘å€‘å…ˆå‰è­‰æ˜é [Thm] Poisson process åœ¨æ¥µå°æ™‚é–“æ®µ:&emsp;$$\\left\\{ \\begin{array}{rl} \\mathcal{P}\\{N_{t+h}-N_t=0\\} = 1 -\\lambda h + o(h), &amp; h\\rightarrow0 \\\\ \\mathcal{P}\\{N_{t+h}-N_t=1\\} = \\lambda h + o(h), &amp; h\\rightarrow0 \\\\ \\mathcal{P}\\{N_{t+h}-N_t\\geq2\\} = o(h), &amp; h\\rightarrow0 \\end{array} \\right.$$ å°æ–¼ N.H.P.P. ä¹Ÿæœ‰é¡ä¼¼çš„çµæœ [Thm] Non-homogeneous Poisson process åœ¨æ¥µå°æ™‚é–“æ®µ:&emsp;$$\\left\\{ \\begin{array}{rl} \\mathcal{P}\\{N_{t+h}-N_t=0\\} = 1 -{\\color{orange}{\\lambda(t)}} h + o(h), &amp; h\\rightarrow0 \\\\ \\mathcal{P}\\{N_{t+h}-N_t=1\\} = {\\color{orange}\\lambda(t)} h + o(h), &amp; h\\rightarrow0 \\\\ \\mathcal{P}\\{N_{t+h}-N_t\\geq2\\} = o(h), &amp; h\\rightarrow0 \\end{array} \\right.$$ æ‰€ä»¥é¡ä¼¼çš„å°æ–¼ N.H.P.P. æˆ‘å€‘ä¹Ÿæœ‰å¦ä¸€ç¨®å®šç¾© (é¡ä¼¼ [Poisson Processes Def3]) [Non-homogeneous Poisson Processes Def2]:&emsp;Let $\\Lambda(t)$ be a differentiable increasing function, and $\\Lambda(0)=0$,&emsp;$N_t$ is a N.H.P.P. (Non-Homogeneous Poisson Processes), if&emsp;1. $N_0=0$&emsp;2. $N_t$ has independent increments&emsp;3. æ»¿è¶³:&emsp;&emsp;$\\lim_{h\\rightarrow0} \\frac{\\mathcal{P}\\{N_{t+h} - N_t\\geq2\\}}{\\mathcal{P}\\{N_{t+h}-N_t=1\\}}=0$ (Non-homogeneous) Poisson processes å¾ˆé©åˆç”¨ä¾† modeling queueing processes. æˆ‘å€‘ç”¨ $M,D,G$ ä¾†è¡¨ç¤º distribution ç¨®é¡: $M$: exponential distribution. æ‰€ä»¥å¦‚æœç”¨ä¾†æè¿° arrival processes (memoryless) å°±æœƒè®Šæˆ Poisson processes $D$: deterministic (constant distribution, å³ä¸å— time $t$ çš„å½±éŸ¿? é‚„æ˜¯é€£ value éƒ½æ˜¯ constant?) $G$: general, è¡¨ç¤ºå¯ä»¥æ˜¯ä»»ä½• distribution Queueing processes åŒ…å«äº†ä¸‰å€‹å­—æ¯, e.g. $M/G/k$, åˆ†åˆ¥è¡¨ç¤º Arrival process, Service time, å’Œ Number of servers Arrival process: $\\in\\{M,D,G\\}$ Service time: $\\in\\{M,D,G\\}$. åŒæ™‚ç‚º I.I.D. Number of servers: $\\in\\{1, 2, ..., \\infty\\}$ æˆ‘å€‘ä»¥å­¸ç”Ÿä¸Šæ©Ÿæˆ¿ç”¨é›»è…¦ä¾†èˆ‰ä¾‹, è‹¥ç”¨ queueing process ç‚º $M/G/\\infty$ ä¾†æè¿°çš„è©±Arrival processes (by Poisson process) æè¿°äº†å­¸ç”Ÿä¾†çš„ $N(t)$Service time è¡¨ç¤ºå­¸ç”Ÿæœƒç”¨å¤šä¹…é›»è…¦, ç”¨ $G_Y(t)$ é€™å€‹ distribution æè¿°è€Œé›»è…¦ (server) çš„æ•¸é‡ç‚º $\\infty$, è¡¨ç¤ºå­¸ç”Ÿä¸€åˆ°å°±é¦¬ä¸Šæœ‰ä¸€å°é›»è…¦å¯ä»¥ç”¨, ç„¡éœ€ç­‰å¾… (æ›´è¤‡é›œçš„ queueing process æœƒè€ƒæ…®ç­‰å¾…æ™‚é–“)æ‰€ä»¥ $N(t)$ æ˜¯ä¸€å€‹ Poisson process, è€ƒæ…®ä¸€å€‹ fixed time $\\tau&gt;0$, æˆ‘å€‘æœƒæœ‰å…©å€‹ processes $N_1(t)$ and $N_2(t)$.$N_1(t)$ è¡¨ç¤ºæœ‰å¤šå°‘ é‚„åœ¨è™•ç† çš„äº‹ä»¶ at time $\\tau$ (å³åœ¨æ™‚é–“ $\\tau$ é‚„æœ‰å¤šå°‘å­¸ç”Ÿåœ¨ç”¨é›»è…¦)$N_2(t)$ è¡¨ç¤ºæœ‰å¤šå°‘ å·²è™•ç†å®Œ çš„äº‹ä»¶ at time $\\tau$ (å³åœ¨æ™‚é–“ $\\tau$ å·²æœ‰å¤šå°‘å­¸ç”Ÿç”¨å®Œé›»è…¦) $t$ and $\\tau$ çš„é—œä¿‚åœ¨è¨è«–å€æœ‰äººé€™éº¼å›ç­” è€ƒæ…® $N_1(t+h) - N_1(t)$, é€™å€‹å€¼è¡¨ç¤ºåœ¨é€™ä¸€æ®µæ™‚é–“å…§å…±ä¾†äº†å¤šå°‘äº‹ä»¶ä¸¦ä¸”é‚„åœ¨è™•ç† (å³é€™æ®µæ™‚é–“ä¾†äº†å¤šå°‘å­¸ç”Ÿ, ä¸¦ä¸”é€™äº›å­¸ç”Ÿéƒ½é‚„åœ¨ç”¨é›»è…¦), æ‰€ä»¥:$$\\mathcal{P}\\{ N_1(t+h)-N_1(t)=1 \\} \\\\ = \\mathcal{P}\\{ N(t+h)-N(t)=1 \\} \\cdot \\mathcal{P}\\{ Y&gt;\\tau-t \\} + o(h) \\ldots(\\blacktriangle)$$ $Y$ è¡¨ç¤º service time çš„ random variable, å…¶ distribution ç‚º $G_Y(t)$ â€œé€™æ®µ $h$ æ™‚é–“ä¾†äº†å¤šå°‘å­¸ç”Ÿ, ä¸¦ä¸”é€™äº›å­¸ç”Ÿéƒ½é‚„åœ¨ç”¨é›»è…¦â€ å¯ä»¥è¿‘ä¼¼æ–¼:â€œé€™æ®µ $h$ æ™‚é–“ä¾†äº† $1$ å€‹å­¸ç”Ÿ, ä¸¦ä¸”é€™ $1$ å€‹å­¸ç”Ÿé‚„åœ¨ç”¨é›»è…¦â€ + $o(h)$æ³¨æ„åˆ° $2$ å€‹å­¸ç”Ÿä»¥ä¸Šçš„æƒ…å½¢æˆ‘å€‘ç”¨ $o(h)$ è¡¨ç¤ºå³å¯, é€™æ˜¯å› ç‚º Poisson process çš„ä¸€å€‹æ€§è³ª:$\\mathcal{P}\\{N_{t+h}-N_t\\geq2\\} = o(h),h\\rightarrow0$ æ‰€ä»¥ç”¨ä¸Šé–‹é ­çš„ Theorem,$$(\\blacktriangle) = (\\lambda h + o(h)) \\cdot (1-G_Y(\\tau-t)) + o(h) \\\\ = \\lambda h(1-G_Y(\\tau-t)) + o(h)$$ é‡è¿°ä¸€é, æˆ‘å€‘æœ‰:$\\mathcal{P}\\{ N_1(t+h)-N_1(t)=1 \\} = \\lambda(1-G_Y(\\tau-t))h + o(\\delta)$ä»¤ $\\lambda(1-G_Y(\\tau-t))$ ç­‰æ–¼æŸå€‹ function $\\lambda_1(t)$, å‰‡ä¸Šå¼èˆ‡ N.H.P.P. çš„æ€§è³ªçµæœç›¸åŒ.åŒæ¨£å¯ä»¥å° $\\mathcal{P}\\{ N_1(t+h)-N_1(t)=0 \\}$ å’Œ $\\mathcal{P}\\{ N_1(t+h)-N_1(t)\\geq2 \\}$ æ¨å°å‡ºç›¸åŒçµæœ. æ‰€ä»¥æ ¹æ“š [Non-homogeneous Poisson Processes Def2] æˆ‘å€‘å¾—åˆ° $N_1$ æ˜¯ N.H.P.P. çš„çµè«– $N_1$ æ˜¯ N.H.P.P. ä¸”å…¶ intensity function $\\lambda_1(t)=\\lambda(1-G_Y(\\tau-t))$ æˆ‘å€‘å°æ–¼ $N_1$ çš„æ¨è«–åŒæ¨£ä¹Ÿå¯ä»¥ç”¨åœ¨ $N_2$ ä¸Š, çµæœä¹Ÿæ˜¯ä¸€æ¨£: $N_2$ æ˜¯ N.H.P.P. ä¸”å…¶ intensity function $\\lambda_2(t)=\\lambda \\cdot G_Y(\\tau-t)$ ä¸‹ä¸€ç¯€èª²æœƒè­‰æ˜ $N_1$ and $N_2$ ç‚ºäº’ç›¸ç¨ç«‹çš„ r.v.s Week 2.14: Elements of the queueing theory. M/G/k systems-2æ¬²è­‰ $\\mathcal{P}\\{N_1(t)=n_1, N_2(t)=n_2\\} = \\mathcal{P}\\{N_1(t)=n_1\\}\\mathcal{P}\\{ N_2(t)=n_2\\}$$$\\mathcal{P}\\{N_1(t)=n_1, N_2(t)=n_2\\}\\\\ = \\mathcal{P}\\{ N_1(t)=n_1, N_2(t)=n_2 | N(t)=n_1+n_2 \\} \\cdot \\mathcal{P}\\{N(t)=n_1+n_2\\} \\\\ = \\mathcal{C}_{n_1}^{n_1+n_2}(1-G(\\tau-t))^{n_1}(G(\\tau-t))^{n_2} \\cdot e^{-\\lambda t}\\frac{(\\lambda t)^{n_1+n_2}}{(n_1+n_2)!} \\ldots(=)$$$(=)$ ç‚º Binomial term, æŠŠâ€æˆåŠŸâ€çš„æ©Ÿç‡ç•¶æˆ â€œäº‹ä»¶åœ¨æ™‚é–“ $\\tau$ é‚„åœ¨servedçš„æ©Ÿç‡â€, é€™å€‹æ©Ÿç‡ç”± service time çš„ distribution probability å¯ä»¥çŸ¥é“:$\\mathcal{P}\\{Y&gt;(\\tau-t)\\}=1-\\mathcal{P}\\{Y\\leq(\\tau-t)\\}=1-G(\\tau-t)$ æ‰€ä»¥å¤±æ•—çš„è©±å°±æ˜¯ $G(\\tau-t)$å…±æœ‰ $n$ å€‹äº‹ä»¶, å…±æœ‰ $n_1$ å€‹äº‹ä»¶ $\\in N_1(t)$, and $n_2$ å€‹äº‹ä»¶ $\\in N_2(t)$, æ‰€ä»¥ $\\mathcal{C}_{n_1}^{n_1+n_2}$ $$(=)= \\frac {(\\lambda t(1-G(\\tau-t)))^{n_1}}{n_1!} e^{-\\lambda t(1-G(\\tau-t))} \\cdot \\frac {(\\lambda tG(\\tau-t))^{n_2}}{n_2!} e^{-\\lambda tG(\\tau-t)} \\\\ =\\mathcal{P}\\{N_1(t)=n_1\\}\\mathcal{P}\\{N_2(t)=n_2\\}$$ æˆ‘ä¸çŸ¥é“çš„æ˜¯ç‚ºä½• $\\frac {(\\lambda t(1-G(\\tau-t)))^{n_1}}{n_1!} e^{-\\lambda t(1-G(\\tau-t))} = \\mathcal{P}\\{N_1(t)=n_1\\}$å› ç‚ºåªçŸ¥é“ $N_1$ æ˜¯ N.H.P.P. ä¸”å…¶ intensity function $\\lambda_1(t)=\\lambda(1-G_Y(\\tau-t))$æ‰€ä»¥å¿…é ˆæ±‚å¾— $\\Lambda_1(t)$ æ‰èƒ½ä»£å…¥$\\mathcal{P}\\{N_t=n\\} \\sim Pois(\\Lambda(t))=e^{-\\Lambda(t)}\\frac{\\Lambda(t)^n}{n!}$æ‰€ä»¥çœ‹èµ·ä¾† $\\Lambda_1(t)=\\lambda t(1-G(\\tau-t))?$ ä¸æ‡‚â€¦ Q.E.D. Week 2.15-17: Compound Poisson processeså¯åƒè€ƒä¸€å€‹æ·ºé¡¯æ˜“æ‡‚çš„å®šç¾©: https://gtribello.github.io/mathNET/COMPOUND_POISSON_PROCESS.html [Compound Poisson Processes (C.P.P.) Def]:&emsp;$X_t=\\sum_{k=1}^{N_t} \\xi_k$&emsp;å…¶ä¸­&emsp;- $N_t$ æ˜¯ Poisson process with intensity $\\lambda$&emsp;- $\\xi_1,\\xi_2,â€¦$ are i.i.d.&emsp;- $\\xi_1,\\xi_2,â€¦$ and $N_t$ are independent $X_t$ çš„ distribution æ²’æœ‰ cloded form, ä½†è‹¥æ˜¯æŸäº›ç‰¹å®šçš„ $\\xi$ distribution å¯ä»¥ç®—å‡ºä¾†. æ³¨æ„åˆ°è‹¥ $\\xi_k=1$, å‰‡ $X_t=N_t$, å¯è—‰æ­¤æƒ³åƒä¸€ä¸‹ C.P.P. çš„ç‰©ç†æ„ç¾© å¦‚æœ $\\xi$ (C.P.P.) æ˜¯ non-negative integer values, æˆ‘å€‘ä½¿ç”¨ PGF å¹«åŠ©è¨ˆç®—[Probability Generating Function (PGF) Def]:&emsp;Let $\\xi$ æ˜¯ä¸€å€‹ integer çš„ random variable, with $\\geq 0$ values. å‰‡ PGF å®šç¾©ç‚º:&emsp;$\\varphi_\\xi(u)=\\mathbb{E}[u^\\xi], \\text{ where }|u|&lt;1$ æ ¹æ“šå®šç¾©æˆ‘å€‘å¯ä»¥å¾—åˆ° (expectation å¯«å‡ºä¾†), å¦‚æœ $\\xi_1 \\perp \\xi_2$, å‰‡ $\\varphi_{\\xi_1+\\xi_2}(u)=\\varphi_{\\xi_1}(u)\\varphi_{\\xi_2}(u)$ å¦‚æœ $\\xi$ (C.P.P.) æ˜¯ non-negative (real) values, æˆ‘å€‘ä½¿ç”¨ MGF å¹«åŠ©è¨ˆç®—[Moment Generating Function (MGF) Def]:&emsp;è·Ÿ Laplace transform å¯†åˆ‡ç›¸é—œ.&emsp;$\\mathcal{L}_\\xi(u)=\\mathbb{E}[e^{-u\\xi}], \\text{ where } \\xi\\geq0, u&gt;0$ å…¶å¯¦å°±æ˜¯ $\\mathcal{L}_f(s)=\\int_{x=0}^\\infty e^{-sx}f(x)dx$, å°‡ $f$ ä»¥ $\\xi$ çš„ P.D.F. ä»£å…¥ æ ¹æ“šå®šç¾©æˆ‘å€‘å¯ä»¥å¾—åˆ°, å¦‚æœ $\\xi_1 \\perp \\xi_2$, å‰‡ $\\mathcal{L}_{\\xi_1+\\xi_2}(u)=\\mathcal{L}_{\\xi_1}(u)\\mathcal{L}_{\\xi_2}(u)$. æ³¨æ„åˆ° ${\\xi_1+\\xi_2}$ å…¶ P.D.F. æ˜¯ $\\xi_1,\\xi_2$ çš„ P.D.F.s çš„ convolution. ä¹‹å‰æˆ‘å€‘ä¹Ÿè­‰é Laplace transform é€™å€‹æ€§è³ª å°æ–¼ $\\xi$ (C.P.P.) æ˜¯ general case çš„æƒ…æ³ä¾†èªª, æˆ‘å€‘éœ€å€ŸåŠ© characteristic function å¹«å¿™[Characteristic Function Def]:&emsp;For random variable $\\xi$, å®šç¾© characteristic function $\\Phi:\\mathbb{R}\\rightarrow \\mathbb{C}$ ç‚º&emsp;$\\Phi_\\xi(u) = \\mathbb{E}\\left[ e^{iu\\xi} \\right]$ åŒæ¨£æ ¹æ“šå®šç¾©æˆ‘å€‘å¯ä»¥å¾—åˆ°, å¦‚æœ $\\xi_1 \\perp \\xi_2$, å‰‡ $\\Phi_{\\xi_1+\\xi_2}(u)=\\Phi_{\\xi_1}(u)\\Phi_{\\xi_2}(u)$ [Characteristic Function of Increment of C.P.P.]:&emsp;For $t&gt;s\\geq0$, and $X_t$ is a C.P.P., we have&emsp;$\\Phi_{X_t-X_s}(u)=e^{\\lambda(t-s)(\\Phi_{\\xi_1}(u)-1)}$[Proof]:&emsp;$$\\Phi_{X_t-X_s}(u)=\\mathbb{E}\\left[ e^{iu(X_t-X_s)} \\right] \\\\ =\\sum_{k=0}^\\infty {\\color{orange} {\\mathbb{E}\\left[ \\left. e^{iu(X_t-X_s)} \\right| N_t-N_s=k\\right]} } \\cdot {\\color{green} {\\mathcal{P}\\{N_t-N_s=k\\}} }$$&emsp;æ³¨æ„åˆ°å·²çŸ¥ $N_t-N_s=k$ çš„æƒ…æ³ä¸‹, $X_t-X_s$ æ ¹æ“š C.P.P. çš„å®šç¾©å°±æ˜¯ $\\xi_1+â€¦+\\xi_k$, å†åŠ ä¸Šæˆ‘å€‘çŸ¥é“ $\\xi\\perp N_t$, æ‰€ä»¥æ©˜è‰²éƒ¨åˆ†çš„ condition å°±å¯ä»¥æ‹”æ‰. åŒæ™‚å·²çŸ¥ç¶ è‰²éƒ¨åˆ†ç‚º Poisson Processes.&emsp;å› æ­¤:&emsp;$$= \\sum_{k=0}^\\infty \\mathbb{E}\\left[e^{iu(X_t-X_s)}\\right] \\cdot Pois(\\lambda(t-s)) \\\\ = \\sum_{k=0}^\\infty (\\Phi_{\\xi_1}(u))^k \\cdot e^{-\\lambda(t-s)}\\frac{(\\lambda(t-s))^k}{k!} \\\\ =e^{-\\lambda(t-s)}\\sum_{k=0}^\\infty\\frac{(\\Phi_{\\xi_1}(u)\\lambda(t-s))^k}{k!} \\\\ = e^{-\\lambda(t-s)}e^{\\Phi_{\\xi_1}(u)\\lambda(t-s)} =e^{\\lambda(t-s)(\\Phi_{\\xi_1}(u)-1)}$$&emsp;Q.E.D. æ­¤å®šç†æè¿°äº† increment of C.P.P. çš„ characteristic function, å…¶å…·æœ‰ closed form solutionæ‰€ä»¥ characteristic function of $X_t$ is$\\Phi_{X_t}(u)=e^{\\lambda t(\\Phi_{\\xi_1}(u)-1)}$ èª²ç¨‹è€å¸«èªªé€™å€‹ Theorem å¾ˆé‡è¦, å¯ä»¥æ ¹æ“šå®ƒæ¨å°å‡ºå¾ˆå¤š Corollaries [Expectation and Variance of C.P.P.]:&emsp;å°æ–¼æ­¤ç¯€å®šç¾©çš„ C.P.P. æˆ‘å€‘æœ‰&emsp;$$\\mathbb{E}[X_t]=\\lambda t\\mathbb{E}[\\xi_1] \\\\ Var[X_t]=\\lambda t\\mathbb{E}[\\xi_1^2]$$ åŸä¾†çš„ Poisson distribution $Pois(\\lambda t)$ çš„ mean and variance ç‚º $\\lambda t$, æ‰€ä»¥ C.P.P. ç­‰æ–¼å¤šä¹˜ä¸Š $\\xi_1$ çš„ moments [Proof]:&emsp;èª²ç¨‹è­‰ expectation, è€Œ variance å¯ç”¨åŒæ¨£æµç¨‹è­‰æ˜&emsp;$\\mathbb{E}[\\xi^r]&lt;\\infty\\Rightarrow\\Phi_\\xi(u)$ is r-times å¯å¾® at 0&emsp;å› ç‚º derivative and expectation éƒ½æ˜¯ç·šæ€§çš„, æ‰€ä»¥æˆ‘å€‘æœ‰&emsp;$\\Phi^{(1)}_\\xi(u)=\\frac{d}{du}\\mathbb{E}[e^{iu\\xi}]=\\mathbb{E}[(i\\xi)e^{iu\\xi}]$&emsp;$\\Phi^{(2)}_\\xi(u)=\\frac{d}{du}\\frac{d}{du}\\mathbb{E}[e^{iu\\xi}]=\\mathbb{E}[(i\\xi)^2 e^{iu\\xi}]$&emsp;$â€¦$&emsp;$\\Phi^{(r)}_\\xi(u)=\\mathbb{E}[(i\\xi)^r e^{iu\\xi}]$&emsp;$\\therefore \\Phi_\\xi^{(r)}(0)=i^r\\cdot\\mathbb{E}[\\xi^r]$&emsp;ç”±å‰é¢çš„ Theorem çŸ¥é“ $\\Phi_{X_t}(u)=e^{\\lambda t(\\Phi_{\\xi_1}(u)-1)}$, æ‰€ä»¥&emsp;$$\\Phi_{X_t}^{(1)}(u)=\\frac{d}{du}\\Phi_{X_t}(u) =\\frac{d}{du}e^{\\lambda t(\\Phi_{\\xi_1}(u)-1)} \\\\ =\\lambda t \\Phi_{\\xi_1}^{(1)}(u)e^{\\lambda t(\\Phi_{\\xi_1}(u)-1)} = \\lambda t \\Phi_{\\xi_1}^{(1)}(u)\\Phi_{X_t}(u)$$&emsp;è¨ˆç®— $\\mathbb{E}[X_t]$:&emsp;$$\\mathbb{E}[X_t]=\\frac{\\Phi_{X_t}^{(1)}(0)}{i} = \\frac{\\lambda t \\Phi_{ \\xi_1}^{(1)}(0) \\overbrace{\\Phi_{X_t}(0)}^{=1} } {i}$$&emsp;è€Œæ ¹æ“š characteristic function çš„ç‰¹æ€§&emsp;$\\frac{\\Phi_{\\xi_1}^{(1)}(0)}{i} = \\mathbb{E}[\\xi_1]$&emsp;æ‰€ä»¥ $\\mathbb{E}[X_t]=\\lambda t\\mathbb{E}[\\xi_1]$&emsp;Q.E.D. Applications of the Poisson Processes and Related ModelsApplications of the Poisson Processes and Related Models.pdf","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Poisson Process","slug":"Poisson-Process","permalink":"https://bobondemon.github.io/tags/Poisson-Process/"}]},{"title":"Stochastic Processes Week 1 Introduction & Renewal processes","date":"2021-12-11T12:56:53.000Z","path":"2021/12/11/Stochastic-Processes-Week-1-Introduction-Renewal-processes/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ Week 1: Introduction &amp; Renewal processes (æœ¬æ–‡) Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes Week 1.2: Difference between various fields of stochasticsæ•¸å­¸ä¸Šçš„ stochastics è·Ÿä¸‰å€‹ä¸»è¦å­¸ç§‘æœ‰é—œ: Probability theory Mathematical statistics stochastic processes ç”¨ä¸€å€‹æ± å­è£¡é¢çš„é­šä¾†ç•¶ä¾‹å­, å‡è¨­æˆ‘å€‘è¦åˆ†ææŸå€‹æ™‚é–“é»æ± å­è£¡æœ‰å¤šå°‘é­š, i.e. $N$ æ¢é­šProbability theory å°±æ˜¯æ‰¾å‡ºé€™å€‹ $N$ çš„æ©Ÿç‡åˆ†å¸ƒ, ç„¶å¾Œå¯ä»¥åˆ†æå…¶ mean, variance â€¦è€Œ mathematical statistics æ˜¯è—‰ç”±ä¸€äº›çµ±è¨ˆå¯¦é©—, å»ä¼°è¨ˆå‡º $N$ èˆ‰ä¾‹ä¾†èªª, æŠ“ $M$ æ¢é­šåšè¨˜è™Ÿå¾Œæ”¾å›æ± å­. ç„¶å¾Œä¸€æ¬¡å¯¦é©—ç‚ºæŠ“ $n$ æ¢é­š, è‹¥ç™¼ç¾æœ‰ $m$ æ¢åšéè¨˜è™Ÿ, å‰‡é€™å€‹æ©Ÿç‡æˆ‘å€‘å¯ä»¥ç®—å‡ºä¾†:$\\mathcal{P}\\{\\#\\text{marked}=m\\}=(C_M^m\\cdot C_{N-M}^{n-m})/C_N^n$ æˆ‘å€‘é‡è¤‡é€™å€‹å¯¦é©— $q$ æ¬¡, å¾—åˆ°çš„åšéè¨˜è™Ÿçš„é­šçš„æ¬¡æ•¸ç‚º ${m_1,m_2,â€¦,m_q}$, å› æ­¤å¯ä»¥ç®—å‡º log-likelihood:$L(N)=\\sum_{k=1}^q \\log\\mathcal{P}\\{\\#\\text{marked}=m_k\\}$ æ‰€ä»¥æ±‚è§£ $\\arg\\max_N L(N)$å°æ–¼ stochastic processes æˆ‘å€‘ä¹Ÿå¯ä»¥å•åŒæ¨£çš„å•é¡Œ: $N$ æ˜¯å¤šå°‘? ä¸éæ­¤æ™‚æœƒå¤šè€ƒæ…® $N$ éš¨è‘—æ™‚é–“è®ŠåŒ– Week 1.3: Probability spaceå»ºè­°å…ˆé–±è®€[æ¸¬åº¦è«–] Sigma Algebra èˆ‡ Measurable function ç°¡ä»‹: https://ch-hsieh.blogspot.com/2010/04/measurable-function.html[æ©Ÿç‡è«–] æ·ºè«‡æ©Ÿç‡å…¬ç† èˆ‡ åŸºæœ¬æ€§è³ª: https://ch-hsieh.blogspot.com/2013/12/blog-post_7.html èª²ç¨‹ä½¿ç”¨å…©å€‹éš¨æ©Ÿå¯¦é©— (å¦‚åŒä¸Šé¢çš„åƒè€ƒé€£çµ): å¾é–‰å€é–“ $[0,1]$ ä¹‹ä¸­ ä»»é¸ä¸€å€‹æ•¸å­— åš $n$ æ¬¡çš„ä¸ŸéŠ…æ¿å¯¦é©— æˆ‘å€‘å¼•ç”¨åƒè€ƒé€£çµçš„å®šç¾©$\\mathcal{F}$ æ˜¯ä¸€å€‹ collection of subsets of $\\Omega$, ä¹Ÿå°±æ˜¯èªªæ¯ä¸€å€‹ element éƒ½æ˜¯ä¸€å€‹ $\\Omega$ çš„ subset. é™¤æ­¤ä¹‹å¤–, é‚„å¿…é ˆæ˜¯ $\\sigma$-algebra. $\\sigma$-algebra å’Œ topology å®šç¾©å¯åƒè€ƒ https://www.themathcitadel.com/topologies-and-sigma-algebras/ æ‰€ä»¥ä¸€å€‹ â€œäº‹ä»¶â€ $A$ æ˜¯ä¸€å€‹ subset of $\\Omega$ (i.e. $A\\subseteq\\Omega$), ä¹Ÿæ˜¯ä¸€å€‹ element of $\\mathcal{F}$, (i.e. $A\\in\\mathcal{F}$). ğŸ’¡ æ³¨æ„ $A$ æ˜¯ subset of $\\Omega$, é‚„ä¸å¤ . $A$ é‚„å¿…é ˆå¾æ˜¯ $\\sigma$-algebra çš„ $\\mathcal{F}$ è£¡é¢æŒ‘. æœ€å¾Œ $\\mathcal{P}:\\mathcal{F} \\rightarrow [0,1]$ æ­¤å‡½æ•¸å¿…é ˆæ»¿è¶³ä»¥ä¸‹å…¬ç†å°æ¯” measure çš„å®šç¾©, ç›¸ç•¶æ–¼å¤šå‡ºäº†ä¸€æ¢ $P(\\Omega)=1$, æ‰€ä»¥ probability measure æ˜¯ä¸€å€‹ç‰¹æ®Šçš„ measureå†å°æ¯” measure space çš„å®šç¾©, å·®åˆ¥åªåœ¨æ–¼ probability space ç”¨çš„ measure ç‚º probability measure Week 1.4: Definition of a stochastic function. Types of stochastic functions.é¦–å…ˆ random variables å…¶å¯¦æ˜¯ä¸€å€‹ measurable function $\\xi:\\Omega\\rightarrow\\mathbb{R}$, è¦ææ¸…æ¥šä»€éº¼æ˜¯ measurable function ä¹‹å‰, æˆ‘å€‘å…ˆè¦äº†è§£ Borel $\\sigma$-algebra, Measurable Space èˆ‡ Measurable sets ä¸€æ¨£, ä¸»è¦åƒè€ƒ [æ¸¬åº¦è«–] Sigma Algebra èˆ‡ Measurable function ç°¡ä»‹ $\\sigma(\\mathcal{E})$ è¡¨ç¤ºåŒ…å« $\\mathcal{E}$ çš„æœ€å° $\\sigma$-algebra, ä¸”ä¸€å®šå­˜åœ¨ (è­‰æ˜è«‹åƒè€ƒè©²æ–‡ç« )ä»¤ $X:=\\mathbb{R}$, å‰‡æˆ‘å€‘å¯ä»¥å–æ‰€æœ‰ open sets ç”¢ç”Ÿ Borel $\\sigma$-algebra, è¨˜åš $\\mathcal{B}(\\mathbb{R})$ $\\mathcal{B}(\\mathbb{R})$ å¯ä»¥æƒ³æˆå¯¦æ•¸è»¸ä¸ŠåŒ…å«æ‰€æœ‰ open sets çš„æœ€å° $\\sigma$-algebra, ç”± $\\sigma$-algebra å®šç¾©çŸ¥ä¹ŸåŒ…å« closed sets $[a,b]$, ${a}$, $(a,b]$, $[a,b)$, ä»¥åŠä¸Šè¿°é€™äº›çš„ countable union (complement) å¯ç¨± $\\sigma$-algebra ä¸­çš„å…ƒç´ ç‚º measurable setæ¥è‘—å®šç¾©å¯æ¸¬å‡½æ•¸:å°æ–¼ $f$ ä¾†èªª, å…¶ domain ($X$) and image ($Y$) spaces éƒ½é…å‚™äº†å°æ‡‰çš„ $\\sigma$-algebra $\\mathcal{A},\\mathcal{B}$å›åˆ° probability space, $(\\Omega, \\mathcal{F}, \\mathcal{P})$, æˆ‘å€‘çŸ¥é“ $\\mathcal{F}$ æ˜¯å®šç¾©åœ¨ sample space $\\Omega$ çš„ $\\sigma$-algebra, i.e. $(\\Omega,\\mathcal{F})$ æ˜¯ measurable space.è€Œ random variable $Z$ å…¶å¯¦æ˜¯å®šç¾©ç‚ºç”± $\\Omega$ æ˜ å°„åˆ° $\\mathbb{R}$ çš„ measurable function. $\\mathbb{R}$ é…å‚™ $\\mathcal{B}(\\mathbb{R})$.èˆ‰ä¸€å€‹ Khan Academy æ·ºé¡¯çš„ä¾‹å­, $X,Y$ ç‚ºå…©å€‹ r.v.s åˆ†åˆ¥æŠŠ outcomes å°æ‡‰åˆ° $\\mathbb{R}$ $Y$ çš„ outcomes æ˜¯$\\{(a_1,...,a_7):a_i\\in \\{\\text{head,tail} \\} \\}$å…± $2^7$ ç¨®å¯èƒ½Mapping åˆ° $\\mathbb{R}$ å¾Œæˆ‘å€‘å°±å¯ä»¥ç®—å°æ‡‰çš„æ©Ÿç‡, ä¾‹å¦‚$\\mathcal{P}(Y\\leq30)$ or $\\mathcal{P}(Y\\text{ is even})$è€Œéœ€è¦ r.v. æ˜¯ measurable function çš„åŸå› å¯ä»¥å¾é€™çœ‹å‡ºä¾†, å› ç‚ºæˆ‘å€‘è¦çŸ¥é“ pre-image:$\\{\\omega:Y(\\omega)\\leq30\\}$ä¹Ÿå°±æ˜¯æ»¿è¶³é€™æ¢ä»¶çš„ outcomes é›†åˆ, å¿…é ˆè¦ $\\in\\mathcal{F}$. æ‰€ä»¥å®ƒæ‰æœƒæ˜¯å€‹ â€œäº‹ä»¶â€é€™æ˜¯å› ç‚ºæˆ‘å€‘çš„ probability measure $\\mathcal{P}:\\mathcal{F}\\rightarrow [0,1]$, æ˜¯å®šç¾©åœ¨ $\\mathcal{F}$ (äº‹ä»¶çš„ $\\sigma$-algebra) ä¸Š Week 1.5: Trajectories and finite-dimensional distributions[Def]: Stochastic process &emsp;Stochastic process æ˜¯ä¸€å€‹ mapping $X:T\\times\\Omega\\rightarrow\\mathbb{R}$, è€Œé€šå¸¸ $T=\\mathbb{R}^+$, ä¸”æ»¿è¶³: &emsp;$\\forall t \\in T$, we have $X_t=X(t,\\cdot)$ is a random variable on probability space $(\\Omega,\\mathcal{F},\\mathcal{P})$ [Def]: Trajectory (sample path, or path) of a stochastic process &emsp;å°ä¸€å€‹ stochastic process $X$ ä¾†èªª, fixed $\\omega\\in\\Omega$, æˆ‘å€‘å¾—åˆ° $X(\\cdot,\\omega)$ ç‚º $T$ çš„å‡½æ•¸, é€™å°±æ˜¯ trajectory [Def]: Finite dimensional distributions &emsp;å°ä¸€å€‹ stochastic process $X$ ä¾†èªª, æˆ‘å€‘æ ¹æ“šæ™‚é–“å¯ä»¥æ‹¿åˆ° $n$ å€‹ random variables: &emsp;$(X_{t_1}, X_{t_2}, ..., X_{t_n})$, where $t_1, t_2,...,t_n \\in \\mathbb{R}$ åœ¨ probability theory è£¡é¢éƒ½æ˜¯å°‡é€™ $n$ å€‹ r.v.s è¦–ç‚ºç¨ç«‹, ä½†åœ¨ stochastic processes è£¡é¢ä¸èƒ½. é€™æ˜¯å¾ˆå¤§çš„ä¸åŒ. æ‰€ä»¥å°±ç®—æ˜¯ finite dimensional distribution, åœ¨ stochastic processes ä¹Ÿæ˜¯å¾ˆæŒ‘æˆ°çš„. video çš„è©¦é¡Œ: Week 1.6: Renewal process. Counting processå¯åƒè€ƒè©³ç´°è§£èªª: https://www.randomservices.org/random/renewal/Introduction.htmlç¬¬ä¸€å€‹äº‹ä»¶ç™¼ç”Ÿçš„æ™‚é–“ç‚º $T_1$, ç¬¬äºŒå€‹äº‹ä»¶ç™¼ç”Ÿçš„æ™‚é–“ç‚º $T_2$, â€¦æ¯ä¸€å€‹äº‹ä»¶è¦éš”å¤šä¹…ç™¼ç”Ÿéƒ½æ˜¯å¾ä¸€å€‹ random variable $X_i$ æ±ºå®šçš„å› æ­¤æˆ‘å€‘æœƒæœ‰ä¸€å€‹ sequence of interarrival times, $X=(X_1,X_2,â€¦)$æ‰€ä»¥ sequence of arrival times å°±æœƒæ˜¯ $T = (T_1, T_2, â€¦)$, å…¶ä¸­$T_n=\\sum_{i=1}^nX_i$ , $n\\in\\mathbb{N}$å®ƒå€‘çš„é—œä¿‚ç”¨åœ–ä¾†çœ‹å¦‚ä¸‹:æœ€å¾Œæˆ‘å€‘å¯ä»¥å®šç¾©ä¸€å€‹ random variable $N_t$ è¡¨ç¤ºåˆ°æ™‚é–“ $t$ ç‚ºæ­¢æœ‰å¤šå°‘å€‹â€äº‹ä»¶â€åˆ°é”äº†:$N_t=\\sum_{n=1}^\\infty \\mathbf{1}(T_n\\leq t)$, $t\\in[0,\\infty)$å…¶ä¸­ $\\mathbf{1}(\\cdot)$ è¡¨ç¤º indicator function.åˆæˆ–è€…å¯ä»¥ç”¨èª²ç¨‹ä¸Šçš„å®šç¾©:$N_t=\\arg\\max_n\\{T_n\\leq t\\}$æ‰€ä»¥å¯ä»¥å®šç¾© counting process ç‚ºä¸€å€‹ random process $N=(N_t:t\\geq 0)$æˆ‘å€‘å¯ä»¥å°‡ $N$ é€™å€‹ random processes çš„ trajectory (path) ç•«å‡ºä¾†.é€™å€‹æ„æ€å°±æ˜¯ fixed ä¸€å€‹ sample space çš„å€¼, ä¾‹å¦‚å›ºå®š $Xâ€™=(X_1=0.5,X_2=0.11,â€¦)$, ç„¶å¾Œå°æ¯å€‹æ™‚é–“é»çš„ $N_t$ çš„å€¼éš¨è‘—æ™‚é–“ç•«å‡ºä¾†. æˆ‘å€‘æœƒç™¼ç¾æ˜¯å¦‚ä¸‹çš„ increasing step function:$T_n\\leq t$ æ„æ€å°±æ˜¯ $n$ å€‹äº‹ä»¶ç™¼ç”Ÿçš„æ™‚é–“æ¯” $t$ å°. ç­‰åŒæ–¼åˆ°æ™‚é–“ $t$ ç‚ºæ­¢è‡³å°‘æœ‰ $n$ å€‹äº‹ä»¶å·²ç¶“ç™¼ç”Ÿ, i.e. $N_t\\geq n$ [Properties]: counting variables $N_t$ èˆ‡ arrival times $T_n$ çš„é—œè¯å¦‚ä¸‹:&emsp;1. ${N_t\\geq n}={T_n\\leq t}$ or ${N_t\\leq n}={T_n\\geq t}$&emsp;2. $\\{N_t=n\\}=\\{T_n\\leq t\\} \\cap \\{T_{n+1}&gt;t\\}$ Week 1.7: Convolutionæˆ‘å€‘æœ‰å…©å€‹äº’ç‚ºç¨ç«‹çš„ r.v.s $X\\bot Y$, ä¸”å·²çŸ¥ $X\\sim F_X$, $Y\\sim F_Y$ (in c.d.f.) æˆ–æ˜¯å¯«æˆ $X\\sim P_X$, $Y\\sim P_Y$ (in p.d.f.). $F_X$ and $F_Y$ æ˜¯ cumulated distribution function of $X$ and $Y$$P_X$ and $P_Y$ æ˜¯ probability density function of $X$ and $Y$$F_X(x)=P_X(X&lt;x)$ å‰‡ convolution of two independent random variables è¨˜åš: $F_X\\ast F_Y$ (convolution in terms of distribution function): $F_{X+Y}(x)=\\int_\\mathbb{R} F_X(x-y)dF_Y(y)$ æˆ– $P_X \\ast P_Y$ (convolution in terms of density function): $P_{X+Y}(x)=\\int_\\mathbb{R} P_X(x-y)P_y(y)dy$ ğŸ’¡ Convolution åŒæ¨£éƒ½æ˜¯ç”¨ $\\ast$ è¡¨ç¤º, ä½†æ ¹æ“šæ˜¯ c.d.f. or p.d.f. æœƒæœ‰ä¸åŒå®šç¾©, ç„¶è€Œå…©è€…ç‚ºç­‰åƒ¹ æŠŠ convolution æ“´å±•åˆ° $n$ å€‹ i.i.d. r.v.s $\\{X_1,X_2,...,X_n\\}$, å…¶ä¸­ $X_i \\sim F$, å‰‡:$S_n=X_1+...+X_n\\sim {\\color{orange}{F^{n\\ast}=\\underbrace{F\\ast ...\\ast F}_\\text{n times}}}$ æ³¨æ„åˆ°é€™è£¡çš„ convolution, $\\ast$, is in terms of distribution function æœ‰å¹¾å€‹ç‰¹æ€§: $F^{n\\ast}(x)\\leq F^n(x)$, if $F(0)=0$é€™æ˜¯å› ç‚º$$\\{X_1 + ... + X_n \\leq x\\}\\subseteq\\{X_1\\leq x, ..., X_n\\leq x\\} \\\\ \\therefore P\\{X_1 + ... + X_n \\leq x\\}\\leq \\prod_{i=1}^n P\\{X_i\\leq x\\} \\\\ =F^{n\\ast}(x)\\leq \\prod_{i=1}^n F(x)=F^n(x)$$ $F^{n\\ast}(x)\\geq F^{(n+1)\\ast}(x)$é€™æ˜¯å› ç‚º$\\{X_1 + ... + X_n \\leq x\\}\\supseteq\\{X_1 + ... + X_n + X_{n+1} \\leq x\\}$ [Thm] Expectation of counting process equals to renewal function $\\mathcal{U}(t)$:&emsp;è€ƒæ…® renewal process: $T_n=T_{n-1}+X_n$, ä¸” $X_1,X_2,â€¦$ are i.i.d. r.v.s with distribution function $F$. $\\mathcal{U}(t):=\\sum_{n=1}^\\infty F^{n\\ast}(t) &lt; \\infty$ èª²ç¨‹ç•¥éè­‰æ˜. æ­¤å®šç†å‘Šè¨´æˆ‘å€‘è©²åºåˆ—æ”¶æ–‚. $F^{n\\ast}(t)$ çš„æ„æ€æ˜¯ $n$ å€‹ i.i.d. r.v.s ç›¸åŠ çš„ CDF, i.e. $P(X_1+â€¦+X_n\\leq t)=P(T_n\\leq t)$, è€Œåœ¨ renewal process æŒ‡çš„å°±æ˜¯ arrival time $P(T_n\\leq t)$, i.e. åˆ°æ™‚é–“ $t$ ç‚ºæ­¢è‡³å°‘æœ‰ $n$ å€‹äº‹ä»¶å·²ç¶“ç™¼ç”Ÿçš„æ©Ÿç‡. ç„¶å¾Œ $\\sum_{n=1}^\\infty$ æœ‰é‚£ç¨®æŠŠæ‰€æœ‰å¯èƒ½çš„æƒ…æ³éƒ½è€ƒæ…®é€²å»çš„æ„æ€, å› æ­¤ $\\mathcal{U}(t)$ å¯èƒ½æœƒè·Ÿåˆ°æ™‚é–“ $t$ ç‚ºæ­¢ç™¼ç”Ÿâ€äº‹ä»¶â€çš„æ¬¡æ•¸çš„æœŸæœ›å€¼ ($\\mathbb{E} N_t$) æœ‰é—œ. è€Œäº‹å¯¦ä¸Šå°±æ˜¯. $\\mathcal{U}(t)$ ç¨± renewal function $\\mathbb{E} N_t = \\mathcal{U}(t)$&emsp;$$\\mathbb{E}N_t = \\mathbb{E}\\left[ \\#\\{n:T_n\\leq t\\} \\right] =\\mathbb{E}\\left[ \\sum_{n=1}^\\infty \\mathbf{1}(T_n\\leq t) \\right] \\\\ =\\sum_{n=1}^\\infty \\mathbb{E}\\left[ \\mathbf{1}(T_n\\leq t) \\right] =\\sum_{n=1}^\\infty P(T_n\\leq t) =\\sum_{n=1}^\\infty F^{n\\ast}(t)$$ é›–ç„¶ $\\mathbb{E} N_t = \\mathcal{U}(t) =\\sum_{n=1}^\\infty F^{n\\ast}(t)$ æˆ‘å€‘å¯ä»¥æ˜ç¢ºå¯«å‡ºä¾†, ä½†å°æ–¼ $F$ æ˜¯æ¯”è¼ƒ general form çš„è©±, å¹¾ä¹å¾ˆé›£ç®—å‡ºä¾†. å› ç‚ºè¦ç®— convolution, åˆè¦æ±‚ sequence çš„ limit. èª²ç¨‹è©¦é¡Œ: é™„ä¸Š exponential distributino å®šç¾© Week 1.8: Laplace transform. Calculation of an expectation of a counting process-1[Def]: Laplace transform&emsp;Given $f:\\mathbb{R}^+\\rightarrow\\mathbb{R}$, Laplace transform å®šç¾©ç‚ºå¦‚ä¸‹ç©åˆ†:&emsp;$\\mathcal{L}_f(s)=\\int_{x=0}^\\infty e^{-sx}f(x)dx$ æœ‰å¹¾å€‹ä¸»è¦çš„ properties: ä»¤ $f$ æ˜¯ p.d.f. of some random variable $\\xi$å‰‡ $\\mathcal{L}_f(s)=\\mathbb{E}\\left[ e^{-s\\xi} \\right]$ çµ¦å®šä»»å…©å€‹ functions (ä¸ä¸€å®šè¦æ˜¯ p.d.f. or c.d.f.) $f_1$, $f_2$, å‰‡ $\\mathcal{L}_{f_1\\ast f_2}(s)=\\mathcal{L}_{f_1}(s)\\cdot\\mathcal{L}_{f_2}(s)$å…¶ä¸­ $\\ast$ æ˜¯ convolution in terms of density[Proof]:Let $f(x)=f_1(x)*f_2(x)$ å‰‡ $$\\mathcal{L}_f(s)=\\int_{x=0}^\\infty e^{-sx}\\left(\\int_{y=0}^\\infty f_1(x-y)f_2(y)dy\\right)dx \\\\ =\\int_{y=0}^\\infty\\left(\\int_{x=0}^\\infty e^{-sx}f_1(x-y)dx\\right)f_2(y)dy \\\\ =\\int_{y=0}^\\infty\\left( e^{-sy}\\int_{x-y=y}^\\infty e^{-s(x-y)}f_1(x-y)d(x-y) \\right) f_2(y)dy \\\\ =\\mathcal{L}_{f_1}(s)\\cdot\\int_{y=0}^\\infty e^{-sy} f_2(y)dy = \\mathcal{L}_{f_1}(s)\\cdot\\mathcal{L}_{f_2}(s)$$ ä»¤ $F$ æ˜¯ c.d.f. ä¸” $F(0)=0$, $p=Fâ€™$ is p.d.f., å‰‡: $\\mathcal{L}_F(s)=\\frac{\\mathcal{L}_p(s)}{s}\\\\$ [Proof]: ä½¿ç”¨åˆ†éƒ¨ç©åˆ†, integration by part $$l.h.s.=-\\int_{\\mathbb{R}^+}F(x)\\frac{d(e^{-sx})}{s} = -\\left[F(x)e^{-sx}/s\\right]|_{x=0}^\\infty+\\frac{1}{s}\\int_{\\mathbb{R}^+}e^{-sx}dF(x) \\\\ = 0+\\frac{1}{s}\\int_{\\mathbb{R}^+}p(x)e^{-sx}dx = r.h.s.$$ [Example 1]: ä»¤ $f(x) = x^n$, æ±‚ $\\mathcal{L}_f(s)$&emsp;[sol]: ä¹Ÿæ˜¯ä½¿ç”¨åˆ†éƒ¨ç©åˆ†, integration by part$$\\mathcal{L}_{x^n}(s) = \\int_{\\mathbb{R}^+}x^n e^{-sx}dx =-\\int_{\\mathbb{R}^+}x^n\\frac{d(e^{-sx})}{s} \\\\ = \\frac{n}{s} \\int_{\\mathbb{R}^+}x^{n-1} e^{-sx}dx=...\\\\ =\\frac{n}{s}\\cdot\\frac{n-1}{s}\\cdot...\\cdot\\frac{1}{s}\\int_{\\mathbb{R}^+}e^{-sx}dx \\\\ =\\frac{n!}{s^n}\\cdot\\left[ -\\left.\\frac{1}{s}e^{-sx} \\right |_0^\\infty \\right] = \\frac{n!}{s^{n+1}}$$ [Example 2]: ä»¤ $f(x) = e^{ax}$, æ±‚ $\\mathcal{L}_f(s)$&emsp;[sol]: ç­”æ¡ˆç‚º $\\mathcal{L}_{e^{ax}}(s)=\\frac{1}{s-a}$, if $a&lt;s$&emsp;ç•¥â€¦ Week 1.9: Laplace transform. Calculation of an expectation of a counting process-2ç¾åœ¨æˆ‘å€‘è¦ä¾†è¨ˆç®— $\\mathbb{E}N_t$, å›é¡§ä¸€ä¸‹ $N_t$ æ˜¯ä¸€å€‹ r.v. è¡¨ç¤ºåˆ°æ™‚é–“ $t$ ç‚ºæ­¢æœ‰å¤šå°‘å€‹äº‹ä»¶åˆ°é”äº†è€Œæˆ‘å€‘ä¹Ÿè­‰æ˜äº† $\\mathbb{E} N_t = \\mathcal{U}(t) =\\sum_{n=1}^\\infty F^{n\\ast}(t)$, ç¾åœ¨æˆ‘å€‘åœ¨ä»”ç´°åˆ†æä¸€ä¸‹$$\\mathbb{E}N_t=\\mathcal{U}(t)=\\sum_{n=1}^\\infty F^{n\\ast}(t) \\\\ = F(t) + \\left( \\sum_{n=1}^\\infty F^{n\\ast} \\right) \\ast F(t) \\\\ = F(t) + \\mathcal{U}(t)\\ast F(t)$$å› æ­¤æˆ‘å€‘å¾—åˆ°: $\\mathcal{U}=F+\\mathcal{U}\\ast F$, å…¶ä¸­ convolution, $\\ast$, is in terms of distribution functionç„¶å¾Œæˆ‘å€‘å°ç­‰è™Ÿå…©é‚Šå¥—ç”¨ Laplace transfrom, ä½†æ˜¯æˆ‘å€‘æ³¨æ„åˆ° Laplace transfrom å¥—ç”¨çš„ convolution å¿…é ˆæ˜¯ density function, å› æ­¤è¦è½‰æ›å…¶å¯¦æˆ‘å€‘å¾å®šç¾©å¯ä»¥çŸ¥é“ $\\mathcal{U}\\ast_{cdf}F=\\mathcal{U}\\ast_{pdf}p$ å·²çŸ¥ $p=Fâ€™$$\\int_{\\mathbb{R}}\\mathcal{U}(x-y)dF(y) = \\int_{\\mathbb{R}}\\mathcal{U}(x-y)p(y)dy$ æ‰€ä»¥$\\mathcal{U}=F+\\mathcal{U}\\ast_{cdf} F = F+\\mathcal{U}\\ast_{pdf} p$, ç„¶å¾Œå°±å¯ä»¥å¥—ç”¨ Laplace transfrom, ä¸¦åˆ©ç”¨ä¸Šé¢æåˆ°çš„ properties 2 &amp; 3$$\\mathcal{L}_\\mathcal{U}(s) = \\mathcal{L}_F(s) + \\mathcal{L}_\\mathcal{U}(s) \\cdot \\mathcal{L}_p(s) \\\\ =\\frac{\\mathcal{L}_p(s)}{s} + \\mathcal{L}_\\mathcal{U}(s) \\cdot \\mathcal{L}_p(s)$$å› æ­¤$\\mathcal{L}_\\mathcal{U}(s) = \\frac{\\mathcal{L}_p(s)}{s(1-\\mathcal{L}_p(s))} \\ldots (\\star)$æ‰€ä»¥é›–ç„¶ç„¡æ³•ç›´æ¥è¨ˆç®—å‡º $\\mathbb{E} N_t = \\mathcal{U}(t)$, ä½†æˆ‘å€‘å¯ä»¥è¿‚è¿´åœ°é€éä»¥ä¸‹ä¸‰å€‹æ­¥é©Ÿä¾†ä¼°è¨ˆ: å¾ $F$ ç®—å‡º $\\mathcal{L}_p$ åˆ©ç”¨ $(\\star)$ å¾ $\\mathcal{L}_p$ ç®—å‡º $\\mathcal{L}_\\mathcal{U}$ åæ¨ä»€éº¼æ¨£çš„ $\\mathcal{U}$ æœƒå¾—åˆ° $\\mathcal{L}_\\mathcal{U}$, é€™ä¸€æ­¥æ˜¯æœ€å›°é›£çš„ ä¸‹ä¸€æ®µèª²ç¨‹å°‡æœƒçµ¦å‡ºä¸€å€‹å¦‚ä½•ä½¿ç”¨ä¸Šé¢ä¸‰æ­¥é©Ÿçš„ç¯„ä¾‹ Week 1.10: Laplace transform. Calculation of an expectation of a counting process-3[Example]: å‡è¨­æˆ‘å€‘æœ‰ä¸€å€‹ renewal process, $S_n=S_{n-1}+\\xi_n$&emsp;å…¶ä¸­ $\\xi_1, \\xi_2, ... \\sim p(x)=\\frac{e^{-x}}{2}+e^{-2x}$&emsp;æˆ‘å€‘è¦å¦‚ä½•è¨ˆç®— $\\mathbb{E}N_t$?, æˆ‘å€‘ä½¿ç”¨ä¸Šé¢æ‰€è¿°çš„ä¸‰æ­¥é©Ÿ:&emsp;&emsp;åœ¨æœ€å¾Œä¸€æ­¥çš„æ™‚å€™æˆ‘è¦éœ€è¦æ‰¾å‡º&emsp;ä»€éº¼æ¨£çš„ $\\mathcal{U}(t)$ æœƒæœ‰ $\\mathcal{L}_\\mathcal{U}(s)=\\frac{1}{s}$? Ans: $1$&emsp;ä»€éº¼æ¨£çš„ $\\mathcal{U}(t)$ æœƒæœ‰ $\\mathcal{L}_\\mathcal{U}(s)=\\frac{1}{s^2}$? Ans $t$&emsp;ä»€éº¼æ¨£çš„ $\\mathcal{U}(t)$ æœƒæœ‰ $\\mathcal{L}_\\mathcal{U}(s)=\\frac{1}{2s+3}$? Ans $\\exp\\{-\\frac{3}{2}t\\}$ Week 1.11: Limit theorems for renewal processesè€ƒæ…®ä¸€å€‹ renewal process, $S_n=S_{n-1}+\\xi_n$, å…¶ä¸­ $\\xi_1,\\xi_2,...$ are i.i.d. &gt;0 almost surelySLLN ç‚º Strong Law of Large Number; CLT ç‚º Central Limit TheoremThm1 ç›´è§€ä¸Šå¯ä»¥ç†è§£, å› ç‚º $N_t$ è¡¨ç¤ºåˆ°æ™‚é–“ $t$ ç‚ºæ­¢å…±æœ‰å¤šå°‘å€‹äº‹ä»¶ç™¼ç”Ÿäº†. ç•¶ $t$ å¾ˆå¤§çš„æ™‚å€™, æ¯å–®ä½æ™‚é–“ç™¼ç”Ÿçš„äº‹ä»¶æ¬¡æ•¸, i.e. $\\frac{N_t}{t}$, æ‡‰è©²æœƒååˆ†æ¥è¿‘é »ç‡, i.e. $\\frac{1}{\\mu}$Thm2 å°±ä¸å¥½ç›´æ¥ç†è§£äº†, å…¶ä¸­ $\\xrightarrow[]{d}$ è¡¨ç¤º convergence in distribution. æ³¨æ„åˆ° $\\frac{1}{\\mu}$ è¡¨ç¤ºå–®ä½æ™‚é–“æ˜¯é–“ç™¼ç”Ÿçš„æ¬¡æ•¸, æ‰€ä»¥ä¹˜ä¸Š $t$ å°±æ˜¯äº‹ä»¶ç™¼ç”Ÿçš„æ¬¡æ•¸, æ³¨æ„åˆ°é€™æ˜¯æœŸæœ›å€¼, è€Œ $N_t$ æ˜¯ç™¼ç”Ÿæ¬¡æ•¸çš„ random variable. å› æ­¤å¯ä»¥æƒ³åƒ mean æ‡‰è©²å°±æ˜¯ $t/\\mu$. å›°é›£çš„æ˜¯ variance æ˜¯ä»€éº¼, ä»¥åŠé€™å‰›å¥½æœƒ follow normal distribution.è€Œé€™å…©å€‹åˆ†åˆ¥è·Ÿ SLLN (Strong Law of Large Number) and CLT (Central Limit Theorem) ç›¸é—œ. ä»¥ä¸‹çµ¦å‡ºè­‰æ˜ Thm1 çš„è­‰æ˜: Thm2 çš„è­‰æ˜: é–‹é ­çš„ç¬¬ä¸€è¡Œ:$\\mathcal{P}\\left\\{ \\frac{\\xi_1 + \\xi_2 + ... + \\xi_n -n\\cdot\\mu}{\\sigma\\sqrt{n}} \\leq x \\right\\} = \\mathcal{P}\\left\\{ \\frac{S_n-n\\cdot\\mu}{\\sigma\\sqrt{n}} \\leq x \\right\\}$æ˜¯å¾ CLT å‡ºç™¼ç¬¬äºŒè¡Œåˆ°ç¬¬ä¸‰è¡Œç”¨åˆ°äº†, $\\mathcal{P}\\left\\{ S_n\\leq t \\right\\} = \\mathcal{P}\\left\\{ N_t \\geq n \\right\\}$ç„¶å¾Œç”± $t=n\\mu+\\sigma\\sqrt{n}x\\Rightarrow n=\\frac{t}{\\mu}-\\frac{\\sigma\\sqrt{n}}{\\mu}x$ ä¸¦å°‡ $n \\approx t/\\mu$ å¸¶å…¥ r.h.s. å¾—åˆ°$n=\\frac{t}{\\mu}-\\frac{\\sigma\\sqrt{t}}{\\mu^{3/2}}x$, ç„¶å¾Œä»£å›åˆ° $\\mathcal{P}\\left\\{ N_t \\geq n \\right\\}$, å†æ•´ç†ä¸€ä¸‹å¾—åˆ°æœ€å¾Œä¸€è¡Œè­‰æ˜æœ€å¾Œä¸€è¡Œæ˜¯ (è¢«æ“‹åˆ°):$\\mathcal{P}\\left\\{ Z_t \\leq x \\right\\} = \\mathcal{P}\\left\\{ Z_t &gt; -x \\right\\} \\rightarrow 1-\\Phi(-x) = \\Phi(x)$æˆ–å¯ä»¥åƒè€ƒ https://www.randomservices.org/random/renewal/LimitTheorems.html çš„ The Central Limit Theorem Applications of the Renewal ProcessesApplications of the Renewal Processes.pdf","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"},{"name":"Probability Space","slug":"Probability-Space","permalink":"https://bobondemon.github.io/tags/Probability-Space/"},{"name":"Renewal Process","slug":"Renewal-Process","permalink":"https://bobondemon.github.io/tags/Renewal-Process/"},{"name":"Counting Process","slug":"Counting-Process","permalink":"https://bobondemon.github.io/tags/Counting-Process/"}]},{"title":"Stochastic Processes Week 0 ä¸€äº›é å‚™çŸ¥è­˜","date":"2021-12-11T12:01:14.000Z","path":"2021/12/11/Stochastic-Processes-Week-0-ä¸€äº›é å‚™çŸ¥è­˜/","text":"Coursera Stochastic Processes èª²ç¨‹ç­†è¨˜, å…±ä¹ç¯‡: Week 0: ä¸€äº›é å‚™çŸ¥è­˜ (æœ¬æ–‡) Week 1: Introduction &amp; Renewal processes Week 2: Poisson Processes Week3: Markov Chains Week 4: Gaussian Processes Week 5: Stationarity and Linear filters Week 6: Ergodicity, differentiability, continuity Week 7: Stochastic integration &amp; ItÃ´ formula Week 8: LÃ©vy processes æœ¬ç¯‡å›é¡§ä¸€äº›åŸºç¤çš„æ©Ÿç‡è¤‡ç¿’, é€™äº›åœ¨ä¹‹å¾Œèª²ç¨‹è£¡æœ‰ç”¨åˆ°.å¼·çƒˆå»ºè­°é–±è®€ä»¥ä¸‹æ–‡ç« : [æ¸¬åº¦è«–] Sigma Algebra èˆ‡ Measurable function ç°¡ä»‹ [æ©Ÿç‡è«–] æ·ºè«‡æ©Ÿç‡å…¬ç† èˆ‡ åŸºæœ¬æ€§è³ª A guide to the Lebesgue measure and integration Measure theory in probability ä»¥ä¸‹å›é¡§é–‹å§‹: å›é¡§æ©Ÿç‡çŸ¥è­˜ $e^x=\\sum_{k=0}^\\infty\\frac{x^k}{k!}$. Proof link. Independent of Random Variables $X\\perp Y \\Longleftrightarrow \\mathcal{P}(XY)=\\mathcal{P}(X)\\mathcal{P}(Y)$ $Cov(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]$[Proof]: $$Cov(X,Y)=\\mathbb{E}[(X-\\mu_x)(Y-\\mu_y)] \\\\ =\\mathbb{E}[XY]-\\mu_x\\mathbb{E}[Y]-\\mu_y\\mathbb{E}[X]+\\mu_x\\mu_y \\\\ =\\mathbb{E}[XY]-\\mu_x\\mu_y$$ $Var(X)=\\mathbb{E}[X^2]-(\\mathbb{E}[X])^2$[Proof]: $$Var(X)=Cov(X,X)=\\mathbb{E}[XX]-\\mathbb{E}[X]\\mathbb{E}[X] \\\\ = \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2$$ $X,Y$ uncorrelated $\\Longleftrightarrow Cov(X,Y)=0 \\Longleftrightarrow \\mathbb{E}[XY]=\\mathbb{E}[X]\\mathbb{E}[Y]$ $X\\perp Y \\Rightarrow$ $X,Y$ uncorrelated $\\Rightarrow \\mathbb{E}[XY]=\\mathbb{E}[X]\\mathbb{E}[Y]$ Covariance æ˜¯ç·šæ€§çš„: $Cov(aX+bY,cZ)=acCov(X,Z)+bcCov(Y,Z)$[Proof]: $$Cov(aX+bY,cZ)=\\mathbb{E}[(aX+bY)cZ]-\\mathbb{E}[aX+bY]\\mathbb{E}[cZ] \\\\ = ac\\mathbb{E}[XZ]+bc\\mathbb{E}[YZ]-ac\\mathbb{E}[X]\\mathbb{E}[Z]-bc\\mathbb{E}[Y]\\mathbb{E}[Z] \\\\ = ac(\\mathbb{E}[XZ]-\\mathbb{E}[X]\\mathbb{E}[Z])+bc(\\mathbb{E}[YZ]-\\mathbb{E}[Y]\\mathbb{E}[Z]) \\\\ = acCov(X,Z)+bcCov(Y,Z)$$ [Characteristic Function Def]: For random variable $\\xi$, å®šç¾© characteristic function $\\Phi:\\mathbb{R}\\rightarrow \\mathbb{C}$ ç‚º $$\\Phi_\\xi(u) = \\mathbb{E}\\left[ e^{iu\\xi} \\right]$$ å¦‚æœ $\\xi_1\\perp\\xi_2$, å‰‡ $\\Phi_{\\xi_1+\\xi_2}(u)=\\Phi_{\\xi_1}(u)\\Phi_{\\xi_2}(u)$ [Proof]: $$\\Phi_{\\xi_1+\\xi_2}(u)=\\mathbb{E}[e^{iu(\\xi_1+\\xi_2)}]=\\mathbb{E}[e^{iu\\xi_1}e^{iu\\xi_2}] \\\\ = \\int_{\\xi_1,\\xi_2} \\mathcal{P}(\\xi_1,\\xi_2)e^{iu\\xi_1}e^{iu\\xi_2} d\\xi_1 d\\xi_2 \\\\ = \\int_{\\xi_1,\\xi_2} \\left(\\mathcal{P}(\\xi_1)e^{iu\\xi_1}\\right)\\left(\\mathcal{P}(\\xi_2)e^{iu\\xi_2}\\right) d\\xi_1 d\\xi_2 \\\\ =\\mathbb{E}[e^{iu\\xi_1}]\\mathbb{E}[e^{iu\\xi_2}] \\\\ =\\Phi_{\\xi_1}(u)\\Phi_{\\xi_2}(u)$$ $\\mathbb{E}[X+Y]=\\mathbb{E}[X]+\\mathbb{E}[Y]$. è·Ÿ $X,Y$ æ˜¯å¦ç¨ç«‹æˆ–ä¸ç›¸é—œç„¡é—œ. $|Cov(X,Y)|\\leq\\sqrt{Var(X)}\\sqrt{Var(Y)}$[Proof]: $Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)$[Proof]: $$Var(X+Y)=Cov(X+Y,X+Y)\\\\ =Cov(X,X)+2Cov(X,Y)+Cov(Y,Y)\\\\ =Var(X)+Var(Y)+2Cov(X,Y)$$ å¦‚æœ $X,Y$ uncorrelated (æ‰€ä»¥ $X\\perp Y$ ä¹Ÿæˆç«‹), å‰‡ $Var(X+Y)=Var(X)+Var(Y)$ Normal distribution of one r.v. $$X\\sim\\mathcal{N}(\\mu,\\sigma^2), \\text{ for }\\sigma&gt;0,\\mu\\in\\mathbb{R} \\\\ p(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$ The characteristic function of normal distribution is: $\\Phi(u)=e^{iu\\mu-\\frac{1}{2}u^2\\sigma^2}$ ç¨ç«‹é«˜æ–¯åˆ†ä½ˆä¹‹å’Œä»ç‚ºé«˜æ–¯åˆ†ä½ˆ, mean and variance éƒ½ç›¸åŠ [Proof]: $(X_1,...,X_n) \\text{ where } X_k\\sim\\mathcal{N}(\\mu_k,\\sigma_k^2),\\forall k=1,...,n$ æˆ‘å€‘çŸ¥é“ $$X_k\\sim\\mathcal{N}(\\mu_k,\\sigma_k^2)\\longleftrightarrow \\Phi_k(u)=e^{iu\\mu_k-\\frac{1}{2}u^2\\sigma_k^2}$$ å‰‡ $$\\sum_k X_k \\longleftrightarrow \\prod_k \\Phi_k(u) = e^{iu(\\sum_k \\mu_k)-\\frac{1}{2}u^2(\\sum_k \\sigma_k^2)}$$ ç”±ç‰¹å¾µæ–¹ç¨‹å¼èˆ‡æ©Ÿç‡åˆ†ä½ˆä¸€å°ä¸€å°æ‡‰å¾—çŸ¥ $\\sum_k X_k \\sim \\mathcal{N}\\left(\\sum_k \\mu_k, \\sum_k \\sigma_k^2\\right)$ $K:\\mathcal{X}\\times\\mathcal{X}\\rightarrow\\mathbb{R}$ is symmetric positive semi-definite: çµ¦å®š $t_1&lt;t_2&lt;â€¦&lt;t_n$ ä¸€å€‹å¾ˆæœ‰ç”¨çš„æŠ€å·§ç‚º:å¯ä»¥è®Šæˆä»¥ä¸‹é€™äº› disjoint å€æ®µçš„ç·šæ€§çµ„åˆ $(t_2-t_1),...,(t_n-t_{n-1})$ å…·é«”å¦‚ä¸‹: $$\\sum_{k=1}^n \\lambda_k B_{t_k} = \\lambda_n(B_{t_n}-B_{t_{n-1}}) + (\\lambda_n+\\lambda_{n-1})B_{t_{n-1}} + \\sum_{k=1}^{n-2} \\lambda_k B_{t_k} \\\\ = \\sum_{k=1}^n d_k(B_{t_n}-B_{t_{n-1}})$$ æœƒæƒ³è¦é€™æ¨£è½‰æ›æ˜¯å› ç‚ºèª²ç¨‹æœƒå­¸åˆ° independent increment ç‰¹æ€§, è¡¨æ˜ disjoint å€æ®µçš„ random variables ä¹‹é–“äº’ç›¸ç¨ç«‹, å› æ­¤å¯ä»¥è®Šæˆäº’ç›¸ç¨ç«‹çš„ r.v.s ç·šæ€§ç›¸åŠ  Calculating Moments with Characteristic Functions (wiki)) Brownian Motion referenceBrownian Motion by Hartmann.pdf Lebesgue Measure and IntegrationA guide to the Lebesgue measure and integrationLebesgue integration from wiki[æ¸¬åº¦è«–] Sigma Algebra èˆ‡ Measurable function ç°¡ä»‹ Probability Theory[æ©Ÿç‡è«–] æ·ºè«‡æ©Ÿç‡å…¬ç† èˆ‡ åŸºæœ¬æ€§è³ªMeasure theory in probabilityDistribution function $F$ defined with (probability) measure $\\mu$ (ref)$F$ åˆç¨± cumulative distribution function (c.d.f.), æˆ–ç¨± cumulative functionå…¶å¾®åˆ†ç¨±ç‚º probability density function (p.d.f.), æˆ–ç°¡ç¨± density function. æ³¨æ„åˆ° density ä¸æ˜¯ (probability) measure $\\mu$!è€ŒæœŸæœ›å€¼å¯ä»¥ç”¨ Lebesgue measure or in probability measure ä¾†çœ‹å¾…:Given Probability space: $(\\Omega,\\Sigma,\\mathcal{P})$, æœŸæœ›å€¼å®šç¾©ç‚º æ‰€æœ‰ event $\\omega\\in\\Sigma$ çš„ probability measure $\\mathcal{P}(\\omega)$, ä¹˜ä¸Šè©² random variable çš„å€¼ $X(\\omega)$æ‰€æœ‰ outcome $\\omega\\in\\Omega$ çš„ probability measure $\\mathcal{P}(d\\omega)$, ä¹˜ä¸Šè©² random variable çš„å€¼ $X(\\omega)$ Lebesgueâ€™s Dominated Convergence Theorem: Exchanging $\\lim$ and $\\int$Let $(f_n)$ be a sequence of measurable functions on a measure space $(S,\\Sigma,\\mu)$. Assume $(f_n)$ converges pointwise to $f$ and is dominated by some (Lebesgue) integrable function $g$, i.e. $|f_n(x)|\\leq g(x), \\qquad \\forall n,\\forall x\\in S$ Then $f$ is (Lebesgue) integrable, i.e. $\\int_S |f|d\\mu&lt;\\infty$and $$\\lim_{n\\rightarrow\\infty}\\int_S |f_n-f|d\\mu=0 \\\\ \\lim_{n\\rightarrow\\infty}\\int_S f_nd\\mu = \\int_S\\lim_{n\\rightarrow\\infty}f_nd\\mu = \\int_S f d\\mu$$","tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Stochastic Processes","slug":"Stochastic-Processes","permalink":"https://bobondemon.github.io/tags/Stochastic-Processes/"}]},{"title":"MCMC by Gibbs and Metropolis-Hasting Sampling","date":"2021-10-27T13:53:41.000Z","path":"2021/10/27/MCMC-by-Gibbs-and-Metropolis-Hasting-Sampling/","text":"PRML book sampling (chapter 11) é–‹é ­æŠŠå‹•æ©Ÿæè¿°å¾—å¾ˆå¥½, ä¹Ÿå¼•ç”¨ä¾†ç•¶é€™ç¯‡æ–‡ç« çš„å‰è¨€.åœ¨ç”¨ machine learning å¾ˆå¤šæ™‚å€™æœƒé‡åˆ°éœ€è¦è¨ˆç®—æŸå€‹ function $f(x)$ çš„æœŸæœ›å€¼, ç•¶ $x$ follow æŸå€‹ distribution $p(x)$ çš„æƒ…æ³, i.e. éœ€è¨ˆç®— $$\\begin{align} \\mu:=\\mathbb{E}_p[f]=\\int f(x)p(x)dx \\end{align}$$ ä¾‹å¦‚ EM algorithm æœƒéœ€è¦è¨ˆç®— $\\mathbb{E}_{p(z|x)}[f(x,z)]$, åƒè€ƒ ref çš„å¼ (23), (28)åˆæˆ–è€…æˆ‘å€‘è¦åš Bayesian çš„ prediction æ™‚, åƒè€ƒ ref çš„å¼ (2) é€™äº›æƒ…æ³å¤§éƒ¨åˆ†éƒ½ç„¡æ³•æœ‰ analytical form. ä¸éå¦‚æœæˆ‘å€‘èƒ½å¾çµ¦å®šçš„ distribution $p(x)$ å– $L$ å€‹ sample çš„è©±, å¼ (1) å°±èƒ½å¦‚ä¸‹é€¼è¿‘ $$\\begin{align} \\mathbb{E}_p[f] \\approx \\hat f:= \\frac{1}{L}\\sum_{l=1}^L f(x_l) \\end{align}$$ æˆ‘å€‘å…ˆä¾†çœ‹ä¸€ä¸‹ $\\hat f$ é€™å€‹ä¼°è¨ˆçš„æœŸæœ›å€¼æ˜¯ä»€éº¼: $$\\begin{align} \\mathbb{E}_p[\\hat f]=\\mathbb{E}_p\\left[ \\frac{1}{L}\\sum_{l=1}^L f(x_l) \\right] = \\frac{1}{L}\\sum_{l=1}^L\\mathbb{E}_p\\left[ f(x_l) \\right] = {E}_p [f] = \\mu \\end{align}$$ å¾—åˆ°ä¸€å€‹å¥½æ¶ˆæ¯æ˜¯æˆ‘å€‘åªè¦ä¼°è¶…å¤šæ¬¡çš„è©±, $\\hat f_1, \\hat f_2, â€¦$ é€™äº›ä¼°è¨ˆçš„å¹³å‡å°±æ˜¯æˆ‘å€‘è¦çš„å€¼ å…¶å¯¦é€™ç­‰åŒæ–¼ä¼°ä¸€æ¬¡å°±å¥½, ä½†ç”¨è¶…å¤§çš„ $L$ å»ä¼°è¨ˆ. å•é¡Œæ˜¯ $L$ è¦å¤šå¤§æ‰å¤  ? å¦‚æœè®Šæ•¸ $x$ çš„ç¶­åº¦å¢åŠ , éœ€è¦çš„ $L$ æ˜¯å¦ä¹Ÿè¦å¢åŠ æ‰æœƒæº–ç¢º ? i.e. æœƒä¸æœƒæœ‰ç¶­åº¦çˆ†ç‚¸çš„å•é¡Œ ? (åƒè€ƒ Curse of dimensionality [1]) æˆ‘å€‘å¯ä»¥è­‰æ˜ (see Appendix): $$\\begin{align} var[\\hat f]=\\frac{1}{L}var(f) \\end{align}$$ é€™å‘Šè¨´æˆ‘å€‘, éš¨è‘— sample æ•¸é‡ $L$ æ„ˆå¤§, æˆ‘å€‘ä¼°å‡ºä¾†çš„ $\\hat f$ çš„â€è®ŠåŒ–â€æœƒæ„ˆä¾†æ„ˆå° (æˆåæ¯”). æ›´é‡è¦çš„æ˜¯, é€™è·Ÿ input dimension ç„¡é—œ! æ‰€ä»¥ä¸æœƒæœ‰ç¶­åº¦çˆ†ç‚¸çš„å•é¡Œ. èª²æœ¬èªªé€šå¸¸ $L$ å–å€‹ 10 å€‹ 20 å€‹ä¼°å‡ºä¾†çš„ $\\hat f$ å°±å¾ˆæº–äº†. (å…¶å¯¦å¾ˆå¥½é©—è­‰) æ‰€ä»¥å‰©ä¸‹è¦è§£æ±ºçš„å•é¡Œä¾¿æ˜¯, è¦æ€éº¼å¾ä¸€å€‹çµ¦å®šçš„ distribution å– sample ? æœ¬ç¯‡æ­£æ–‡å¾é€™é–‹å§‹ å…ˆèªªæ˜ 1-d æƒ…æ³ä¸‹çš„ r.v. æ€éº¼ sampling å†ä¾†èªªæ˜å¦‚ä½•ç”¨ Markov chain sampling, ä¹Ÿå°±æ˜¯å¤§åé¼é¼çš„ MCMC (Markov Chain Monte Carlo) æœ€å¾Œä»‹ç´¹å…©å€‹å¯¦ä½œæ–¹æ³• Gibbs and Metropolis-Hasting sampling. ä»¥ä¸‹æ–‡ç« å…§å®¹çµ•å¤§å¤šæ•¸éƒ½æ˜¯å¾ Coursera: Bayesian Methods for Machine Learning èª²ç¨‹ä¾†çš„éå¸¸æ¨è–¦é€™é–€èª²ç¨‹! å¾ 1-D èªªèµ·Discrete caseå…ˆè¨è«– discrete distribution çš„æƒ…å½¢, æˆ‘å€‘ç¸½æ˜¯å¯ä»¥å– samples from uniform distribution [0, 1], i.e. $\\text{sample} \\sim \\mathcal{U}[0,1]$æ‰€ä»¥è‹¥è¦å¾ä¸‹åœ–ä¾‹å­çš„ discrete distribution å– samples å…¶å¯¦å¾ˆå®¹æ˜“, è‹¥è½åœ¨ [0, 0.6) å°± sample $a_1$, è½åœ¨ [0.6, 0.7) å– $a_2$, è½åœ¨ [0.7, 1) å– $a_3$. Gaussian caseå¦‚æœæ˜¯ continuous distribution å‘¢?è€ƒæ…®å¦‚ä¸‹çš„ standard Gaussian distribution $\\mathcal{N}(0,1)$ å¯ä»¥ä½¿ç”¨ Central Limit Theorem. èˆ‰ä¾‹ä¾†èªªæˆ‘å€‘å¯ä»¥å¾ $n$ å€‹ I.I.D. çš„ $\\mathcal{U}[0,1]$ å– samples, ç„¶å¾Œå¹³å‡èµ·ä¾†. CLT å‘Šè¨´æˆ‘å€‘ç•¶ $n$ å¾ˆå¤§çš„æ™‚å€™, çµæœåˆ†å¸ƒæœƒæ¥è¿‘ $\\mathcal{N}(0,1)$ General continuous caseé‚£å¦‚æœæ˜¯ general case å‘¢? æ–¹æ³•æ˜¯æ‰¾ä¸€å€‹å·²çŸ¥æœƒ sampling çš„åˆ†å¸ƒä¹˜ä¸Š constant value ä½¿å®ƒæˆç‚º upper boundä¾‹å¦‚åˆ©ç”¨ $2q(x)=2\\mathcal{N}(1,9)$ å¯ä»¥è®Šæˆ $p(x)$ çš„ upper bound å› æ­¤æˆ‘å€‘å¯ä»¥ sample $\\tilde{x}$ from $2q(x)$, èˆ‰ä¾‹ä¾†èªªå¾ˆæœ‰å¯èƒ½ $\\tilde{x}=0$ å› ç‚ºåœ¨ $0$ é™„è¿‘çš„æ©Ÿç‡æœ€å¤§. ä½†æ˜¯å°æ–¼æˆ‘å€‘çœŸå¯¦æƒ³è¦ samping çš„ $p(x)$ ä¾†èªª, $0$ åè€Œæ©Ÿç‡æ¯”è¼ƒå°. å› æ­¤æˆ‘å€‘è¦æœ‰ä¸€äº› rejection æ©Ÿåˆ¶. æ‰€ä»¥æµç¨‹å°±æ˜¯, é¦–å…ˆå…ˆå¾å·²çŸ¥çš„ $q(x)$ sample å‡º $\\tilde{x}$, ç”±æ–¼ $2q(x)$ æ˜¯ $p(x)$ çš„ upper bound, å› æ­¤æˆ‘å€‘å¯ä»¥æ ¹æ“šæ¯”ä¾‹ä¾†æ±ºå®šé€™ä¸€æ¬¡çš„ $\\tilde{x}$ æ˜¯å¦æ¥å—. ä¸Šåœ–ç´…è‰²ç‚º rejection è€Œç¶ è‰²ç‚º acception. å› æ­¤ acception æ©Ÿç‡ç‚º: $$\\begin{align} \\frac{p(x)}{2q(x)} \\end{align}$$ æˆ‘å€‘è§£é‡‹ä¸€ä¸‹ç‚ºä½•é€™æ–¹æ³•å¯ä»¥é‹ä½œ, é¦–å…ˆæ³¨æ„åˆ°æ‰€æœ‰å–å‡ºä¾†çš„ $\\tilde{x}$ (é‚„æ²’æ‹’çµ•ä¹‹å‰) æ˜¯å‡å‹»åˆ†å¸ƒåœ¨ $2q(x)$ curve ä¸‹çš„ (è¦‹ä¸‹åœ–). è€Œä¸€æ—¦å¼•å…¥æˆ‘å€‘ rejection çš„æ–¹æ³•, å–å‡ºä¾†çš„é»å°±æ˜¯å‡å‹»åˆ†å¸ƒåœ¨æˆ‘å€‘è¦çš„ $p(x)$ curve ä¸‹äº†. å¾ä¸Šé¢çš„èªªæ˜å¯ä»¥çœ‹å‡º, accept çš„æ¯”ä¾‹å…¶å¯¦å°±æ˜¯è—è‰²çš„æ¯”ä¾‹, å› æ­¤ upper bound æ„ˆç·Šå¯†æ•ˆæœæ„ˆå¥½.æ‰€ä»¥å¦‚æœ $p(x)\\leq Mq(x)$, å‰‡å¹³å‡ accept $1/M$ points. é€™æ˜¯å› ç‚º $p,q$ éƒ½æ˜¯æ©Ÿç‡åˆ†å¸ƒ, æ‰€ä»¥ area under curve éƒ½æ˜¯ $1$. å› æ­¤æ¯”ä¾‹å°±æ˜¯ $1/M$.æœ€å¾Œ, é€™å€‹æ–¹æ³•å¯ä»¥ç”¨åœ¨ä¸çŸ¥é“ normalization term $Z$ çš„æƒ…å½¢. ä¾‹å¦‚æˆ‘å€‘åªçŸ¥é“ $\\hat{p}(x)$, ä½†æˆ‘å€‘ä»ç„¶å¯ä»¥æ‰¾åˆ°ä¸€å€‹ distribution $q(x)$ ä¹˜ä¸Š constant $\\tilde{M}$ å¾Œæ˜¯ upper bound: $$\\hat{p}(x) \\leq \\tilde{M}q(x) \\\\ \\Longrightarrow p(x)=\\frac{\\hat{p}(x)}{Z} \\leq Mq(x)$$ ç¸½è§£ä¸€ä¸‹æ­¤æ³• çµè«–å°±æ˜¯é›–ç„¶å°å¤§éƒ¨åˆ† distribution éƒ½å¯ä»¥ç”¨, ä½†æ•ˆç‡ä¸å¥½. å°¤å…¶åœ¨ç¶­åº¦é«˜çš„æ™‚å€™æœƒå¤§éƒ¨åˆ†éƒ½ reject.é‚£æœ‰ä»€éº¼æ–¹æ³•å¯ä»¥å°ä»˜é«˜ç¶­åº¦å‘¢? ä¸‹é¢è¦ä»‹ç´¹çš„ MCMC with Gibbs/Metropolis-Hastings å°±èƒ½è™•ç†. Markov Chains Monte Carloé€™è£¡å‡è¨­å¤§å®¶å·²ç¶“ç†Ÿæ‚‰ Markov chain äº†, ä¸å¤šåšä»‹ç´¹.ä½¿ç”¨ Markov chain çš„ç­–ç•¥ç‚ºä»¥ä¸‹å¹¾å€‹æ­¥é©Ÿ: é‡é»åœ¨å¦‚ä½•è¨­è¨ˆä¸€å€‹ Markov chain (é€™è£¡ç­‰åŒæ–¼è¨­è¨ˆ transition probability $T$), æ”¶æ–‚çš„ stationary distribution æ­£å¥½å°±æ˜¯æˆ‘å€‘è¦çš„ $p(x)$é¦–å…ˆä¸æ˜¯æ¯å€‹ Markov chain éƒ½æœƒæ”¶æ–‚, ä½†æœ‰ä¸€äº›å……åˆ†æ¢ä»¶å¦‚ä¸‹åœ– Theorem: å°ç…§ Stochastic Processes è£¡çš„ç­†è¨˜ (ä¹‹å¾Œè£œ link), é€™è£¡çš„ theorem éš±å«äº†æ­¤ Markov chain ç‚º ergodic, i.e. 1-equivalence class, recurrent, and aperiodic. è€Œ ergodic Markov chain å¿…å®šå­˜åœ¨ stationary distribution. Gibbs samplingä¸Šé¢æåˆ°ä½¿ç”¨ Markov chain å– sample çš„è©±, æ€éº¼æ¨£çš„ $T$ æœƒè®“å®ƒæ”¶æ–‚åˆ° desired $p(x)$Gibbs sampling å¯ä»¥æƒ³æˆä¸€ç¨®ç‰¹æ®Šçš„ $T$ çš„è¨­è¨ˆæ–¹æ³•, å¯ä»¥ç¢ºä¿æ”¶æ–‚è‡³ $p(x)$å‡è¨­æˆ‘å€‘æœ‰ä¸€å€‹ 3-dim çš„ P.D.F., å¯ä»¥ä¸çŸ¥é“ normalization term $Z$: $$\\begin{align} p(x_1,x_2,x_3)=\\frac{\\hat{p}(x_1,x_2,x_3)}{Z} \\end{align}$$ å¾ $(x_1^0, x_2^0, x_3^0)$ é–‹å§‹, e.g. $(0,0,0)$å…ˆå°ç¬¬ä¸€ç¶­å– sample: $$\\begin{align} x_1^1 \\sim p(x_1 | x_2=x_2^0, x_3=x_3^0) \\\\ = \\frac{\\hat{p}(x_1,x_2^0,x_3^0)}{Z_1} \\end{align}$$ é‡å° 1-d distribution å– sample æ˜¯å¾ˆå®¹æ˜“çš„, å¯ä»¥ä½¿ç”¨ä¸Šä¸€ç¯€çš„åšæ³•æ¥è‘—å°ç¬¬äºŒç¶­å– sample: $$\\begin{align} x_2^1 \\sim p(x_2 | x_1=x_1^{\\color{red}{1}}, x_3=x_3^0) \\end{align}$$ æœ€å¾Œå°ç¬¬ä¸‰ç¶­å– sample: $$\\begin{align} x_3^1 \\sim p(x_3 | x_1=x_1^{\\color{red}{1}}, x_2=x_2^{\\color{red}{1}}) \\end{align}$$ ä»¥ä¸Šä¾¿æ˜¯ä¸€æ¬¡çš„ iteration, æ‰€ä»¥: é¡¯è€Œæ˜“è¦‹, é€™å€‹æ–¹æ³•ä¸èƒ½ parallel, ä¹‹å¾Œæœƒèªªæ€éº¼åŠ é€Ÿ (åˆ©ç”¨ Metropolis-Hastings) è­‰æ˜æ”¶æ–‚è‡³ desired distributionç¾åœ¨è¦è­‰æ˜é€™æ¨£çš„æ¡æ¨£æ–¹å¼å®šç¾©äº†ä¸€å€‹ Markov chain ä¸”æœƒæ”¶æ–‚åˆ° desired distribution $p(x)$, which is stationary!Markov chain çš„ states å®šç¾©ç‚º $p(x)$ çš„ domain, æˆ‘å€‘ä»¥ $n$-dim ä¾†èªªå°±æ˜¯ $(x_1,x_2,â€¦,x_n)$Transition probabilities $p_T(x\\rightarrow xâ€™)$ , i.e. å¾ state $x$ åˆ° $xâ€™$ çš„æ©Ÿç‡, ä½¿ç”¨ Gibbs sampling ä¾†å®šç¾©: $$\\begin{align} p_T(x\\rightarrow x&apos;)=p(x_1&apos;|x_2,x_3,...,x_n)p(x_2&apos;|x_1&apos;,x_3,...,x_n)...p(x_n&apos;|x_1&apos;,x_2&apos;,...,x_{n-1}&apos;) \\end{align}$$ é€™è£¡æˆ‘å€‘åšå€‹å‡è¨­, ä»¤ $p_T(x\\rightarrow xâ€™)&gt;0,\\forall x,xâ€™$, å‰‡ç”±å®šç†çŸ¥é“æ­¤ Markov chain å¿… $\\exists !$ stationary distribution. æ‰€ä»¥ç¾åœ¨å•é¡Œæ˜¯è©² stationary distribution æ˜¯æˆ‘å€‘è¦çš„ $p(x)$ å—?è¦è­‰æ˜ $p(x)$ æ˜¯ stationary, æˆ‘å€‘åªéœ€è­‰æ˜: $$\\begin{align} p(x&apos;)=\\sum_x p(x\\rightarrow x&apos;)p(x) \\end{align}$$ é€™è¡¨ç¤º $p(x)$ ç¶“é 1-step transition å¾Œ, åˆ†å¸ƒä»ç„¶æ˜¯ $p(x)$æ‰€ä»¥å†ä¾†å°±æ˜¯ç”¨ $p_T(x\\rightarrow xâ€™)$ ä»£å…¥, é©—è­‰çœ‹çœ‹å°ä¸å° $$\\begin{align} \\sum_x p_T(x\\rightarrow x&apos;)p(x) \\\\ = \\sum_x p(x_1&apos;|x_2,...,x_n)p(x_2&apos;|x_1&apos;,x_3,...,x_n)...p(x_n&apos;|x_1&apos;,x_2&apos;,...,x_{n-1}&apos;) p(x) \\\\ =p(x_n&apos;|x_1&apos;,...,x_{n-1}&apos;) \\sum_x p(x_1&apos;|x_2,...,x_n)...p(x_{n-1}&apos;|x_1&apos;,...,x_{n-2}&apos;,x_n)p(x) \\\\ = p(x_n&apos;|x_1&apos;,...,x_{n-1}&apos;) \\sum_{x_2,..,x_n} p(x_1&apos;|x_2,...,x_n)...p(x_{n-1}&apos;|x_1&apos;,...,x_{n-2}&apos;,x_n) \\sum_{x_1}p(x) \\\\ = p(x_n&apos;|x_1&apos;,...,x_{n-1}&apos;) \\sum_{x_2,..,x_n} {\\color{orange}{p(x_1&apos;|x_2,...,x_n)}} ...p(x_{n-1}&apos;|x_1&apos;,...,x_{n-2}&apos;,x_n) {\\color{orange}{p(x_2,...,x_n)}} \\\\ = p(x_n&apos;|x_1&apos;,...,x_{n-1}&apos;) \\sum_{x_2,..,x_n} {\\color{orange}{p(x_1&apos;,x_2,...,x_n)}} p(x_2&apos;|x_1&apos;,x_3,...,x_n)...p(x_{n-1}&apos;|x_1&apos;,...,x_{n-2}&apos;,x_n) \\ldots(\\star) \\\\ = p(x_n&apos;|x_1&apos;,...,x_{n-1}&apos;) \\sum_{x_3,..,x_n} {\\color{orange}{p(x_1&apos;,x_3,...x_n)}}p(x_2&apos;|x_1&apos;,x_3,...,x_n)...p(x_{n-1}&apos;|x_1&apos;,...,x_{n-2}&apos;,x_n) \\\\ = p(x_n&apos;|x_1&apos;,...,x_{n-1}&apos;) \\sum_{x_3,..,x_n} {\\color{orange}{p(x_1&apos;,x_2&apos;,x_3,...,x_n)}}p(x_3&apos;|x_1&apos;,x_2&apos;,x_4,...,x_n)...p(x_{n-1}&apos;|x_1&apos;,...,x_{n-2}&apos;,x_n) \\ldots(\\square) \\end{align}$$ è§€å¯Ÿ $(\\star)$ åˆ° $(\\square)$, æ˜¯æ¶ˆè€—æ‰ $x_2$ çš„ summantion, åŒæ™‚ä¹Ÿæ¶ˆè€—æ‰å° $x_2$ çš„ gibbs sampling step. å› æ­¤æˆ‘å€‘å¯ä»¥å° $(\\square)$ åšä¸€æ¨£çš„äº‹æƒ…, å»æ¶ˆè€—æ‰ $x_3$ çš„ summantion ä»¥åŠå° $x_3$ çš„ gibbs step.é‡è¤‡åšæœƒå¾—åˆ°: $$\\begin{align} = p(x_n&apos;|x_1&apos;,x_2&apos;,...,x_{n-1}&apos;)\\sum_{x_n}p(x_1&apos;,...,x_{n-1} &apos;,x_n) \\\\ = p(x_n&apos;|x_1&apos;,x_2&apos;,...,x_{n-1}&apos;) p(x_1&apos;,x_2&apos;,...,x_{n-1}&apos;) \\\\ = p(x_1&apos;,x_2&apos;,...,x_n&apos;)=p(x&apos;) \\end{align}$$ Q.E.D. ç¸½çµå¤§è‡´ä¸Šæœ‰å…©å€‹å‰æ: å›ºå®šå…¶ä»–ç¶­åº¦, å°æŸä¸€ç¶­åº¦å– samples æ˜¯å¾ˆå®¹æ˜“çš„ $p(x_i|x_1,...,x_{i-1}, x_{i+1}, ..., x_n)&gt;0$, é€™ä¿è­‰äº†æˆ‘å€‘é€é Gibbs sampling ç”¢ç”Ÿçš„ Markov chain ä¸€å®šæ”¶æ–‚åˆ° desired $p(x)$ å„ªé»ç‚º: å°‡ multi-dimensional sampling åŒ–ç°¡ç‚º 1-d sampling å®¹æ˜“å¯¦ä½œ ç¼ºé»ç‚º: Highly correlated samples, é€™ä½¿å¾—æˆ‘å€‘è·‘åˆ° stationary distribution å¾Œ, ä¹Ÿä¸èƒ½é€£çºŒçš„å– sample é» Slow convergence (mixing) Not parallel (æ¥ä¸‹ä¾†ä»‹ç´¹çš„ Metropolis Hastings å¹«å¿™å¯ä»¥æ”¹å–„) Metropolis-HastingsGibbs sampling ç¼ºé»æ˜¯ samples are too correlated, ä¸”ä¸èƒ½å¹³è¡ŒåŒ–. æ³¨æ„åˆ°åœ¨ Gibbs sampling æ–¹æ³•è£¡, å·²ç¶“å®šç¾©å¥½æŸä¸€å€‹ç‰¹åˆ¥çš„ Markov chain äº†. Metropolis-Hastings å‰‡å¯ä»¥å®šç¾©å‡ºä¸€å€‹ famliy of Markov chain éƒ½æ”¶æ–‚åˆ° desired distribution. å› æ­¤å¯ä»¥é¸æ“‡æŸä¸€å€‹ Markov chain å¯èƒ½æ”¶æ–‚è¼ƒå¿«, æˆ–æ˜¯ less correlated.Metropolis-Hastings ä¸­å¿ƒæƒ³æ³•å°±æ˜¯ â€œapply rejection sampling to Markov chainsâ€ Algorithm å…¶ä¸­ $Q(x^k\\rightarrow x)$ æ˜¯ä»»æ„äº‹å…ˆçµ¦å®šçš„ä¸€å€‹ transition probabilities (æ³¨æ„åˆ°éœ€æ»¿è¶³ $&gt;0,\\forall x,xâ€™$, é€™æ¨£æ‰èƒ½ä¿è­‰å”¯ä¸€æ”¶æ–‚)$A(x^k\\rightarrow x)$ è¡¨ç¤º given $x^k$ accept $x$ çš„æ©Ÿç‡, ç¨±ç‚º criticæ¼”ç®—æ³•æµç¨‹ç‚º: å…ˆå¾ $Q(x^k\\rightarrow x)$ å–æ¨£å‡º $xâ€™$, $xâ€™$ æœ‰ $A(x^k\\rightarrow xâ€™)$ çš„æ©Ÿç‡è¢«æ¥å—, ä¸€æ—¦æ¥å—å‰‡ $x^{k+1}=xâ€™$ å¦å‰‡ $x^{k+1}=x^k$, ç„¶å¾Œ iterate ä¸‹å»ä½¿ç”¨é€™ç¨®æ–¹å¼çš„è©±, æˆ‘å€‘å…¶å¯¦å¯ä»¥ç®—å‡º transition probability $T(x\\rightarrow xâ€™)$, å¦‚ä¸Šåœ–æ‰€ä»¥é—œéµå°±æ˜¯, æ€éº¼é¸æ“‡ $A(x^k\\rightarrow x)$ ä½¿å¾—é€™æ¨£çš„ Markov chain å¯ä»¥æ”¶æ–‚åˆ° desired probability $\\pi(x)$ æ€éº¼é¸æ“‡ Critic $A$ ä½¿å¾— Markov chain æ”¶æ–‚åˆ° $\\pi$æˆ‘å€‘å…ˆä»‹ç´¹ä¸€å€‹å……åˆ†æ¢ä»¶ (æ‰€ä»¥æœ‰å¯èƒ½ $\\pi(x)$ æ˜¯ stationary ä½†æ˜¯ä¸æ»¿è¶³ detailed balance equation) [Detailed Balance Equation]:è‹¥ $\\pi(x)T(x\\rightarrow xâ€™)=\\pi(xâ€™)T(xâ€™\\rightarrow x), \\forall x,xâ€™$, å‰‡ $\\pi(x)$ ç‚º stationary distribution, i.e. $\\pi(x&apos;)=\\sum_x \\pi(x)T(x\\rightarrow x&apos;)$ [Proof]: $$\\begin{align} \\sum_x \\pi(x)T(x\\rightarrow x&apos;) \\\\ \\text{by assumption} = \\sum_x \\pi(x&apos;)T(x&apos;\\rightarrow x) \\\\ = \\pi(x&apos;)\\sum_x T(x&apos;\\rightarrow x) = \\pi(x&apos;) \\end{align}$$ æ‰€ä»¥åªè¦é¸æ“‡çš„ $A(x\\rightarrow xâ€™)$ èƒ½å¤ è®“ $T(x\\rightarrow xâ€™)$ é‡å° $\\pi(x)$ æ»¿è¶³ detailed balance ç‰¹æ€§å°±èƒ½ä¿è­‰ Markov chain æ”¶æ–‚åˆ° $\\pi(x)$å› æ­¤æˆ‘å€‘è¨ˆç®—ä¸€ä¸‹, åªéœ€è€ƒæ…® $x\\neq xâ€™$ çš„æƒ…å½¢ (å› ç‚º $x=xâ€™$ ä¸€å®šæ»¿è¶³ detailed balance equation, é€™ä¸æ˜¯å»¢è©±å—) $$\\begin{align} \\pi(x)T(x\\rightarrow x&apos;)=\\pi(x&apos;)T(x&apos;\\rightarrow x) \\\\ \\Longleftrightarrow \\pi(x)Q(x\\rightarrow x&apos;)A(x\\rightarrow x&apos;) = \\pi(x&apos;)Q(x&apos;\\rightarrow x)A(x&apos;\\rightarrow x) \\\\ \\Longleftrightarrow \\frac{A(x\\rightarrow x&apos;)}{A(x&apos;\\rightarrow x)} = \\frac{\\pi(x&apos;)Q(x&apos;\\rightarrow x)}{\\pi(x)Q(x\\rightarrow x&apos;)} =: \\rho \\end{align}$$ æ‰€ä»¥ç•¶ $\\rho&lt;1$ æˆ‘å€‘è¨­å®š $$\\begin{align} \\left\\{ \\begin{array}{r} A(x\\rightarrow x&apos;)=\\rho \\\\ A(x&apos;\\rightarrow x)=1 \\end{array} \\right. \\end{align}$$ è€Œå¦‚æœ $\\rho&gt;1$ æˆ‘å€‘è¨­å®š $$\\begin{align} \\left\\{ \\begin{array}{r} A(x\\rightarrow x&apos;)=1 \\\\ A(x&apos;\\rightarrow x)=1/\\rho \\end{array} \\right. \\end{align}$$ ç¸½çµä¾†èªª $A$ å¯ä»¥é€™éº¼è¨­å®š $$\\begin{align} A(x\\rightarrow x&apos;)=\\min\\left\\{ 1, \\frac{\\pi(x&apos;)Q(x&apos;\\rightarrow x)}{\\pi(x)Q(x\\rightarrow x&apos;)} \\right\\} \\end{align}$$ æ³¨æ„åˆ° $\\rho$ æ˜¯å¯ä»¥ç›´æ¥ç®—å‡ºä¾†çš„, å› ç‚º $Q,\\pi$ éƒ½æ˜¯äº‹å…ˆçµ¦å®šå·²çŸ¥çš„, å› æ­¤æˆ‘å€‘å°±èƒ½è¨­å®šå‡ºå°æ‡‰çš„ acceptance distribution $A$. åŒæ™‚å¦‚æœæˆ‘å€‘åªæœ‰ unnormalized distribution, i.e. $\\hat\\pi(x)$, ç”± $A$ çš„è¨­å®šå¯ä»¥çœ‹å‡ºä¸å—å½±éŸ¿ $$\\begin{align} A(x\\rightarrow x&apos;)=\\min\\left\\{ 1, \\frac{ {\\color{orange}{\\hat\\pi(x&apos;)}} Q(x&apos;\\rightarrow x)}{ {\\color{orange}{\\hat\\pi(x)}} Q(x\\rightarrow x&apos;)} \\right\\} \\end{align}$$ æ€éº¼é¸æ“‡ $Q$é¦–å…ˆéœ€æ»¿è¶³ $Q(x\\rightarrow xâ€™)&gt;0,\\forall x,xâ€™$. é€™æ¨£æ‰æœƒæœ‰ä»¥ä¸Šçš„æ¨è«–.$Q$ æœƒå¸Œæœ›èƒ½èµ°â€å¤§æ­¥â€ä¸€é», ä¹Ÿå°±æ˜¯ transition ä¸è¦åªåœç¹åœ¨ç›¸é„°çš„é». å¥½è™•æ˜¯ç”¢ç”Ÿçš„ sample æœƒæ¯”è¼ƒç„¡é—œ.ä½†å¦‚æœèµ°å¤ªå¤§æ­¥, critic $A$ å°±æœ‰å¯èƒ½ä¸€ç›´ reject (why?) å°è‡´æ•ˆç‡å¤ªå·® æƒ³åƒå¦‚æœ $x$ å·²ç¶“åœ¨æ©Ÿç‡å¾ˆé«˜çš„åœ°æ–¹äº†, ä¾‹å¦‚ local maximum point. å¦‚æœ $Q$ èµ°å¤ªå¤§æ­¥åˆ° $xâ€™$, å‰‡å®¹æ˜“ $\\pi(xâ€™)&lt;&lt;\\pi(x)$, é€ æˆ $A$ å¤ªå°å®¹æ˜“ rejectæ‰€ä»¥å¦‚æœ $Q$ èµ°å°æ­¥ä¸€é», $xâ€™$ é‚„æ˜¯åœç¹åœ¨ $x$ é™„è¿‘, ç›¸å°ä¾†èªªå¯èƒ½æ©Ÿç‡å°±ä¸æœƒé‚£éº¼ä½ Example of Metropolis-Hastings1-d case toy example å‘Šè¨´æˆ‘å€‘ proposal çš„ distribution é¸æ“‡ä¹Ÿæ˜¯å¾ˆé‡è¦çš„. æœ€å¾Œå¯ä»¥ä½¿ç”¨ Metropolis Hastings ä¾†å¹³è¡ŒåŒ– Gibbs sampling!æˆ‘å€‘ä½¿ç”¨å¦‚ä¸‹åœ– â€œéŒ¯èª¤çš„â€ Gibbs sampling æ–¹æ³•, ä¸¦å°‡é€™æ–¹æ³•è¦–ç‚º Metropolis Hastings çš„ proposal $Q(x\\rightarrow xâ€™)$å› æ­¤å¯ä»¥å¹³è¡Œå°æ¯å€‹ç¶­åº¦å– sample! (å¥½è°æ˜!) çµèªMCMC è¢«è­½ç‚º 20 ä¸–ç´€åå€‹å‰å¤§çš„æ¼”ç®—æ³•ç™¼æ˜ä¹‹ä¸€ [3]. æ‰¾çŸ¥ä¹çš„æ–‡ç« å¯ä»¥çœ‹åˆ°é€™å€‹è¨è«–: æœ‰ä»€ä¹ˆç†è®ºå¤æ‚ä½†æ˜¯å®ç°ç®€å•çš„ç®—æ³•ï¼Ÿ[4] æœç„¶ MCMC ç†è«–ä¸æ˜¯ä¸€èˆ¬äººèƒ½åšçš„.å¾ŒçºŒå°æ–¼ Metropolis-Hastings çš„æ”¹é€²æœ‰ä¸€å€‹ç®—æ³•æ˜¯ Metropolis-adjusted Langevin algorithm [5] (MALA). è©²æ–¹æ³•æå‡ºä½¿ç”¨ Langevin dynamics [6] ç•¶ä½œ proposal, é€™æœƒä½¿å¾— random walk æœƒèµ°å‘æ©Ÿç‡æ¯”è¼ƒé«˜çš„åœ°æ–¹, å› æ­¤è¢«æ‹’çµ•æ©Ÿç‡è¼ƒä½. ä½†æ˜¯ MALA æˆ‘å¯¦åœ¨çœ‹ä¸æ‡‚, åªçŸ¥é“è·Ÿ Langevin dynamics sampling [7] æœ‰é—œ åœ¨ Generative Modeling by Estimating Gradients of the Data Distribution [8] çš„ Langevin dynamics æ®µè½è£¡æåˆ° MALA å¯ä»¥åªæ ¹æ“š score function ($\\nabla_x \\log p(x)$) å°±å¾ P.D.F. $p(x)$ å– samples! æœƒçœ‹åˆ° MALA æ˜¯å› ç‚ºé™¤äº† GAN ä¹‹å¤–æœ€è¿‘å¾ˆç†±é–€çš„ generative models: DPM [9]), å…¶æ ¸å¿ƒæŠ€è¡“ä¹‹ä¸€ç”¨åˆ°å®ƒ.çœ‹ä¾†è¦å…¨éƒ¨èæœƒè²«é€šç›®å‰æœƒå…ˆå¡é—œåœ¨é€™äº†. MALA ä½ ç­‰è‘—! åˆ¥è·‘å•Š, ä¸è¦ä»¥ç‚ºæˆ‘æ€•äº†ä½ , ç¸½æœ‰ä¸€å¤©æˆ‘ #$@^#@$Q (é€ƒ~) Appendixè­‰æ˜ $var[\\hat f]=\\frac{1}{L}Var(f)$ å¦‚ä¸‹: é¦–å…ˆå…©å€‹ independent r.v.s $X,Y$ æˆ‘å€‘çŸ¥é“å…¶ covariance ç‚º $0$: $$\\begin{align} 0 = Cov[XY] = \\mathbb{E}\\left[ (X-\\mu_x)(Y-\\mu_y) \\right] \\\\ = \\mathbb{E}[XY-X\\mu_y-\\mu_xY+\\mu_x\\mu_y] = \\mathbb{E}[XY] - \\mu_x\\mu_y \\\\ \\Rightarrow \\mathbb{E}[XY] = \\mu_x\\mu_y \\ldots(\\star) \\end{align}$$ ä¸”æœ‰ variance çš„æ€§è³ª: $Var(X)=\\mathbb{E}[X^2]-\\mu_x^2\\ldots(\\star\\star)$æ¥è‘—é–‹å§‹è¨ˆç®—: $$\\begin{align} Var[\\hat f]=\\mathbb{E}[(\\hat f - \\mathbb{E}[\\hat f])^2] = \\mathbb{E}[(\\hat f - \\mu)^2] = \\mathbb{E}[\\hat f^2] - \\mu^2 \\\\ = \\mathbb{E}\\left[ \\frac{1}{L}\\sum_k f(x_k) \\frac{1}{L}\\sum_m f(x_m) \\right] - \\mu^2 \\\\ = \\frac{1}{L^2}\\sum_k\\sum_m\\left[ \\mathbb{E}[f(x_k)f(x_m)] - \\mu^2 \\right] \\\\ \\text{by }(\\star)= \\frac{1}{L^2}\\sum_k \\left[ (\\mathbb{E}[f(x_k)^2]-\\mu^2)+(L-1)(\\mu^2-\\mu^2) \\right] \\\\ \\text{by }(\\star\\star) = \\frac{1}{L^2}\\sum_k Var(f(x_k)) \\\\ = \\frac{1}{L} Var(f) \\end{align}$$ Reference Curse of Dimensionality â€” A â€œCurseâ€ to Machine Learning Coursera: Bayesian Methods for Machine Learning The Best of the 20th Century: Editors Name Top 10 Algorithms æœ‰ä»€ä¹ˆç†è®ºå¤æ‚ä½†æ˜¯å®ç°ç®€å•çš„ç®—æ³•ï¼Ÿ Metropolis-adjusted Langevin algorithm: wiki Langevin dynamics: wiki æŠ½æ ·ç†è®ºä¸­æœ‰å“ªäº›ä»¤äººå°è±¡æ·±åˆ»(æœ‰è¶£)çš„ç»“è®º? Generative Modeling by Estimating Gradients of the Data Distribution What are Diffusion Models?","tags":[{"name":"MCMC","slug":"MCMC","permalink":"https://bobondemon.github.io/tags/MCMC/"},{"name":"Metropolis Hastings","slug":"Metropolis-Hastings","permalink":"https://bobondemon.github.io/tags/Metropolis-Hastings/"},{"name":"Coursera","slug":"Coursera","permalink":"https://bobondemon.github.io/tags/Coursera/"},{"name":"Markov Chain","slug":"Markov-Chain","permalink":"https://bobondemon.github.io/tags/Markov-Chain/"},{"name":"Gibbs Sampling","slug":"Gibbs-Sampling","permalink":"https://bobondemon.github.io/tags/Gibbs-Sampling/"}]},{"title":"Gumbel-Max Trick","date":"2021-08-07T10:41:01.000Z","path":"2021/08/07/Gumbel-Max-Trick/","text":"æˆ‘å€‘åœ¨ä»‹ç´¹ VAE çš„æ™‚å€™æœ‰èªªæ˜åˆ° re-parameterization trick, å¤§æ„æ˜¯é€™æ¨£çš„ $y$ æ˜¯ sampling from distribution $\\alpha$, i.e., $y=\\text{Sampling}(\\alpha)$, å…¶ä¸­ $\\alpha=\\text{NN}_1(a;\\theta)$ç”±æ–¼æˆ‘å€‘æœ‰æ¡æ¨£, å› æ­¤ loss æ¡ç”¨æœŸæœ›å€¼. Loss function ç‚º: $$\\begin{align} L = \\mathbb{E}_{y\\sim\\alpha}[\\text{NN}_2(y;\\nu)] \\end{align}$$ Loss å° $\\theta$ åå¾®åˆ†çš„æ™‚å€™æœƒå¤±æ•—, ä¸»è¦æ˜¯å› ç‚º: $$\\begin{align} \\nabla_\\theta L = \\nabla_\\theta \\mathbb{E}_{y\\sim\\alpha}[\\text{NN}_2(y;\\nu)] \\\\ \\neq \\mathbb{E}_{y\\sim\\alpha}[\\nabla_\\theta \\text{NN}_2(y;\\nu)] \\end{align}$$ å¾®åˆ†ä¸èƒ½è·Ÿ Expectation äº’æ›æ˜¯å› ç‚º sampling çš„ distribution $\\alpha$ å…¶å¯¦ä¹Ÿæ˜¯ depends on $\\theta$. å› æ­¤åœ¨ VAE é‚£é‚Šçš„å‡è¨­å°±æ˜¯å°‡ $\\alpha$ å®šç¾©ç‚º Gaussian pdf. å› æ­¤å¯ä»¥è®Šæˆ: $$\\begin{align} \\nabla_\\theta L = \\nabla_\\theta \\mathbb{E}_{y\\sim\\alpha}\\left[ \\text{NN}_2(y;\\nu) \\right] \\\\ = \\nabla_\\theta \\mathbb{E}_{\\varepsilon\\sim N(0,I)}\\left[ \\text{NN}_2(\\mu+\\sigma\\varepsilon; \\nu) \\right] \\\\ = \\mathbb{E}_{\\varepsilon\\sim N(0,I)}\\left[ \\nabla_\\theta \\text{NN}_2(\\mu+\\sigma\\varepsilon; \\nu) \\right] \\end{align}$$ æ¡æ¨£è®Šæˆå¾ä¸€å€‹ è·Ÿ $\\theta$ ç„¡é—œçš„åˆ†å¸ƒ, å› æ­¤å¾®åˆ†è·ŸæœŸæœ›å€¼å°±èƒ½äº’æ›, æ‰€ä»¥å¯ä»¥åš backprop. ç¾åœ¨çš„æƒ…æ³æ˜¯å¦‚æœæ˜¯ Gaussian çš„æƒ…å½¢å¾ˆå¥½åšè®Šæ›, ä½†å¦‚æœæ˜¯ categorical distribution è©²æ€éº¼è¾¦å‘¢? ä»€éº¼æƒ…æ³æœƒé‡åˆ° categorical distribution? åœ¨ reinforcement learning æ™‚, $\\text{NN}_1$ predict å‡ºä¾‹å¦‚ 4 å€‹ actions çš„æ©Ÿç‡, æˆ‘å€‘éœ€è¦éš¨æ©Ÿæ¡æ¨£ä¸€ç¨® action, ç„¶å¾Œå‚³çµ¦å¾Œé¢çš„ NN å»è¨ˆç®— reward.(å…¶å¯¦æˆ‘ä¸ç†Ÿ RL, çœ‹ç¶²è·¯ä¸Šçš„æ–‡ç« èªªçš„) Gumbel max trick å°±æä¾›äº†è§£æ³•! Gumbel Distribution and Gumbel Max Samplingé€™ä¸€ç¯‡æ–‡ç«  The Humble Gumbel Distribution æä¾›äº†éå¸¸æ¸…æ™°çš„è§£é‡‹, ååˆ†æ¨è–¦é–±è®€ å‡è¨­æˆ‘å€‘ç¶“ç”±ä¸€å€‹ network ç®—å‡º logits $(x_k)_k$, ä¸€èˆ¬æˆ‘å€‘å¦‚æœè¦ sampling çš„è©±é‚„å¿…é ˆé softmax è®“å®ƒè®Šæˆæ©Ÿç‡ $(\\alpha_k)_k$, ç„¶å¾Œåœ¨ç”¨ä¾‹å¦‚ np.random.choice æ ¹æ“šæ©Ÿç‡æ¡æ¨£å‡ºçµæœ. ç¾åœ¨ sampling æµç¨‹æ”¹ç‚º: å…ˆå¾æ¨™æº– Gumbel åˆ†ä½ˆ (å…ˆä¸ç®¡é€™åˆ†ä½ˆé•·ä»€éº¼æ¨£) æ¡æ¨£å‡º $N$ å€‹å€¼, ä»¤ç‚º $(G_k)_k$, è®“å®ƒè·Ÿ logits ç›¸åŠ : $z_k=x_k+G_k$, ç„¶å¾Œ $\\text{argmax}_k (z_k)$ å°±æ˜¯æˆ‘å€‘é€™æ¬¡çš„æ¡æ¨£çµæœ åœ–ç¤ºç‚º: æ³¨æ„åˆ°æˆ‘å€‘å”¯ä¸€çš„ä¸€å€‹æ¡æ¨£å‹•ä½œå®Œå…¨è·Ÿ network çš„åƒæ•¸ $\\theta$ ç„¡é—œ! å› æ­¤ re-parameterization trick å°±èƒ½ç”¨ä¸Š. (å…ˆå‡è¨­ $\\text{argmax}_k (z_k)$ å¯å¾®, å› æ­¤å¯ä»¥ backprop, é€™ç­‰ä¸‹æœƒèªª)å‰©ä¸‹å”¯ä¸€ä¸ç¢ºå®šçš„å°±æ˜¯, é€™æ¨£çš„æ¡æ¨£è¡Œç‚ºå‡ºä¾†çš„çµæœ, æœƒè·Ÿä½¿ç”¨ $(\\alpha_k)_k$ çš„æ©Ÿç‡åˆ†ä½ˆæ¡æ¨£å‡ºä¾†ä¸€æ¨£å— ?æ›å¥è©±èªª, $\\text{argmax}_k (z_k)$ å‡ºä¾†çš„çµæœ, å…¶çµæœçš„åˆ†ä½ˆæ˜¯ä¸æ˜¯ç¬¦åˆ $(\\alpha_k)_k$ ?ç¨‹å¼é©—è­‰å¯åƒè€ƒ The Humble Gumbel Distribution, å°‡æœ€ä¸»è¦çš„éƒ¨åˆ†ä¿®çŸ­æ“·å–å¾Œå¦‚ä¸‹: 123456789101112131415161718192021222324252627282930313233343536373839# Modified from http://amid.fish/humble-gumbelimport numpy as npimport matplotlib.pyplot as plt# Assign categorical probabilities, for example:probs = [0.13114754, 0.01639344, 0.21311475, 0.24590164, 0.19672131, 0.06557377, 0.13114754]n_classes = len(probs)logits = np.log(probs) # logits is log probability (with constant offset)n_samples = 10000 # experimental number of samplingdef gumbel_sampling(logits): noise = np.random.gumbel(size=len(logits)) sample = np.argmax(logits + noise) return samplesamples_with_gumbel_max_trick = [gumbel_sampling(logits) for _ in range(n_samples)]samples_from_true_distribution = np.random.choice(np.arange(n_classes), size=n_samples , p=probs)# Plotting area, comparing `samples_with_gumbel_max_trick` and `samples_from_true_distribution`def plot_estimated_probs(samples, n_classes): estd_probs, _, _ = plt.hist(samples, bins=np.arange(n_classes + 1), align='left', edgecolor='white', density=True) plt.xlabel(\"Category\") plt.ylabel(\"Estimated probability\") return estd_probsplt.figure()plt.subplot(1, 2, 1)plot_estimated_probs(samples_from_true_distribution, n_classes)plt.title('Sampling from true pdf')plt.subplot(1, 2, 2)estd_probs = plot_estimated_probs(samples_with_gumbel_max_trick, n_classes)plt.title('Sampling with Gumbel-max trick')plt.tight_layout()plt.show() å¯ä»¥çœ‹åˆ°ç”¨ Gumbel-max trick æ¡æ¨£å‡ºä¾†çš„ samples å…¶åˆ†ä½ˆè·ŸçœŸå¯¦çš„æ©Ÿç‡åˆ†ä½ˆååˆ†æ¥è¿‘.äº‹å¯¦ä¸Šå¯ä»¥è­‰æ˜æœƒæ˜¯ä¸€æ¨£çš„, åœ¨ä¸‹ä¸€ç¯€æˆ‘å€‘å°‡è­‰æ˜å¯«å‡ºä¾†.å†å›‰å—¦ä¸€ä¸‹, ä¸è¦å¿˜è¨˜äº†, ä½¿ç”¨ np.random.choice å°çœŸå¯¦åˆ†ä½ˆæ¡æ¨£æ˜¯æ²’æœ‰è¾¦æ³•åš backprop çš„ (è¦‹ eq (2) (3))è€Œé€é Gumbel-max trick æˆ‘å€‘å¯ä»¥å¾ä¸€å€‹èˆ‡è¦ optimize çš„åƒæ•¸ $\\theta$ ç„¡é—œçš„åˆ†ä½ˆ (Gumbel distribution) é€²è¡Œæ¡æ¨£, æ‰èƒ½åˆ©ç”¨ re-parameterization trick åš backprop (ä¾‹å¦‚ eq (4)~(6) çš„æ¦‚å¿µ) å…¶å¯¦æˆ‘å°‘è¬›äº†ä¸€ä»¶äº‹, np.argmax ä¸å¯å¾®, æ‰€ä»¥ä¸èƒ½ backprop. å› æ­¤ä¸€å€‹å¯¦éš›çš„åšæ³•æ˜¯ä½¿ç”¨ softmax (with temperature) è¿‘ä¼¼: $$\\begin{align} \\text{softmax}(z_k,\\tau)=\\frac{\\exp(z_k/\\tau)}{\\sum_{i=1}^N\\exp(z_i/\\tau)} \\end{align}$$ å¯¦ä½œä¸Šæœƒå…ˆè®“ temperature $\\tau$ å¾æ¯”è¼ƒå¤§çš„å€¼é–‹å§‹ (æ¯”è¼ƒä¸é‚£éº¼å‡¸é¡¯å€¼ä¹‹é–“å¤§å°çš„å·®ç•°), ä¹‹å¾Œæ…¢æ…¢è®Šå°æ¥è¿‘ $0$ (ç­‰åŒæ–¼ argmax). åƒè€ƒ paper çš„åœ–: Proof of Gumbel-Max Trick for Discrete Distributionså…¶å¯¦å®Œå…¨åƒè€ƒ The Gumbel-Max Trick for Discrete Distributions, ä½†æœ€å¾Œä¸€è¡Œçš„æ¨å°ç”¨çœ‹çš„å¯¦åœ¨æ²’çœ‹å‡ºä¾†, å› æ­¤è‡ªå·±è£œé½Šå®Œæ•´ä¸€é» Math warning, å¾ˆæ¯ç‡¥ Gumbel PDF: $f(z;\\mu)=\\exp\\left[-(z-\\mu)-\\exp\\left[-(z-\\mu)\\right]\\right]$ $f(z;0)=\\exp\\left[-z-\\exp\\left[-z\\right]\\right]$ Gumbel CDF: $F(z;\\mu)=\\exp\\left[-\\exp\\left[-(z-\\mu)\\right]\\right]$ $F(z;0)=\\exp\\left[-\\exp\\left[-z\\right]\\right]$ Categorical distribution ä¾‹å¦‚åˆ†æˆ $N$ é¡, NN é€šå¸¸æœ€å¾Œæœƒè¼¸å‡ºä¸€å€‹ logits vector, $(x_k)_k$, $k=1â€¦N$ $z_k=x_k+G_k$, å…¶ä¸­ $G_k$ æ˜¯ä¸€å€‹æ¨™æº– Gumbel distribution (mean=0, scale=1) $$\\begin{align} \\Pr(k\\text{ is largest}|\\{x_i\\},z_k) = \\Pr(\\max_{i\\neq k}z_i&lt;z_k) \\\\ =\\prod_{i\\neq k}\\Pr(z_i&lt;z_k) = \\prod_{i\\neq k}\\Pr(x_i+G_i&lt;z_k) \\\\ =\\prod_{i\\neq k}\\Pr(G_i&lt;z_k-x_i) \\\\ =\\prod_{i\\neq k}F(z_k-x_i;0) \\\\ =\\prod_{i\\neq k}\\exp\\{-\\exp\\{-z_k+x_i\\}\\} \\end{align}$$ $$\\begin{align} \\therefore \\Pr(k\\text{ is largest}|\\{x_i\\})=\\int\\Pr(z_k)\\Pr(k\\text{ is largest}|\\{x_i\\},z_k)dz_k \\\\ = \\int f(z_k-x_k;0)\\prod_{i\\neq k}\\exp\\{-\\exp\\{-z_k+x_i\\}\\} \\\\ = \\int \\left(\\exp\\{-z_k+x_k-e^{-z_k+x_k}\\}\\right) \\prod_{i\\neq k}\\exp\\{-e^{-z_k+x_i}\\} dz_k \\\\ =\\int \\exp\\{-z_k+x_k\\}\\prod_{i=1}^N{ \\exp\\{-e^{-z_k+x_i}\\} } dz_k \\\\ = \\int \\exp\\{-z_k+x_k\\} \\cdot \\exp\\{-\\sum_{i=1}^Ne^{-z_k+x_i}\\} dz_k \\\\ =\\int \\exp\\{-z_k+x_k-\\sum_{i=1}^Ne^{-z_k+x_i} \\} dz_k \\\\ =\\int \\exp\\{-z_k+x_k-e^{-z_k} {\\color{orange}{\\sum_{i=1}^Ne^{x_i}}} \\} dz_k \\\\ =\\int \\exp\\{-z_k+x_k- {\\color{orange}A} e^{-z_k} \\} dz_k \\end{align}$$ é€™è£¡æˆ‘å€‘ç‚ºäº†æ–¹ä¾¿å®šç¾© $A=\\sum_{i=1}^N e^{x_i}$ $$\\begin{align} =\\int \\exp\\{-z_k+x_k - {\\color{orange}{e^{\\ln A}}} e^{-z_k} \\} dz_k \\\\ = e^{x_k} \\int \\exp\\{-z_k-e^{-z_k + \\ln A}\\} dz_k \\\\ = e^{x_k} \\int \\exp\\{-z_k {\\color{orange}{+\\ln A-\\ln A}} -e^{-z_k + \\ln A}\\} dz_k \\\\ = e^{x_k}\\cdot e^{-\\ln A} \\int \\exp\\{-(z_k-\\ln A)-e^{-(z_k-\\ln A)}\\} dz_k \\\\ = \\frac{e^{x_k}}{A} \\int f(z_k;\\ln A) dz_k \\\\ = \\frac{e^{x_k}}{\\sum_{i=1}^N e^{x_i}} \\end{align}$$ Reference The Humble Gumbel Distribution The Gumbel-Max Trick for Discrete Distributions The Gumbel-Softmax Trick for Inference of Discrete Variables ã€ä¸€æ–‡å­¦ä¼šã€‘Gumbel-Softmaxçš„é‡‡æ ·æŠ€å·§ Categorical Reparameterization with Gumbel-Softmax","tags":[{"name":"Gumbel distribution","slug":"Gumbel-distribution","permalink":"https://bobondemon.github.io/tags/Gumbel-distribution/"},{"name":"Gumbel max trick","slug":"Gumbel-max-trick","permalink":"https://bobondemon.github.io/tags/Gumbel-max-trick/"},{"name":"Gumbel max sampling","slug":"Gumbel-max-sampling","permalink":"https://bobondemon.github.io/tags/Gumbel-max-sampling/"},{"name":"Re-parameterization trick","slug":"Re-parameterization-trick","permalink":"https://bobondemon.github.io/tags/Re-parameterization-trick/"}]},{"title":"Noise Contrastive Estimation (NCE) ç­†è¨˜","date":"2021-06-05T02:15:04.000Z","path":"2021/06/05/Noise-Contrastive-Estimation-NCE-ç­†è¨˜/","text":"ä¹‹å‰è½äººä»‹ç´¹ wav2vec [3] æˆ–æ˜¯çœ‹å…¶ä»–äººçš„æ–‡ç« å¤§éƒ¨åˆ†éƒ½åªæœ‰ä»‹ç´¹ä½œæ³•, ç›´åˆ°æœ‰ä¸€å¤©è‡ªå·±å»çœ‹è«–æ–‡æ‰ç™¼ç¾çœ‹ä¸æ‡‚ CPC [2] (wav2vec ä½¿ç”¨ CPC æ–¹æ³•). å› æ­¤æ‰æ±ºå®šå¥½å¥½è®€ä¸€ä¸‹ä¸¦è¨˜éŒ„. å…ˆå°‡é€™äº›æ–¹æ³•é—œä¿‚æ¢³ç†ä¸€ä¸‹, NCE â€“&gt; CPC (infoNCE) â€“&gt; wav2vec. æ­¤ç¯‡ç­†è¨˜ä¸»è¦ç´€éŒ„ NCE (Noise Contrastive Estimation) åœ¨åš ML æ™‚å¸¸å¸¸éœ€è¦ä¼°è¨ˆæ‰‹ä¸Š training data çš„ distribution $p_d(x)$. è€Œæˆ‘å€‘é€šå¸¸æœƒä½¿ç”¨åƒæ•¸ $\\theta$, ä½¿å¾—åƒæ•¸çš„æ¨¡å‹è·Ÿ $p_d(x)$ ä¸€æ¨£. åœ¨ç¾åœ¨ DNN çµ±æ²»çš„å¹´ä»£å¯èƒ½æœƒèªª, ä¸ç„¶å°±ç”¨ä¸€å€‹ NN ä¾†è¨“ç·´å§, å¦‚ä¸‹åœ–: çµ¦ input $x$, ä¸Ÿçµ¦ NN å¸Œæœ›ç›´æ¥åå‡º $p_\\theta(x)$. ä¸Šåœ–çš„æ¶æ§‹æ˜¯ $x$ å…ˆä¸Ÿçµ¦åƒæ•¸ç‚º $\\theta_f$ çš„ NN, è©² NN æœ€å¾Œä¸€å±¤çš„ outputs å†ä¸Ÿçµ¦åƒæ•¸ç‚º $w$ çš„ linear layer æœ€å¾Œåå‡ºä¸€å€‹ scalar å€¼, è©²å€¼å°±æ˜¯æˆ‘å€‘è¦çš„æ©Ÿç‡.è€Œè¨“ç·´çš„è©±å°±ä½¿ç”¨ MLE (Maximum Likelihood Estimation) ä¾†æ±‚åƒæ•¸ $\\theta$. æ©, å•é¡Œä¼¼ä¹å¾ˆå–®ç´”ä½†çœŸæ­£å¯¦ä½œèµ·ä¾†å»å›°é›£é‡é‡. ä¸€å€‹å•é¡Œæ˜¯ NN outputs è‹¥è¦ä¿æŒ p.d.f. å‰‡å¿…é ˆé softmax, ç¢ºä¿ sum èµ·ä¾†æ˜¯ 1 (ä¹Ÿå°±æ˜¯è¦ç®— $Z_\\theta$). $$\\begin{align} p_\\theta(x)=\\frac{u_\\theta(x)}{Z_\\theta}=\\frac{e^{G(x;\\theta)}}{Z_\\theta} \\\\ \\text{where } Z_\\theta = \\sum_x u_\\theta(x) \\end{align}$$ å¼ (1) ç‚º energy-based model, åœ¨åš NN classification æ™‚, NN çš„ output å°±æ˜¯ $G(x;Î¸)$, ä¹Ÿå°±æ˜¯å¸¸çœ‹åˆ°çš„ logit, ç¶“é softmax å°±ç­‰åŒæ–¼å¼ (1) åœ¨åšçš„äº‹ è€Œåšé€™ä»¶äº‹æƒ…åœ¨ $x$ æ˜¯ discrete space ä½†æ•¸é‡å¾ˆå¤š, ä¾‹å¦‚ NLP ä¸­ LM vocabulary å¾ˆå¤§æ™‚, è¨ˆç®—è³‡æºæœƒæ¶ˆè€—éå¤§.æˆ–æ˜¯ $x$ æ˜¯ continuous space ä½†æ˜¯ç®— $Z_\\theta$ çš„ç©åˆ†æ²’æœ‰å…¬å¼è§£çš„æƒ…å½¢æœƒåšä¸ä¸‹å». (ä¸ç„¶å°±è¦ç”¨ sampling æ–¹æ³•, å¦‚ MCMC) NCE å·§å¦™çš„å°‡æ­¤ MLE å•é¡Œè½‰åŒ–æˆ binary classification å•é¡Œ, å¾è€Œå¾—åˆ°æˆ‘å€‘è¦çš„ MLE è§£. ä¸éåœ¨æ­¤ä¹‹å‰, æˆ‘å€‘å…ˆä¾†çœ‹çœ‹ MLE çš„ gradient é•·ä»€éº¼æ¨£. MLE æ±‚è§£å¯«å‡º likelihood: $$\\begin{align} \\text{likilhood}=\\prod_{x\\sim p_d} p_\\theta(x) \\end{align}$$ Loss å°±æ˜¯ negative log-likelihood $$\\begin{align} -\\mathcal{L}_{mle}=\\mathbb{E}_{x\\sim p_d}\\log p_{\\theta}(x)= \\mathbb{E}_{x\\sim p_d}\\log \\frac{u_\\theta(x)}{Z_\\theta}\\\\ \\end{align}$$ è¨ˆç®—å…¶ gradient: $$\\begin{align} -\\nabla_{\\theta}\\mathcal{L}_{mle}= \\mathbb{E}_{x\\sim p_d} \\left[ \\nabla_{\\theta}\\log{u_\\theta(x)} - \\color{orange}{\\nabla_{\\theta}\\log{Z_\\theta}} \\right] \\\\ \\color{orange}{\\nabla_{\\theta}\\log{Z_\\theta}} = \\frac{1}{Z_\\theta}\\nabla_{\\theta}Z_\\theta = \\frac{1}{Z_\\theta} \\sum_x \\nabla_{\\theta} e^{G(x;\\theta)} \\\\ =\\frac{1}{Z_\\theta} \\sum_x e^{G(x;\\theta)} \\nabla_{\\theta}G(x;\\theta) = \\sum_x \\left[ \\frac{1}{Z_\\theta}e^{G(x;\\theta)} \\right] \\nabla_{\\theta}G(x;\\theta) \\\\ =\\sum_x p_{\\theta}(x) \\nabla_{\\theta} \\log u_{\\theta}(x) = \\mathbb{E}_{x \\sim p_{\\theta}} \\nabla_{\\theta} \\log u_{\\theta}(x) \\\\ \\therefore \\text{ } -\\nabla_{\\theta}\\mathcal{L}_{mle} = \\mathbb{E}_{x\\sim p_d} \\left[ \\nabla_{\\theta} \\log u_{\\theta}(x) - \\color{orange}{\\mathbb{E}_{x \\sim p_{\\theta}} \\nabla_{\\theta} \\log u_{\\theta}(x)} \\right] \\\\ = \\mathbb{E}_{x\\sim p_d} \\nabla_{\\theta} \\log u_{\\theta}(x) - \\mathbb{E}_{x \\sim p_{\\theta}} \\nabla_{\\theta} \\log u_{\\theta}(x)\\\\ = \\sum_x \\left[ p_d(x) - p_{\\theta}(x) \\right] \\nabla_{\\theta} \\log u_{\\theta}(x) \\\\ \\end{align}$$ å¾ (11) å¼å¯ä»¥çœ‹åˆ°, ä¼°è¨ˆçš„ pdf èˆ‡ training data çš„ pdf å·®è¶Šå¤§ gradient æ„ˆå¤§, ç•¶å…©è€…ç›¸åŒæ™‚ gradient ç‚º 0 ä¸ update. Sigmoid or Logistic Functionåœ¨èªªæ˜ NCE ä¹‹å‰å…ˆè«‡ä¸€ä¸‹ sigmoid function. å‡è¨­ç¾åœ¨æˆ‘å€‘åšäºŒåˆ†é¡å•é¡Œ, å…©å€‹é¡åˆ¥ $C=1$ or $C=0$. ä»¤ $p$ æ˜¯æŸå€‹ input $x$ å±¬æ–¼ class 1 çš„æ©Ÿç‡ (æ‰€ä»¥ $1-p$ å°±æ˜¯å±¬æ–¼ class 0 çš„æ©Ÿç‡)å®šç¾© log-odd ç‚º (å…¶å¯¦ä¹Ÿç¨±ç‚º logit): $$\\begin{align} \\text{log-odd} = \\log \\frac{p}{1-p} \\end{align}$$ æˆ‘å€‘çŸ¥é“ sigmoid function $\\sigma(x)=\\frac{1}{1+e^{-x}}$ å°‡å¯¦æ•¸ input mapping åˆ° 0 ~ 1 å€é–“çš„å‡½å¼. è‹¥æˆ‘å€‘å°‡ log-odd ä»£å…¥æˆ‘å€‘å¾ˆå®¹æ˜“å¾—åˆ°: $$\\begin{align} \\sigma(\\text{log-odd})=...=p \\end{align}$$ ç™¼ç¾ sigmoid å›å‚³çµ¦æˆ‘å€‘çš„æ˜¯ $x$ å±¬æ–¼ class 1 çš„æ©Ÿç‡å€¼, i.e. $\\sigma(\\text{log-odd})=p(C=1|x)$. æ‰€ä»¥åœ¨äºŒåˆ†é¡å•é¡Œä¸Š, æˆ‘å€‘å°±æ˜¯è¨“ç·´ä¸€å€‹ NN èƒ½ predict logit å€¼. NCE çš„ Network æ¶æ§‹é¦–å…ˆ NCE å¼•å…¥äº†ä¸€å€‹ Noise distribution $q(x)$. è«–æ–‡æåˆ°è©² $q$ åªè¦æ»¿è¶³ç•¶ $p_d(x)$ nonzero å‰‡ $q(x)$ ä¹Ÿå¿…é ˆ nonzero å°±å¯ä»¥. äºŒåˆ†é¡å•é¡Œç‚º, å‡è¨­è¦å–ä¸€å€‹æ­£ä¾‹ (class 1), å°±å¾ training data pdf $p_d(x)$ å–å¾—. è€Œè‹¥è¦å–ä¸€å€‹åä¾‹ (class 0) å‰‡å¾ noise pdf $q(x)$ å–å¾—.æˆ‘å€‘å¯ä»¥å– $N_p$ å€‹æ­£ä¾‹ä»¥åŠ $N_n$ å€‹åä¾‹, ä»£è¡¨ prior ç‚º: $$\\begin{align} p(C=1)=\\frac{N_p}{N_p+N_n} \\\\ p(C=0)=1-p(C=1) \\\\ \\end{align}$$ å› æ­¤å°±å¯ä»¥å¾—åˆ°ä¸€å€‹ batch å…± $N_p+N_n$ å€‹ samples, ä¸Ÿå…¥ä¸‹åœ–çš„ NN structure åšäºŒåˆ†é¡å•é¡Œ: Network å‰åŠæ®µé‚„æ˜¯è·ŸåŸä¾†çš„ MLE æ¶æ§‹ä¸€æ¨£, åªæ˜¯æˆ‘å€‘æœŸæœ› $NN_{\\theta}$ åå‡ºä¾†çš„æ˜¯ logit, ç”±ä¸Šé¢ä¸€å€‹ section æˆ‘å€‘çŸ¥é“ç¶“é sigmoid å¾—åˆ°çš„æœƒæ˜¯ $x$ å±¬æ–¼ class 1 çš„æ©Ÿç‡. å› æ­¤å¾ˆå®¹æ˜“å°±ç”¨ xent loss å„ªåŒ–. ç¥å¥‡çš„ä¾†äº†, NCE å‘Šè¨´æˆ‘å€‘, optimize é€™å€‹äºŒåˆ†é¡å•é¡Œå¾—åˆ°çš„ $\\theta$ ç­‰æ–¼ MLE è¦æ‰¾çš„ $\\theta$! $$\\begin{align} \\theta_{nce} = \\theta_{mle} \\end{align}$$ ä¸” NN è¨ˆç®—çš„ logit ç›´æ¥å°±è®Šæˆ MLE è¦ç®—çš„ $p_{\\theta}(x)$. åŒæ™‚è—‰ç”±æ›æˆäºŒåˆ†é¡å•é¡Œ, ä¹Ÿé¿é–‹äº†å¾ˆé›£è¨ˆç®—çš„ $Z_{\\theta}$ å•é¡Œ.ç‚ºäº†ä¸å½±éŸ¿é–±è®€æµæš¢åº¦, æ¨å°éç¨‹è«‹åƒç…§ Appendix æ‰€ä»¥æˆ‘å€‘å¯ä»¥é€éå¼•å…¥ä¸€å€‹ Noise pdf ä¾†é”åˆ°ä¼°è¨ˆ training data çš„ generative model äº†. é€™ä¹Ÿæ˜¯ç‚ºä»€éº¼å«åš Noise Contrastive Estimation. Representationç”±æ–¼é€é NCE è¨“ç·´æˆ‘å€‘å¯ä»¥å¾—åˆ° $\\theta$, æ­¤æ™‚åªéœ€è¦ç”¨ $\\theta_f$ çš„ NN ä¾†ç•¶ä½œ feature extractor å°±å¯ä»¥äº†. ç¸½çµæœ€å¾Œæµç¨‹å¯ä»¥ç¸½çµæˆä¸‹é¢é€™å¼µåœ–: æœ€å¾ŒèŠä¸€ä¸‹ CPC (Contrastive Predictive Coding) [2]. æˆ‘è¦ºå¾—è·Ÿ NCE å°±å…©é»ä¸åŒ: æˆ‘å€‘ç•«çš„ NCE åœ–è£¡çš„ $w$, æ”¹æˆè«–æ–‡è£¡çš„ $c_t$, æ‰€ä»¥è®Šæˆ network æ˜¯ä¸€å€‹ conditioned çš„ network ä¸æ˜¯ä¸€å€‹äºŒåˆ†é¡å•é¡Œ, æ”¹æˆ N é¸ 1 çš„åˆ†é¡å•é¡Œ (batch size $N$, æŒ‡å‡ºå“ªä¸€å€‹æ˜¯æ­£ä¾‹), å› æ­¤ç”¨ categorical cross-entorpy ç•¶ loss æ‰€ä»¥æ–‡ç« ç¨±é€™æ¨£çš„ loss ç‚º infoNCE loss åŒæ™‚ CPC [2] è«–æ–‡ä¸­å¾ˆæ£’çš„ä¸€é»æ˜¯å°‡é€™æ¨£çš„è¨“ç·´æ–¹å¼ä¹Ÿè·Ÿ Mutual Information (MI) é€£æ¥èµ·ä¾†.è­‰æ˜äº†æœ€å°åŒ– infoNCE loss å…¶å¯¦å°±æ˜¯åœ¨æœ€å¤§åŒ– representation èˆ‡æ­£ä¾‹çš„ MI (çš„ lower bound). é€™äº›èƒŒå¾Œæ•¸å­¸æ’èµ·äº†æ•´å€‹åˆ©ç”¨ CPC åœ¨ SSL (Self-Supervised Learning) çš„åŸºç¤. ç°¡å–®è¬›å°±æ˜¯ä¸éœ€è¦æ˜‚è²´çš„ label å…¨éƒ¨éƒ½ unsupervised å°±èƒ½å­¸åˆ°å¾ˆå¥½çš„ representation.è€Œè¿‘æœŸ facebook æ›´åˆ©ç”¨ SSL å­¸åˆ°çš„å¥½ representation çµåˆ GAN åœ¨ ASR é”åˆ°äº† 19 å¹´çš„ STOA WER. è«–æ–‡: Unsupervised Speech Recognition or see [9] SSL å¥½æ±è¥¿, ä¸è©¦è©¦çœ‹å—? AppendixPrior pdf:$$\\begin{align} p(C=1)=\\frac{N_p}{N_p+N_n} \\\\ p(C=0)=1-p(C=1) \\\\ \\end{align}$$ Generative pdf:$$\\begin{align} p(x|C=1)=p_{\\theta}(x) \\\\ p(x|C=0)=q(x) \\end{align}$$ å› æ­¤ Posterior pdf:$$\\begin{align} p(C=1|x)=\\frac{p(C=1)p(x|C=1)}{p(C=1)p(x|C=1)+p(C=0)p(x|C=0)}=\\frac{p_{\\theta}(x)}{p_{\\theta}(x)+N_r q(x)} \\\\ p(C=0|x)=\\frac{p(C=0)p(x|C=0)}{p(C=1)p(x|C=1)+p(C=0)p(x|C=0)}=\\frac{N_r q(x)}{p_{\\theta}(x)+N_r q(x)} \\\\ \\end{align}$$å…¶ä¸­ $N_r=\\frac{N_n}{N_p}$ å› æ­¤ likelihood ç‚º:$$\\begin{align} \\text{likilhood}=\\prod_{t=1}^{N_p} p(C_t=1|x_t) \\cdot \\prod_{t=1}^{N_n} p(C_t=0|x_t) \\end{align}$$ Loss ç‚º negative log-likelihood:$$\\begin{align} - \\mathcal{L}_{nce} = \\sum_{t=1}^{N_p} \\log p(C_t=1|x_t) + \\sum_{t=1}^{N_n} \\log p(C_t=0|x_t) \\\\ = N_p \\left[ \\frac{1}{N_p} \\sum_{t=1}^{N_p} \\log p(C_t=1|x_t) \\right] + N_n \\left[ \\frac{1}{N_n} \\sum_{t=0}^{N_n} \\log p(C_t=0|x_t) \\right] \\\\ \\propto \\left[ \\frac{1}{N_p} \\sum_{t=1}^{N_p} \\log p(C_t=1|x_t) \\right] + N_r \\left[ \\frac{1}{N_n} \\sum_{t=0}^{N_n} \\log p(C_t=0|x_t) \\right] \\end{align}$$ ç•¶å›ºå®š $N_r$ ä½†æ˜¯è®“ $N_p\\rightarrow\\infty$ and $N_n\\rightarrow\\infty$. æ„å‘³è‘—æˆ‘å€‘å›ºå®šæ­£è² æ¨£æœ¬æ¯”ä¾‹, ä½†å–ç„¡çª®å¤§çš„ batch. é‡å¯«ä¸Šå¼æˆ:$$\\begin{align} - \\mathcal{L}_{nce} = \\mathbb{E}_{x\\sim p_d} \\log p(C=1|x) + N_r \\mathbb{E}_{x\\sim q} \\log p(C=0|x) \\\\ \\therefore \\text{} -\\nabla_{\\theta}\\mathcal{L}_{nce} = \\nabla_{\\theta}\\left[ \\mathbb{E}_{x\\sim p_d} \\log \\frac{p_{\\theta}(x)}{p_{\\theta}(x)+N_rq(x)} + N_r\\mathbb{E}_{x\\sim q} \\log \\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)} \\right] \\\\ = \\mathbb{E}_{x\\sim p_d} \\color{orange}{\\nabla_{\\theta} \\log \\frac{p_{\\theta}(x)}{p_{\\theta}(x)+N_rq(x)}} + N_r \\mathbb{E}_{x\\sim q} \\color{green}{\\nabla_{\\theta} \\log \\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)} } \\end{align}$$ è¨ˆç®—æ©˜è‰²å’Œç¶ è‰²å…©é …, ä¹‹å¾Œå†ä»£å›ä¾†: $$\\begin{align} \\color{orange}{\\nabla_{\\theta} \\log \\frac{p_{\\theta}(x)}{p_{\\theta}(x)+N_rq(x)}} = \\nabla_{\\theta}\\log\\frac{1}{1+N_r\\frac{q(x)}{p_{\\theta}(x)}} = -\\nabla_{\\theta}\\log \\left( 1+\\frac{N_rq(x)}{p_{\\theta}(x)} \\right) \\\\ = -\\frac{1}{1+\\frac{N_rq(x)}{p_{\\theta}(x)}}\\nabla_{\\theta}\\frac{N_rq(x)}{p_{\\theta}(x)} = -\\frac{N_rq(x)}{1+\\frac{N_rq(x)}{p_{\\theta}(x)}}\\nabla_{\\theta}\\frac{1}{p_{\\theta}(x)} \\\\ = -\\frac{N_rq(x)}{1+\\frac{N_rq(x)}{p_{\\theta}(x)}} \\frac{-1}{p_{\\theta}^2(x)} \\nabla_{\\theta} p_{\\theta}(x) \\\\ = \\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)} \\left[ \\frac{1}{p_{\\theta}(x)} \\nabla_{\\theta} p_{\\theta}(x) \\right] \\\\ = \\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)} \\nabla_{\\theta} \\log p_{\\theta}(x) \\end{align}$$ $$\\begin{align} \\color{green}{\\nabla_{\\theta} \\log \\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)}} = -\\nabla_{\\theta} \\log\\left( 1+\\frac{p_{\\theta}(x)}{N_rq(x)} \\right) = -\\frac{1}{1+\\frac{p_{\\theta}(x)}{N_rq(x)}} \\nabla_{\\theta} \\frac{p_{\\theta}(x)}{N_rq(x)} \\\\ = -\\frac{1}{N_rq(x)+p_{\\theta}(x)} \\nabla_{\\theta} p_{\\theta}(x) \\\\ = -\\frac{p_{\\theta}(x)}{N_rq(x)+p_{\\theta}(x)} \\left[ \\frac{1}{p_{\\theta}(x)} \\nabla_{\\theta} p_{\\theta}(x) \\right] \\\\ = -\\frac{p_{\\theta}(x)}{N_rq(x)+p_{\\theta}(x)} \\nabla_{\\theta} \\log p_{\\theta}(x) \\end{align}$$ å°‡ (34), (38) ä»£å›å» (29) å¾—åˆ°: $$\\begin{align} - \\nabla_{\\theta}\\mathcal{L}_{nce} = \\mathbb{E}_{x\\sim p_d} {\\color{orange}{\\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)} \\nabla_{\\theta} \\log p_{\\theta}(x)}} - N_r \\mathbb{E}_{x\\sim q} {\\color{green}{\\frac{p_{\\theta}(x)}{N_rq(x)+p_{\\theta}(x)} \\nabla_{\\theta} \\log p_{\\theta}(x)}} \\\\ = \\sum_x \\left[ p_d(x) \\frac{N_rq(x)}{p_{\\theta}(x)+N_rq(x)} \\nabla_{\\theta} \\log p_{\\theta}(x) \\right] - \\sum_x \\left[ q(x) \\frac{N_r p_{\\theta}(x)}{N_rq(x)+p_{\\theta}(x)} \\nabla_{\\theta} \\log p_{\\theta}(x)\\right] \\\\ = \\sum_x \\frac{(p_d(x)-p_{\\theta}(x))N_rq(x)}{p_{\\theta}(x)+N_rq(x)} \\nabla_{\\theta}\\log p_{\\theta}(x) \\\\ = \\sum_x \\frac{(p_d(x)-p_{\\theta}(x))q(x)}{\\frac{p_{\\theta}(x)}{N_r}+q(x)} \\nabla_{\\theta}\\log p_{\\theta}(x) \\\\ \\end{align}$$ ç•¶ $N_r\\rightarrow\\infty$ æ„å‘³è‘—æˆ‘å€‘è®“è² æ¨£æœ¬é å¤šæ–¼æ­£æ¨£æœ¬, ä¸Šå¼è®Šæˆ:$$\\begin{align} \\lim_{N_r\\rightarrow\\infty} - \\nabla_{\\theta}\\mathcal{L}_{nce} = \\sum_x \\frac{(p_d(x)-p_{\\theta}(x))q(x)}{0+q(x)} \\nabla_{\\theta}\\log p_{\\theta}(x) \\\\ = \\sum_x (p_d(x)-p_{\\theta}(x)) \\nabla_{\\theta}\\log p_{\\theta}(x) \\\\ = \\sum_x \\left[ p_d(x) - p_{\\theta}(x) \\right] \\left( \\nabla_{\\theta}\\log u_{\\theta}(x) -\\nabla_{\\theta}\\log Z_{\\theta} \\right) \\end{align}$$ æ­¤æ™‚æˆ‘å€‘ç™¼ç¾é€™ gradient ä¹Ÿèˆ‡ Noise pdf $q(x)$ ç„¡é—œäº†! æœ€å¾Œæˆ‘å€‘å°‡ MLE and NCE çš„ gradient æ‹‰å‡ºä¾†å°æ¯”ä¸€ä¸‹:$$\\begin{align} -\\nabla_{\\theta}\\mathcal{L}_{mle} = \\sum_x \\left[ p_d(x) - p_{\\theta}(x) \\right] \\nabla_{\\theta} \\log u_{\\theta}(x) \\\\ -\\nabla_{\\theta}\\mathcal{L}_{nce} = \\sum_x \\left[ p_d(x) - p_{\\theta}(x) \\right] \\left( \\nabla_{\\theta}\\log u_{\\theta}(x) -\\nabla_{\\theta}\\log Z_{\\theta} \\right) \\end{align}$$ æˆ‘å€‘ç™¼ç¾ MLE and NCE åªå·®åœ¨ä¸€å€‹ normalization factor (or partition) $Z_{\\theta}$.æœ€é­”è¡“çš„åœ°æ–¹å°±åœ¨æ–¼ NCE è«–æ–‡ [1] è­‰æ˜æœ€ä½³è§£æœ¬èº«çš„ logit å·²ç¶“æ˜¯ probability å‹å¼, å› æ­¤ä¹Ÿä¸éœ€è¦ normalize factor. è«–æ–‡è£¡èªªç¤™æ–¼ç¯‡å¹…æ²’çµ¦å‡ºè­‰æ˜, ä¸»è¦æ˜¯ä¾†è‡ª Theorem 1 çš„çµæœ: æ‰€ä»¥æˆ‘å€‘ä¸å¦¨å°‡ $Z_{\\theta}=1$, çµæœæœ‰: $$\\begin{align} \\color{red} {\\nabla_{\\theta}\\mathcal{L}_{mle} = \\nabla_{\\theta}\\mathcal{L}_{nce}} \\\\ \\color{red} {\\Rightarrow \\theta_{mle} = \\theta_{nce}} \\\\ \\end{align}$$ Reference 2010: Noise-contrastive estimation: A new estimation principle for unnormalized statistical models 2019 DeepMind infoNCE/CPC: Representation learning with contrastive predictive coding 2019 FB: wav2vec: Unsupervised pre-training for speech recognition 2020 MIT &amp; Google: Contrastive Representation Distillation Noise Contrastive Estimation å‰ä¸–ä»Šç”Ÿâ€”â€”ä» NCE åˆ° InfoNCE â€œå™ªå£°å¯¹æ¯”ä¼°è®¡â€æ‚è°ˆï¼šæ›²å¾„é€šå¹½ä¹‹å¦™ [è¯‘] Noise Contrastive Estimation The infoNCE loss in self-supervised learning High-performance speech recognition with no supervision at all","tags":[{"name":"Noise Contrastive Estimation","slug":"Noise-Contrastive-Estimation","permalink":"https://bobondemon.github.io/tags/Noise-Contrastive-Estimation/"},{"name":"NCE","slug":"NCE","permalink":"https://bobondemon.github.io/tags/NCE/"},{"name":"infoNCE","slug":"infoNCE","permalink":"https://bobondemon.github.io/tags/infoNCE/"}]},{"title":"Distributed Data Parallel and Its Pytorch Example","date":"2020-12-20T04:19:38.000Z","path":"2020/12/20/Distributed-Data-Parallel-and-Its-Pytorch-Example/","text":"è¨“ç·´æ™‚å€™çš„å¹³è¡ŒåŒ–å¯åˆ†ç‚º: Model Parallel: æ‰€æœ‰ GPUs è·‘åŒä¸€å€‹ batch ä½†æ˜¯å„è‡ªè·‘æ¨¡å‹ä¸åŒéƒ¨åˆ† Data Parallel: GPUs è·‘ä¸åŒçš„ batches, ä½†è·‘åŒä¸€å€‹å®Œæ•´çš„æ¨¡å‹ ç”±æ–¼ Data Parallel è·‘åŒä¸€å€‹å®Œæ•´æ¨¡å‹ä¸”å„ GPU éƒ½ç”¨è‡ªå·±è¤‡è£½çš„ä¸€ä»½, åœ¨ update åƒæ•¸æ™‚è¦å¦‚ä½•ç¢ºä¿æ›´æ–°ä¸€è‡´? å¯åˆ†ç‚º synchronous å’Œ asynchronous update. (æ–‡ç« å¾Œé¢æœƒè©³ç´°è¨è«–) æœ¬æ–‡è¨è«– Data Parallel with Synchronous update. æ—¢ç„¶è¦åš data parallel, ç¬¬ä¸€ä»¶äº‹æƒ…ä¾¿æ˜¯å¦‚ä½•å°ä¸åŒ GPU åˆ†æ´¾ä¸åŒçš„ batches, æ¥ä¸‹ä¾†æˆ‘å€‘å°±ä½¿ç”¨ PyTorch åšé€™ä»¶äº‹. æŒ‡æ´¾ä¸åŒ Batch çµ¦ä¸åŒ GPUç›´æ¥ä¸Šä¸€å€‹ toy example (minimal_distributed_data_example.py) 123456789101112131415161718192021222324252627282930313233343536# file: minimal_distributed_data_example.pyimport ...class SimpleDataset(torch.utils.data.Dataset): def __init__(self, start, end): assert(start &lt; end) self.start, self.end, self.data_num = start, end, end - start def __len__(self): return self.data_num def __getitem__(self, idx): return idx + self.startif __name__ == '__main__': # ===== Distributed Settings world_size = int(os.environ.get('WORLD_SIZE', 1)) local_rank = 0 is_distributed = world_size &gt; 1 if is_distributed: torch.distributed.init_process_group(backend='nccl') local_rank = torch.distributed.get_rank() torch.cuda.set_device(local_rank) device = torch.device(\"cuda\", local_rank) # ===== Dataset/DataLoader Settings dataset = SimpleDataset(0, 4*6) sampler = DistributedSampler(range(4*6), shuffle=False, seed=1111) # Shuffle here (set True) if needed rather than in DataLoader print(f'========== device:&#123;device&#125;') data_parallel_dl = DataLoader(dataset, batch_size=4, num_workers=8, shuffle=False, sampler=sampler) # since we use sampler, so we set shuffle to False (default) in DataLoader # ===== Traverse All Data arr = [] for sample_batch in data_parallel_dl: arr += sample_batch.tolist() t = np.random.randint(100)/100.0 sample_batch.to(device) print('sleep &#123;:.2f&#125;; device:&#123;&#125;\\t&#123;&#125;'.format(t, device, sample_batch)) time.sleep(t) print(f'device:&#123;device&#125;\\n&#123;np.sort(np.array(arr))&#125;') [Line 23~27 æœ‰é—œ Dataset/DataLoader] Line 24 dataset åªæ˜¯ä¸€å€‹ 0 åˆ° 23 çš„ int list. Line 27 DataLoader åœ¨åˆ†é… batches çµ¦ä¸åŒ GPUs æ™‚åªéœ€è¦å°‡ sampler ä½¿ç”¨ DistributedSampler å‰µå»ºå°±å¯ä»¥. DistributedSampler åœ¨åˆ†é…ä¸€å€‹ batch é™¤äº†æœƒæŒ‡å®šè³‡æ–™æ˜¯é‚£äº› index ä¹‹å¤–, é‚„æœƒæŒ‡å®šè©²ç­† batch æ˜¯è¦åˆ†åˆ°å“ªå€‹ gpu. [Line 14~22 æœ‰é—œ Distributed Settings]åœ¨åŸ·è¡Œé€™å€‹æª”æ¡ˆçš„æ™‚å€™, æˆ‘å€‘æœƒä½¿ç”¨ torch.distributed.launch, ç¯„ä¾‹æŒ‡ä»¤å¦‚ä¸‹: 1CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --use_env minimal_distributed_data_example.py æ­¤æ™‚ PyTorch æœƒé–‹å•Ÿå…©å€‹ processes å»åŸ·è¡Œä½ çš„ .py, é€™è£¡æ³¨æ„ä¸æ˜¯ threads, é€™æ˜¯å› ç‚º python Global Interpreter Lock (GIL) çš„åŸå› , ä½¿ç”¨ thread æ•ˆç‡æœƒä¸é«˜. å¦å¤–ä½¿ç”¨ --use_env å‰‡æœƒåœ¨å„è‡ªçš„ process è£¡è¨­å®šç’°å¢ƒè®Šæ•¸: WORLD_SIZE (ç¯„ä¾‹ = 2) LOCAL_RANK (ç¯„ä¾‹ = 0 or 1) å› æ­¤ line 17 æˆ‘å€‘ä¾¿å¯è—‰ç”± world_size å¾—çŸ¥æ˜¯å¦ç‚º distributed ç’°å¢ƒ. æ˜¯çš„è©± line 20 å°±å¯ä»¥æ‹¿åˆ°é€™å€‹ process çš„ local_rank (å¯ä»¥æƒ³æˆæ˜¯ worker çš„ç·¨è™Ÿ, ä¹Ÿå°±æ˜¯ç¬¬å¹¾å€‹å¹³è¡Œçš„å–®ä½), æ¥è‘— line 21, 22 å°±å¯ä»¥æ ¹æ“š local_rank è¨­ç½® gpu. [Line 28~36 æœ‰é—œ go through all data] åœ¨åŸ·è¡Œæ™‚, å„å€‹ process æœƒæ‹¿åˆ°ç›¸å°æ‡‰å€‹ batches. Line 35 æ¨¡æ“¬è™•ç†è©²ç­†è³‡æ–™æ‰€èŠ±çš„æ™‚é–“. Line 36 ç‚ºç¢ºèªè‡ªå·±é€™å€‹ process ç¸½å…±æ‹¿åˆ°é‚£äº› batches. ä»¥ç¯„ä¾‹ä¾†èªª, å…©å€‹ gpus æ‡‰è©²è¦æ‹¿åˆ° exclusive çš„å…©å€‹ sets å…¶è¯é›†æ˜¯ {0,1, â€¦, 23}. çµæœå¦‚ä¸‹: Good Job! ç¾åœ¨æˆ‘å€‘æœƒæŠŠæ¯å€‹ GPU éƒ½åˆ†é…ä¸åŒçš„ batches äº†, ä¸éé‚„æœ‰ä¸€å€‹é—œéµçš„å•é¡Œ: è©²æ€éº¼å„è‡ªè¨ˆç®— gradients ç„¶å¾Œ update? é€™å°±é–‹å§‹è¨è«– update çš„å…©ç¨® case, synchronous and asynchronous update. Asynchronous Update Synchronous: æ¯ä¸€æ¬¡æ¨¡å‹ update è¦ç­‰åˆ°æ‰€æœ‰ device çš„ batch éƒ½çµæŸ, çµ±åˆå¾Œ update Asynchronous: æ¯å€‹ device ç®—å®Œè‡ªå·±çš„ batch å¾Œå³å¯ç›´æ¥ update å¯ä»¥æƒ³åƒéåŒæ­¥çš„åŒ–å¯ä»¥æ›´æ–°çš„æ¯”è¼ƒæœ‰æ•ˆç‡, ä½†å¯èƒ½æ•ˆæœæœƒä¸å¦‚åŒæ­¥çš„æ–¹å¼.Asynchronous æœƒé‡åˆ°çš„ç‹€æ³æ˜¯ç®—å®Œ gradient å¾Œè¦ update parameters æ™‚, parameters å·²ç¶“è¢«å…¶ä»– process update éäº†, é‚£ç‚ºä»€éº¼é‚„å¯ä»¥ work? Asynchronous ç‹€æ³ 1ç¯„ä¾‹å‡è¨­å…©å€‹ GPU (1&amp;2) å…¶åƒæ•¸ç©ºé–“éƒ½åœ¨ $\\theta_a$. Step 1. å‡è¨­ GPU2 å…ˆç®—å®Œ $\\Delta P_2(\\theta_a)$ ä¸¦ä¸” update åˆ° $\\theta_b$: $$\\begin{align} \\theta_b = \\theta_a + \\Delta P_2(\\theta_a) \\end{align}$$ Step2. é€™æ™‚å€™ GPU1 ç®—å®Œ gradient äº†, ç”±æ–¼ç•¶æ™‚ç®— gradient æ˜¯åŸºæ–¼ $\\theta_a$, å› æ­¤ gradient ç‚º $\\Delta P_1(\\theta_a)$, ä½†æ˜¯è¦ update çš„æ™‚å€™ç”±æ–¼å·²ç¶“è¢« GPU2 æ›´æ–°åˆ° $\\theta_b$ äº†, æ‰€ä»¥æœƒæ›´æ–°åˆ° $\\theta_c$: $$\\begin{align} \\theta_c = \\theta_b + \\Delta P_1(\\theta_a) \\end{align}$$ é€™è£¡è®€è€…å¯èƒ½æœƒç–‘å•, è¨ˆç®— gradient èˆ‡ update æ™‚æ ¹æ“šçš„åƒæ•¸æ˜¯ä¸åŒ, é€™æ¨£ update æœƒä¸æœƒå‡ºå•é¡Œ? ä»¥ä¸Šé¢é€™å€‹ä¾‹å­ä¾†èªª, é‚„å‰›å¥½æ²’äº‹. åŸå› æ˜¯å…¶å¯¦ç­‰åŒæ–¼ synchronous update: $$\\begin{align} \\theta_c = \\theta_a + \\left[ \\Delta P_2(\\theta_a) + \\Delta P_1(\\theta_a) \\right] \\end{align}$$ é‚£å¯èƒ½æœƒç¹¼çºŒå•, é€™åªæ˜¯å‰›å¥½, å¦‚æœä¸€å€‹ GPU æ¯”å¦ä¸€å€‹æ…¢å¾ˆå¤š, æœƒæ€æ¨£? æˆ‘å€‘çœ‹çœ‹ case 2 Asynchronous ç‹€æ³ 2GPU2 å¤ªå¿«äº†â€¦ å·²ç¶“ update å¥½å¹¾è¼ª å¥½å§â€¦ æƒ³æˆé¡ä¼¼æœ‰ momentum æ•ˆæœå§ å¯¦å‹™ä¸Šæœƒåœ¨å¹¾æ¬¡çš„ update éå¾Œå¼·åˆ¶ synchronize update ä¸€æ¬¡, å¯ä»¥æƒ³åƒå¦‚æœä¸€äº›æ¢ä»¶æˆç«‹ (è­¬å¦‚ gradients æ˜¯ bounded), æ‡‰è©²èƒ½ä¿è­‰æ”¶æ–‚ (é€™é‚Šæˆ‘æ²’åšåŠŸèª²é˜¿, ç´”ç²¹çŒœæ¸¬) Synchronous Updateæ¯å€‹ gpu éƒ½ç®—å®Œå„è‡ª batch çš„ gradients å¾Œ, çµ±ä¸€æ•´ç† update parameters, å¸¸è¦‹å…©ç¨®æ–¹å¼: Parameter Server Ring Allreduce æ¥è‘—ä»‹ç´¹çš„é€™å…©ç¨®æ–¹æ³•åœ–ç‰‡ä¸»è¦å¾ Baidu: Bringing HPC techniques to deep learning [Andrew Gibiansky] ç­†è¨˜ä¸‹ä¾†. Parameter Server çš„ Synchronous Updateä¸€æ¬¡ Update åˆ†å…©æ­¥é©Ÿ GPU 0 å…¨éƒ¨éƒ½æ‹¿åˆ° GPU 1~4 çš„ Gradients å¾Œ, æ›´æ–° parameters GPU 0 æŠŠ model ç™¼é€çµ¦ GPU 1~4 å‡è¨­æœ‰ $N$ å€‹ GPU, é€šä¿¡ä¸€æ¬¡èŠ±è²»æ™‚é–“ $K$, å‰‡ PS æ–¹æ³•æˆæœ¬ç‚º: Gradients passing: $(N-1)K$ Model passing: $(N-1)K$ Total $2K(\\color{orange}{N}-1)$, è·Ÿ GPU æ•¸é‡æ­£æ¯” Ring Allreduce æ¯”è¼ƒå¤šåœ–, ç‰¹åˆ¥æ‹‰å‡ºä¸€å€‹ section èªªæ˜ Ring Allreduce çš„ Synchronous Updateæ¯ä¸€å€‹ GPU éƒ½åˆ†åˆ¥æœ‰ä¸€å€‹å‚³é€å’Œæ¥æ”¶çš„å°è±¡ GPU, åˆ†é…èµ·ä¾†æ­£å¥½å½¢æˆä¸€å€‹ç’°. å‡è¨­æ¯å€‹ GPUs éƒ½ç®—å¥½ gradients äº†, ä¸¦ä¸”æˆ‘å€‘å°‡ gradients åˆ†æˆè·Ÿ GPU æ•¸é‡ä¸€æ¨£çš„ $N$ å€‹ chunks: é€™æ–¹æ³•åˆ†å…©æ­¥é©Ÿ: Scatter Reduce All Gather 1. Scatter Reduce åšå®Œ $N-1$ æ¬¡ iteration å¾Œå¯ä»¥ç™¼ç¾æ¯å¼µ GPU éƒ½æœƒæœ‰ä¸€å€‹æ˜¯å®Œæ•´çš„ chunk. 2. All Gather åšå®Œ $N-1$ æ¬¡ iteration å¾Œå¯ä»¥ç™¼ç¾æ¯å¼µ GPU éƒ½æ‹¿åˆ°æ‰€æœ‰å®Œæ•´çš„ chunk. All Gather æµç¨‹è·Ÿ Scatter Reduce æ˜¯ä¸€æ¨£, åªæ˜¯å°‡ç´¯åŠ è¡Œç‚ºè®Šæˆå–ä»£è€Œå·². æˆæœ¬æ¯å€‹ GPUs éƒ½å¾—åˆ°çµ±åˆå¾Œçš„ gradients, å› æ­¤ å„å€‹ GPU ä¸Šçš„ model å¯ä»¥å„è‡ª update (gradients ç›¸åŒ, æ‰€ä»¥ update å¾Œçš„ models ä¹Ÿç›¸åŒ) å‡è¨­æœ‰ $N$ å€‹ GPU,å‰‡æˆæœ¬ç‚º: é€šä¿¡ä¸€æ¬¡èŠ±è²»æ™‚é–“ $K/N$ (å› ç‚ºæˆ‘å€‘åˆ†æˆ $N$ å€‹ chunks åŒæ™‚å‚³è¼¸) Scatter reduce: $(N-1)K/N$ All gather: $(N-1)K/N$ Total $2K(\\color{orange}{N}-1)/\\color{orange}{N}$, è·Ÿ GPU æ•¸é‡ç„¡é—œ PyTorch: Model with DDPé‚„è¨˜å¾—æœ€é–‹é ­çš„ç¯„ä¾‹å—? æˆ‘å€‘åšåˆ°äº†æŠŠæ¯å€‹ GPU éƒ½åˆ†é…ä¸åŒçš„ batches, ä½†é‚„ä¸æœƒå°‡å„è‡ªè¨ˆç®— gradients çµ±åˆç„¶å¾Œ update. å…¶å¯¦æˆ‘å€‘åªéœ€è¦é‡å°ä¸Šé¢ç¯„ä¾‹çš„ minimal_distributed_data_example.py åšé»ä¿®æ”¹å°±å¯ä»¥. é‡å° model ä½œå¦‚ä¸‹æ”¹å‹•: 1model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank) é€™æ¨£å°±ä½¿å¾— model çš„ backward() æˆç‚º sync op. ä¹Ÿå°±æ˜¯åœ¨å‘¼å« loss.backward() æœƒç­‰åˆ°æ¯å¼µ GPU çš„ gradient éƒ½ç®—å®Œä¸” sync äº† (PS or All Gather éƒ½å¯ä»¥) æ‰æœƒæ¥ä¸‹å»åŸ·è¡Œ. æ³¨æ„äº‹é … ç”±æ–¼æ¯å€‹ process éƒ½æœ‰è‡ªå·±çš„ optimizer(scheduler), è€Œ momentum æœƒæ ¹æ“šç•¶å‰çš„ gradient update, å¦‚ä½•ç¢ºä¿æ¯å€‹ optimizers éƒ½ç›¸åŒ?Ans: ç”±æ–¼ .backward() æ˜¯ sync op, å› æ­¤ opt.step() æ™‚æ¯å€‹ processes çš„ gradients å·²ç¶“åŒæ­¥äº†, æ‰€ä»¥ momentum æœƒæ ¹æ“šç›¸åŒçš„ gradient update Batch-norm çš„ statistics åŒæ­¥?Ans: See torch.nn.SyncBatchNorm Save checkpoint æ™‚åœ¨ä¸€å¼µå¡ä¸Šå­˜å°±å¯ä»¥ (é€šå¸¸ç”¨ LOCAL_RANK=0 çš„é‚£å€‹ process) æ€éº¼ç¢ºä¿æ¯å€‹ process ä¸Šçš„ model random initial ç›¸åŒçš„ weights?Ans: DistributedDataParallel åœ¨ init æ™‚å°±æœƒç¢ºä¿ parameters/buffers sync éäº†, see here model ç¶“é DistributedDataParallel åŒ…éå¾Œ name æœƒå¤šä¸€å€‹å‰ç¶´ module., å¦‚æœè¨“ç·´å’ŒåŠ è¼‰æ¨¡å‹ä¸€å€‹ä½¿ç”¨ DDP ä¸€å€‹æ²’æœ‰ load_state_dict æœ‰å¯èƒ½æœƒå› æ­¤å‡ºéŒ¯, éœ€è‡ªè¡Œè™•ç† ä¸€äº› metrics å¦‚ accuracy/loss ç”±æ–¼åœ¨å„å€‹ GPUs è¨ˆç®—, å¯ä»¥åˆ©ç”¨ torch.distributed.all_reduce, torch.distributed.all_gather ç­‰ä¾† syncSee DISTRIBUTED COMMUNICATION PACKAGE - TORCH.DISTRIBUTED and Appendix æœ‰ä¸€å€‹ä¸éŒ¯çš„ DDP ç¯„ä¾‹ [2] å¦‚æœå¯ä»¥çš„è©±, æ¨è–¦ä½¿ç”¨ PyTorch Lightning, ç›´æ¥å¹«ä½ æŠŠé€™äº›ç¹ç‘£çš„ç´°ç¯€åŒ…å¥½, å‘Šè¨´å®ƒè¦ç”¨å¹¾å¼µ GPUs å°±çµæŸäº†. Reference[1] Bringing HPC Techniques to Deep Learning[2] A good example of DDP in PyTorch Appendixä½¿ç”¨ torch.distributed.all_reduce ä¾†åŒæ­¥ä¸åŒ GPU ä¹‹é–“çš„ statisticsèˆ‡æœ¬æ–‡ä¸Šé¢çš„ç¯„ä¾‹ codes é›·åŒ, ä¸»è¦å¢åŠ  AvgMetric ç•¶ç¯„ä¾‹èªªæ˜ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import math, time, os, fireimport numpy as npimport torchfrom torch.utils.data import DataLoaderfrom torch.utils.data.distributed import DistributedSamplerfrom torch.utils.data import RandomSampler, SequentialSampler, Samplerimport torch.distributed as distclass AvgMetric: def __init__(self): self._acc = torch.zeros([]) self._num = torch.zeros([], dtype=torch.long) def reset(self): self._acc = 0 self._num = 0 def update(self, value_arr): self._acc += value_arr.sum().item() self._num += value_arr.numel() def summarize(self): acc = self._acc.clone().cuda() num = self._num.clone().cuda() if dist.is_available() and dist.is_initialized(): dist.all_reduce(acc, op=dist.ReduceOp.SUM) # all tensors in each local rank have final results dist.all_reduce(num, op=dist.ReduceOp.SUM) # all tensors in each local rank have final results # dist.reduce(acc, 0, op=dist.ReduceOp.SUM) # only tensor in local rank 0 has final results # dist.reduce(num, 0, op=dist.ReduceOp.SUM) # only tensor in local rank 0 has final results return acc.item() / num.item()class SimpleDataset(torch.utils.data.Dataset): def __init__(self, start, end): assert start &lt; end self.start = start self.end = end self.data_num = end - start def __len__(self): return self.data_num def __getitem__(self, idx): return idx + self.startdef run(shuffle=False): print(f\"shuffle=&#123;shuffle&#125;\") # ===== Distributed Settings world_size = int(os.environ.get(\"WORLD_SIZE\", 1)) local_rank = 0 is_dist = world_size &gt; 1 if is_dist: torch.distributed.init_process_group(backend=\"nccl\") local_rank = torch.distributed.get_rank() torch.cuda.set_device(local_rank) # makes tensor.cuda() to the specified cuda device device = torch.device(\"cuda\", local_rank) # ===== Dataset/DataLoader Settings num_workers = 16 dataset = SimpleDataset(0, 4 * 6) indices = list(np.arange(4 * 6)) print(indices) sampler = ( DistributedSampler(indices, shuffle=shuffle, seed=1111) # DistributedSubsetSampler(indices, shuffle=shuffle, seed=1111) if is_dist else RandomSampler(indices) if shuffle else SequentialSampler(indices) ) print(f\"========== device:&#123;device&#125;\") data_parallel_dl = DataLoader(dataset, batch_size=4, num_workers=num_workers, shuffle=False, sampler=sampler) avg_metric = AvgMetric() # ===== Traverse all data arr = [] for sample_batched in data_parallel_dl: arr += sample_batched.tolist() t = np.random.randint(100) / 100.0 sample_batched.to(device) print(\"sleep &#123;:.2f&#125;; device:&#123;&#125;\\t&#123;&#125;\".format(t, device, sample_batched)) avg_metric.update(sample_batched) time.sleep(t) print(f\"device:&#123;device&#125;\\t&#123;np.sort(np.array(arr))&#125;\\tavg=&#123;avg_metric.summarize()&#125;\")# ========== [Entry Point] ==========if __name__ == \"__main__\": # Usage: # Single GPU: `CUDA_VISIBLE_DEVICES=2 python practice.py --shuffle=False` # Multiple GPU: `CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --use_env practice.py --shuffle=True` fire.Fire(run) Output ç‚º: Cheers! ğŸ‘","tags":[{"name":"Distributed Data Parallel (DDP)","slug":"Distributed-Data-Parallel-DDP","permalink":"https://bobondemon.github.io/tags/Distributed-Data-Parallel-DDP/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://bobondemon.github.io/tags/PyTorch/"}]},{"title":"Quantization çš„é‚£äº›äº‹","date":"2020-10-03T01:35:24.000Z","path":"2020/10/03/Quantization-çš„é‚£äº›äº‹/","text":"NN åœ¨åš quantization æ™‚æ¡ç”¨çš„æ˜¯éå°ç¨±çš„æ–¹å¼, real ($r$) å’Œ quantized ($q$) values å°æ‡‰é—œä¿‚å¦‚ä¸‹: å…¶ä¸­ zero point $Z$ æœƒè·Ÿ $q$ ç›¸åŒ type, ä¾‹å¦‚ int8, è€Œ scaling value $S$ å‰‡æœƒè·Ÿ $r$ ç›¸åŒ, ä¾‹å¦‚ float. ä»¥ uint3 (0~7) åš quantization, å¦‚ä¸‹åœ–æ‰€ç¤º: æœ¬ç¯‡è¨è«–ä»¥ä¸‹å…©é»: åŒä¸€å€‹ real å€¼å¦‚ä½•åœ¨ä¸åŒçš„ $Z$/$S$ åšè½‰æ›, e.g.: $q_1$ with ($Z_1$/$S_1$) å¦‚ä½•å°æ‡‰åˆ° $q_2$ with ($Z_2$/$S_2$) PyTorch çš„ Quantization Aware Training (QAT) è¨è«– åœ¨ä¸åŒ $Z$/$S$ è½‰æ›æœ‰å…©å€‹å¸¸è¦‹ç†ç”±: åœ¨åš NN çš„ quantization æ™‚å€™, æ¯å€‹ layer çš„ output domain éƒ½ä¸åŒ, é€™å°è‡´äº†ä½¿ç”¨ä¸åŒçš„ $Z$/$S$. åˆæˆ–è€…ä¸Ÿçµ¦ NN åš inference ä¹‹å‰, mfcc/mfb éœ€è¦å…ˆè½‰æ›åˆ° NN input çš„ $Z$/$S$ quantized domain ä¸Š. é¡å¤–æä¸€é» PyTorch çš„ quantized Tensor å…¶å¯¦å°±åªæ˜¯æ¯”åŸæœ¬çš„ Tensor å¤šäº† $Z$ and $S$. ä¾‹å¦‚çµ¦å®š $Z$ and $S$, torch.quantize_per_tensor æœƒå°‡ä¸€å€‹æ­£å¸¸çš„ tensor å¾ $r$ è½‰æˆ $q$, å®˜ç¶²ç¯„ä¾‹: 12345&gt;&gt;&gt; torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8)tensor([-1., 0., 1., 2.], size=(4,), dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)&gt;&gt;&gt; torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr()tensor([ 0, 10, 20, 30], dtype=torch.uint8) ä»¥ä¸‹æˆ‘å€‘éƒ½ä»¥ uint8 ç•¶ä½œ quantized çš„ type, real value ä»¥ float (4 bytes) ç‚ºæº–. è€Œ int ç‚º 4 bytes. å…ˆä½¿ç”¨ Float è½‰æ›è¦å°‡ç¬¬ä¸€å€‹ domain ($Z_1$/$S_1$) çš„æ•¸å€¼è½‰æ›åˆ°ç¬¬äºŒå€‹ domain ($Z_2$/$S_2$) æœ€ç°¡å–®çš„æ–¹æ³•å°±æ˜¯å…ˆæŠŠç¬¬ä¸€å€‹ domain çš„ $r_1$ ç®—å‡ºä¾†, å†åˆ©ç”¨ç¬¬äºŒå€‹ domain çš„ $Z_2$/$S_2$ æ±‚å¾— $q_2$ $$\\begin{align} \\color{orange}{r_1}=(float)\\left( \\left( (int32)q_1-Z_1 \\right)*S_1 \\right) \\\\ q_2=\\text{uint8_saturated_round}\\left( \\frac{\\color{orange}{r_2}}{S_2}+Z_2 \\right) \\end{align}$$ ç”±æ–¼ $r_2=r_1$ å› æ­¤ (2) å¯è¨ˆç®—å‡º $q_2$. ä½†é€™æ¨£è¨ˆç®—é‚„æ˜¯ç”¨åˆ° float, å…¶å¯¦æˆ‘å€‘å¯ä»¥å®Œå…¨ä½¿ç”¨ integer é‹ç®—ä¾†é”æˆ. ç´”ç”¨ Integer é‹ç®— å…¶ä¸­ $M&gt;1.0$ æ˜¯æ²’æœ‰æ„ç¾©çš„, e.g. $S_1&gt;S_2$. å¦‚ä¸‹åœ–èˆ‰ä¾‹ä¾†èªª, data domain åˆ†å¸ƒåªæœƒåœ¨ 8 å€‹é»ä½ç½®ä¸Š, ä½¿ç”¨æ›´ç´°çš„ resolution å»å­˜æ²’æ„ç¾©. $M_0$ å¾ˆæ˜é¡¯å¯ä»¥ç”¨ Q0.31 çš„ int32 ä¾†ä¿å­˜, æ‰€ä»¥ $M_0$ èˆ‡ $(q_1-Z_1)$ ç›¸ä¹˜çš„æ™‚å€™ä½¿ç”¨ fractional multiplication, æœ€å¾Œ $2^{-n}$ ä½¿ç”¨ shift å³å¯. ä»€éº¼æ˜¯ fractional multiplication? ä¸€å¼µåœ–è¡¨ç¤ºå°±çŸ¥é“: æœ€å¾Œæˆ‘å€‘è¦é©—è­‰çš„è©±å…¶å¯¦å¯ä»¥è·Ÿä¸Šä¸€æ®µè¬›çš„ Float ç‰ˆæœ¬å°æ¯”å°±å¯ä»¥. çŸ©é™£é‹ç®—çš„ Quantization è½‰æ›å…¶å¯¦ convolution è£¡çš„çŸ©é™£é‹ç®—åªæ˜¯åŸä¾†çš„ $r_2=r_1$ è®Šæˆ $r_3=r_1r_2$ çš„é—œä¿‚è€Œå·², å…¶é¤˜éƒ½ç›¸åŒ. è²¼ä¸€å¼µè«–æ–‡çš„å…§å®¹å³å¯. æ›´å¤šå…§å®¹å¯ä»¥åƒè€ƒè«–æ–‡ ref [1], ä¾‹å¦‚ä½¿ç”¨ ReLU6 æ›¿ä»£ ReLU, å› ç‚ºå¦‚æœæˆ‘å€‘ä½¿ç”¨ uint8 çš„è©±ç”±æ–¼ ReLU6 å°‡ domain é™åˆ¶åœ¨ [0,6] ä¹‹é–“, é€™æ¨£ 8 bits å¯ä»¥ç”¨ $Z=0$, $S=1.0/2^5=0.03125$ ä¾†è¡¨ç¤º. åŒæ™‚æœ€å¾Œå†è½‰æ›æˆ quantization model æ™‚å¯ä»¥ç›´æ¥æ‹¿æ‰ ReLU6 (å› ç‚ºç›´æ¥ä½¿ç”¨ quantization å°±å¥½) Symmetric Fixed Pointå‚³çµ±ä¸Šå¸¸è¦‹çš„ fixed point æ¡ç”¨çš„æ˜¯ symmetric quantization, ä¾‹å¦‚ Q4.3 é€™ç¨® int8 çš„è¡¨ç¤ºæ–¹å¼ (-8.0 ~ 7.875). ä½†å®ƒå…¶å¯¦åªæ˜¯ asymmetric quantization çš„ç‰¹ä¾‹. Q4.3 åŸºæœ¬ä¸Šå°±æ˜¯ $Z=0$ å’Œ $S=1.0/2^3=0.125$ çš„ asymmetric quantization. PyTorch çš„ Quantization Aware Training (QAT) ç­†è¨˜PyTorch 1.7.0 quantization doc ä¸€é–‹å§‹è¦å…ˆå°ä½ çš„ NN Module å…ˆä½œå¦‚ä¸‹æ”¹å‹•: åœ¨è‡ªå·±å®šç¾©çš„ NN Module è£¡, æ‰€æœ‰ç”¨åˆ° torch.nn.functional çš„ op éƒ½è½‰æ›æˆ torch.nn.Module åœ¨è‡ªå·±å®šç¾©çš„ NN Module è£¡, forward æ™‚å…ˆå°‡ input é QuantStub(), ç„¶å¾Œæœ€å¾Œ output é DeQuantStub(). QuantStub() æœƒå°‡æ­£å¸¸çš„ input tensor è®Šæˆ quantized tensor (è£¡é¢åŒ…å« $Z$/$S$), ç„¶å¾Œ DeQuantStub() æœƒå°‡ quantized tensor è½‰æ›æˆæ­£å¸¸çš„ tensor. åœ¨è‡ªå·±å®šç¾©çš„ NN Module è£¡, ä½¿ç”¨ torch.quantization.fuse_modules å®šç¾©ä½ çš„ fuse_model function. ç›®å‰ PyTorch åªæ”¯æ´æœ‰é™ç¨® modules fusion (see function fuse_known_modules in fuse_modules.py). æ¥è‘— QAT ç‚ºä»¥ä¸‹å¹¾å€‹æ­¥é©Ÿ: å°‡ NN çš„ object (net) è¨­å®šç‚º net.train() (å¦‚æœåªæ˜¯åš post-quantization å‰‡ç”¨ net.eval()).é€™æ˜¯å› ç‚º QAT è¦åœ¨ training æ™‚æ¨¡æ“¬ inference çš„ quantization precision loss, æ‰€ä»¥è¦æ’å…¥å¾ˆå¤š fake-quantization çš„ op. å¯ä»¥åƒè€ƒè«–æ–‡ ref [1] çš„ Figure C.4 åˆ° Figure C.8. è€Œå¦‚æœåªæ˜¯ post-quantization å‰‡åœ¨åŸä¾†æ­£å¸¸çš„ floating trianing å®Œå¾Œ, å°‡ net.eval() è¨­å®šå¥½ç›´æ¥å°± fuse model äº† (torch.quantization.fuse_modules å°æ˜¯ train or eval æœ‰ä¸åŒçš„ fuse è¡Œç‚º). å‘¼å« net.fuse_model().ä¾‹å¦‚å‡è¨­æˆ‘å€‘è¦ fuse [&#39;conv1&#39;, &#39;bn1&#39;, &#39;relu1&#39;], PyTorch æœƒå°‡ç¬¬ä¸€å€‹ Module è®Šæˆ fused Module, å‰©ä¸‹çš„å…©å€‹ç‚º Identity() Module å°‡ net è¨­å®š attribute qconfig.ä¾‹å¦‚: net.qconfig= torch.quantization.get_default_qat_qconfig(&#39;fbgemm&#39;) å‘¼å« torch.quantization.prepare_qat(net, inplace=True).æ­¤ function ä¸»è¦å¹«ä½ åšå…©ä»¶äº‹æƒ…: a. propagate qconfig: å°æ‰€æœ‰å­ Module è¨­å®šç›¸å°æ‡‰çš„ qconfig (å› ç‚ºæ­¥é©Ÿ3æˆ‘å€‘åªé‡å° root Module è¨­å®š qconfig) b. add observer/fake-quantization: observer ç‚ºç°¡å–®çš„ min/max ç·šæ€§é‡åŒ–æ–¹å¼(æˆ– histogram æ–¹å¼ç­‰). å°‡åœ–éœ€è¦ quantization çš„åœ°æ–¹å®‰æ’å¥½é€™äº› observer/fake-quantization. åŸ·è¡Œä¸€èˆ¬ training æµç¨‹.åœ¨ training çš„éç¨‹ä¸­å°±æœƒé †ä¾¿çµ±è¨ˆå¥½å°æ‡‰çš„ min/max ç­‰, ç„¶å¾Œæ¯å€‹ tensor çš„ $Z$/$S$ ä¹Ÿæœƒå°æ‡‰å¾—åˆ° (é€šå¸¸ç”¨ moving average æ–¹å¼åš smoothing). æœ€å¾Œè½‰æ›æˆ quantized model torch.quantization.convert(net, inplace=True) ä»¥ä¸Šä¸€å€‹æœ€å°ç¯„ä¾‹å¦‚ä¸‹: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import torchimport torch.nn as nnfrom torch.quantization import QuantStub, DeQuantStubimport torch.quantizationclass Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.bn1 = nn.BatchNorm2d(6) self.relu1 = nn.ReLU() self.quant = QuantStub() self.dequant = DeQuantStub() def forward(self, x): x = self.quant(x) x = self.relu1(self.bn1(self.conv1(x))) x = self.dequant(x) return x # Fuse Conv+BN and Conv+BN+Relu modules prior to quantization # This operation does not change the numerics def fuse_model(self): torch.quantization.fuse_modules(self, ['conv1', 'bn1', 'relu1'], inplace=True)net = Net()print('===== Before fuse_model:')print(net)print('===== After fuse_model:')net.train()net.fuse_model()print(net)print('===== Setting qconfig:')# Specify quantization configuration# Start with simple min/max range estimation and per-tensor quantization of weightsnet.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')print(net.qconfig)print('===== After torch.quantization.prepare:')torch.quantization.prepare_qat(net, inplace=True)print(net)# Do your regular trainingtraining_loop(net)print('===== After torch.quantization.convert:')torch.quantization.convert(net, inplace=True)print(net) æœ€å¾Œé™„ä¸Šä¸€å€‹å¾ˆæ£’çš„ convolution and batchnorm fusion è§£èªª [é€£çµ], ä½œè€…æ˜¯ Nenad MarkuÅ¡ Reference Paper: Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference (BETA) STATIC QUANTIZATION WITH EAGER MODE IN PYTORCH Nenad MarkuÅ¡: Fusing batch normalization and convolution in runtime","tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://bobondemon.github.io/tags/PyTorch/"},{"name":"Quantization Aware Training (QAT)","slug":"Quantization-Aware-Training-QAT","permalink":"https://bobondemon.github.io/tags/Quantization-Aware-Training-QAT/"},{"name":"Asymmetric Quantization","slug":"Asymmetric-Quantization","permalink":"https://bobondemon.github.io/tags/Asymmetric-Quantization/"},{"name":"Symmetric Quantization","slug":"Symmetric-Quantization","permalink":"https://bobondemon.github.io/tags/Symmetric-Quantization/"}]},{"title":"TF Notes (7), Some TF2.x Eager Mode Practices","date":"2020-06-26T02:52:18.000Z","path":"2020/06/26/TF-Notes-some-TF2-x-eager-mode-practices/","text":"ç‚ºäº†å­¸ç¿’ TF2.x åªå¥½æŠŠä»¥å‰ç·´ç¿’çš„ä¸€äº› projects é‡å¯«ä¸€æ¬¡, ä½†å¾Œä¾†æ™‚é–“æ–·æ–·çºŒçºŒçš„, æ‰€ä»¥åªåšäº†ä¸€éƒ¨åˆ†. ç¸½ä¹‹å…ˆè¨˜éŒ„ä¸€ä¸‹ç›®å‰çš„ç·´ç¿’é€²åº¦å§. TFDataset ç·´ç¿’: jupyter notebook if map() has random ops: dataset.shuffle().batch().cache().map().prefetch() map() has NO random ops: dataset.shuffle().batch().map().cache().prefetch() NeuralStyleTransfer: jupyter notebook ç·´ç¿’ optimization è®Šæ•¸æ˜¯ input x è€Œä¸æ˜¯åŸä¾†çš„ weights w TSLearning ToyExample: jupyter notebook å›ºå®šæŸä¸€éƒ¨åˆ†çš„ model æœ€åŸå§‹çš„ distillation AutoEncoder jupyter notebook: decoder éƒ¨åˆ†ä½¿ç”¨ deconvolution jupyter notebook: å…¨éƒ¨ FC ä½† decoder æ˜¯ encoder çš„ transpose (share weights) GAN jupyter notebook: MMGAN jupyter notebook: WGAN jupyter notebook: WGAN-div Adversarial Domain Adaptation jupyter notebook å’Œ ä»‹ç´¹åŠå¯¦é©—çµæœ é‚„æœ‰å¾ˆå¤šæ²’ç·´ç¿’åˆ°, VAE, seq2seq, transformer ç­‰â€¦.åªå¥½å†èªªäº†","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://bobondemon.github.io/tags/TensorFlow/"}]},{"title":"CTC Model and Loss","date":"2020-05-31T10:07:24.000Z","path":"2020/05/31/CTC-Model-and-Loss/","text":"CTC model æ˜¯ä¸€å€‹ decoder éƒ¨åˆ†ç‚ºç°¡å–®çš„ (independent) linear classifer çš„ seq2seq model. å› æ­¤ input frame æœ‰ $T$ å€‹, å°±æœƒæœ‰ $T$ å€‹ output distribution vectors. æ­£å¸¸ä¾†èªª (ex: ASR) output token æ•¸é‡ $N&lt;T$, æ‰€ä»¥æœƒæœ‰ alignment å•é¡Œ. ä»¥å¾€çš„ alignment (HMM) å¼·è¿«æ¯å€‹ frame index éƒ½éœ€å°æ‡‰åˆ°ä¸€å€‹ phoneâ€™s state, ä½† CTC å…è¨±å°æ‡‰åˆ° â€œç©ºâ€ çš„ state (null or blank). é€™è®“ CTC çš„ alignment æ¯” HMM æ›´æœ‰å½ˆæ€§. RNN-T æ˜¯å¦ä¸€ç¨®æ¯” CTC æ›´æœ‰å½ˆæ€§çš„ alignment è¡¨é”æ–¹å¼. CTC çš„ gradient å¯ä»¥éå¸¸æœ‰æ•ˆç‡çš„ç”¨ dynamic programming æ±‚å¾— (forward/backward æ¼”ç®—æ³•, ä¸‹åœ–). å› æ­¤æ¡ç”¨ gradient-based optimization æ–¹æ³•å°±å¾ˆåˆé©. æœ¬æ–‡æœƒè©³ç´°ä»‹ç´¹ä¸Šé¢æåˆ°çš„å¹¾é». Decoding éƒ¨åˆ†ä¸ä»‹ç´¹. CTC Model and Loss: PDF Slide é€£çµ Link PDF","tags":[{"name":"CTC","slug":"CTC","permalink":"https://bobondemon.github.io/tags/CTC/"}]},{"title":"Exp of Adversarial Domain Adaptation","date":"2020-05-17T09:15:21.000Z","path":"2020/05/17/Exp-of-Adversarial-Domain-Adaptation/","text":"Domain Adaptation æ˜¯å¸Œæœ›åœ¨ source domain æœ‰ label ä½†æ˜¯ target domain ç„¡ label çš„æƒ…æ³ä¸‹, èƒ½é‡å° target domain (æˆ–åŒæ™‚ä¹Ÿèƒ½å° source domain) é€²è¡Œåˆ†é¡ä»»å‹™. â€œAdversarialâ€ çš„æ„æ€æ˜¯åˆ©ç”¨ GAN çš„ â€œå°æŠ—â€ æƒ³æ³•: Label predictor é›–ç„¶åªèƒ½ä¿è­‰ source domain çš„åˆ†é¡. ä½†ç”±æ–¼æˆ‘å€‘æŠŠ feature ç”¨ GAN æ¶ˆé™¤äº† domain ä¹‹é–“çš„å·®ç•°, å› æ­¤æˆ‘å€‘æ‰èƒ½æœŸæœ›é€™æ™‚å€™çš„ source domain classifier ä¹Ÿèƒ½ä½œç”¨åœ¨ target domain. é€™ç¯‡æ–‡ç«  å¼µæ–‡å½¥, é–‹é ­çš„åœ–å‚³é”çš„æ„æ€å¾ˆç²¾ç¢º, è«‹é»é€²å»åƒè€ƒ. æ¥è‘—å˜—è©¦è¤‡ç¾äº†ä¸€æ¬¡ Domain-Adversarial Training of Neural Networks çš„ mnist(source) to mnist_m(target) çš„å¯¦é©—. ä¸Šä¸€ç¯‡èªªæ˜ GAN çš„ framework: $$\\begin{align} Div\\left(P_d\\|P_G\\right) = \\max_D\\left[ E_{x\\sim P_d} D(x) - E_{x\\sim P_G}f^*(D(x)) \\right] \\\\ G^*=\\arg\\min_G{Div\\left(P_d\\|P_G\\right)} + reg(G) \\\\ \\end{align}$$ å°æ–¼ Adversarial Domain Adaptation ä¾†èªªåªè¦åœ¨æ­£å¸¸ GAN çš„ training æµç¨‹ä¸­, update $G$ æ™‚å¤šåŠ ä¸€å€‹ regularization term $reg(G)$ å°±å¯ä»¥äº†. è€Œ $reg(G)$ å°±æ˜¯ Label Predictor çš„ loss, ä½œç”¨å°±æ˜¯ train $G$ æ™‚é™¤äº†è¦æ¬ºé¨™ $D$, åŒæ™‚è¦èƒ½é™ä½ prediction error. å¯¦é©— source domain ç‚ºæ¨™æº–çš„ mnist, è€Œ target domain æ˜¯ modified mnist, å¦‚ä½•ç”¢ç”Ÿå¯ä»¥åƒè€ƒDaipuwei/DANN-MNIST. ä¸‹åœ–æ˜¯ mnist_m çš„ä¸€äº›ç¯„ä¾‹: æˆ‘å€‘å…ˆä¾†çœ‹ä¸€ä¸‹åˆ†ä½ˆ, è—è‰²çš„é»æ˜¯ mnist, ç´…è‰²æ˜¯ mnist_m, ç”¨ tSNE è·‘å‡ºä¾†çš„çµæœæ˜é¡¯çœ‹åˆ°å…©å€‹ domain åˆ†ä½ˆä¸åŒ: æˆ‘å€‘ä¹‹å‰èªªé, ä¸ç”¨ç®¡ GRL (Gradient Reversal Layer), å°±ä¸€èˆ¬çš„ GAN æ¶æ§‹, åŠ ä¸Š regularization term å°±å¯ä»¥. è½èµ·ä¾†å¾ˆå®¹æ˜“, æˆ‘å°±éš¨æ‰‹è‡ªå·±ç”¨äº†å¹¾å€‹ CNN åœ¨ generator, å¹¾å±¤ fully connected layers çµ¦ classifier å’Œ discriminator å°±åšäº†èµ·ä¾†. ç™¼ç¾æ€éº¼å¼„éƒ½è¨“ç·´ä¸èµ·ä¾†! ç”¢ç”Ÿä¸‹é¢å…©ç¨®æƒ…å½¢: GAN too weak:é‡æ–°èª¿æ•´äº†ä¸€ä¸‹ $reg(G)$ çš„æ¯”é‡å¾Œâ€¦. GAN too strong:å…©å€‹ domain çš„ features å¹¾ä¹å®Œå…¨ overlap, ç„¶å¾Œ classifier å¹¾ä¹ç„¡ä½œç”¨ (ä¹Ÿçœ‹ä¸å‡ºæœ‰10å€‹åˆ†ç¾¤). è©±èªª, é€™åœ–å¾ˆåƒè…¦çš„ç´‹è·¯? è²ªé£Ÿè›‡? è¿·å®®? è‚šå­è£¡çš„è›”èŸ²? å¾Œä¾†åœ¨å˜—è©¦èª¿äº†å¹¾å€‹åƒæ•¸å¾Œä»ç„¶è¨“ç·´ä¸èµ·ä¾†. é€™è®“æˆ‘æ„Ÿåˆ°å¾ˆæŒ«æŠ˜. å¯¦åœ¨å—ä¸äº†å¾Œ, åƒè€ƒäº†ç¶²è·¯ä¸Šçš„åšæ³•æ”¹æˆä»¥ä¸‹å¹¾é»: WGAN æ”¹æˆç”¨ MMGAN RMSProp(1e-4) æ”¹æˆ Adam(1e-3) ä½¿ç”¨ç¶²è·¯ä¸Šä¸€å€‹æ›´ç°¡å–®çš„æ¶æ§‹ github æ”¹æˆç”¨ MMGAN å¾Œ, å»æ‰ BN layer å°±èƒ½è¨“ç·´èµ·ä¾† ç„¶å¾Œå°±å¯ä»¥è¨“ç·´èµ·ä¾†äº†(ç¿»æ¡ŒxN), è¨“ç·´å¾Œçš„çµæœå¦‚ä¸‹: å¯ä»¥çœ‹åˆ°åœ¨ mnist è¾¨è­˜ç‡ ~99% çš„æƒ…å½¢ä¸‹, mnist_m èƒ½å¤ æœ‰ 83.6% çš„è¾¨è­˜ç‡ (æ²’åš adaptation åªæœ‰ç´„50%) Feature çš„åˆ†å¸ƒå¦‚ä¸‹åœ– (è—è‰²çš„é»æ˜¯ mnist, ç´…è‰²æ˜¯ mnist_m): é›–ç„¶é‚„æœ‰ä¸€äº› feature æ²’æœ‰å®Œå…¨ match åˆ°, ä½†å·²ç¶“å¾ˆé‡ç–Šäº†. åŒæ™‚æˆ‘å€‘ä¹Ÿèƒ½æ˜é¡¯åˆ°åˆ° 10 ç¾¤çš„åˆ†é¡. çµè«–é›–ç„¶ç†è«–ä¸Šçš„ç†è§£å¾ˆå®¹æ˜“, ä½†å¯¦ä½œèµ·ä¾†å»ç™¼ç¾å¾ˆé›£èª¿æ•´. GAN å°±æ˜¯é‚£éº¼é›£æé˜¿â€¦. Reference GAN framework Domain-Adversarial Training of Neural Networks åƒè€ƒç”¢ç”Ÿ mnist_m çš„ codes Daipuwei/DANN-MNIST Domain-Adversarial Training of Neural Networks with TF2.0: lancerane/Adversarial-domain-adaptation å¼µæ–‡å½¥ Domain-adaptation-on-segmentation è‡ªå·±å¯¦é©—çš„ jupyter notebook","tags":[{"name":"GAN","slug":"GAN","permalink":"https://bobondemon.github.io/tags/GAN/"},{"name":"ADDA","slug":"ADDA","permalink":"https://bobondemon.github.io/tags/ADDA/"}]},{"title":"Framework of GAN","date":"2020-05-11T12:29:12.000Z","path":"2020/05/11/Note-for-Framework-of-GAN/","text":"èªªä¾†æ±—é¡, è‡ªå¾17å¹´ä¸‰æœˆç­†è¨˜å®Œ WGAN å¾Œ, å°±æ²’å†ç¢° GAN ç›¸é—œçš„æ±è¥¿äº†. æƒ¡è£œäº†ä¸€ä¸‹ æå®æ¯…GAN çš„èª²ç¨‹å’Œå…¶ä»–ç›¸é—œè³‡æ–™, å› æ­¤ç­†è¨˜ä¸€ä¸‹. MMGAN(æœ€åŸå§‹çš„GAN), NSGAN(è·ŸMMGANå·®åˆ¥åœ¨ G çš„ update ç›®æ¨™å‡½å¼æœ‰é»ä¸åŒ), f-GAN, WGAN, ADDA (Adversarial Discriminative Domain Adaptation), infoGAN, VAE-GAN ç­‰â€¦ é€™äº›å…¨éƒ¨éƒ½æ˜¯ follow ä¸‹é¢é€™æ¨£çš„ framework: $$\\begin{align} Div\\left(P_d\\|P_G\\right) = \\max_D\\left[ E_{x\\sim P_d} D(x) - E_{x\\sim P_G}f^*(D(x)) \\right] \\\\ G^*=\\arg\\min_G{Div\\left(P_d\\|P_G\\right)} + reg(G) \\\\ \\end{align}$$ å…¶ä¸­ $P_d$ ç‚º real data pdf, $P_G$ ç‚º generator ç”¢ç”Ÿçš„ data pdf. $f^*$ å¸¶å…¥ä¸åŒçš„å®šç¾©æœƒç”¢ç”Ÿä¸åŒçš„ divergence, é€™ä¹‹å¾Œæœƒå†èªªæ˜. å¼ (1) å®šç¾©äº† $P_G$ èˆ‡ $P_d$ çš„ divergence, å…¶ä¸­é€™å€‹ divergence çš„å€¼ç‚ºè—‰ç”±è§£é€™å€‹æœ€ä½³åŒ–å•é¡Œæ±‚å¾—çš„. å¼ (2) è¡¨ç¤ºè¦æ‰¾çš„ $G$ å°±æ˜¯ divergence æœ€å°çš„é‚£å€‹. Divergence æœ€å° ($=0$) åŒæ™‚ä¹Ÿè¡¨ç¤º $P_G=P_d$ (ç”Ÿæˆå™¨éŠæˆ). å¦‚æœåŒæ™‚è€ƒæ…® regularization term, $reg(G)$, å‰‡æœƒæœ‰å¾ˆå¤šè®ŠåŒ–ç”¢ç”Ÿ, å¦‚ ADDA, infoGAN, VAE-GANâ€¦ æˆ‘å€‘æ¥è‘—ä¾†çœ‹ MMGAN, NSGAN, f-GAN, WGAN, ADDA, infoGAN, VAE-GAN é€™äº›æ€éº¼ fit é€²é€™å€‹æ¡†æ¶. MMGANMMGAN æ˜¯ MinMax GAN çš„ç¸®å¯«, æŒ‡çš„æ˜¯æœ€åŸå§‹çš„ GAN. å°‡ (1) ä¸­çš„ $D(x)$ ä½¿ç”¨ $\\log D(x)$ æ›¿æ›, ä¸¦ä¸” $f^*(t)=-\\log(1-exp(t))$ æ›¿æ›å¾—åˆ°å¦‚ä¸‹å¼å­: $$\\begin{align} Div\\left(P_d\\|P_G\\right) = \\max_D\\left[ E_{x\\sim P_d} \\log D(x) - E_{x\\sim P_G}[-\\log(1-D(x))] \\right] \\\\ \\end{align}$$ ç¨å¾®å†æ•´ç†ä¸€ä¸‹: $$\\begin{align} Div\\left(P_d\\|P_G\\right) = \\max_D\\left[ E_{x\\sim P_d} \\log D(x) + E_{x\\sim P_G}[\\log(1-D(G(z)))] \\right] \\\\ \\end{align}$$ é€™å°±æ˜¯ GAN discriminator åŸå§‹çš„å¼å­. è€Œæˆ‘å€‘çŸ¥é“çµ¦å®š $G$ ä¸Šè¿°çš„æœ€ä½³è§£ç‚º \\( D_G^*(x) = \\frac{P_d(x)}{P_d(x)+P_G(x)} \\), ä¸¦å¸¶å…¥ (4) æˆ‘å€‘å¾—åˆ°: $$\\begin{align} Div\\left(P_d\\|P_G\\right) = -\\log4+KL(p_d\\vert\\frac{p_d+p_g}{2})+KL(p_g\\vert\\frac{p_d+p_g}{2}) \\\\ =-\\log4+2JSD(p_d \\vert p_g) \\end{align}$$ å› æ­¤ discriminator çš„æœ€å¤§åŒ–ç›®çš„æ˜¯è¨ˆç®—å‡º JS divergence. è€Œ generator $G$ æ±‚è§£æ²’ä»€éº¼å¥½èªª, ç›´æ¥å° (3) æœ€å°åŒ–: $$\\begin{align} G^*=\\arg\\min_G E_{x\\sim P_G}[\\log(1-D(x))] \\end{align}$$ æ³¨æ„åˆ°èˆ‡ (2) å°æ¯”, MMGAN åªæ˜¯æ²’æœ‰ regularization term è€Œå·². NSGANNSGAN ç‚º Non-Saturating GAN ç¸®å¯«, èˆ‡ MMGAN åªå·®åœ¨ generator $G$ æ±‚è§£å¼å­ä¸åŒ, åŸæœ¬æ˜¯å¸Œæœ›åœ¨ä¸€é–‹å§‹ generator æ¯”è¼ƒå·®çš„æƒ…å½¢ä¸‹ç”¨ (7) ç®—çš„ gradient æœƒå¤ªå°, å› æ­¤æ”¹æˆä¸‹å¼, ä½¿å¾— gradient èƒ½åœ¨ä¸€é–‹å§‹çš„æ™‚å€™æ¯”è¼ƒå¤§, è®“ update å‹•èµ·ä¾†. NSGAN generator $G$ ç‚º: $$\\begin{align} G^*=\\arg\\min_G E_{x\\sim P_G}[-\\log(D(x))] \\end{align}$$ å¦‚æœæˆ‘å€‘å°‡ \\( D_G^*(x) = \\frac{P_d(x)}{P_d(x)+P_G(x)} \\) å¸¶å…¥ä¸¦æ•´ç†, æˆ‘å€‘æœƒç™¼ç¾: $$\\begin{align} G^*=\\arg\\min_G E_{x\\sim P_G}[-\\log(D^*(x))] \\\\ =\\arg\\min_G \\left[ KL(P_G\\|P_d)-2JSD(P_d\\|P_G) \\right] \\end{align}$$ ç”¢ç”Ÿäº†å…©å€‹äº’ç›¸ trade-off çš„ objective funtionâ€¦ é€™é€ æˆäº†çŸ›ç›¾ è©³ç´°æ¨å°è«‹åƒè€ƒ ä»¤äººæ‹æ¡ˆå«ç»çš„Wasserstein GAN ä¸€æ–‡, éå¸¸æ£’çš„æ–‡ç« . å¼•ç”¨æ–‡ç« å…§çš„èªªæ˜: ä¸€å¥è¯æ¦‚æ‹¬ï¼šæœ€å°åŒ–ç¬¬äºŒç§ç”Ÿæˆå™¨losså‡½æ•°ï¼Œä¼šç­‰ä»·äºæœ€å°åŒ–ä¸€ä¸ªä¸åˆç†çš„è·ç¦»è¡¡é‡ï¼Œå¯¼è‡´ä¸¤ä¸ªé—®é¢˜ï¼Œä¸€æ˜¯æ¢¯åº¦ä¸ç¨³å®šï¼ŒäºŒæ˜¯collapse modeå³å¤šæ ·æ€§ä¸è¶³ã€‚ f-GANæˆ‘å€‘åœ¨ MMGAN æ™‚æåˆ° â€œå°‡ (1) ä¸­çš„ $D(x)$ ä½¿ç”¨ $\\log D(x)$ æ›¿æ›, ä¸¦ä¸” $f^*(t)=-\\log(1-exp(t))$ æ›¿æ›â€ å‰‡æœƒå¾—åˆ° discriminator å°±æ˜¯åœ¨æ±‚è§£ JS divergence. é‚£éº¼æœ‰æ²’æœ‰å…¶ä»–è¨­å®šæœƒç”¢ç”Ÿå…¶ä»– divergence å‘¢? æœ‰çš„, è—‰ç”± f-GAN çš„å®šç¾©å¯ä»¥å›Šæ‹¬å„å¼å„æ¨£çš„ divergence. ä½¿ç”¨æè€å¸«çš„èªªæ˜æµç¨‹ç­†è¨˜: é¦–å…ˆå®šç¾© f-divergence, å¯ä»¥ç™¼ç¾ JSD, KL, reverse-KL, Chi square ç­‰ç­‰éƒ½å±¬æ–¼å…¶ä¸­çš„ç‰¹ä¾‹. æ¥è‘—èªªæ˜ convex function çš„ conjugate function. æœ€å¾Œæ‰èªªæ˜æ€éº¼è·Ÿ GAN ç”¢ç”Ÿé—œè¯ (ç¥å¥‡çš„é€£çµ). f-divergence$$\\begin{align} Div_f(P\\|Q)=\\int_x q(x)f\\left( \\frac{p(x)}{q(x)} \\right) dx \\\\ \\text{where } f \\text{ is }\\color{orange}{convex} \\text{ and } f(1)=0 \\end{align}$$ æ˜é¡¯çŸ¥é“ $p(x)=q(x)$ æ™‚ $Div_f(P|Q)=0$, åŒæ™‚å¯ä»¥è­‰æ˜ $Div_f(P|Q)\\geq 0$, å› æ­¤æ»¿è¶³ divergence å®šç¾©(search â€œDivergence (statistics) wikiâ€ for definition): $$\\begin{align} Div_f(P\\|Q)=\\int_x q(x)f\\left( \\frac{p(x)}{q(x)} \\right) dx \\\\ \\geq f\\left( \\int_x q(x)\\frac{p(x)}{q(x)} dx \\right)=f(1)=0 \\\\ \\end{align}$$ $f$ æ˜¯ convex é€™é»å¾ˆé‡è¦, æ‰èƒ½å°‡ (13) åˆ° (14) ä½¿ç”¨ Jensenâ€™s inequality. å®šç¾©ä¸åŒ $f$ æœƒç”¢ç”Ÿä¸åŒ divergence, å¸¸è¦‹çš„ç‚º(æè€å¸«slide): ç”±æ–¼ $f$ æ˜¯ convex, è€Œæ¯ä¸€å€‹ convex function éƒ½æœƒæœ‰ä¸€å€‹ conjugate function $f^*$ (å®ƒä¹Ÿæ˜¯ convex), åˆ©ç”¨é€™å€‹ç‰¹æ€§æœ€å¾Œå¯ä»¥è·Ÿ GAN é€£èµ·ä¾†. å› æ­¤ä»¥ä¸‹å…ˆèªªæ˜ conjugate function. Fenchel ConjugateEvery convex function $f$ has a conjugate function $f^*$: $$\\begin{align} f^*(t)=\\max_{x\\in dom(f)}\\{xt-f(x)\\} \\end{align}$$ è€å¸«çš„æŠ•å½±ç‰‡éå¸¸å½¢è±¡çš„è¡¨ç¤ºå‡º $f$ èˆ‡ $f^*$ çš„é—œä¿‚L é‚„å…·é«”èˆ‰äº†å€‹ç•¶ $f(x)=x\\log x$ çš„ä¾‹å­: èˆ‡ GAN çš„é—œè¯é€™æ˜¯æˆ‘è¦ºå¾—éå¸¸å²å®³çš„åœ°æ–¹. é¦–å…ˆ $f^*$ çš„ conjugate å°±è®Šå› $f$ äº†, å®ƒå€‘äº’ç‚º conjugate. $$\\begin{align} f^*(t)=\\max_{x\\in dom(f)}\\{xt-f(x)\\}\\longleftrightarrow f(x)=\\max_{t\\in dom(f^*)}\\{xt-f^*(t)\\} \\end{align}$$ å°‡ (11) åˆ©ç”¨ conjugate çš„é—œä¿‚é‡æ–°è¡¨ç¤ºä¸€ä¸‹ $$\\begin{align} Div_f(P\\|Q)=\\int_x q(x)f\\left( \\frac{p(x)}{q(x)} \\right) dx \\\\ =\\int_x q(x) \\left( \\max_{t\\in dom(f^*)} \\left[ \\frac{p(x)}{q(x)}t - f^*(t) \\right] \\right) dx \\end{align}$$ å²å®³çš„åœ°æ–¹ä¾†äº†â€¦. å‡è¨­æˆ‘å€‘æœ‰ä¸€å€‹ function $D$ å¯ä»¥ç›´æ¥å¹«æˆ‘å€‘è§£å‡º (18) çš„é‚£å€‹ $t$ æ˜¯ä»€éº¼, ä¹Ÿå°±æ˜¯: $$\\begin{align} D(x)=\\hat{t}=\\arg\\max_{t\\in dom(f^*)} \\left[ \\frac{p(x)}{q(x)}t - f^*(t) \\right] \\end{align}$$ é‚£éº¼ $Div_f(P||Q)$ ç›´æ¥å°±æ˜¯ $$\\begin{align} Div_f(P||Q)=\\int_x q(x) \\left[ \\frac{p(x)}{q(x)}\\hat{t} - f^*(\\hat{t})) \\right] dx \\end{align}$$ å¯¦ä½œä¸Š $D$ çš„è¡¨é”èƒ½åŠ›æœ‰é™, åŒæ™‚è®“æˆ‘å€‘æ‰¾åˆ°æœ€æº–çš„é‚£å€‹å«åš $\\hat{D}$, å› æ­¤åªèƒ½æ±‚å¾—ä¸€å€‹ä¸‹ç•Œä¸¦æ•´ç†ä¸€ä¸‹å¾—åˆ°: $$\\begin{align} Div_f(P||Q)\\geq \\int_x q(x) \\left[ \\frac{p(x)}{q(x)}\\hat{D}(x) - f^*(\\hat{D}(x))) \\right] dx \\\\ \\approx \\int_x q(x) \\left[ \\frac{p(x)}{q(x)}\\hat{D}(x) - f^*(\\hat{D}(x))) \\right] dx \\\\ = \\int_x {p(x)\\hat{D}(x)}dx - \\int_x{q(x)f^*(\\hat{D}(x))} dx \\\\ = E_{x\\sim P}\\left[ \\hat{D}(x) \\right] - E_{x\\sim Q}\\left[ f^*( \\hat{D}(x) ) \\right] \\\\ = \\max_D \\left[ E_{x\\sim P}\\left[ D(x) \\right] - E_{x\\sim Q}\\left[ f^*( D(x) ) \\right] \\right] \\\\ \\end{align}$$ è«‹æŠŠ (25) è·Ÿ (1) æ¯”è¼ƒ, å…¶å¯¦å°±ä¸€æ¨¡ä¸€æ¨£. å› æ­¤, åªè¦ $f$ æ˜¯ convex function , ä¸” $f(1)=0$, discriminator $D$ çš„æœ€ä½³åŒ–å•é¡Œ ((1) ç”¨ $f$ çš„ conjugate, $f^*$, å¸¶å…¥) å°±æ˜¯åœ¨è¨ˆç®—å…©å€‹åˆ†å¸ƒçš„ f-divergence. è«–æ–‡ç›´æ¥çµ¦å‡ºå„ç¨® f-divergence çš„ $f$ and $f^*$ å› æ­¤æˆ‘å€‘å¯ä»¥ç™¼ç¾ MMGAN å’Œ LSGAN éƒ½æ˜¯ f-GAN çš„ä¸€ç¨®ç‰¹ä¾‹. WGANå…·é«”è«‹åƒè€ƒä¹‹å‰è‡ªå·±ç­†è¨˜çš„æ–‡ç«  æè€å¸«çš„è¬›ç¾©å°æ–¼ Earth Moverâ€™s Distance (æˆ–ç¨± Wasserstein distance) è¬›è§£å¾—å¾ˆæ¸…æ¥š, å…¶ä¸­çš„ä¸€å€‹åƒè€ƒé€£çµæ›´è§£é‡‹äº† Wasserstein distance å¦‚ä½•è½‰æ›æˆæ±‚è§£ $\\max_D$ ä¸” $D$ å¿…é ˆé™åˆ¶åœ¨ Lipschitz æ¢ä»¶ä¸‹. ç¸½ä¹‹é€™è£¡è¦èªªçš„æ˜¯, Wasserstein distance ä¸å±¬æ–¼ f-divergence, ä½†ä¹Ÿå®Œå…¨ follow æˆ‘å€‘ä¸€é–‹å§‹èªªçš„ (1) &amp; (2) çš„æ¶æ§‹: ä»¤ $f^*(x)=x$ åŒæ™‚å¤šä¸€å€‹é™åˆ¶æ˜¯ $D\\in k-Lipschitz$ $$\\begin{align} Div\\left(P_d\\|P_G\\right) = \\max_{D\\in k-Lipschitz}\\left[ E_{x\\sim P_d} D(x) - E_{x\\sim P_G}D(x) \\right] \\\\ \\end{align}$$ æ±‚è§£ discriminator çš„æœ€ä½³åŒ–å•é¡Œå…¶å¯¦å°±æ˜¯åœ¨ä¼°ç®—å…©å€‹åˆ†å¸ƒçš„ divergence. åŸå§‹è«–æ–‡é‡å° $D\\in k-Lipschitz$ çš„é™åˆ¶ç›´æ¥ç”¨å¾ˆæš´åŠ›çš„ weight clipping æ–¹æ³•è§£æ‰. å› æ­¤å¾Œé¢æœ‰ä¸€ç¯‡ WGAN-GP (Gradient Panelty) çš„æ–¹å¼è£œå¼·. é€™è£¡ä¸å±•é–‹è¨è«–, å› ç‚ºæˆ‘ä¹Ÿæ²’ä»€éº¼ç ”ç©¶, ç°¡å–®å¸¶éä¸€é»å¾…è®€çš„è«–æ–‡. å¦å¤–æœ‰ä¸€ç¯‡ SN-GAN â€œSpectral Normalization for Generative Adversarial Networksâ€œ çœ‹èµ·ä¾†æ˜¯ä¸€ç¨®ä¸»æµè¨“ç·´ WGAN çš„æ–¹å¼, äº‹å…ˆå°±å°‡ gradient éƒ½é™åˆ¶ norm&lt;=1. é€™ç¯‡æ–‡ç« å¤§è‡´æ•´ç†å„ç¨®è®Šé«”, åƒè€ƒé€£çµ. é—œæ–¼ regularization term, $reg(G)$Adversarial Domain Adaptationæˆ‘å€‘å…ˆèªª Domain-Adversarial Training of Neural Networks é€™ç¯‡ç¶“å…¸çš„æ–‡ç« . Generator ç¾åœ¨åšçš„æ˜¯ feature extractor çš„å·¥ä½œ, è€Œæˆ‘å€‘å¸Œæœ› target domain çš„ feature èƒ½è·Ÿ source domain çš„ feature åˆ†ä½ˆä¸€æ¨£, é€™æ¨£åœ¨ source domain (æœ‰ label) è¨“ç·´å¥½çš„ model, å°±èƒ½ç›´æ¥åœ¨ target domain (ç„¡ label) ä¸Šä½œç”¨. è¦åšåˆ°ç„¡æ³•å€åˆ†å‡ºé€™å€‹ feature æ˜¯ source or target domain é€™ä»¶äº‹æƒ…â€¦.æ­£å¥½å°±å¯ä»¥ç”¨ GAN çš„æ–¹å¼é”åˆ°. ä¸çœ‹ Label Predictor çš„éƒ¨åˆ†çš„è©±, å°±æ˜¯ä¸€å€‹å…¸å‹çš„ GAN. ä½œç”¨å°±æ˜¯æŠŠ source and target çš„ feature æŠ•å½±åˆ°å…±åŒçš„ç©ºé–“, ä¸¦ä¸”åˆ†ä¸é–‹. ä½†ç¼ºå°‘ Label Predictor æœ‰å¯èƒ½é€ æˆ feature extractor ç”¢ç”Ÿ trivial solution (ä¾‹å¦‚å…¨éƒ¨ map åˆ° constant) é€™æ¨£ä¹Ÿèƒ½ä½¿ discriminator åˆ†ä¸é–‹. å› æ­¤åŠ ä¸Š Label Predictor é™¤äº†é¿å…é€™ä»¶äº‹å¤–, ä¹Ÿä¿è­‰åœ¨ source domain èƒ½å¤ å¾ˆå¥½çš„å®Œæˆæˆ‘å€‘çš„åˆ†é¡ä»»å‹™. æ³¨æ„, å› ç‚º label åªæœ‰åœ¨ source domain, å› æ­¤ label predictor åªèƒ½ä¿è­‰ source domain çš„åˆ†é¡. ä½†ç”±æ–¼æˆ‘å€‘æŠŠ feature ç”¨ GAN æ¶ˆé™¤äº† domain ä¹‹é–“çš„å·®ç•°, å› æ­¤æˆ‘å€‘æ‰èƒ½æœŸæœ›é€™æ™‚å€™çš„ source domain classifier ä¹Ÿèƒ½ä½œç”¨åœ¨ target domain. è«–æ–‡ä½¿ç”¨äº†ä¸€å€‹å«åš Gradient Reversal Layer (GRL), å…¶å¯¦æˆ‘å€‘å¯ä»¥å¿½ç•¥é€™ä»¶äº‹æƒ…, å› ç‚ºé€™åªæ˜¯ discriminator and generator ä¸€å€‹ maximize å¦ä¸€å€‹ minimize, è€Œä½¿å¾—è¦ update generator æ™‚ç•¶æ™‚ç®—çš„ discriminator gradient è¦å–è² è™Ÿ. æˆ‘å€‘ç…§æ­£å¸¸çš„ GAN training å°±å¯ä»¥äº†. Label Predictor çš„ loss å…·é«”å°±æ˜¯ (2) çš„ regularization term, $reg(G)$. é€™æ˜¯å¸Œæœ›æˆ‘å€‘ train $G$ çš„æ™‚å€™é™¤äº†è¦æ¬ºé¨™ $D$, åŒæ™‚è¦èƒ½é™ä½ $reg(G)$ (prediction loss). å¾ŒçºŒæœ‰ä¸€ç¯‡ Advesarial Discriminative Domain Adaptation ç®—æ˜¯è±å¯Œäº†é€™ç¨®æ¶æ§‹. è«–æ–‡è£¡å° source and target çš„ feature extractor ä½¿ç”¨ä¸åŒçš„ neural networks. ä¸¦ä¸”ä¸€é–‹å§‹çš„ source domain feature extractor æ˜¯äº‹å…ˆè¨“ç·´å¥½çš„. ç„¶å¾Œå¾Œé¢çš„ GAN éƒ¨åˆ†è¨“ç·´çš„æ™‚å€™, target domain çš„ feature extractor è¦å»åŒ¹é… source domain çš„. é€™æ¨£åšçš„å¥½è™•æ˜¯è‡³å°‘ä¸€é‚Šçš„åˆ†ä½ˆæ˜¯å›ºå®šä½çš„, æ¯”è¼ƒå®¹æ˜“è¨“ç·´. åŒæ™‚ä¹Ÿç°¡åŒ–äº†è¨“ç·´æµç¨‹, è¦‹ä¸‹åœ–: infoGANè©³ç´°å°±ä¸è§£é‡‹äº†, äº‹å¯¦ä¸Šæ¨å°è¼ƒè¤‡é›œä½†å¯¦ä½œä¸Šå»ç•°å¸¸å®¹æ˜“, ä¹‹å¾Œæœ‰æ©Ÿæœƒå†è¨˜éŒ„ä¸€ä¸‹. ç¸½ä¹‹åœ¨åŸå§‹ GAN æ¶æ§‹ä¸Šå¤šäº†ä¸€å€‹ Decoder, ç”¨ä¾†é‚„åŸ generator input ä¸­æ‰€æŒ‡å®šçš„éƒ¨åˆ†($c$). Decoder å¸Œæœ›èƒ½å°‡ $c$ ç„¡æçš„é‚„åŸ, é‚£éº¼ä»€éº¼å«ç„¡æ? æŒ‡çš„å°±æ˜¯ Mutual Information of $c$ and $\\hat{c}$ æœ€å¤§. å…¶ä¸­ $\\hat{c}$ è¡¨ç¤ºç”± Decoder é‚„åŸå‡ºä¾†çš„çµæœ. é‚„åŸçš„ loss term åŸºæœ¬å°±æ˜¯ $reg(G)$, åŒæ¨£çš„ç†è§£, $G$ é™¤äº†è¦é¨™é $D$ ä¹‹å¤–, å¤šäº†ä¸€å€‹ä»»å‹™å°±æ˜¯ä½¿å¾—é‚„åŸçš„ loss æ„ˆå°æ„ˆå¥½. é™„ä¸Šæå®æ¯…æ•™æˆèª²ç¨‹çš„å…©å¼µåœ–ç‰‡: VAE-GANç›´æ¥ä¸Šè€å¸«çš„ slides ä»¥ GAN çš„è§’åº¦ä¾†çœ‹, $G$ é™¤äº†è¦æ¬ºé¨™ $D$ ä¹‹å¤–, é‚„å¤šäº† VAE çš„ loss ($reg(G)$) ç”¨ä¾† reconstruct åŸæœ¬çš„ input image. å° GAN ä¾†èªªæ˜¯æœ‰å¥½è™•çš„, å› ç‚º GAN é›–ç„¶èƒ½å¤ ç”¢ç”Ÿå¤ çœŸçš„ image, ä½†æ˜¯æœƒè‡ªå·±â€æé€ â€, å› æ­¤å¤šäº† VAE çš„ $reg(G)$ æœƒè®“æé€ çš„æƒ…æ³é™ä½. ä»¥ VAE çš„è§’åº¦ä¾†çœ‹, GAN çš„ loss è®Šæˆäº† regularization term äº†. ä¹Ÿå°±æ˜¯èªª VAE é™¤äº†è¦ç”¢ç”Ÿè·ŸåŸæœ¬æ¥è¿‘çš„ image (pixel-level), é‚„è¦èƒ½é¨™é $D$. é€™æ˜¯ç‚ºäº†è£œè¶³ VAE çš„ç¼ºé», åŸå§‹ VAE çš„ç›®æ¨™å‡½å¼æ˜¯ pixel-level çš„ l2-norm, é€™è·Ÿäººé¡èªç‚ºçš„çœŸå¯¦ä¸çœŸå¯¦ä¸ä¸€è‡´, å› æ­¤ AVE æœƒç”¢ç”Ÿæ¨¡ç³Šçš„ image. ç”¨ GAN çš„ loss ç•¶æˆ regularization term å‰‡è£œè¶³äº† VAE é€™é». å› æ­¤ VAE-GAN é€™æ˜¯å€‹äº’æƒ çš„çµæ§‹, å¾ˆæ¼‚äº®. é€™å€‹çµæ§‹æ–°çš„ä¸€ç¯‡ Adversarial Latent Autoencoders ç²—ç•¥è¬›ä¹Ÿæ˜¯ VAE-GAN æ¶æ§‹, åªæ˜¯ reconstruction ä¸æ˜¯å† image, è€Œæ˜¯åœ¨ latent space. è«–æ–‡çµæœååˆ†é©šè‰·, github. çµè«–æœ¬ç¯‡é–‹é ­èªªæ˜çš„ framework åŸºæœ¬å¯ä»¥è§£é‡‹äº†ä¸Šè¿°å„ç¨® GAN. ä½†ç”±æ–¼æœ¬é­¯æ‰ç–å­¸æ·º, é‚„æœ‰ä¸€å¤§å †æ²’çœ‹çš„è®Šç¨®, EBGAN, BEGAN, CycleGAN, â€¦etc. åªèƒ½èªªä¹‹å¾Œè®€åˆ°çš„æ™‚å€™, çœ‹çœ‹èƒ½å¦è©¦è‘—é€™éº¼è§£é‡‹. GAN å¯¦åœ¨å¤ªå¤šäº†, å¯ä»¥çœ‹çœ‹ GAN Zoo æœ‰å¤šå°‘ç”¨ GAN ä¾†å‘½åçš„æ¶æ§‹(ä¼¼ä¹åœæ­¢æ›´æ–°). Reference æå®æ¯…GAN f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization ä»¤äººæ‹æ¡ˆå«ç»çš„Wasserstein GAN WGANç­†è¨˜ Wasserstein GAN and the Kantorovich-Rubinstein Duality Spectral Normalization for Generative Adversarial Networks GANè®ºæ–‡é˜…è¯»ç¬”è®°3ï¼šWGANçš„å„ç§å˜ä½“ by æ—å°åŒ— InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets Domain-Adversarial Training of Neural Networks Advesarial Discriminative Domain Adaptation Autoencoding beyond pixels using a learned similarity metric Adversarial Latent Autoencoders","tags":[{"name":"GAN","slug":"GAN","permalink":"https://bobondemon.github.io/tags/GAN/"},{"name":"ADDA","slug":"ADDA","permalink":"https://bobondemon.github.io/tags/ADDA/"},{"name":"Generative Model","slug":"Generative-Model","permalink":"https://bobondemon.github.io/tags/Generative-Model/"},{"name":"fGAN","slug":"fGAN","permalink":"https://bobondemon.github.io/tags/fGAN/"},{"name":"WGAN","slug":"WGAN","permalink":"https://bobondemon.github.io/tags/WGAN/"},{"name":"infoGAN","slug":"infoGAN","permalink":"https://bobondemon.github.io/tags/infoGAN/"},{"name":"VAE-GAN","slug":"VAE-GAN","permalink":"https://bobondemon.github.io/tags/VAE-GAN/"}]},{"title":"Notes for (conditional/cross-)Entropy, Mutual-information, ...","date":"2020-05-02T03:37:12.000Z","path":"2020/05/02/Notes-for-conditional-cross-Entropy-Mutual-information/","text":"æ•´ç†ä¸‹ entropy çš„ä¸€äº›æ±è¥¿, ä¸ç„¶ä¹…æ²’çœ‹è€æ˜¯å¿˜è¨˜. Entropy of a r.v. $X$: $H(X)$ Conditional Entropy of $Y$ given $X$: $H(Y|X)$ Cross(Relative) Entropy of two pdf, $p$ and $q$: $D(p\\Vert q)$ Mutual Information of two r.v.s: $I(X;Y)$ æ–‡ç« æœƒæ˜ç¢ºå®šç¾©æ¯ä¸€é …, ç„¶å¾Œåœ¨æ¨å°å®ƒå€‘ä¹‹é–“é—œä¿‚çš„åŒæ™‚æœƒè§£é‡‹å…¶ç‰©ç†æ„ç¾©. æœ€å¾Œå…¶å¯¦å°±å¯ä»¥æ•´ç†æˆé¡ä¼¼é›†åˆé—œä¿‚çš„åœ– (wiki) Entropy$$\\begin{align} H(X) = \\sum_{x\\in X}{p(x)\\log{\\frac{1}{p(x)}}} \\end{align}$$ ä¸€å€‹ r.v. $X$ å‡è¨­é…çµ¦ä»–çš„ pdf ç‚º $p$, å‰‡å¯ä»¥ç®—å‡ºç›¸å°æ‡‰çš„ entropy $H(X)$, æ‰€ä»¥æˆ‘å€‘å…¶å¯¦å¯ä»¥çœ‹æˆæ˜¯ $H(p)$.å¯ä»¥çŸ¥é“ç•¶ $p$ æ˜¯ uniform distribution æ™‚ entropy é”åˆ°æœ€å¤§ (å¾Œé¢å†è­‰æ˜). åŒæ™‚è©²å®šç¾©å¯ä»¥å¾ˆå®¹æ˜“çœ‹å‡º $H(X)\\geq 0$. ç›´è§€è§£é‡‹: å› ç‚º uniform distribution æ™‚æœ€å¤§ (æœ€ç„¡æ³•ç¢ºå®šå“ªä¸€å€‹ outcome æœ€æœ‰å¯èƒ½), å¦ä¸€å€‹æ¥µç«¯ç‚º $X$ ç‚º constant (r.v. åªæœ‰ä¸€å€‹ outcome) æ‰€ä»¥æˆ‘å€‘å¯ä»¥ç†è§£ç‚º entropy ç‚ºé‡æ¸¬ä¸€å€‹ r.v. $X$ çš„ä¸ç¢ºå®šæ€§ å¦‚æœè¦å°æ¯ä¸€å€‹ outcome æ±ºå®šè¦ç”¨å¤šå°‘ bit ä¾†ä»£è¡¨, æˆ‘å€‘å¸Œæœ›å¹³å‡èŠ±çš„ bits æ•¸èƒ½æœ€å°, ç›´è§€ä¸Šæ©Ÿç‡æ„ˆå¤§çš„ outcome ç”¨æ„ˆå°çš„ bits ä¾†è¡¨é”. å› æ­¤ outcome $x_i$ æˆ‘å€‘ç”¨ $\\log{\\frac{1}{p(x_i)}}$ é€™éº¼å¤š bits è¡¨ç¤º, å‰‡ entropy ä»£è¡¨äº† encode æ‰€æœ‰ outcome æ‰€éœ€è¦çš„å¹³å‡ bits æ•¸, å‰‡é€™å€‹æ•¸æ˜¯æœ€å°çš„. (é€™å¯ä»¥å¾ä¸‹é¢çš„ cross entropy å¾—åˆ°è­‰æ˜) æˆ‘å€‘å¯ä»¥ç”¨ entropy ä¾†è¡¨ç¤ºè©² r.v. æ‰€åŒ…å«çš„è³‡è¨Šé‡. å› ç‚ºæ¯” entropy æ›´å¤šçš„è³‡è¨Šé‡éƒ½æ˜¯ reduandant çš„ (ç”±ä¸Šä¸€é»å¯çœ‹å‡º) ç‚ºäº†æ–¹ä¾¿æˆ‘å€‘æœƒäº¤å‰ä½¿ç”¨ è³‡è¨Šé‡ æˆ–æ˜¯ encode çš„æœ€å°å¹³å‡ bits æ•¸ ä¾†è¡¨ç¤º entropy çš„ç‰©ç†æ„ç¾©. Cross(Relative) Entropyç‚ºé‡æ¸¬å…©å€‹ pdfs, $p(x)$ and $q(x)$ ä¹‹é–“çš„ â€œdivergenceâ€, ä¹Ÿç¨±ç‚º KL divergence. æ³¨æ„ divergence ä¸éœ€æ»¿è¶³ä¸‰è§’ä¸ç­‰å¼ä¹Ÿä¸éœ€æ»¿è¶³å°ç¨±æ€§, å› æ­¤ä¸æ˜¯ä¸€å€‹ â€œmetricâ€. ä½†ä¹Ÿè¶³å¤ ç•¶æˆæ˜¯æŸç¨®â€è·é›¢â€ä¾†çœ‹å¾… (ä¸æ˜¯æŒ‡æ•¸å­¸ä¸Šçš„ norm) $$\\begin{align} D(p\\Vert q) = \\sum_x{p(x)\\log{\\frac{p(x)}{q(x)}}} \\end{align}$$ ç”± Jensenâ€™s inequality å¯ä»¥æ¨å¾— $D(p\\Vert q) \\geq 0$, å¦å¤– $D(p\\Vert q)=0$ iff $p=q$ $$\\begin{align} D(p\\Vert q) = - \\sum_x{p(x)\\log{\\frac{q(x)}{p(x)}}} \\\\ \\text{by Jensen&apos;s inequality: } \\geq \\log\\sum_x{p(x)\\frac{q(x)}{p(x)}} = 0 \\end{align}$$ é‡å¯«ä¸€ä¸‹ (2):$$\\begin{align} 0\\leq D(p\\Vert q) = \\sum_x{p(x)\\log{\\frac{1}{q(x)}}} - H(p) \\end{align}$$ é€™èªªæ˜äº†å°æ–¼ outcome $x_i$ (true distribution ç‚º $p(x)$) æˆ‘å€‘ç”¨ $\\log{\\frac{1}{\\color{red}{q}(x_i)}}$ é€™éº¼å¤š bits è¡¨ç¤ºæ˜¯æµªè²»çš„. æ‰€ä»¥è­‰æ˜äº†ä¸Šé¢ Entropy ç¬¬äºŒç¨®è§£é‡‹. ç›´è§€è§£é‡‹: $D(p\\Vert q)$ è¡¨ç¤ºä½¿ç”¨éŒ¯èª¤çš„ distribution $q$ ä¾† encode è¦å¤šèŠ±çš„å¹³å‡ bits æ•¸é‡ Conditional Entropy$$\\begin{align} H(Y|X) = \\sum_{x\\in X}{p(x)H(Y|x=X)} \\\\ =\\sum_x{p(x)\\sum_y{p(y|x)\\log{\\frac{1}{p(y|x)}}}} \\end{align}$$ $H(Y|x=X)$ è§£é‡‹ç‚º given $x$ encode $Y$ çš„æœ€å°å¹³å‡ bits æ•¸ (å°±æ˜¯ entropy åªæ˜¯åˆé‡è¤‡èªªäº†ä¸€æ¬¡), ä½†æ˜¯æ¯ä¸€å€‹ $x$ æœ‰è‡ªå·±çš„æ©Ÿç‡, å› æ­¤å° $x$ å†å–ä¸€æ¬¡å¹³å‡. case 1:å¦‚æœ $Y$ å®Œå…¨å¯ä»¥ç”± $X$ æ±ºå®š, å› æ­¤ä¸€æ—¦çµ¦å®š $x$, $Y$ å°±æ˜¯ä¸€å€‹ constant, æ‰€ä»¥ $H(Y|x=X)=0$. å†å° $X$ ç®—æœŸæœ›å€¼ä»ç„¶æ˜¯ 0. case 2:å¦‚æœ $X$ and $Y$ independent. $$\\begin{align} (7)=\\sum_x{p(x)\\sum_y{p(y)\\log{\\frac{1}{p(y)}}}}=\\sum_x{p(x)H(Y)}=H(Y) \\end{align}$$ å¾—åˆ°çµè«– $H(Y|X)=H(Y)$ Case 1 and 2 èªªæ˜äº† $X$ and $Y$ åœ¨å®Œå…¨ä¾è³´å’Œå®Œå…¨ç„¡é—œæ™‚ $H(Y|X)$ åˆ†åˆ¥ç‚º $0$ and $H(Y)$. ç›´è¦ºä¸Šæˆ‘å€‘å¯ä»¥èªç‚º $0\\leq H(Y|X) \\leq H(Y)$, å› ç‚ºå‰›å¥½æ˜¯å…©å€‹æ¥µç«¯æƒ…å½¢. ä½†ç›´è¦ºæ˜¯ä¸å¤ çš„, æˆ‘å€‘è­‰æ˜ä¸€ä¸‹. ä½¿ç”¨å®šç¾©, æˆ‘å€‘å¯ä»¥å¾ˆå®¹æ˜“æ¨å°å‡º $$\\begin{align} \\color{orange}{I(X;Y)\\equiv}H(Y)-H(Y|X)=\\sum_{x,y}{p(x,y)\\log{\\frac{p(x,y)}{p(x)p(y)}}} \\\\ =D(p(x,y)\\Vert p(x)p(y)) \\geq 0 \\end{align}$$ æˆ‘å€‘é€™è£¡å…ˆå·è·‘å‡ºäº† mutual information $I(X;Y)$ çš„å®šç¾©, ä¸‹é¢æœƒå†è©³ç´°è¬›. ç›´è§€è§£é‡‹:$H(Y|X)$ è¡¨ç¤ºçµ¦äº† $X$ çš„è³‡è¨Šå¾Œ, $Y$ å‰©ä¸‹çš„è³‡è¨Šé‡. å…¶ä¸­ $0\\leq H(Y|X) \\leq H(Y)$ Chain Rule for Entropyæˆ‘å€‘åœ¨æŠŠ (7) åšå€‹é‹ç®—: $$\\begin{align} H(Y|X)=(7)=-\\sum_x{p(x)\\sum_y{p(y|x)\\log{p(y|x)}}} \\\\ =-\\sum_{x,y}{p(x,y)\\log{\\frac{p(x,y)}{p(x)}}} \\\\ =-\\sum_{x,y}{p(x,y)\\log{p(x,y)}}+\\sum_{x,y}{p(x,y)\\log{p(x)}} \\\\ =H(X,Y) - H(X) \\end{align}$$ ç›´è§€è§£é‡‹:çµ¦å®š $X$ å¾Œ $Y$ å‰©ä¸‹çš„è³‡è¨Šé‡ ($H(Y|X)$) å°±ç­‰æ–¼ $X,Y$ æ•´é«”çš„è³‡è¨Šé‡æ‰£æ‰å–®ç¨ $X$ éƒ¨åˆ†çš„è³‡è¨Šé‡ Mutual Information(9) å·²ç¶“å…ˆçµ¦å‡ºäº†å®šç¾©, æˆ‘å€‘é€™è£¡é‡è¤‡ä¸€æ¬¡: $$\\begin{align} I(X;Y)\\equiv\\sum_{x,y}{p(x,y)\\log{\\frac{p(x,y)}{p(x)p(y)}}} =D(p(x,y)\\Vert p(x)p(y))\\\\ \\text{(ç”¨ entropy å®šç¾©å¾—åˆ°) }=H(Y)-H(Y|X) \\\\ \\text{(ç”¨ entropy å®šç¾©å¾—åˆ°) }=H(X)-H(X|Y) \\end{align}$$ åœ¨ç”¨ Chain Rule for Entropy: $H(Y)=H(X,Y)-H(X|Y)$ ä»£é€² (16) å¾—åˆ° $$\\begin{align} I(X;Y)=H(X,Y)-H(Y|X)-H(X|Y) \\end{align}$$ æˆ‘çŸ¥é“é€™éº¼å¤šå¼å­ä¸€å®šçœ¼èŠ±äº†â€¦.å¥½åœ¨å®Œå…¨å¯ä»¥ç”¨é›†åˆçš„ Venn diagram è¡¨ç¤º! æ‰€æœ‰å¼å­çš„ç›´è§€è¡¨é” Reference wiki mutual information Dr. Yao Xie, ECE587, Information Theory, Duke University æœ¬ç¯‡å…§å®¹åªæ˜¯ lecture 1 ~ 4 çš„ç¯„åœ","tags":[{"name":"Entropy","slug":"Entropy","permalink":"https://bobondemon.github.io/tags/Entropy/"},{"name":"Conditional Entropy","slug":"Conditional-Entropy","permalink":"https://bobondemon.github.io/tags/Conditional-Entropy/"},{"name":"Cross Entropy","slug":"Cross-Entropy","permalink":"https://bobondemon.github.io/tags/Cross-Entropy/"},{"name":"Mutual Information","slug":"Mutual-Information","permalink":"https://bobondemon.github.io/tags/Mutual-Information/"}]},{"title":"Determinant of Covariance Matrix","date":"2019-07-15T13:41:13.000Z","path":"2019/07/15/Determinant-of-Covariance-Matrix/","text":"ç­†è¨˜ covariance matrix $R$ çš„ determinant æ„ç¾©ä»¥åŠä»–çš„ bound. é€™æ˜¯åœ¨è®€ Time-delay estimation via linear interpolation and cross correlation æ™‚çš„ appendix è­‰æ˜. è¦ºå¾—æœ‰ç”¨å°±ç­†è¨˜ä¸‹ä¾†. é–‹é–€è¦‹å±±, $det(R)$ å¯ä»¥æƒ³æˆ volumn (ç­‰æ–¼æ‰€æœ‰ eigenvalues ç›¸ä¹˜), ç„¶å¾Œ upper bound å°±æ˜¯æ‰€æœ‰å°è§’é …å…ƒç´ ç›¸ä¹˜. $$\\begin{align} det(R)=\\prod_i \\lambda_i \\leq \\prod_i r_{ii} \\end{align}$$ $\\lambda_i$ æ˜¯ i-th eingenvalue. äº‹å¯¦ä¸Šåªè¦ $R$ æ˜¯ square matrix, å‰‡ $|det(R)|$ ç­‰æ–¼ç”¨æ¯å€‹ row vector åšå‡ºä¾†çš„ â€œå¹³è¡Œå…­é¢é«”â€ çš„é«”ç© [ref] ä»¥ä¸‹ç­†è¨˜è«–æ–‡ä¸­è­‰æ˜ $det(R)$ çš„ upper bound, å¾é€™å€‹ bound æˆ‘å€‘ä¹Ÿèƒ½çœ‹å‡ºç‰©ç†æ„ç¾©. Upper bound of the determinant of positive definite matrix[Theorem]: ä»¤ $H$ ç‚º $L$ by $L$ æ­£å®šçŸ©é™£, å‰‡$$\\begin{align} det(H) \\leq \\prod_{i=1}^{L} h_{ii} \\end{align}$$ [Proof]:å…ˆå°‡ $H$ ä½œå¦‚ä¸‹æ‹†è§£$$\\begin{align} H=\\left( \\begin{array}{cc} \\tilde{H} &amp; h \\\\ h^T &amp; h_{LL} \\end{array} \\right) \\end{align}$$ å…¶ä¸­ $\\tilde{H}$ æ˜¯ $L-1$ by $L-1$ çŸ©é™£.å¾ Determinant of block matrices æˆ‘å€‘çŸ¥é“:$$\\begin{align} det(H)=det(\\tilde{H})(h_{LL}-h^T \\tilde{H}^{-1}h) \\end{align}$$ å› ç‚º $H$ æ˜¯æ­£å®š, æ‰€ä»¥ $\\tilde{H}$ ä¹Ÿæ˜¯æ­£å®š, åŒ…å«å…¶ inverse Every principal submatrix of a positive definite matrix is positive definite. æ­£å®šçš„ $det&gt;0$, ä»¥åŠæ­£å®šçš„äºŒæ¬¡å¼ $&gt;0$, å¸¶å…¥åˆ° (4) å°±ä¸é›£ç™¼ç¾$$\\begin{align} det(H)\\leq h_{LL}det(\\tilde{H}) \\end{align}$$ é‡è¤‡æ­¤æ­¥é©Ÿå°±èƒ½æ¨å°å‡º (2) Determinant of covariance matrixæˆ‘å€‘çŸ¥é“ covariance matrix $R$ æ˜¯æ­£å®š (åš´æ ¼ä¸Šç‚ºåŠæ­£å®š, å¦‚æœæ²’æœ‰å…©å€‹å®Œå…¨ linear depedent çš„ç¶­åº¦çš„è©±, å°±æ˜¯æ­£å®š), å› æ­¤ç¬¦åˆ upper bound (2). è§€å¯Ÿç•¶ coordinate ä¹‹é–“ç‚º independent æ™‚, è¡¨ç¤ºéå°è§’é …éƒ½æ˜¯ $0$, åªå‰©ä¸‹å°è§’é … (æ¯å€‹ç¶­åº¦çš„ variance). é€™æ™‚ (2) çš„ä¸ç­‰å¼è®Šæˆç­‰å¼, å°è§’é …ç›¸ä¹˜æ„ç¾©ç›¸ç•¶æ–¼ç®— volumn å¯ä»¥çœ‹å‡ºå…©é»çµè«– covariance matrix å°è§’é …çš„ç›¸ä¹˜ç¸½æ˜¯æœƒæ¯” $det$ å¤§ coordinate ä¹‹é–“æ˜¯ independent å‰‡ covariance matrix å°è§’é …çš„ç›¸ä¹˜æœƒç­‰æ–¼ $det$ Correlation matrixæˆ‘å€‘çŸ¥é“ correlation matrix å°è§’é …éƒ½æ˜¯ $1$, ä¸”æ˜¯æ­£å®šæ ¹æ“šä»¥ä¸Šçš„è¨è«–çŸ¥é“:$$\\begin{align} 0\\leq det(\\mbox{corr}(X))\\leq 1 \\end{align}$$ Take Home Messagesä»¤ $R$ ç‚º covariance matrix, $\\tilde{R}$ æ˜¯ correlation matrix $R$ å°è§’é …çš„ç›¸ä¹˜ç¸½æ˜¯æœƒæ¯” $det(R)$ å¤§ coordinate ä¹‹é–“æ˜¯ independent å‰‡ $R$ å°è§’é …çš„ç›¸ä¹˜ç­‰æ–¼ $det(R)$ $det(\\tilde{R})$ åœ¨ 0 å’Œ 1 ä¹‹é–“ (åŒ…å«) ä»¤ $A$ ç‚º square matrix, å‰‡ $|det(A)|$ ç­‰æ–¼ä»¥æ¯å€‹ row vector åšå‡ºä¾†çš„ â€œå¹³è¡Œå…­é¢é«”â€ çš„é«”ç© [ref] Reference Time-delay estimation via linear interpolation and cross correlation Determinants and Volumes","tags":[{"name":"Covariance matrix","slug":"Covariance-matrix","permalink":"https://bobondemon.github.io/tags/Covariance-matrix/"},{"name":"Correlation matrix","slug":"Correlation-matrix","permalink":"https://bobondemon.github.io/tags/Correlation-matrix/"},{"name":"determinant","slug":"determinant","permalink":"https://bobondemon.github.io/tags/determinant/"}]},{"title":"TF Notes (6), Candidate Sampling, Sampled Softmax Loss","date":"2019-07-02T12:34:12.000Z","path":"2019/07/02/TF-Notes-Candidate-Sampling/","text":"NN åšåˆ†é¡æœ€å¾Œä¸€å±¤é€šå¸¸ä½¿ç”¨ softmax loss, ä½†å¦‚æœé¡åˆ¥æ•¸é‡å¾ˆå¤§æœƒå°è‡´è¨ˆç®— softmax çš„ cost å¤ªé«˜, é€™æ¨£æœƒè®“è¨“ç·´è®Šå¾—å¾ˆæ…¢. å‡å¦‚ç¸½å…±çš„ class æ•¸é‡æ˜¯ 10000 å€‹, candidate sampling çš„æƒ³æ³•å°±æ˜¯å°æ–¼ä¸€å€‹ input $x$ æ¡æ¨£å‡ºä¸€å€‹ subset (ç•¶ç„¶éœ€è¦åŒ…å«æ­£ç¢ºçš„ label), è­¬å¦‚åªç”¨ 50 å€‹ classes, æ‰£æ‰æ­£ç¢ºçš„é‚£å€‹ class, å‰©ä¸‹çš„ 49 å€‹ classes å¾ 9999 å€‹æ¡æ¨£å‡ºä¾†. ç„¶å¾Œè¨ˆç®— softmax åªåœ¨é‚£ 50 å€‹è¨ˆç®—. é‚£éº¼å•é¡Œä¾†äº†, é€™æ¨£çš„æ¡æ¨£æ–¹å¼æœ€çµ‚è¨“ç·´å‡ºä¾†çš„ logits æœƒæ˜¯å°çš„å—? å®ƒèˆ‡æœªæ¡æ¨£å‰ (full set) çš„ logtis æœ‰ä½•å°æ‡‰é—œä¿‚? æ¡ç”¨ candidate sampling æ–¹å¼çš„ softmax loss åœ¨ tensorflow ä¸­å·²ç¶“ç›´æ¥æœ‰ op äº†, åƒè€ƒ tf.nn.sampled_softmax_loss. æ–‡æª”è£¡æœ€çµ‚æ¨å°å¾—åˆ°å¦‚ä¸‹çš„ä¸€å€‹å¼å­: $$\\begin{align} \\log(P(y|x_i,C_i))=\\log(P(y|x_i))-\\log(Q(y|x_i))+K&apos;(x_i,C_i) \\end{align}$$ æ¨å°éç¨‹è‡ªè¡Œçœ‹æ–‡æª”å°±å¯ä»¥, é‡è¦çš„æ˜¯äº†è§£å¼å­çš„ç‰©ç†æ„ç¾©.$C_i$ æ˜¯å° input $x_i$ æ¡æ¨£å‡ºçš„ subset, åŒ…å«äº† ä¸€å€‹æ­£ç¢ºçš„é¡åˆ¥æ¨™ç±¤ å’Œ å…¶ä»–æ¡æ¨£å‡ºçš„é¡åˆ¥ $S_i$. $Q(y|x_i)$ æ˜¯åŸºæ–¼ input $x_i$, label $y$ è¢«é¸ä¸­æˆç‚º $S_i$ çš„æ©Ÿç‡. $Kâ€™$ æ˜¯è·Ÿ $y$ ç„¡é—œçš„, æ‰€ä»¥å°æ–¼å¼å­ä¾†èªªæ˜¯ constant. æ³¨æ„åˆ°å¼å­çš„è®Šæ•¸æ˜¯ $y$ ä»£è¡¨äº†æ˜¯ softmax çš„å“ªä¸€å€‹ output node. å¼ (1) çš„è§£é‡‹ç‚º: â€œåœ¨ candidate set $C_i$ ä¸‹çš„ logits çµæœâ€ ç­‰æ–¼ â€œåœ¨ full set ä¸‹çš„ logtis çµæœæ¸›å» $\\log Q(y|x_i)$â€, $Kâ€™$ æœƒç›´æ¥è¢« $\\log P(y|x_i)$ å¸æ”¶, å› ç‚º logits åŠ ä¸Š constant å°æ–¼ softmax ä¾†èªªæœƒåˆ†å­åˆ†æ¯æ¶ˆæ‰, æ‰€ä»¥ä¸å½±éŸ¿. ä»¥ä¸‹æˆ‘å€‘é †ä¾¿è¤‡ç¿’ä¸€ä¸‹, ç‚ºä»€éº¼ logits å¯ä»¥å¯«æˆ â€œ$\\mbox{const}+\\log P(y|x)$â€ é€™ç¨®å½¢å¼. (åŒ…å«è¤‡ç¿’ Entropy, cross-entropy, softmax loss) Entropy å®šç¾©$$\\begin{align} \\sum_i{q(x_i)\\log{\\frac{1}{q(x_i)}}} \\end{align}$$ å°æ–¼ input $x_i$, å…¶æ©Ÿç‡ç‚º $q(x_i)$, è‹¥æˆ‘å€‘ä½¿ç”¨ $\\log{\\frac{1}{q(x_i)}}$ é€™éº¼å¤š bits çš„æ•¸é‡ä¾† encode å®ƒçš„è©±, å‰‡ä¸Šé¢çš„ entropy ä»£è¡¨äº† encode æ‰€æœ‰ input æ‰€éœ€è¦çš„å¹³å‡ bits æ•¸, è€Œé€™å€‹æ•¸æ˜¯æœ€å°çš„. ç”¨éŒ¯èª¤çš„ encoding æ–¹å¼æˆ‘å€‘å‡è¨­ç”¨ $\\log{\\frac{1}{p(x_i)}}$ é€™éº¼å¤š bits çš„æ•¸é‡ä¾† encode çš„è©±, å‰‡å¹³å‡ encode bits æ•¸ç‚º: $$\\begin{align} \\sum_i{q(x_i)\\log{\\frac{1}{p(x_i)}}} \\end{align}$$ é€™å€‹æ•¸é‡ä¸€å®šæœƒæ¯” entropy ä¾†çš„å¤§, è€Œå¤§å‡ºä¾†çš„å€¼å°±æ˜¯æˆ‘å€‘ä½¿ç”¨éŒ¯èª¤çš„ encoding é€ æˆçš„ä»£åƒ¹ (cross-entropoy). Cross-entropyå¦‚ä¸Šé¢æ‰€èªª, éŒ¯èª¤çš„ encoding æ–¹å¼é€ æˆçš„ä»£åƒ¹å¦‚ä¸‹: $$\\begin{align} \\mbox{Xent}(p,q)\\triangleq\\sum_i{q(x_i)\\log{\\frac{1}{p(x_i)}}} - \\sum_i{q(x_i)\\log{\\frac{1}{q(x_i)}}} \\\\ =\\sum_i{q(x_i)\\log{\\frac{q(x_i)}{p(x_i)}}} \\\\ \\end{align}$$ Sparse softmax lossæœ€å¸¸è¦‹çš„æƒ…å½¢ç‚ºç•¶åªæœ‰ $q(x_j)=1$ è€Œå…¶ä»– $x\\neq x_j$ æ™‚ $q(x)=0$ çš„è©± ($q$ è®Šæˆ one-hot), ä¸Šé¢çš„ corss-entropy è®Šæˆ: $$\\begin{align} \\mbox{SparseSoftmaxLoss}\\triangleq\\mbox{Xent}(p,q\\mbox{ is one-hot})=-\\log p(x_j) \\\\ =-\\log\\frac{e^{z_j}}{\\sum_i{e^{z_i}}}=-\\log e^{z_j} + \\log\\sum_i{e^{z_i}} \\\\ =-z_j + \\log\\sum_i{e^{z_i}} \\end{align}$$ å…¶ä¸­ $z_i$ è¡¨ç¤º i-th logtis, åƒè€ƒ tf.nn.sparse_softmax_cross_entropy_with_logits Logits çš„è§£é‡‹j-th logtis $z_j$ å¯è§£é‡‹ç‚º â€œconst + class $j$ çš„ log probabilityâ€. $$\\begin{align} z_j = \\mbox{cosnt} + \\log p(j) \\end{align}$$ ç‚ºä»€éº¼å‘¢? é€™æ˜¯å› ç‚º logtis ç¶“é softmax å¾Œæœƒè®Šæˆæ©Ÿç‡, æˆ‘å€‘å‡è¨­ç¶“é softmax å¾Œ node $j$ çš„æ©Ÿç‡ç‚º $pâ€™(j)$, è¨ˆç®—ä¸€ä¸‹é€™å€‹å€¼: $$\\begin{align} p&apos;(j)=\\frac{e^{z_j}}{\\sum_i e^{z_i}} \\\\ =\\frac{e^{\\log p(j)}e^{\\mbox{const}}}{e^{\\mbox{const}}\\sum_i e^{\\log p(i)}} \\\\ =\\frac{p(j)}{\\sum_i p(i)} \\\\ =p(j) \\end{align}$$ é€™æ™‚å€™æˆ‘å€‘å†å›å»å°ç…§é–‹å§‹çš„å¼ (1), å°±èƒ½æ¸…æ¥šçš„è§£é‡‹ candidate sampling çš„ logtis å’Œ full set çš„ logits ä¹‹é–“çš„é—œä¿‚äº†. Sampled softmax lossç”±å¼ (1) æˆ‘å€‘å·²ç¶“çŸ¥é“ candidate sampling çš„ logtis å’Œ full set çš„ logits ä¹‹é–“çš„é—œä¿‚. å› æ­¤åœ¨è¨“ç·´çš„æ™‚å€™, æ­£å¸¸ forward propagation åˆ° logits æ™‚, é€™æ™‚å€™çš„ logits æ˜¯ full set çš„. ä½†ç”±æ–¼æˆ‘å€‘è¨ˆç®— softmax åªæœƒåœ¨ candidate set ä¸Š. å› æ­¤è¦æŠŠ full set logits æ¸›å» $\\log Q(y|x_i)$, æ¸›å®Œå¾Œæ‰æœƒæ˜¯æ­£ç¢ºçš„ candiadtes logits. å°æ–¼ inference éƒ¨åˆ†, å‰‡å®Œå…¨ç…§èˆŠ, å› ç‚ºåŸæœ¬ forward propagation çš„çµæœå°±æ˜¯ full set logits äº†. é€™ä¹Ÿæ˜¯ tf å®˜ç¶²ç¯„ä¾‹é€™éº¼å¯«çš„åŸå› : 123456789101112131415if mode == \"train\": loss = tf.nn.sampled_softmax_loss( weights=weights, biases=biases, labels=labels, inputs=inputs, ..., partition_strategy=\"div\")elif mode == \"eval\": logits = tf.matmul(inputs, tf.transpose(weights)) logits = tf.nn.bias_add(logits, biases) labels_one_hot = tf.one_hot(labels, n_classes) loss = tf.nn.softmax_cross_entropy_with_logits( labels=labels_one_hot, logits=logits) Reference tf.nn.sampled_softmax_loss Candidate Sampling tf.nn.sparse_softmax_cross_entropy_with_logits","tags":[{"name":"Entropy","slug":"Entropy","permalink":"https://bobondemon.github.io/tags/Entropy/"},{"name":"Candidate sampling","slug":"Candidate-sampling","permalink":"https://bobondemon.github.io/tags/Candidate-sampling/"},{"name":"Sampled softmax loss","slug":"Sampled-softmax-loss","permalink":"https://bobondemon.github.io/tags/Sampled-softmax-loss/"}]},{"title":"SphereFace Paper Study and Implementation Notes","date":"2019-06-18T13:13:46.000Z","path":"2019/06/18/SphereFace-paper-study-and-implementation-notes/","text":"SphereFace: Deep Hypersphere Embedding for Face Recognition ä½¿å¾—è¨“ç·´å‡ºä¾†çš„ embeddings å¯ä»¥å¾ˆå¥½çš„ä½¿ç”¨ cosine similarity åš verification/identification. å¯ä»¥å…ˆç¶²è·¯ä¸Šæœå°‹ä¸€ä¸‹å…¶ä»–äººçš„ç­†è¨˜å’Œè¨è«–, ç•¶ç„¶ç›´æ¥çœ‹è«–æ–‡æœ€å¥½.ä¸€èˆ¬ä¾†èªªæˆ‘å€‘å°è¨“ç·´é›†çš„æ¯å€‹äººç”¨ classification çš„æ–¹å¼è¨“ç·´å‡º embeddings, ç„¶å¾Œåœ¨æ¸¬è©¦çš„æ™‚å€™å¯ä»¥å°æ¯”å…©å€‹äººçš„ embeddings ä¾†åˆ¤æ–·æ˜¯å¦ç‚ºåŒä¸€å€‹äºº. ä½¿ç”¨ verification ç•¶ä¾‹å­, å¯¦ç”¨ä¸Šæ¸¬è©¦çš„äººä¸æœƒå‡ºç¾åœ¨è¨“ç·´é›†ä¸­, æ­¤æƒ…å½¢ç¨±ç‚º openset è¨­å®š. æ³¨æ„åˆ° embedding æ˜¯ä½¿ç”¨ classification æ–¹å¼è¨“ç·´å‡ºä¾†, ä¹Ÿå°±æ˜¯èªª, å¦‚æœè¨“ç·´é›†æœ‰ 1000 å€‹äºº, æœ€å¾Œä¸€å±¤çš„ softmax å°±æœ‰ 1000 å€‹ nodes. ç„¶å¾Œ embedding ä¸€èˆ¬å– softmax å‰ä¸€å±¤ (å‰å…©å±¤ä¹Ÿå¯).æ¸¬è©¦æ™‚å¸¸è¦‹çš„åšæ³•å°±æ˜¯è¨ˆç®—å…©å€‹ embeddings çš„ cosine similarity, ç›´è§€ä¸Šç›¸åŒçš„äººä»–å€‘çš„ embedding æœƒæ¥è¿‘, å› æ­¤å¤¾è§’å° (cosine å¤§), è€Œä¸åŒçš„äººå¤¾è§’å¤§ (cosine å°).ä½†å•é¡Œä¾†äº†, ç•¶åˆè¨“ç·´ embedding æ™‚ä¸¦æ²’æœ‰é‡å° classification ç”¨å¤¾è§’ä¾†åˆ†é¡, ä¹Ÿå°±ä¸èƒ½ä¿è­‰ softmax loss å°æ–¼ä½¿ç”¨ cosine similarity æ˜¯æœ€æœ‰æ•ˆçš„. Modified softmax loss (M-softmax loss) å’Œ Angular softmax loss (A-softmax loss) å°±èƒ½é‡å°é€™ç¨®æƒ…å½¢ (æ¸¬è©¦æ™‚ä½¿ç”¨ cosine similarity) è¨ˆç®— loss. A-softmax loss æ¯” M-softmax loss æ¢ä»¶æ›´åš´è‹›, é™¤äº†å¸Œæœ›é‡å° angular åšåˆ†é¡å¤–, é‚„å¸Œæœ›åŒä¸€é¡çš„å¤¾è§’èƒ½èšå†ä¸€èµ·, ä¸åŒé¡çš„å¤¾è§’èƒ½ç›¡é‡åˆ†é–‹. ä¸‹é¢å°±èªªæ˜ä¸€ä¸‹ softmax loss, M-softmax loss and A-softmax loss, ç„¶å¾Œä»¥ tensorflow çš„å¯¦ä½œä¾†èªªæ˜ Softmax Losså…¶å¯¦æ²’ä»€éº¼å¥½èªªæ˜çš„, å…¬å¼å¦‚ä¸‹ Decision boundary ä»¥å…©é¡ä¾†çœ‹å¦‚ä¸‹: $$\\begin{align} (W_1 - W_2)x+b_1 - b_2=0 \\end{align}$$ M-Softmax Losså¦‚æœæˆ‘å€‘å°‡ $W_j$ çš„ norm é™åˆ¶ç‚º 1, ä¸”å»æ‰ biases, $b_j=0$, å‰‡åŸä¾†çš„ softmax loss è®Šæˆå¦‚ä¸‹: Decision boundary ä»¥å…©é¡ä¾†çœ‹å¦‚ä¸‹: $$\\begin{align} \\parallel x \\parallel (\\cos \\theta_1 - \\cos \\theta_2)=0 \\Rightarrow \\cos \\theta_1 = \\cos \\theta_2 \\end{align}$$ æˆ‘å€‘å¯ä»¥ç™¼ç¾ decision boundary å®Œå…¨ç”±å¤¾è§’ä¾†æ±ºå®šäº†! è«–æ–‡ä½¿ç”¨ toy example ä¾†èªªæ˜ M-softmax loss é€ æˆçš„ç¾è±¡: A-Softmax Lossä»¥å…©é¡ä¾†èªªæ˜, M-softmax loss å°‡ $x$ åˆ†é¡æˆ class 1 çš„æ¢ä»¶ç‚º $\\cos \\theta_1 &gt; \\cos \\theta_2$, ä¹Ÿå°±æ˜¯ $\\theta_1 &lt; \\theta_2$. A-softmax loss å‰‡è®“é€™å€‹æ¢ä»¶æ›´åš´æ ¼, å®ƒå¸Œæœ› $m$ å€çš„ $\\theta_1$ éƒ½é‚„å°æ–¼ $\\theta_2$, å› æ­¤æ¢ä»¶ç‚º $\\cos m\\theta_1 &gt; \\cos \\theta_2$. è«–æ–‡ä¸­ä»¥å¹¾ä½•çš„æ–¹å¼èªªæ˜å¾ˆæ¸…æ¥š: å› æ­¤ A-softmax loss å¦‚ä¸‹: è«–æ–‡ä½¿ç”¨ toy example ä¾†èªªæ˜ A-softmax loss é€ æˆçš„ç¾è±¡: å¯ä»¥çœ‹åˆ°ç›¸æ¯”æ–¼ M-softmax loss, A-softmax loss æœƒä½¿å¾— margin å¢å¤§ é€™ç¨® within class é è¿‘, between class æ‹‰é å°±å¦‚åŒ LDA çš„æ¦‚å¿µ. A-softmax ä¹Ÿèƒ½é€ æˆé€™ç¨®æ•ˆæœä¸”æ˜¯åœ¨ angular çš„ measure ä¸‹. è€Œå¸¸è¦‹çš„æƒ…å½¢éƒ½æ˜¯é‡å° euclidean distance, ä¾‹å¦‚ä½¿ç”¨ triplet loss (æ¨è–¦é€™ç¯‡ blog èªªæ˜å…·é«”ä¸” tensorflow å¯¦ç¾éå¸¸å²å®³). åŸå‰‡ä¸Šæˆ‘å€‘å¸Œæœ›èˆ‡ class $i$ çš„å¤¾è§’ $\\theta_i$ æ„ˆå°, æ‰€ç®—å‡ºä¾†çš„ logits ä¹Ÿå°±æ˜¯ $\\cos\\theta_i$ è¦æ„ˆå¤§, æ‰€ä»¥æ”¾å¤§ $m$ å€çš„å¤¾è§’æ‰€ç®—å‡ºä¾†çš„ logits, $\\cos m\\theta_i$ å¿…é ˆè¦è®Šå°.ä½†ç”±æ–¼ $\\cos$ æ˜¯ periodic function, ä¸€æ—¦ $m\\theta_i$ è¶…é $2\\pi$ å°±åè€Œå¯èƒ½ä½¿å¾— logits è®Šå¤§, é€™å°±é©å¾—å…¶åäº†. ç²¾ç¢ºä¾†èªª $\\cos m\\theta_i &lt; \\cos\\theta_i$ åªæœƒåœ¨ $\\theta_i$ å±¬æ–¼ $[0,\\pi/m]$ å€é–“ç¯„åœå…§æˆç«‹. å› æ­¤æˆ‘å€‘å¿…é ˆå° A-softmax loss ä½œå¦‚ä¸‹æ”¹å‹•: å…¶ä¸­ $$\\begin{align} \\psi(\\theta)=(-1)^k \\cos(m\\theta)-2k\\\\ \\mbox{where }\\theta\\in[\\frac{k\\pi}{m},\\frac{(k+1)\\pi}{m}]\\mbox{ and }k\\in[0,m-1] \\end{align}$$ æˆ‘å€‘å°‡ $\\psi$ ç•«å‡ºä¾†: å…©å€‹è§€å¯Ÿ: é¦–å…ˆ $\\psi$ çš„ç¢ºæœƒéš¨è‘—è§’åº¦è®Šå¤§è€Œè®Šå°, é€™ç¬¦åˆæˆ‘å€‘è¦çš„ logits çš„è¡Œç‚º. å†ä¾†è¦è¨ˆç®—å‡ºæ­£ç¢ºçš„ $\\psi(\\theta)$ å¿…é ˆè¦å…ˆçŸ¥é“ $k$, ä¹Ÿå°±æ˜¯éœ€è¦çŸ¥é“ $\\theta$ è½åœ¨å“ªå€‹å€é–“æ‰è¡Œ. ç¬¬äºŒé»å¯èƒ½æ¯”è¼ƒæ£˜æ‰‹, æˆ‘å€‘æ€è€ƒä¸€ä¸‹æ€éº¼åœ¨ tensorflow çš„ graph ä¸­å¯¦ç¾ â€¦. hmmâ€¦. å¥½åƒæœ‰é»éº»ç…© Tensorflow Implementation A-softmax Losså…¶å¯¦ç¶²è·¯ä¸Šå°±å¾ˆå¤š tensorflow çš„å¯¦ç¾äº†, ä¸çœ‹é‚„å¥½, ä¸€çœ‹æ‰ç™¼ç¾ A-softmax loss çš„ $\\psi$ å¯¦ç¾æ­¥é©Ÿå¦‚ä¸‹: é€™ä»€éº¼æ“ä½œ?! æ€éº¼è·ŸåŸä¾†ç†è§£çš„ (3) and (4) é•·ç›¸å·®é€™éº¼å¤š! ç¶²è·¯ä¸Šå¹¾ä¹å¤§å®¶éƒ½ç›´æ¥æ‹¿ä¾†ç”¨, ä¹Ÿæ²’ä»€éº¼èªªæ˜. ä¸éæˆ‘å€‘ä»”ç´°åˆ†æä¸€ä¸‹, é‚„æ˜¯èƒ½ç™¼ç¾ç«¯å€ª.é¦–å…ˆæ³¨æ„åˆ°é€™æ¨£çš„å¯¦ç¾æ˜¯åŸºæ–¼ $m=4$ åšçš„. (è«–æ–‡çš„å¯¦é©—æœ€å¾Œåœ¨é€™å€‹è¨­å®šæœ‰ä¸éŒ¯çš„æ•ˆæœ) å› æ­¤å°‡ $m=4$ å¥—å…¥ (3)(4) å¾—: $$\\begin{align} \\psi(\\theta)=(-1)^k \\cos(\\color{red}{4}\\theta)-2k\\\\ \\mbox{where }\\theta\\in[\\frac{k\\pi}{\\color{red}{4}},\\frac{(k+1)\\pi}{\\color{red}{4}}]\\mbox{ and }k\\in[0,\\color{red}{3}] \\end{align}$$ æ¥è‘—æˆ‘å€‘ä½œå¦‚ä¸‹åˆ†æ: ç™¼ç¾ $s3=(-1)^k$ å’Œ $s4=-2k$, å› æ­¤ $$\\begin{align} \\psi(\\theta)=\\color{green}{(-1)^k} \\cos(4\\theta)\\color{blue}{-2k} = \\color{green}{s3}[1-8\\cos^2\\theta +8\\cos^4\\theta]\\color{blue}{+s4} \\end{align}$$ è€Œ $\\cos\\theta$ å‰‡å› ç‚º weights $W$ çš„ norm é™åˆ¶ç‚º 1, æ‰€ä»¥åªéœ€è¦ $Wx$ å†é™¤ä»¥ $x$ çš„ norm å³å¯. åˆ°é€™è£¡æœ€éº»ç…©çš„å¯¦ä½œå•é¡Œåˆ†æå®Œç•¢, ä¾æ¨£ç•«è‘«è˜†ä¹Ÿå¯ä»¥åšå‡º $m=2$, $m=3$. SummaryTake home messages: M-softmax loss ç®—å‡ºä¾†çš„ embeddings åœ¨ test éšæ®µå¯ä»¥ç›´æ¥ç”¨ cosine measure A-softmax loss æ›´é€²ä¸€æ­¥ä½¿å¾—å„é¡åˆ¥ä¹‹é–“çš„è§’åº¦æ‹‰æ›´é–‹, é”åˆ° large margin æ•ˆæœ A-softmax loss å¯¦ä½œä¸Šä¸å¥½è¨“ç·´, å¯ä»¥ä½¿ç”¨è«–æ–‡ä¸­æåˆ°çš„è¨“ç·´æ–¹æ³•, ä¸€é–‹å§‹åå‘åŸä¾†çš„ softmax loss, ç„¶å¾Œæ¼¸æ¼¸åå‘ A-softmax loss M-softmax loss ç°¡å–®å¯¦ç”¨, ç¶“é weight norm = 1 çš„æ¢ä»¶, è«–æ–‡ä¸­èªªæ˜èƒ½å»æ‰ prior åˆ†å¸ƒ Reference SphereFace: Deep Hypersphere Embedding for Face Recognition Blog: Triplet loss","tags":[{"name":"SphereFace","slug":"SphereFace","permalink":"https://bobondemon.github.io/tags/SphereFace/"},{"name":"Angular softmax loss","slug":"Angular-softmax-loss","permalink":"https://bobondemon.github.io/tags/Angular-softmax-loss/"},{"name":"Modified softmax loss","slug":"Modified-softmax-loss","permalink":"https://bobondemon.github.io/tags/Modified-softmax-loss/"}]},{"title":"Adaptive Filters ç°¡ä»‹ (2) Fast Convolution and Frequency Domain","date":"2019-06-08T15:35:35.000Z","path":"2019/06/08/Adaptive-Filters-Notes-2/","text":"ä¸Šä¸€ç¯‡èªªæ˜äº† time domain çš„ adaptive filters, ç”±æ–¼æ˜¯ sample-by-sample è™•ç†, å› æ­¤å¤ªæ…¢äº†ä¸å¯ç”¨, çœŸæ­£å¯ç”¨çš„éƒ½æ˜¯åŸºæ–¼ frequency domain. ä¸éåœ¨æ·±å…¥ä¹‹å‰, ä¸€å®šè¦å…ˆäº†è§£ convolution åœ¨ input ç‚º block-by-block çš„æƒ…æ³ä¸‹å¦‚ä½•åŠ é€Ÿ. æœ¬æ–‡å…§å®¹ä¸»è¦åƒè€ƒ Partitioned convolution algorithms for real-time auralization by Frank Wefers (æ›¸çš„ä»‹ç´¹ååˆ†è©³ç›¡). Convolution åˆ†é¡å¦‚ä¸‹: æˆ‘å€‘å°±é‡å°æœ€å¸¸ä½¿ç”¨çš„æƒ…å½¢ä»‹ç´¹: Input (UP) and Filter (0). é€™æ˜¯å› ç‚ºå¯¦éš›æ‡‰ç”¨ input æ˜¯ infinite length, æ‰€ä»¥éœ€è¦ block-by-block çµ¦å®š, è€Œ filter é€šå¸¸éƒ½æ˜¯ finite length, å¯ä»¥é¸æ“‡ä¸ partition, æˆ– uniformly partitioned ä»¥ä¾¿å¾—åˆ°æ›´ä½çš„å»¶é²æ•ˆæœ. é‡å° block-based input çš„ convolution, æˆ‘å€‘æœ‰å…©ç¨®æ¶æ§‹: OverLap-and-Add (OLA) OverLap-and-Save (OLS) OLAOLA ç›¸å°ä¾†èªªå¾ˆå¥½ç†è§£çš„. æ¯ä¸€å€‹æ–°ä¾†çš„ data block $x_i$ (é•·åº¦ç‚º $M$), éƒ½èˆ‡ filter $h$ (é•·åº¦ç‚º $N$) åš linear convolution, ç”¢ç”Ÿçš„ output $y_i$ (é•·åº¦ç‚º $M+N-1$) é–‹é ­çš„ $N-1$ å€‹çµæœèˆ‡å‰ä¸€å€‹output block é‡ç–Šçš„éƒ¨åˆ†ç–ŠåŠ  (â€œaddâ€), æ‰€ä»¥ç¨± overlap-and-ADD. ç¤ºæ„åœ–å¦‚ä¸‹: OLSOLS å‰‡å¾ output è§’åº¦ä¾†çœ‹. æ ¹æ“šç¾åœ¨çš„ output ä¾†æ±ºå®šéœ€è¦ç”¨åˆ°é‚£äº› input åš linear convolution. èˆ‰ä¾‹ input block $x_i$ é•·åº¦ç‚º $B=3$, filter $h$ é•·åº¦ç‚º $N=4$, å‰‡ output block $y_i$ çš„çµæœå¯ä»¥å¾ä¸‹åœ–ä¾†çœ‹å‡ºä¾†: æ³¨æ„åˆ°, æˆ‘å€‘ä¸€é–‹å§‹å…ˆå°‡ $h$ å³é‚Šè£œä¸Š $B-1=2$ å€‹ $0$, è€Œ input block $x_i$ å·¦é‚Šè£œä¸Š $N-1=3$ å€‹èˆŠçš„ input data. ç›®çš„æ˜¯æŠŠ $x_i$ å’Œ $h$ éƒ½æ¹Šæˆ $B+N-1$ é€™éº¼é•·.å‰‡æˆ‘å€‘å¯ä»¥ç™¼ç¾, é‡å°å¢é•·å¾Œçš„ input and filter åš lineaer convolution, é›–ç„¶æœƒå¾—åˆ°é•·åº¦ç‚º $2*(B+N-1)-1$ çš„ output, ä½†é€™å…¶ä¸­æœ‰ $B$ å€‹çµæœæ˜¯æˆ‘å€‘è¦çš„! å› æ­¤æˆ‘å€‘åªéœ€è¦ â€œsaveâ€ éœ€è¦çš„é€™ $B$ å€‹ output, å…¶ä»–éƒ½ä¸Ÿè¼ƒå³å¯. æ‰€ä»¥ç¨± overlap-and-SAVE. å¦‚ä½•æœ‰æ•ˆç‡çš„åš linear convolution?ä¸ç®¡æ˜¯ OLA æˆ– OLS éƒ½éœ€è¦å°å…©å€‹å›ºå®šé•·åº¦ (é€šå¸¸ä½¿ç”¨ padding $0$ æˆç­‰é•·) çš„ signal åš linear convolution. æ€éº¼æœ‰æ•ˆç‡çš„åš linear convolution å°±è®Šå¾—ååˆ†é‡è¦.æˆ‘å€‘éƒ½çŸ¥é“é »åŸŸçš„ç›¸ä¹˜ç›¸ç•¶æ–¼æ™‚åŸŸçš„ circular convolution. å› æ­¤å¦‚æœèƒ½ç”¨ ciruclar convolution ä¾†åšå‡º linear convolution çš„è©±, æˆ‘å€‘å°±èƒ½è½‰åˆ°é »åŸŸä¸Šå†ç›¸ä¹˜å°±å¯ä»¥äº†.Circular convolution çš„å®šç¾©å¦‚ä¸‹[1], å…¶å¯¦æ¦‚å¿µä¹Ÿå¾ˆå®¹æ˜“: æˆ‘å€‘åªéœ€è¦é©ç•¶åœ° padding zeros, å°±å¯ä»¥ä½¿å¾— padding å¾Œçš„ signals åš circular convolution æœƒç­‰æ–¼åŸä¾†çš„ singals åš linear convolution. å¦‚ä¸‹åœ–[1] å› æ­¤ä½¿ç”¨ FFT-domain çš„ circular convolution ä¾†å¯¦ç¾ fast linear convolution æµç¨‹å¦‚ä¸‹ Fast Conv with OLAåœ¨ OLA æ¶æ§‹ä¸­ä½¿ç”¨ FFT-domain çš„ circular convolution å¦‚ä¸‹: Padding zeros ä¸ç®¡åœ¨å‰é‚„æ˜¯åœ¨å¾Œéƒ½å¯ä»¥, åªè¦æ»¿è¶³ $K=\\geq M+B-1$ é¿å… aliasing å³å¯. Fast Conv with OLSåœ¨ OLS æ¶æ§‹ä¸­ä½¿ç”¨ FFT-domain çš„ circular convolution å¦‚ä¸‹: Input signal ä¸æ˜¯ padding zeros, è€Œæ˜¯åœ¨å·¦é‚Š padding ä¹‹å‰çš„ input è¨Šè™Ÿ (åƒè€ƒæœ¬ç¯‡ä¸Šé¢çš„ OLS æ®µè½), ç”¨é€™æ¨£çš„ padding æ–¹å¼ä¾†çœ‹ circular convolution çš„è©±, æ¯ä¸€æ¬¡æˆ‘å€‘å°± â€œsaveâ€ output çš„æœ€å¾Œ $B$ å€‹çµæœå³å¯. åœ¨å¯¦ä½œä¸Šé€šå¸¸æœƒå°‡ $B=N$, ä¸¦ä¸”è¨­å®š $K=2B=2N$, é€™æ¨£æˆ‘å€‘æ¯ä¸€æ¬¡åªéœ€è¦ä¿ç•™å‰ä¸€æ¬¡çš„ input block, ä¸¦ä¸” padding çµ¦æ–°ä¾†çš„ input block. Frequncy Domain Adaptive FilterFrequency Domain Adaptive Filter (FDAF) è«‹åƒè€ƒ [2], æ•´ç†çš„éå¸¸å¥½, æ‰€ä»¥é€™è£¡å°±ä¸å¤šæè¿°, å®Œå…¨å¯ä»¥ç…§è‘—å¯¦ä½œå‡ºä¾†! æˆ‘å€‘æœƒç™¼ç¾å…¶å¯¦å®ƒæ¡ç”¨çš„æ˜¯æˆ‘å€‘ä¸Šé¢èªªéçš„ Fast Convolution with OLS æ¶æ§‹, åªæ˜¯ filter å¿…é ˆ adaptive æ›´æ–°. ä»¥ä¸‹æ˜¯ python implementation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# In the frequency domain methods, notations are defined as:# x: reference signal, [-1, 1]# d: desired signal, [-1, 1]# step_size: step size# alpha: the alpha filter for tracking the energy for each bin# w: the retruned filter# e: the error signal, of size (itr_num,)# ========== FDAF (Frequency Domain Adaptive Filters)def FDAF(x,d,step_size,N=512,alpha=0.9): iter_num = len(d)//N-1 assert(iter_num&gt;0) # Init W = np.zeros(2*N,dtype=complex) pow_lambda = np.ones(2*N)*np.finfo(np.float32).eps rtn_e = np.zeros((iter_num-1)*N) # Main Iteration for itridx in range(1,iter_num): x_2blocks = x[(itridx-1)*N:(itridx+1)*N] # (2N) d_block = d[itridx*N:(itridx+1)*N] # (N) X = fft(x_2blocks) # (2N) Y = np.einsum('i,i-&gt;i',X,W) y = ifft(Y) # (2N) y = y[N:] # (N), discard first half block # print (y) # e = np.real(d_block - y) # (N) e = d_block - y # (N) # print(len(rtn_e)) rtn_e[(itridx-1)*N:itridx*N] = np.real(e) e = np.concatenate([np.zeros([N]),e]) # (2N) E = fft(e) # (2N) pow_lambda = alpha*pow_lambda + (1-alpha)*(np.abs(X)**2) # scale error signal, just like NLMS E = E/pow_lambda # Set the upper bound of E, to prevent divergence m_errThreshold = 0.2 Enorm = np.abs(E) # (2N) # print(E) for eidx in range(2*N): if Enorm[eidx]&gt;m_errThreshold: E[eidx] = m_errThreshold*E[eidx]/(Enorm[eidx]+1e-10) # Constraint Part gradient = np.einsum('i,i-&gt;i',X.conj(),E) # (2N) gradient = ifft(gradient) gradient[N:] = 0 gradient = fft(gradient) # (2N) # Update Part W = W + step_size*gradient return rtn_e Summaryæˆ‘å€‘ä»‹ç´¹äº†é‡å° input æ˜¯ block-by-block çµ¦å®šæ™‚, è¨ˆç®— linear convolution çš„å…©ç¨®æ¶æ§‹: OLA, OLS. è€Œå¦‚ä½•åŠ é€Ÿ linear convolution æˆ‘å€‘å‰‡ä»‹ç´¹äº†ä½¿ç”¨ circular convolution ä¾†ç­‰åƒ¹åœ°å®Œæˆ linear convolution. Circular convolution å¯ä»¥åˆ©ç”¨é »åŸŸç›¸ä¹˜ä¾†åŠ å¿«é€Ÿåº¦ (å¾—ç›Šæ–¼ FFT çš„æ•ˆç‡). é™¤äº†å° input åˆ‡ block ä¹‹å¤–, æˆ‘å€‘ä¹Ÿé‚„å¯ä»¥å° filter $h$ åˆ‡ block, é€™æ¨£çš„å¥½è™•æ˜¯è¨ˆç®—é‡å¯ä»¥åœ¨æ›´ä½, ä¸” latency ä¹Ÿæœƒé™ä½. é€™éƒ¨åˆ†è«‹åƒè€ƒæ›¸çš„ Ch5, é™„ä¸Šä¸€å¼µæ›¸æœ¬è£¡çš„æ¶æ§‹åœ–: é€™ç¨®æ–¹å¼å…¶å¯¦å¾ˆé‡è¦, åŸå› æ˜¯ webrtc ä¸­çš„ AEC æ¡ç”¨çš„æ˜¯ Partitioned Block Frequency Domain Adaptive Filter (PBFDAF) [3], å°±æ˜¯ filter ä¹Ÿæ˜¯ uniformly partitioned. æœ€å¾Œæˆ‘å€‘åˆ©ç”¨ OLA å’Œ fast convolution, åˆ—å‡ºä¾† frequency domain AF çš„æ¶æ§‹åœ–. åŒæ™‚å¦‚æœæƒ³è¦é€²ä¸€æ­¥é™ä½ latency å‰‡éœ€ä½¿ç”¨ PBFDAF[3] (filter ä¹Ÿ partition). Reference Partitioned convolution algorithms for real-time auralization by Frank Wefers Block Adaptive Filters and Frequency Domain Adaptive Filters by Prof. Ioan Tabus On the implementation of a partitioned block frequency domain adaptive filter (PBFDAF) for long acoustic echo cancellation","tags":[{"name":"Adaptive Filters","slug":"Adaptive-Filters","permalink":"https://bobondemon.github.io/tags/Adaptive-Filters/"},{"name":"OLA","slug":"OLA","permalink":"https://bobondemon.github.io/tags/OLA/"},{"name":"OLS","slug":"OLS","permalink":"https://bobondemon.github.io/tags/OLS/"},{"name":"circular convolution","slug":"circular-convolution","permalink":"https://bobondemon.github.io/tags/circular-convolution/"},{"name":"linear convolution","slug":"linear-convolution","permalink":"https://bobondemon.github.io/tags/linear-convolution/"}]},{"title":"Adaptive Filters ç°¡ä»‹ (1) Time Domain","date":"2019-05-14T14:03:03.000Z","path":"2019/05/14/Adaptive-Filters-Notes/","text":"ç²—ç•¥ç­†è¨˜ time domain adaptive filters, frequency domain adaptive filters æœƒåœ¨ä¸‹ä¸€ç¯‡ç­†è¨˜. æ‡‰ç”¨ä»¥ Acoustic Echo Cancellation (AEC) ä¾†èªªæ˜. Motivationç›´æ¥ä½¿ç”¨ wiki. AEC è¦è§£æ±ºçš„æ˜¯å¦‚ä¸‹çš„æƒ…å½¢ å„å€‹è¨Šè™Ÿé—œè¯å¦‚ä¸‹: $$\\begin{align} y(n)=h(n)\\ast x(n) \\\\ d(n)=y(n)+v(n) \\\\ \\hat{y}(n)=\\hat{h}(n)\\ast x(n)\\\\ e(n)=d(n)-\\hat{y}(n) \\end{align}$$ ç›®çš„æ˜¯æ‰¾åˆ° $\\hat{h}$ æ»¿è¶³ä¸‹å¼: $$\\begin{align} \\hat{y}(n)\\approx y(n)\\Rightarrow e(n)\\approx v(n) \\end{align}$$ å°æ–¼ç¬¬ $n$ å€‹ sample é»ä¾†èªª, æˆ‘å€‘é€šå¸¸ä½¿ç”¨éå»(å«è‡ªå·±) $p$ å€‹ samples. ä¸‹é¢å°å¯«ç²—é«”è¡¨ç¤º vector, å¤§å¯«ç²—é«”è¡¨ç¤º matrix. Optimal Solutionä¹Ÿå°±æ˜¯ Wiener solution. ä½†åœ¨çœŸå¯¦ä¸–ç•Œä¸­, ä¸ç®¡ reference signal ($x(n)$) or desired signal ($d(n)$) éƒ½æ˜¯ non-stationary çš„. æœ€ç›´æ¥ä¸”æš´åŠ›çš„æƒ³æ³•å°±æ˜¯æ¯éš”ä¸€æ®µæ™‚é–“é‡æ–°ç®—ä¸€æ¬¡ Wiener solution. ä¸éæƒ³ç•¶ç„¶çˆ¾é€™æ˜¯è¡Œä¸é€šçš„. å› æ­¤å°±å¿…é ˆæ¡ç”¨ Stochastic update æ–¹å¼. Stochastic Update ä¸Šé¢ç´…è‰²çš„å¼å­å°±æ˜¯å…¸å‹çš„ LMS algorithm. å¦å¤–æˆ‘å€‘çŸ¥é“ optimization é‚„å¯ä»¥ä½¿ç”¨ second-moment, ä¹Ÿå°±æ˜¯ä½¿ç”¨äºŒéšå°å‡½æ•¸ (Hessian Matrix). é€™å°±æ˜¯ Newtonâ€™s method: é‡å° $\\mathbf{R}_{xx} \\mbox{ , } \\mathbf{R}_{xd}$ ä½¿ç”¨ä¸åŒçš„ approximation æ–¹å¼å°±æœƒå¾—åˆ°ä¸åŒæ¼”ç®—æ³•, ä¾‹å¦‚: ä¸Šé¢ç´…è‰²çš„å¼å­å°±æ˜¯å…¸å‹çš„ NLMS algorithm. ç”¨é€™æ¨£çš„æ–¹å¼é‚„å¯æ¨å‡º e-NLMS, leaky-LMS, RLS ç­‰ç­‰â€¦ å¯¦ä½œä¸Š NLMS åœ¨ reference signal $x(n)$ å¾ˆå°çš„æ™‚å€™, ç”±æ–¼å…¬å¼ä¸Šåˆ†æ¯æœƒé™¤ä»¥ $x^Hx$, è€Œåˆ†å­åªæœ‰ä¸€æ¬¡æ–¹ $x$, å› æ­¤é™¤ä¸‹ä¾†æœƒå°è‡´ gradient å®¹æ˜“è®Šå¤§, æ‰€ä»¥ç™¼æ•£. é€™æ˜¯ NLMS å¯¦ä½œä¸Šè¦è€ƒæ…®çš„æƒ…å½¢. Misadjustmentæˆ‘å€‘çŸ¥é“æœ€ä½³è§£ç‚º Wiener solution, ä½†ç”±æ–¼æˆ‘å€‘æ¡ç”¨ stochastic gradient æ–¹å¼, ä¹Ÿå°±æ˜¯èªª update çš„ gradient æœ¬èº«å­˜åœ¨èª¤å·®, é€™äº› gradient çš„ variance å°±ç›´æ¥å½±éŸ¿äº†æœ€çµ‚æ”¶æ–‚çš„æ•ˆæœè·Ÿ Wiener solution çš„æ”¶æ–‚çµæœä¹‹é–“çš„å·®è·. æ­¤å·®è·æˆ‘å€‘ç¨± misadjustment æˆ–ç¨± Excess Meam Square Error ç›´æ¥æ“·å– Ali Sayed, Adaptive Filters p230 çš„å®šç¾©: ç‚ºä»€éº¼è¦èªªé€™å€‹å‘¢? æ˜¯å› ç‚ºå¯¦ä½œä¸Šæœ‰å…©å€‹å› ç´ æœƒç›´æ¥å½±éŸ¿æœ€çµ‚æ”¶æ–‚æ•ˆæœçš„å¥½å£, åˆ†åˆ¥æ˜¯ tap length å’Œ step size. å¾ç†è«–åˆ†æå’Œå¯¦ä½œç¶“é©—ä¾†èªª, tap length å¤ªå°æœƒç„¡æ³•æœ‰æ•ˆæ¨¡æ“¬ RIR, è€Œå¤ªå¤§æœƒå°è‡´ EMSE æé«˜ (æ”¶æ–‚æ•ˆæœåè€Œè®Šå·®), å› æ­¤é¸å–çš„ tap length å¿…é ˆè¦æ ¹æ“š sampling rate å’Œè¦æ¶ˆé™¤çš„ echo path ä¾†è¨ˆç®—ä¸€ä¸‹. LMS or NLMS çš„ EMSE å¯çŒœè€ƒ Ali Sayed, Adaptive Filters p249 and p253. (æ¢ä»¶å·²ç°¡åŒ–åœ¨ ref and desired signals ç‚º stationary æƒ…æ³) å¦å¤– step size è¼ƒå°æœƒæœ‰è¼ƒå¥½çš„æ”¶æ–‚æ•ˆæœ, ä½†æ˜¯æ”¶æ–‚é€Ÿåº¦æœƒæ…¢ä¸” tracking èƒ½åŠ›è¼ƒå·®. ä¸€å€‹æœ‰æ•ˆçš„æ–¹å¼ç‚ºä½¿ç”¨ Practical Variable Step Size (PVSS) æ–¹æ³•, å…·é«”å¯åƒè€ƒ å¾…è£œ å¥½äº†, time domain åˆ°é€™å°±å·®ä¸å¤šäº†, ç¼ºé»ä¹Ÿå¾ˆæ˜é¡¯, æ…¢!, å› ç‚ºæ˜¯ sample-by-sample è™•ç†. æ¥è‘—ç¨å¾®æ¢³ç†ä¸€ä¸‹ frequency domain æ–¹æ³•. Reference wiki Least mean squares filter Ali Sayed, Adaptive Filters","tags":[{"name":"Adaptive Filters","slug":"Adaptive-Filters","permalink":"https://bobondemon.github.io/tags/Adaptive-Filters/"},{"name":"AEC","slug":"AEC","permalink":"https://bobondemon.github.io/tags/AEC/"},{"name":"LMS","slug":"LMS","permalink":"https://bobondemon.github.io/tags/LMS/"},{"name":"NLMS","slug":"NLMS","permalink":"https://bobondemon.github.io/tags/NLMS/"}]},{"title":"Far Field Notes (4) How Spatial Feature Clusters","date":"2019-04-12T13:36:17.000Z","path":"2019/04/12/Far-Field-Notes-4-How-Spatial-Feature-Clusters/","text":"é€™æ˜¯ far field ç­†è¨˜ç³»åˆ—ç¬¬å››ç¯‡, å¯«é€™ç¯‡æ˜¯å› ç‚ºåš CGMM-MVDR æ™‚, å¾ˆå¥½å¥‡ç‚ºä½• spatial features èšé¡çš„çµæœå¯ä»¥å°æ‡‰ä¸åŒæ–¹å‘çš„è²æº. å› æ­¤è¨˜éŒ„ä¸‹è‡ªå·±çš„ä¸€é»æƒ³æ³•. å‡è¨­æˆ‘å€‘æœ‰ $M$ å€‹éº¥å…‹é¢¨, å‰‡åœ¨ stft (short-time fourier transform) ä¸Šä¾†èªª, $\\mathbf{f}_{\\omega,t}$ è¡¨ç¤ºä¸€å€‹é »ç‡ $\\omega$, æ™‚é–“ $t$ çš„ $M$ ç¶­å‘é‡. å°æ–¼æŸä¸€å€‹ $\\theta$ æ–¹å‘çš„ narrowband è¨Šè™Ÿ, ideally æˆ‘å€‘å¯ä»¥é€™éº¼è¡¨ç¤º $$\\begin{align} \\mathbf{f}_{\\omega,t}^{\\theta}=f(\\omega)\\mathbf{\\upsilon}(\\theta)=f(\\omega) \\left[ \\begin{array}{clr} e^{-j\\omega\\tau_0} \\\\ e^{-j\\omega\\tau_1} \\\\ \\vdots \\\\ e^{-j\\omega\\tau_{M-1}} \\end{array} \\right] \\end{align}$$ $\\tau_i$ è¡¨ç¤ºç”± $\\theta$ ç”¢ç”Ÿçš„ç¬¬ $i$ å€‹ mic çš„ time delay. å› æ­¤ spatial feature æ¯å€‹ç¶­åº¦ä¹‹é–“çš„ phase offset é—œä¿‚æ˜¯å›ºå®šçš„, ç”± $\\mathbf{\\upsilon}(\\theta)$ æ±ºå®š. æ‰€æœ‰å¦‚æœæœ‰å…©å€‹æ–¹å‘ $\\theta_1$ and $\\theta_2$ çš„è²æº, phase offset é—œä¿‚å„è‡ªæ˜¯ $\\mathbf{\\upsilon}(\\theta_1)$ å’Œ $\\mathbf{\\upsilon}(\\theta_2)$. å•é¡Œæ˜¯è¦ç”¨ä»€éº¼æ¨£çš„ cluster èƒ½å°ç›¸åŒ phase offset é—œä¿‚çš„ complex vector èšé¡åœ¨ä¸€èµ·, è€Œå°ä¸åŒ phase offset é—œä¿‚èƒ½åˆ†é–‹å‘¢? é—œéµçš„ç­”æ¡ˆå°±æ˜¯ Circularly Symmetric Gaussian Distribution Circularly Symmetric Gaussian Distributionç›´æ¥å¼•ç”¨ slides è£¡çš„ä¸€æ®µå®šç¾© A complex Gaussian random vector $Z$ is circularly symmetric if $e^{j\\phi}Z$ has the same distribution as $Z$ for all real $\\phi$. æ„æ€å°±æ˜¯å¦‚æœæˆ‘å€‘ä¹˜ä¸Šå›ºå®šçš„ phase offset $\\phi$ (è²æºæœ‰ time delay), é€™ç›¸ç•¶æ–¼ä¸æ”¹è®Šç¶­åº¦ä¹‹é–“çš„ phase offset é—œä¿‚ (ä¸æ”¹è®Šè²æºæ–¹å‘ $\\theta$), é€™æ¨£çš„è©±å®ƒå€‘æœƒæ˜¯åŒä¸€å€‹æ©Ÿç‡åˆ†ä½ˆ, è€Œé€™ç¨®ç‰¹æ€§å®Œå…¨ç¬¦åˆæˆ‘å€‘çš„éœ€æ±‚! æˆ‘å€‘ç›´æ¥æ“·å– slide ä¸­çš„ Circularly Symmetric Gaussian Distribution çš„å®šç¾©: è©³ç´°è«‹è¦‹ [1] çš„ slides. Reference Circularly Symmetric Gaussian Random Vectors","tags":[{"name":"CGMM","slug":"CGMM","permalink":"https://bobondemon.github.io/tags/CGMM/"},{"name":"Spatial","slug":"Spatial","permalink":"https://bobondemon.github.io/tags/Spatial/"}]},{"title":"æ‡·èˆŠç¯‡, å–®é€šé“é™å™ª, MMSE-STSA, MMSE-LSA æ–¹æ³•","date":"2019-03-20T13:04:18.000Z","path":"2019/03/20/MMSE-STSA-and-LSA/","text":"è¨˜éŒ„ä¸€ä¸‹å–®é€šé“é™å™ªçš„ä¸€å€‹ç¶“å…¸æ–¹æ³•, MMSE-STSA, MMSE-LSA, å·²ç¶“æ˜¯ 1984 å·¦å³çš„æ–‡ç« äº†. å–®é€šé“é™å™ª OMLSA ä¹Ÿå¾é€™è¡ç”Ÿå‡ºä¾†çš„. æˆ‘å€‘å…ˆå¾ MMSE-STSA èªªèµ·, å…¨åæ˜¯ minimum mean-square error short time spectral amplitude.$y(t)=x(t)+d(t),0\\leq t\\leq T$$x$, $d$, $y$ åˆ†åˆ¥æ˜¯ speech, noise, å’Œæ”¶åˆ°çš„ noisy signal, å…¶ä¸­ $x$, $d$ ç›¸äº’ç¨ç«‹. ç›¸å°æ‡‰çš„ç¬¬ $k$ å€‹ frequency bin å¦‚ä¸‹:$$X_k=A_k\\exp(j\\alpha_k) \\\\ D_k \\\\ Y_k=R_k\\exp(j\\theta_k)$$ MMSE-STSA $^{[1]}$ç›®æ¨™å‡½å¼ç‚º$$\\begin{align} \\arg\\min_{\\hat{A}_k}{\\mathbb{E}\\left[\\left(A_k-\\hat{A}_k\\right)^2\\vert y(t),0\\leq t\\leq T\\right]} \\end{align}$$ æœ€ä½³è§£ç‚º$$\\begin{align} \\hat{A}_k=\\mathbb{E}\\left[A_k\\vert y(t),0\\leq t \\leq T\\right] \\end{align}$$ ä½†é—œéµæ˜¯æˆ‘å€‘ä¸çŸ¥é“ clean speech çš„ amplitude $A_k$, é‚£è©²æ€éº¼ä¼°å‘¢? é¦–å…ˆæˆ‘å€‘å°æ¯å€‹ frequency bin çš„åˆ†å¸ƒå‡è¨­ç‚º Gaussian distribution (complex). å¼•ç”¨åŸæ–‡ â€œSince the Fourier coefficient is, after all, a weighted sum (or integral) of random variables resulting from the random process samplesâ€, åœ¨ä¸€å€‹çŸ­æ™‚çš„ frame ä¸­å¤§è‡´ä¸Šæ˜¯ stationary, å› æ­¤å¯ä»¥çœ‹ä½œæ˜¯ä¸€å€‹ WSS çš„ ramdom process, å†åŠ ä¸Š cental limit theorem, å°±ç•¶ä½œé«˜æ–¯åˆ†å¸ƒå§. å¥—ç”¨ Guassian distribution å‡è¨­, åšå¦‚ä¸‹æ¨å°$$\\begin{align} \\hat{A}_k=\\mathbb{E}\\left[A_k\\vert y(t),0\\leq t \\leq T\\right]=\\mathbb{E}\\left[A_k\\vert Y_0,Y_1,...\\right] \\\\ =\\mathbb{E}\\left[A_k\\vert Y_k\\right] \\\\ =\\int_0^{\\infty}\\int_0^{2\\pi}a_k p(a_k,\\alpha_k\\vert Y_k)d\\alpha_k d a_k = \\int_0^{\\infty}\\int_0^{2\\pi}a_k \\frac{p(a_k,\\alpha_k,Y_k)}{p(Y_k)}d\\alpha_k d a_k \\\\ =\\frac{ \\int_0^{\\infty}\\int_0^{2\\pi}a_k p(Y_k\\vert a_k,\\alpha_k) p(a_k,\\alpha_k) d\\alpha_k d a_k }{ \\int_0^{\\infty}\\int_0^{2\\pi} p(Y_k\\vert a_k,\\alpha_k) p(a_k,\\alpha_k) d\\alpha_k d a_k } \\end{align}$$ å…¶ä¸­ (3) åˆ° (4) æˆ‘å€‘å‡è¨­æ¯å€‹ frequency bin æ˜¯ç¨ç«‹çš„ç”±æ–¼æˆ‘å€‘å‡è¨­æ¯å€‹ frequency bin éƒ½æ˜¯ complex Gaussian distribution, å› æ­¤ (6) çš„æ©Ÿç‡åˆ†ä½ˆå¦‚ä¸‹å®šç¾©:$$\\begin{align} p(Y_k\\vert a_k,\\alpha_k)=\\frac{1}{\\pi\\lambda_d (k)}\\exp\\left[ -\\frac{1}{\\lambda_d (k)}\\vert Y_k - a_k e^{j\\alpha_k} \\vert^2 \\right] \\\\ p(a_k,\\alpha_k)=\\frac{1}{\\pi\\lambda_x (k)}\\exp\\left[-\\frac{a_k^2}{\\lambda_x (k)}\\right] \\end{align}$$ æ³¨æ„åˆ° (7) èƒ½é€™éº¼å¯«æ˜¯å› ç‚ºæˆ‘å€‘çŸ¥é“ $x$ and $d$ äº’ç›¸ç¨ç«‹, å› æ­¤åœ¨çµ¦å®š $x$ çš„æƒ…å½¢ä¸‹, åªæ˜¯æ”¹è®Š mean çš„ä½ç½®, å…¶ variance ä»ç”± $d$ ä¾†æ±ºå®š. å¦å¤–:$$\\begin{align} \\lambda_x (k)=\\mathbb{E}\\left[\\vert X_k \\vert ^2\\right]=A_k^2 \\\\ \\lambda_d (k)=\\mathbb{E}\\left[\\vert D_k \\vert ^2\\right] \\end{align}$$ è¡¨ç¤ºç¬¬ $k$ å€‹ bin çš„ speech and noise çš„ varianceå°‡ (7) and (8) å¸¶å…¥ (6) ä¸¦æ„Ÿè¬å‰å¤§çš„ä½œè€…æ¨å°å¾—åˆ°:$$\\begin{align} \\hat{A}_k=\\Gamma(1.5)\\frac{\\sqrt{\\upsilon_k}}{\\gamma_k}M(-0.5;1;-\\upsilon_k)R_k \\\\ \\hat{A}_k=\\Gamma(1.5)\\frac{\\sqrt{\\upsilon_k}}{\\gamma_k}\\exp\\left(-\\frac{\\upsilon_k}{2}\\right)\\left[(1+\\upsilon_k)I_0(\\frac{\\upsilon_k}{2})+\\upsilon_k I_1(\\frac{\\upsilon_k}{2})\\right]R_k \\end{align}$$ å…¶ä¸­ $\\Gamma$ è¡¨ç¤º gamma function, $\\Gamma(1.5)=\\sqrt{\\pi}/2$; $M(a;c;x)$ æ˜¯ confluent hypergeometric function (é€™æ˜¯å¤–æ˜Ÿç¬¦è™Ÿå§), $I_0$ and $I_1$ æ˜¯ modified Bessel funciton of zero and first order. ç¸½ä¹‹å°±æ˜¯èƒ½å¸¶å…¥è¨ˆç®—çš„æ±è¥¿, æœ€é‡è¦, ä¹Ÿæ˜¯éœ€è¦æˆ‘å€‘ä¼°è¨ˆçš„è®Šæ•¸å¦‚ä¸‹:$$\\begin{align} \\upsilon_k\\triangleq \\frac{\\xi_k}{1+\\xi_k}\\gamma_k \\\\ \\color{orange}{ \\xi_k\\triangleq\\frac{\\lambda_x (k)}{\\lambda_d (k)} } \\\\ \\color{orange}{ \\gamma_k\\triangleq\\frac{R_k^2}{\\lambda_d (k)} } \\\\ \\end{align}$$ $\\xi_k$ å’Œ $\\gamma_k$ åˆ†åˆ¥ç¨±ç‚º prior SNR å’Œ posterior SNR. ç¸½ä¹‹å¦‚èƒ½ä¼°å‡º $\\xi_k$ å’Œ $\\gamma_k$, æˆ‘å€‘å°±èƒ½è¨ˆç®—å‡º gain å€¼, ä¹‹å¾Œçš„æ–¹æ³•å¦‚ LSA, OMLSA ä¹Ÿéƒ½å¦‚æ­¤. æ–‡ç« å¾Œé¢æœƒä½¿ç”¨ MCRA ä¾†ä¼°ç®—é€™å…©å€‹ SNR. ç¾åœ¨å°±ç®—å‚³çµ±æ–¹æ³•ä¸€èˆ¬ä¹Ÿå¾ˆå°‘ä½¿ç”¨ MMSE-STSA, è‡³å°‘æœƒä½¿ç”¨ LSA å–ä»£. LSA æœ‰è¿‘ä¼¼çš„è¨ˆç®—æ–¹å¼, å› æ­¤æˆ‘å€‘ä¹Ÿä¸ç³¾çµ (12) åˆ°åº•æ€éº¼ç®—å‡ºä¾†. MMSE-LSA $^{[2]}$å¤§è‡´æƒ³æ³•è·Ÿæµç¨‹è·Ÿä¸Šé¢ä¸€æ¨£(åªæ˜¯æˆ‘ç®—ä¸å‡ºä¾†), åªæ˜¯ç›®æ¨™å‡½æ•¸é‡å° log å€¼ä¾†è¨ˆç®—$$\\begin{align} \\arg\\min_{\\hat{A}_k}{\\mathbb{E}\\left[\\left(\\log A_k-\\log\\hat{A}_k\\right)^2\\vert y(t),0\\leq t\\leq T\\right]} \\end{align}$$ åŒæ¨£ç¶“éä¸æ˜¯äººé¡çš„è¨ˆç®—å¾Œå¾—åˆ°:$$\\begin{align} \\hat{A}_k=\\frac{\\xi_k}{1+\\xi_k}\\exp\\left[\\frac{1}{2}\\int_{\\upsilon_k}^{\\infty}\\frac{e^{-t}}{t}dt\\right]R_k \\end{align}$$ [3] çµ¦å‡ºäº†ä¸€å€‹å¥½ç®—çš„è¿‘ä¼¼çµæœ$$\\begin{align} \\int_{\\upsilon_k}^{\\infty}\\frac{e^{-t}}{t}dt\\approx \\left\\{ \\begin{array}{rcl} -2.31\\log_{10}(\\upsilon_k)-0.6\\mbox{ for }\\upsilon_k&lt;0.1 \\\\ -1.544\\log_{10}(\\upsilon_k)+0.166\\mbox{ for }0.1\\leq\\upsilon_k\\leq 1 \\\\ 10^{-(0.52\\upsilon_k+0.26)}\\mbox{ for }\\upsilon_k&gt;1 \\\\ \\end{array}\\right. \\end{align}$$ å¦å¤–é‚„æœ‰ optimally-modified log-spectral amplitude (OMLSA) [4] æ–¹æ³•, ä½œè€…æœ‰æä¾› MATLAB codes. é€™ç®—å–®é€šé“é™å™ªæ¨™é…äº†, ä½†å¯¦é©—çµæœå°è½è¦ºæœ‰å¹«åŠ©, å° WER ä¸ä¸€å®šé™ä½. ç¸½ä¹‹ä¸ç®¡å“ªä¸€ç¨®æ–¹æ³•, éƒ½å¿…é ˆå¾ˆå¥½çš„ä¼°å‡º prior and posterior SNR. MCRA Prior/Posterior SNR ä¼°è¨ˆé‡å° STFT æ™‚é–“ $l$, frequency bin $k$ ä¾†èªª, å‡è¨­æˆ‘å€‘å·²ä¼°å‡ºä¾† speech presence probability $p(k,l)$, æˆ‘å€‘å¯ä»¥é€™éº¼ update noise çš„ variance:$$\\begin{align} \\hat{\\lambda}_d(k,l+1)=\\hat{\\lambda}_d(k,l)p(k,l)+\\left[\\alpha_d\\hat{\\lambda}_d(k,l)+(1-\\alpha_d)|Y(k,l)|^2\\right](1-p(k,l)) \\end{align}$$ é€™å¾ˆå¥½ç†è§£, å¦‚æœæœ‰ speech çš„è©±, noise variance å°±æ²¿ç”¨åŸä¾†èˆŠçš„, è€Œå¦‚æœæ²’æœ‰ speech, nosie vaiance å°±è¦ç”¨ç•¶å‰ frame é€é $\\alpha_d$ å¹³æ»‘åœ°æ›´æ–°ä¸€ä¸‹ (å°±ç¨±é€™æ¨£çš„å¹³æ»‘ç‚º $\\alpha$ å¹³æ»‘). ä¼°è¨ˆ $p(k,l)$ ä¹‹å‰, æ–‡ç« çš„åšæ³•æ˜¯éƒ½å…ˆé‡å° time and frequency åšå¹³æ»‘. frequency å¯é¸ç”¨ä¸€å€‹ window (å¯ç”¨é¡ä¼¼ Gaussian window), è€Œæ™‚é–“ä¸Šçš„å¹³æ»‘å¯ä½¿ç”¨ $\\alpha$ å¹³æ»‘. ä»¤ $S(k,l)$ ç‚ºæˆ‘å€‘å¹³æ»‘å¾Œçš„ spectrum power, ç„¶å¾Œå°æ¯å€‹ bin éƒ½ tracking ä¸€å°æ®µæ™‚é–“çš„æœ€å°å€¼, ä»¤ç‚º $Sâ€™(k,l)$. å‰‡å¾ˆæ˜é¡¯å¦‚æœ $S(k,l)&gt;\\delta Sâ€™(k,l)$, æˆ‘å€‘å°±å¯ä»¥èªç‚ºæœ‰ speech, æ©Ÿç‡ç‚º 1, å¦å‰‡ç‚º 0. é€™æ¨£çš„ speech æ©Ÿç‡éäº† $\\alpha$ å¹³æ»‘çš„çµæœå°±æ˜¯ $p(k,l)$. æ˜ç¢ºä¸€é»å¯«ä¸‹ç‚º:$$\\begin{align} p(k,l)=\\alpha_p p(k,l-1)+(1-\\alpha_p)\\mathbf{I}[S(k,l)&gt;\\delta S&apos;(k,l)] \\end{align}$$ å…¶ä¸­ $\\mathbf{I}[.]$ ç‚º indicator function MCRA æœ‰å“ªäº›èª¿æ•´çš„åƒæ•¸å¯¦éš›æƒ…å½¢æœ‰ä¸€äº›éœ€è¦èª¿æ•´çš„åƒæ•¸, åˆ—åœ¨ä¸‹é¢ $\\alpha_d$: noise variance smoothing $\\alpha_p$: speech probability smoothing STFT çš„ time and frequency smoothing åƒæ•¸ $\\delta$: åˆ¤æ–·ç•¶å‰ frame and bin æ˜¯å¦ç‚º speech çš„ threshold tracking minimal power $Sâ€™(k,l)$ çš„åƒæ•¸, è­¬å¦‚è¦ç”¨å¤šå°‘å€‹ frame ä¾†æ‰¾ minimum å¾…åšäº›å¯¦é©—æ‰æœƒçŸ¥é“æ•ˆæœâ€¦ Reference Speech Enhancement Using a Minimum Mean-Square Error Short-Time Spectral Amplitude Estimator by Yariv Ephraim and David Malah Speech Enhancement Using a Minimum Mean-Square Error Log-Spectral Amplitude Estimator by Yariv Ephraim and David Malah [A Noise Reduction Pre-processor for Mobile Voice Communication] by R. Martin â€¦ Speech enhancement for non-stationary noise environments by Israel Cohen and Baruch Berdugo","tags":[{"name":"MMSE-STSA","slug":"MMSE-STSA","permalink":"https://bobondemon.github.io/tags/MMSE-STSA/"},{"name":"MMSE-LSA","slug":"MMSE-LSA","permalink":"https://bobondemon.github.io/tags/MMSE-LSA/"},{"name":"OMLSA","slug":"OMLSA","permalink":"https://bobondemon.github.io/tags/OMLSA/"},{"name":"MCRA","slug":"MCRA","permalink":"https://bobondemon.github.io/tags/MCRA/"}]},{"title":"Far Field Notes (3) Equivalence of MWF, MaxSNR, and MVDR Filters","date":"2019-03-18T12:33:46.000Z","path":"2019/03/18/Far-Field-Notes-3-MWF-MaxSNR-MVDR-Filters/","text":"é€™æ˜¯ far field ç­†è¨˜ç³»åˆ—ç¬¬ä¸‰ç¯‡, ä¸»è¦ç‚ºè‡ªå·±å­¸ç¿’ç”¨, å¦‚æœ‰éŒ¯èª¤é‚„è«‹æŒ‡æ­£. ä¸»è¦åƒè€ƒ Microphone Array Signal Processing Ch6 å’Œ Speech Processing in Modern Communication: Challenges and Perspectives Ch9.3.4 åœ¨ narrow-band çš„æƒ…å½¢ä¸‹, Multi-channel Wiener Filter (MWF), maximum SNR (MSNR) å’Œ Minimum Variance Distortionless Response (MVDR) ä¸‰è€…æ±‚å‡ºä¾†çš„ filter è§£åªå·®åœ¨ norm å¤§å°ä¸åŒ. ä½†åæ‡‰åœ¨æœ€å¾Œçš„ full-bank è¡Œç‚ºä»ç„¶ä¸åŒ. é€™éƒ¨åˆ†å¯çœ‹æ›¸. æœ¬ç¯‡ä¸»è¦ç´€éŒ„ narrow-bank ä¸‹ä¸‰è€…ç‚ºä½• equivalent. ç®—æ˜¯æ›¸æœ¬çš„æ‘˜è¦ç­†è¨˜å§. Signal Modelåœ¨ frequency doamin ä¸‹, æˆ‘å€‘æœ‰å¦‚ä¸‹çš„é—œä¿‚ $$\\begin{align} Y_n(j\\omega)=G_n(j\\omega)S(j\\omega)+V_n(j\\omega) \\\\ =X_n(j\\omega)+V_n(j\\omega)\\mbox{, }n=1,2,...,N \\\\ \\end{align}$$ $N$ æ˜¯éº¥å…‹é¢¨æ•¸é‡, $S(j\\omega)$ æ˜¯åŸå§‹è¨Šè™Ÿ, $G_n(j\\omega)$ æ˜¯è²æºåˆ° mic $n$ çš„ impluse response, $V_n(j\\omega)$ æ˜¯ noise, è€Œ $X_n(j\\omega)$ æ˜¯ mic $n$ çš„è¨Šè™Ÿ. æˆ‘å€‘å¸Œæœ›é‚„åŸçš„æ˜¯ $X_1(j\\omega)$ è€Œä¸æ˜¯ $S(j\\omega)$.æ’æˆ vector å½¢å¼å¦‚ä¸‹$$\\begin{align} Z(j\\omega)=\\mathbf{h}^H(j\\omega)\\mathbf{y}(j\\omega) \\\\ =\\mathbf{h}^H(j\\omega)[\\mathbf{x}(j\\omega)+\\mathbf{v}(j\\omega)] \\\\ \\end{align}$$ å…¶ä¸­$$\\begin{align} \\mathbf{y}(j\\omega)=[Y_1(j\\omega),Y_2(j\\omega),...,Y_N(j\\omega)]^T \\\\ \\mathbf{x}(j\\omega)=S(j\\omega)[G_1(j\\omega),G_2(j\\omega),...,G_N(j\\omega)]^T=S(j\\omega)\\mathbf{g}(j\\omega) \\\\ \\mathbf{v}(j\\omega)=[V_1(j\\omega),V_2(j\\omega),...,V_N(j\\omega)]^T \\\\ \\mathbf{h}(j\\omega)=[H_1(j\\omega),H_2(j\\omega),...,H_N(j\\omega)]^T \\\\ \\end{align}$$ æ³¨æ„åˆ°$$\\begin{align} \\Phi_{xx}(j\\omega)=\\mathbb{E}\\left[\\mathbf{x}(j\\omega)\\mathbf{x}^H(j\\omega)\\right]=\\phi_{ss}(j\\omega)\\mathbf{g}(j\\omega)\\mathbf{g}^H(j\\omega) \\end{align}$$ MWFå°‡ error term å¯«å‡ºä¾† $$\\begin{align} \\mathcal{E}(j\\omega)=Z(j\\omega)-X_1(j\\omega) \\\\ =\\mathbf{h}^H(j\\omega)\\mathbf{v}(j\\omega)+[\\mathbf{h}(j\\omega)-\\mathbf{u}]^H\\mathbf{x}(j\\omega)\\\\ =\\color{orange}{\\mathcal{E}_v(j\\omega)}+\\color{blue}{\\mathcal{E}_x(j\\omega)} \\\\ \\end{align}$$ å…¶ä¸­ $\\mathbf{u}$ æ˜¯ä¸€å€‹ $N\\times 1$ çš„ vector, åªæœ‰ç¬¬ä¸€å€‹æ˜¯1, å…¶ä»–æ˜¯0. Error term å¯ä»¥æ‹†æˆå…©é …, åˆ†åˆ¥å°æ‡‰äº† noise reduction ç¨‹åº¦å’Œ speech distortion ç¨‹åº¦MWF çš„ç›®æ¨™å‡½å¼å¦‚ä¸‹:$$\\begin{align} J_{MWF}[\\mathbf{h}(j\\omega)]=\\mathbb{E}\\left[| \\mathcal{E}(j\\omega) |^2\\right]\\\\ = \\color{orange}{ \\mathbb{E}\\left[| \\mathcal{E}_v(j\\omega) |^2\\right] } + \\color{blue}{ \\mathbb{E}\\left[| \\mathcal{E}_x(j\\omega) |^2\\right] } \\end{align}$$ å¯ä»¥çœ‹æˆ noise reduction å’Œ speech distortion åŒç­‰é‡è¦æƒ…æ³ä¸‹å»æ±‚è§£æœ€å¥½çš„ $\\mathbf{h}$å¾®åˆ†ç­‰æ–¼é›¶æ±‚è§£å¾—åˆ°å¦‚ä¸‹:$$\\begin{align} \\Phi_{yy}(j\\omega)\\mathbf{h}_W(j\\omega)=\\Phi_{yx}(j\\omega)\\mathbf{u}=\\Phi_{xx}(j\\omega)\\mathbf{u} \\end{align}$$ä¸Šå¼æœ€å¾Œæ¨å°æ˜¯ç”±æ–¼ $x$ and $v$ æ˜¯ independent. å› æ­¤æœ€å¾Œçš„ MWF è§£ç‚º:$$\\begin{align} \\mathbf{h}_W(j\\omega)=\\Phi_{yy}^{-1}(j\\omega)\\Phi_{xx}(j\\omega)\\mathbf{u} \\\\ =\\left[ \\mathbf{I}_{N\\times N} - \\Phi_{yy}^{-1}(j\\omega)\\Phi_{vv}(j\\omega) \\right]\\mathbf{u} \\end{align}$$ MVDRMVDR è¦è§£çš„å•é¡Œå¦‚ä¸‹:$$\\min \\color{orange}{ \\mathbb{E}\\left[| \\mathcal{E}_v(j\\omega) |^2\\right] }\\\\ \\mbox{subject to } \\color{blue}{\\mathbb{E}\\left[| \\mathcal{E}_x(j\\omega) |^2\\right]}=0$$ é€™ä¹Ÿå¯ä»¥çœ‹å‡º MVDR ç‚ºä»€éº¼å« MVDR.é¦–å…ˆå…ˆå°‡ constraint æ”¹å¯«æˆ (æ”¹å¯« speech distortion error term, å®šç¾©åœ¨ (11), (12)):$\\left[\\mathbf{u}-\\mathbf{h}(j\\omega)\\right]^H\\mathbf{x}(j\\omega)=0 \\\\$ ä¸¦åˆ©ç”¨ $\\mathbf{x}(j\\omega)=S(j\\omega)\\mathbf{g}(j\\omega)$ å¯å¾—åˆ°$\\mathbf{h}^H(j\\omega)\\mathbf{g}(j\\omega)=G_1(j\\omega)$å› æ­¤ MVDR å•é¡Œçš„é€šå¸¸å¦‚ä¸‹è¡¨é”:$$\\min \\mathbf{h}^H(j\\omega) \\Phi_{vv}(j\\omega) \\mathbf{h}(j\\omega) \\\\ \\mbox{subject to } \\mathbf{h}^H(j\\omega)\\mathbf{g}(j\\omega)=G_1(j\\omega) \\\\$$ é€™å€‹æœ€ä½³åŒ–å•é¡Œæ­£å¥½å°±æ˜¯ä¸Šä¸€ç¯‡çš„ LCMV, æ‰€ä»¥èªª MVDR æ˜¯ LCMV çš„ä¸€ç¨® case.ç”¨ Lagrange multipliers æ±‚è§£å¾—åˆ°$$\\begin{align} \\mathbf{h}_{MVDR}(j\\omega)=G_1^{\\ast}(j\\omega)\\frac{\\Phi_{vv}^{-1}(j\\omega)\\mathbf{g}(j\\omega)}{\\mathbf{g}^H(j\\omega)\\Phi_{vv}^{-1}(j\\omega)\\mathbf{g}(j\\omega)} \\end{align}$$ å° (18) é€²ä¸€æ­¥æ¨å°, ç‚ºäº†ç²¾ç°¡ä»¥ä¸‹ ${j\\omega}$ çœç•¥ä¸å¯«$$\\begin{align} \\mathbf{h}_{MVDR}=\\frac{\\Phi_{vv}^{-1}\\phi_{ss}\\mathbf{g}G_1^{\\ast}}{tr\\left[\\Phi_{vv}^{-1}\\phi_{ss}\\mathbf{g}\\mathbf{g}^H\\right]}=\\frac{\\Phi_{vv}^{-1}\\phi_{ss}\\mathbf{g}\\mathbf{g}^H\\mathbf{u}}{tr\\left[\\Phi_{vv}^{-1}\\phi_{ss}\\mathbf{g}\\mathbf{g}^H\\right]} \\\\ =\\frac{ \\Phi_{vv}^{-1}\\Phi_{xx}\\mathbf{u} }{ tr\\left[\\Phi_{vv}^{-1}\\Phi_{xx}\\right] } \\\\ =\\frac{ \\Phi_{vv}^{-1}(\\Phi_{yy}-\\Phi_{vv})\\mathbf{u} }{ tr\\left[ \\Phi_{vv}^{-1}(\\Phi_{yy}-\\Phi_{vv}) \\right] } \\\\ =\\frac{ (\\Phi_{vv}^{-1}\\Phi_{yy}-\\mathbf{I})\\mathbf{u} }{ tr\\left[\\Phi_{vv}^{-1}\\Phi_{yy}\\right]-N } \\end{align}$$ (19) åˆ° (20) ä½¿ç”¨äº† (9).(22) çš„å½¢å¼æ›¸æœ¬èªªå¾ˆé‡è¦, å› ç‚ºé¿å…äº†å¾ˆé›£ä¼°è¨ˆçš„ $\\mathbf{g}$, å–è€Œä»£ä¹‹çš„æ˜¯æˆ‘å€‘è¦ä¼°è¨ˆå‡º $\\Phi_{vv}$ MWF èˆ‡ MVDR ç­‰åƒ¹æƒ…å½¢åŒæ¨£ç‚ºäº†ç²¾ç°¡ä»¥ä¸‹ ${j\\omega}$ çœç•¥ä¸å¯«, é¦–å…ˆæˆ‘å€‘çŸ¥é“$$\\begin{align} \\Phi_{yy}=\\Phi_{vv} + \\phi_{ss}\\mathbf{g}\\mathbf{g}^H \\end{align}$$ ä½¿ç”¨ Woodburyâ€™s identity å¯å¾—:$$\\begin{align} \\Phi_{yy}^{-1}=\\Phi_{vv}^{-1}-\\frac{ \\Phi_{vv}^{-1}\\Phi_{xx}\\Phi_{vv}^{-1} }{ 1+tr\\left[\\Phi_{vv}^{-1}\\Phi_{xx}\\right] } \\end{align}$$ å°‡ (24) å¸¶å…¥åˆ° (17) ä¸¦ç¶“éä¸€äº›ä»£æ•¸æ›¿æ›æˆ‘å€‘å¾—åˆ°$$\\begin{align} \\mathbf{h}_{W}=\\frac{ \\Phi_{vv}^{-1}\\Phi_{xx} }{ 1+tr\\left[\\Phi_{vv}^{-1}\\Phi_{xx}\\right] }\\mathbf{u} \\end{align}$$ é€™å€‹å¼å­èˆ‡ MVDR çš„ (20) æ¯”è¼ƒä¸€ä¸‹æˆ‘å€‘ç™¼ç¾$$\\begin{align} \\mathbf{h}_{W}(j\\omega)=c(\\omega)\\mathbf{h}_{MVDR}(j\\omega) \\end{align}$$ å…¶ä¸­ $c(\\omega)$ æ˜¯èˆ‡ $\\omega$ ç›¸é—œçš„ä¸€å€‹ scalar. å› æ­¤ MWF èˆ‡ MVDR è§£åªå·®åœ¨ä¸€å€‹ $\\omega$ ç›¸é—œçš„å¸¸æ•¸é … Maximum SNR (MSNR)åŒæ¨£ç‚ºäº†ç²¾ç°¡ä»¥ä¸‹ ${j\\omega}$ çœç•¥ä¸å¯«, output SNR å®šç¾©ç‚º:$$\\begin{align} \\mbox{oSNR}\\left[\\mathbf{h}\\right]=\\frac{ \\mathbf{h}^H \\Phi_{xx} \\mathbf{h} }{ \\mathbf{h}^H \\Phi_{vv} \\mathbf{h} } \\end{align}$$ é€™å€‹ç­‰åŒæ–¼ generalized eigenvalue problem.$$\\begin{align} \\Phi_{xx}\\mathbf{h}=\\lambda\\Phi_{vv}\\mathbf{h} \\end{align}$$ æ‰€ä»¥$\\mathbf{h}_{MSNR}\\mbox{ is eigenvector w.r.t max eigenvalue of matrix } \\Phi_{vv}^{-1}\\Phi_{xx}$eigenvector ä¹˜ä¸Šä¸€å€‹ scalar ä»ç„¶æ˜¯ eigenvector, å› æ­¤é€šå¸¸éƒ½æœƒå°‡ $\\mathbf{h}_{MSNR}$ çš„ norm å®šç‚º 1 æ¥è‘—æˆ‘å€‘èªªæ˜ $\\mathbf{h}$ çš„è§£å…·æœ‰ä»¥ä¸‹å½¢å¼:$$\\begin{align} \\mathbf{h}\\propto\\Phi_{vv}^{-1}\\mathbf{g} \\end{align}$$ å…ˆå‡å®š (29) ç‚ºç­‰å¼:$$\\begin{align} \\mathbf{h}=\\Phi_{vv}^{-1}\\mathbf{g} \\end{align}$$ åˆ©ç”¨ (9) å’Œ (30) å¾—åˆ°ä»¥ä¸‹çš„æ¨å°$$\\begin{align} \\Phi_{vv}^{-1}\\Phi_{xx}\\mathbf{h}=\\Phi_{vv}^{-1} \\phi_{ss}\\mathbf{g}\\mathbf{g}^H \\mathbf{h}=\\left(\\Phi_{vv}^{-1}\\mathbf{g}\\right)\\left(\\phi_{ss}\\mathbf{g}^H\\mathbf{h}\\right)=\\mathbf{h}\\lambda \\end{align}$$ æˆ‘å€‘ç™¼ç¾ $\\mathbf{h}$ å¦‚æœ‰ (30) çš„å½¢å¼, å‰‡ç‚º maximum SNR (27) çš„è§£. ç•¶ç„¶ eigenvector ä¹˜ä¸Š scalar ä»ç„¶æ˜¯ eigenvector, æ‰€ä»¥ (29) ç‚º maximum SNR çš„è§£.æœ€å¾Œç”±æ–¼ $\\Phi_{xx}$ ç‚º rank 1 æ‰€ä»¥åªæœƒæœ‰ä¸€å€‹ nonzero eigenvalue, å› æ­¤ maximum SNR æ‰€æœ‰è§£çš„å½¢å¼å¿…ç„¶ç‚º (29) çš„å½¢å¼. MVDR èˆ‡ MSNR ç­‰åƒ¹æƒ…å½¢æª¢æŸ¥ä¸‹ (18) çš„ MVDR è§£, å¾ˆå¿«å°±ç™¼ç¾æ»¿è¶³ (29) MSNR çš„è§£çš„å½¢å¼, å› æ­¤$$\\begin{align} \\mathbf{h}_{MVDR}(j\\omega)=d(\\omega)\\mathbf{h}_{MSNR}(j\\omega) \\end{align}$$ çµè«–MWF, MVDR, MSNR ä¸‰å€‹å•é¡Œçš„è§£åœ¨ narrowband ä¸Šåªå·®åœ¨ scalar. ä½†ä»¥ fullband ä¾†èªª, è¡¨ç¾é‚„æ˜¯ä¸åŒçš„. Reference Microphone Array Signal Processing by Jocab Benesty Speech Processing in Modern Communication: Challenges and Perspectives","tags":[{"name":"MVDR","slug":"MVDR","permalink":"https://bobondemon.github.io/tags/MVDR/"},{"name":"MWF","slug":"MWF","permalink":"https://bobondemon.github.io/tags/MWF/"},{"name":"MSNR","slug":"MSNR","permalink":"https://bobondemon.github.io/tags/MSNR/"}]},{"title":"Far Field Notes (2) LCMV filter and Frost's algorithm","date":"2019-03-02T09:36:58.000Z","path":"2019/03/02/Far-Field-Notes-2-LCMV-and-Frost/","text":"é€™æ˜¯ far field ç­†è¨˜ç³»åˆ—ç¬¬äºŒç¯‡, ä¸»è¦ç‚ºè‡ªå·±å­¸ç¿’ç”¨, å¦‚æœ‰éŒ¯èª¤é‚„è«‹æŒ‡æ­£. ä¸»è¦åƒè€ƒ Microphone Array Signal Processing Ch4 å’Œ Frostâ€™s algorithm ä¸Šä¸€ç¯‡æœ€å¾Œé›–ç„¶ä½¿ç”¨ fixed beamformer å¾—åˆ°äº† response-invariant beamformer, ä½†é€™å€‹æ–¹æ³•é™åˆ¶æ˜¯ filter ä¸€æ—¦è¨­è¨ˆå¥½å°±å¯«æ­»äº†, æ²’è¾¦æ³•è‡ªå·± update (æ‰€ä»¥æ‰å« â€œfixedâ€ beamformer). é€™å¼•å…¥ä¸€å€‹å•é¡Œæ˜¯, å¦‚æœå‰›å¥½æœ‰ä¸€å€‹ inteference noise åœ¨è¡°æ¸›ä¸é‚£éº¼å¤§çš„è§’åº¦æ™‚, å°±ç„¡æ³•å£“å¾—å¾ˆå¥½. è€Œé€™ç¯‡è¦ä»‹ç´¹çš„ LCMV (Linear Constrained minimum variance) filter ä»¥åŠ Frostâ€™s beamformer èƒ½é‡å°çµ¦å®šçš„æ–¹å‘æŠ½å–è¨Šè™Ÿ, ä¸¦ä¸”å°å…¶ä»–æ–¹å‘çš„ inteference nosie å£“æŠ‘çš„æœ€å¥½. æ³¨æ„ sound source æ–¹å‘å¿…é ˆçµ¦å®š, LCMV æ±‚å¾—çš„ weights æœƒæƒ³è¾¦æ³•å°å…¶ä»–æ–¹å‘çš„ inteference å£“æŠ‘. å¦‚åŒ LCMV å­—é¢ä¸Šçš„æ„æ€ä¸€æ¨£. æœƒå°‡æ•´å€‹å•é¡Œè½‰æ›æˆ minimize variance subject to some linear constraints. å¦å¤–ç›¸ç•¶ç¶“å…¸çš„ Frostâ€™s beamformer (1972å¹´å‘¢!) å‰‡å°‡ filter çš„ optimal æ±‚è§£æ”¹æˆä½¿ç”¨ stochastic gradient descent æ–¹å¼, æ‰€ä»¥éå¸¸é©åˆå¯¦éš›çš„ real time ç³»çµ±, é€™äº›ä¸‹æ–‡æœƒè©³ç´°èªªæ˜. æ¶æ§‹è¨­å®šå’Œ Signal Modelæ¶æ§‹å¦‚ä¸‹åœ– (åœ–ç‰‡ä¾†æº:ref), ç¬¬ä¸€æ­¥æ˜¯ä¸€å€‹ delay stage, é€™ç›¸ç•¶æ–¼æ˜¯é‡å°ä¸€å€‹ steering direction è£œå„Ÿæ¯å€‹ mic ä¹‹é–“çš„ time delay (è¨Šè™Ÿå°é½Šå¥½). ç¬¬äºŒæ­¥æ‰æ˜¯ beamformer, æˆ‘å€‘çŸ¥é“ time domain ä½¿ç”¨ filter-and-sum æ¶æ§‹, å¦‚æœæ˜¯ frequency domain å‰‡ä½¿ç”¨æ‹†é »çš„æ¶æ§‹. å¿˜äº†å¯åƒè€ƒç¬¬ä¸€ç¯‡. æœ¬æ–‡ä»¥ filter-and-sum ä¾†ç­†è¨˜, å¦å¤– signal model ä»¥ä¸‹æ¨å°å°‡æœƒä½¿ç”¨ anechoic model, ç¬¬ä¸€ç¯‡æœ‰å®šç¾©å¯å›å»æŸ¥é–±. åŒæ™‚æœ¬æ–‡æ¥ä¸‹ä¾†çš„ notation æœƒèˆ‡åœ–ä¸­çš„ä¸åŒ. ä¸Šåœ–åªæ˜¯ç”¨ä¾†é¡¯ç¤º filter-and-sum æ¶æ§‹. Notationsä¸€äº› notations æˆ‘å€‘å…ˆå®šç¾©èµ·ä¾†. $N$ æ˜¯éº¥å…‹é¢¨æ•¸é‡, $L$ æ˜¯ filter tap æ•¸é‡, æˆ‘å€‘ aligned å¥½çš„ anechoic model å¦‚ä¸‹:$$\\begin{align} \\mathbf{y}(k)=s(k)\\mathbf{\\alpha}+\\mathbf{v}(k) \\end{align}$$å…¶ä¸­$$\\begin{align} \\mathbf{y}(k)=[y_1(k),...,y_N(k)]^T \\\\ \\mathbf{v}(k)=[v_1(k),...,v_N(k)]^T \\\\ \\mathbf{\\alpha}=[\\alpha_1,\\alpha_2,...,\\alpha_N]^T \\end{align}$$ $s(k)$ æ˜¯æ™‚é–“ $k$ çš„è²æºè¨Šè™Ÿ, $\\alpha$ æ˜¯ $N\\times 1$ çš„ attenuation factors, $\\mathbf{v}(k)$ æ˜¯æ™‚é–“ $k$ çš„ $N\\times 1$ noise è¨Šè™Ÿå‘é‡, å› æ­¤ $\\mathbf{y}(k)$ æ˜¯æ™‚é–“ $k$ çš„ $N\\times 1$ éº¥å…‹é¢¨æ”¶åˆ°çš„è¨Šè™Ÿå‘é‡. æ³¨æ„åˆ°ç”±æ–¼æˆ‘å€‘å…ˆ align å¥½ delay äº†, æ‰€ä»¥åŸå…ˆçš„ anechoic model å¯ä»¥ç°¡åŒ–æˆä¸Šé¢çš„è¡¨é”. è€ƒæ…®åˆ° filter-and-sum æ¶æ§‹, æˆ‘å€‘å°‡æ•´å€‹ $N$ å€‹ mic æ¯å€‹ mic éƒ½æœ‰ $L$ å€‹å€¼ä»¥ä¸‹åœ–(åœ–ç‰‡ä¾†æº:ref)çš„é †åºä¸²æˆä¸€å€‹ $NL$ vectorå› æ­¤æˆ‘å€‘å¾—åˆ°é€™äº›å‘é‡$$\\begin{align} \\mathbf{y}_{NL}(k)=[\\mathbf{y}^T(k), \\mathbf{y}^T(k-1), ..., \\mathbf{y}^T(k-L+1)]^T \\\\ \\mathbf{x}_{NL}(k)=[s(k)\\mathbf{\\alpha}^T, s(k-1)\\mathbf{\\alpha}^T, ..., s(k-L+1)\\mathbf{\\alpha}^T]^T \\\\ \\mathbf{v}_{NL}(k)=[\\mathbf{v}^T(k), \\mathbf{v}^T(k-1), \\mathbf{v}^T(k-L+1)]^T \\end{align}$$æ‰€ä»¥æ•´é«”çš„ signal model æ”¹å¯« (1) å¾Œå¯å¾—:$$\\begin{align} \\mathbf{y}_{NL}(k)=\\mathbf{x}_{NL}(k) + \\mathbf{v}_{NL}(k) \\end{align}$$ Filter-and-sum çš„ filter $\\mathbf{h}$ ä¹Ÿç”¨é€™å€‹é †åºå®šç¾©å¦‚ä¸‹, å› æ­¤æ˜¯ä¸€å€‹é•·åº¦ç‚º $NL$ çš„å‘é‡$$\\begin{align} \\mathbf{h}=[\\mathbf{h}_0^T, \\mathbf{h}_1^T, \\mathbf{h}_{L-1}^T]^T \\end{align}$$æœ€å¾Œæ•´å€‹ beamformer çš„è¼¸å‡º $z(k)$ å°±å¯ä»¥é€™éº¼å¯«$$\\begin{align} z(k)=\\mathbf{h}^T\\mathbf{y}_{NL}(k) = \\color{orange}{ \\mathbf{h}^T\\mathbf{x}_{NL}(k) } + \\color{blue}{ \\mathbf{h}^T\\mathbf{v}_{NL}(k) } \\end{align}$$ Problem DefinitionLCMV çš„ä¸»è¦æƒ³æ³•å°±åœç¹åœ¨ (10) çš„æ©˜è‰²å’Œè—è‰²å…©å€‹éƒ¨åˆ†ä¸Šé¢: æˆ‘å€‘å¸Œæœ›æ©˜è‰²éƒ¨åˆ†èƒ½å¤ é‚„åŸå‡ºåŸå§‹è¨Šè™Ÿ $s(k)$ ä¸”è—è‰²éƒ¨åˆ†èƒ½å¤ æ„ˆå°æ„ˆå¥½ (ä»£è¡¨è‘— noise æ„ˆå°æ„ˆå¥½). é¦–å…ˆæˆ‘å€‘å°‡æ©˜è‰²éƒ¨åˆ†ä½œå¦‚ä¸‹æ¨å°: $$\\begin{align} \\color{orange}{ \\mathbf{h}^T\\mathbf{x}_{NL}(k) } =\\mathbf{h}^T \\left[ \\begin{array}{clr} s(k)\\mathbf{\\alpha} \\\\ s(k-1)\\mathbf{\\alpha} \\\\ \\vdots \\\\ s(k-L+1)\\mathbf{\\alpha} \\end{array} \\right] = sum\\left( \\left[ \\begin{array}{clr} \\mathbf{h}_0^T\\mathbf{\\alpha}\\cdot s(k) \\\\ \\mathbf{h}_1^T\\mathbf{\\alpha}\\cdot s(k-1) \\\\ \\vdots \\\\ \\mathbf{h}_{L-1}^T\\mathbf{\\alpha}\\cdot s(k-L+1) \\end{array} \\right] \\right) \\\\ = sum\\left( \\color{red}{ \\left[ \\begin{array}{clr} u_0\\cdot s(k) \\\\ u_1\\cdot s(k-1) \\\\ \\vdots \\\\ u_{L-1}\\cdot s(k-L+1) \\end{array} \\right] } \\right) \\end{align}$$ (12) ç‚ºå¼•å…¥çš„æ¢ä»¶, è—‰ç”±é€™æ¨£çš„æ¢ä»¶ä¾†é‚„åŸåŸå§‹è¨Šè™Ÿ.$u$ ($L$é•·åº¦çš„å‘é‡) å®šç¾©äº†æˆ‘å€‘å¸Œæœ›åœ¨æ™‚é–“ $k$ çš„é‚„åŸçµæœ, æ˜¯åŸå§‹è¨Šè™Ÿçš„æ¬Šé‡å’Œå®šç¾©ä¸€å€‹ matrix (size of $NL\\times L$) å¦‚ä¸‹: $$\\begin{align} \\mathbf{C}_{\\mathbf{\\alpha}}= \\left[ \\begin{array}{clr} \\mathbf{\\alpha} &amp; \\mathbf{0} &amp; \\cdots &amp; \\mathbf{0} \\\\ \\mathbf{0} &amp; \\mathbf{\\alpha} &amp; \\cdots &amp; \\mathbf{0} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\mathbf{0} &amp; \\mathbf{0} &amp; \\cdots &amp; \\mathbf{\\alpha} \\\\ \\end{array} \\right] = \\left[ \\begin{array}{clr} \\mathbf{c}_{\\alpha,0} &amp; \\mathbf{c}_{\\alpha,1} &amp; \\cdots &amp; \\mathbf{c}_{\\alpha,L-1} \\\\ \\end{array} \\right] \\end{align}$$ è§€å¯Ÿ (11) and (12) ä¸¦åˆ©ç”¨ $\\mathbf{C_{\\alpha}}$ å¯ä»¥å°‡ constraint æ˜ç¢ºå¯«å‡ºå¦‚ä¸‹: $$\\begin{align} \\mathbf{C_{\\alpha}}^T\\mathbf{h}=\\mathbf{\\mathbf{u}} \\end{align}$$ è—è‰²éƒ¨åˆ†ä»£è¡¨æœ€å¾Œçš„ noise æˆåˆ†, å¸Œæœ›æ„ˆå°æ„ˆå¥½è¨ˆç®—è—è‰²éƒ¨åˆ†çš„èƒ½é‡ç‚º $$\\begin{align} \\mathbf{h}^T \\mathbb{E} \\left[ \\mathbf{v}_{NL}(k)\\mathbf{v}_{NL}^T(k) \\right] \\mathbf{h}=\\mathbf{h}^T\\mathbf{R}_{\\mathbf{v},\\mathbf{v}}\\mathbf{h} \\end{align}$$ ä½†é—œéµæ˜¯æˆ‘å€‘ç„¡æ³•å¾—çŸ¥å¯¦éš›çš„ noise signal, æˆ‘å€‘æœ‰çš„åªæœ‰ observation $\\mathbf{y}_{NL}(k)$, é‚£è©²æ€éº¼è¾¦å‘¢?LCMV å¾ˆå²å®³çš„ä¸€é»æ˜¯, ç”±æ–¼ä¸Šé¢å‰›æåˆ°çš„ constraints, å°è‡´æ©˜è‰²éƒ¨åˆ†çš„èƒ½é‡æ˜¯ constant, å› æ­¤ä»¥ä¸‹å…©å€‹å•é¡Œæ˜¯ç­‰åƒ¹çš„ $$\\begin{align} \\min_{\\mathbf{h}}{ \\mathbf{h}^T\\mathbf{R}_{\\mathbf{v},\\mathbf{v}}\\mathbf{h} } \\equiv \\min_{\\mathbf{h}}{ \\mathbf{h}^T\\mathbf{R}_{\\mathbf{y},\\mathbf{y}}\\mathbf{h} } \\end{align}$$ åˆ°é€™è£¡æˆ‘å€‘å¯ä»¥å¯«å‡ºå®Œæ•´çš„æœ€ä½³åŒ–å•é¡Œ$$\\begin{align} \\begin{array}{clr} \\color{blue}{ \\min_{\\mathbf{h}}{ \\mathbf{h}^T\\mathbf{R}_{\\mathbf{y},\\mathbf{y}}\\mathbf{h} } } \\\\ \\color{orange}{ \\mbox{subject to }\\mathbf{C_{\\alpha}}^T\\mathbf{h}=\\mathbf{\\mathbf{u}} } \\end{array} \\end{align}$$ Optimal Solutionè¦è§£å•é¡Œ (17), åŸºæœ¬ä¸Šä½¿ç”¨ Lagrange function æ±‚è§£å°±å¯ä»¥, è§£å¦‚ä¸‹:$$\\begin{align} \\mathbf{h}=\\mathbf{R}_{\\mathbf{y},\\mathbf{y}}^{-1}\\mathbf{C_{\\alpha}} \\left( \\mathbf{C_{\\alpha}}^T \\mathbf{R}_{\\mathbf{y},\\mathbf{y}}^{-1} \\mathbf{C_{\\alpha}} \\right)^{-1} \\mathbf{u} \\end{align}$$ ä½†æ˜¯é‡é»ä¾†äº†, ä»¥ä¸Šé€™äº›æ¨å°å…¨éƒ¨éƒ½å‡è¨­æ˜¯ stationary, å¯¦éš›æƒ…æ³ä¸€å®šæ˜¯ non-stationary æ€éº¼è¾¦? æœ€ç›´è¦ºçš„æƒ³æ³•å°±æ˜¯, æˆ‘å€‘æ¯éš”ä¸€æ®µæ™‚é–“å°±ç”¨ (18) é‡æ–°ç®—ä¸€ä¸‹ $\\mathbf{h}$. ä½†å¾ˆæ˜é¡¯é€™éå¸¸æ²’æ•ˆç‡ (covarianceä¼°è¨ˆ, inverseé‹ç®—) æ ¹æœ¬ä¸å¯è¡Œ. å› æ­¤å¿…é ˆæ”¹æˆ iteratively update $\\mathbf{h}$ çš„æ–¹å¼.Frostâ€™s algorithm çš„ä¸€å€‹é‡è¦è²¢ç»ä¹Ÿå°±æ˜¯åœ¨é€™, ä½¿ç”¨ stochastic gradient descent æ–¹å¼ update $\\mathbf{h}$! Frostâ€™s Algorithmå•é¡Œ (17) çš„ Lagrange function å¦‚ä¸‹:$$\\begin{align} \\mathcal{L}(\\mathbf{h},\\mathbf{\\lambda}) = \\frac{1}{2} \\mathbf{h}^T\\mathbf{R}_{\\mathbf{y},\\mathbf{y}}\\mathbf{h} + \\mathbf{\\lambda}^T(\\mathbf{C_{\\alpha}}^T\\mathbf{h}-\\mathbf{\\mathbf{u}}) \\end{align}$$å› æ­¤ gradient å¦‚ä¸‹:$$\\begin{align} \\nabla_{\\mathbf{h}}\\mathcal{L} = \\mathbf{R}_{\\mathbf{y},\\mathbf{y}}\\mathbf{h} + \\mathbf{C_{\\alpha}}\\mathbf{\\lambda} \\end{align}$$gradient descent update å¼å­å¦‚ä¸‹:$$\\begin{align} \\mathbf{h}_{t+1} = \\mathbf{h}_{t} - \\mu \\left( \\mathbf{R}_{\\mathbf{y},\\mathbf{y}}\\mathbf{h}_t + \\mathbf{C_{\\alpha}}\\mathbf{\\lambda}_t \\right) \\end{align}$$ç”±æ–¼æœ‰ constraint, å¿…é ˆæ»¿è¶³ update å¾Œä»ç„¶æ»¿è¶³æ¢ä»¶, å› æ­¤:$$\\begin{align} \\mathbf{u}=\\mathbf{C_{\\alpha}}^T\\mathbf{h}_{t+1} \\end{align}$$å°‡(21)å¸¶å…¥(22)æ•´ç†å¾—åˆ°$\\lambda_t$, æ¥è‘—å†å°‡$\\lambda_t$å¸¶å›(21)å¾—åˆ°çµæœå¦‚ä¸‹, ä¸¦ä¸å›°é›£åªæ˜¯ä¸€äº›ä»£æ•¸é‹ç®—:$$\\begin{align} \\mathbf{h}_{t+1} = \\mathbf{h}_{t} - \\mu \\left[ \\mathbf{I} - \\mathbf{C}(\\mathbf{C}^T\\mathbf{C})^{-1}\\mathbf{C}^T \\right] \\mathbf{R}_{\\mathbf{y},\\mathbf{y}} \\mathbf{h}_{t} + \\mathbf{C}(\\mathbf{C}^T\\mathbf{C})^{-1} \\left[ \\mathbf{u}-\\mathbf{C}^T\\mathbf{h}_t \\right] \\end{align}$$å®šç¾©å…©å€‹ matrix $\\mathbf{A}$, $\\mathbf{B}$ å¦‚ä¸‹ (æ³¨æ„åˆ°é€™å…©å€‹ matrix æ˜¯äº‹å…ˆè¨ˆç®—å¥½çš„):$$\\begin{align} \\mathbf{A} \\triangleq \\mathbf{C}(\\mathbf{C}^T\\mathbf{C})^{-1}\\mathbf{u} \\\\ \\mathbf{B} \\triangleq \\mathbf{I} - \\mathbf{C}(\\mathbf{C}^T\\mathbf{C})^{-1}\\mathbf{C}^T \\end{align}$$å› æ­¤å¯ä»¥æ”¹å¯«(23)å¦‚ä¸‹:$$\\begin{align} \\mathbf{h}_{t+1} = \\mathbf{B}[\\mathbf{h}_t - \\mu \\mathbf{R}_{\\mathbf{y},\\mathbf{y}} \\mathbf{h}_t] + \\mathbf{A} \\end{align}$$ç”±æ–¼ä½¿ç”¨ stochastic æ–¹å¼, å› æ­¤ expectation ä½¿ç”¨æœ€æ–°çš„ä¸€æ¬¡ sample å³å¯:$$\\begin{align} \\mathbf{R}_{\\mathbf{y},\\mathbf{y}} = \\mathbb{E} \\left[ \\mathbf{y}_{NL}(t)\\mathbf{y}_{NL}^T(t) \\right] \\thickapprox \\color{green}{ \\mathbf{y}_{NL}(t)\\mathbf{y}_{NL}^T(t) } \\end{align}$$å°‡(27)å¸¶å…¥(26)ä¸¦ç”¨(10)æ›¿æ›ä¸€ä¸‹, æˆ‘å€‘å¾—åˆ°æœ€çµ‚çš„ update å¼å­:$$\\begin{align} \\color{red}{ \\mathbf{h}_{t+1} = \\mathbf{B}[\\mathbf{h}_t - \\mu z(t)\\mathbf{y}_{NL}(t)] + \\mathbf{A} } \\end{align}$$ç”±æ–¼ $\\mathbf{A}$ å’Œ $\\mathbf{B}$ æ˜¯å›ºå®šçš„, è·ŸåŸä¾†çš„ optimal è§£æ¯”è¼ƒ (18), å¯ä»¥æ˜é¡¯çŸ¥é“é€Ÿåº¦ä¸Šæœƒå¿«éå¸¸å¤š.å¦å¤– $\\mathbf{h}_0$ åªéœ€è¦é¸æ“‡ä¸€å€‹ trivial çš„ feasible point å³å¯:$$\\begin{align} \\mathbf{h}_{0} = \\mathbf{A} \\end{align}$$ çµè«–æœ¬ç¯‡è¨˜éŒ„äº† filter-and-sum æ¶æ§‹çš„ beamformer, LCMV çš„å•é¡Œå’Œå…¶æœ€ä½³è§£. LCMV å¯ä»¥é‡å°çµ¦å®šçš„ä¸€å€‹æ–¹å‘, æ‰¾å‡º filter $\\mathbf{h}$ ä½¿å¾—æŠ½å–çœ‹çš„æ–¹å‘çš„è¨Šè™ŸåŒæ™‚å£“æŠ‘å…¶ä»–æ–¹å‘çš„è¨Šè™Ÿ.å¯¦ä½œä¸Šç›´æ¥å¥—ç”¨æœ€ä½³è§£å¤ªæ…¢ä¸å¯è¡Œ, è€Œ Frostâ€™s algorithm æä¾›äº†ä¸€å€‹ stochastic gradeint update æ–¹æ³•æ›´æ–° $\\mathbf{h}$, é€™ä½¿å¾— real-time system è®Šå¾—å¯è¡Œ. Reference Microphone Array Signal Processing by Jocab Benesty Frostâ€™s algorithm","tags":[{"name":"LCMV","slug":"LCMV","permalink":"https://bobondemon.github.io/tags/LCMV/"},{"name":"Frost","slug":"Frost","permalink":"https://bobondemon.github.io/tags/Frost/"},{"name":"MVDR","slug":"MVDR","permalink":"https://bobondemon.github.io/tags/MVDR/"}]},{"title":"Far Field Notes (1), Beampattern","date":"2019-02-26T12:22:55.000Z","path":"2019/02/26/Far-Field-Notes-1-Beampattern/","text":"é€™æ˜¯ far field ç­†è¨˜ç³»åˆ—ç¬¬ä¸€ç¯‡, ä¸»è¦ç‚ºè‡ªå·±å­¸ç¿’ç”¨, å¦‚æœ‰éŒ¯èª¤é‚„è«‹æŒ‡æ­£. ä¸»è¦åƒè€ƒ Optimum Array Processing Ch2 ä»¥åŠ Microphone Array Signal Processing Ch3. Beampattern å°±æ˜¯å¸Œæœ›èƒ½å¾—åˆ°å¦‚ä¸‹åœ– [ref Fig3.3] çš„è¡¨ç¤º, èªªæ˜ç¶“éä¸€å€‹éº¥å…‹é¢¨é™£åˆ—çš„è™•ç†å¾Œ, æ¯å€‹è§’åº¦æ‰€å¾—åˆ°çš„å¢ç›Šæƒ…å½¢. å› æ­¤å¯ä»¥çœ‹å‡ºä¸»è¦ä¿ç•™å“ªäº›æ–¹å‘çš„è¨Šè™Ÿ, ä»¥åŠæŠ‘åˆ¶å“ªäº›æ–¹å‘çš„è¨Šè™Ÿ. Geometry Settingsé å ´ä¸€èˆ¬å‡è¨­ plan wave, å’Œ narrow band. å¯¦éš›è™•ç†èªéŸ³ç­‰ broadband æ™‚æˆ‘å€‘æœƒæ¡å– fft åˆ†é ». æˆ‘å€‘å®šç¾©å¦‚ä¸‹çš„ geometry, å…¶ä¸­é‡è¦çš„å…©å€‹è§’åº¦ç‚º $\\theta$ å’Œ $\\phi$ (å¦‚åœ–ç´…åœˆ). $\\mathbf{a}$ è¡¨ç¤ºè²æºçš„å…¥å°„å–®ä½å‘é‡. ä»¥ä¸‹ç¬¦è™Ÿå¦‚æœæ˜¯ç²—é«”è¡¨ç¤ºç‚ºå‘é‡æˆ–çŸ©é™£, å¦å‰‡å°±æ˜¯ scalar. Signal Modelæˆ‘å€‘å®šç¾© $f(t)$ ç‚ºè²æºè¨Šè™Ÿ, $v_n(t)$ ç‚º nth mic çš„å™ªè²æº Anechoic Model æˆ‘å€‘ä»¥ä¸‹çš„ä»‹ç´¹éƒ½æ˜¯åŸºæ–¼ Anechoic Model, ä¸¦ä¸”å…ˆåšå¦‚ä¸‹çš„ç°¡åŒ– Reverberant Model ç›¸ç•¶æ–¼å°‡ attenuation factor $\\alpha$ æ”¹æˆ impulse response, æ‰€ä»¥ç›¸ä¹˜æ”¹æˆ convolution. Time Delayç‚ºäº†æ–¹ä¾¿æ¨å°éº¥å…‹é¢¨ä¹‹é–“çš„ time delay, æˆ‘å€‘å…ˆå°‡ Anechoic Model åšå¦‚ä¸‹ç°¡åŒ– å› æ­¤å°æ–¼ plan wave å‡è¨­å’Œè²æºçš„å…¥å°„å–®ä½å‘é‡ $a$ ä¾†èªª, æˆ‘å€‘å¾ˆå®¹æ˜“å°±å¾—åˆ° time delay å¦‚ä¸‹ Uniform Lineary Array (ULA) Circular Arrayä»¥ä¸€å€‹ 6 mic çš„ circular array ä¾†èªª, æœ‰å¦‚ä¸‹çš„ time delay Array Manifold Vectorç”±æ–¼ time delay $\\tau$ åœ¨ freqeuncy $\\omega$ åªæ˜¯ä¹˜ä¸Š $e^{-j\\omega\\tau}$, å› æ­¤æˆ‘å€‘å¯ä»¥å¾—åˆ°ä¸€å€‹ compact çš„è¡¨ç¤º é‡è¤‡ä¸€éé€™è£¡å¾—åˆ°çš„é‡è¦å¼å­ $$\\begin{align} \\color{red}{ \\mathbf{F}(\\omega,\\mathbf{p})=F(\\omega)\\mathbf{\\upsilon}_k(\\mathbf{k}) } \\end{align}$$ æˆ‘å€‘ç¨± $\\mathbf{\\upsilon}_k(\\mathbf{k})$ ç‚º Array Manifold Vector. è¦æ³¨æ„çš„æ˜¯, å…¶å¯¦ä¹Ÿå¯ä»¥ç”¨ time delay $\\tau$ ä¾†è¡¨ç¤º, é€™æ™‚æˆ‘å€‘é€™éº¼å¯« (å¦‚ä¸Šåœ–ç°è‰²çš„éƒ¨åˆ†)$$\\mathbf{\\upsilon}_\\tau (\\mathbf{\\tau})= \\left[ \\begin{array}{clr} e^{-j\\omega\\tau_0} \\\\ e^{-j\\omega\\tau_1} \\\\ \\vdots \\\\ e^{-j\\omega\\tau_{N-1}} \\end{array} \\right]$$æˆ–ç”šè‡³å…¥å°„è§’åº¦ $\\theta$ å¦‚æœå¯ä»¥å®Œå…¨è¡¨é” $\\tau$ çš„è©±, æˆ‘å€‘ä¹Ÿèƒ½é€™éº¼å¯« $\\mathbf{\\upsilon}_\\theta(\\mathbf{\\theta})$. Array Signal Processingæ—©æœŸçš„ array processing (narrow band) æ˜¯å°æ¯å€‹éº¥å…‹é¢¨æœ‰å„è‡ªçš„ weights, ç„¶å¾Œå†ç¸½åˆèµ·ä¾†, é€™ç¨®ä½œæ³•å«åš weight-and-sum. è€Œå°æ–¼ broadband è¨Šè™Ÿä¾†èªª, ç›¸ç•¶æ–¼æ‹†é »ä¹˜å¾ˆå¤š narrow band, å› æ­¤åœ¨æ¯å€‹é »å¸¶ä¸Š, éƒ½æœ‰ N å€‹éº¥å…‹é¢¨çš„ weights. é€™åœ¨æ™‚åŸŸä¸Šç­‰åƒ¹æ–¼æ¯å€‹éº¥å…‹é¢¨éƒ½æœ‰å„è‡ªçš„ filters, ç¨± filter-and-sum. ä»¥ä¸‹ä»‹ç´¹ filter-and-sum å’Œé »åŸŸçš„æ¶æ§‹. Filter-and-Sum åœ¨å¯¦ä½œä¸Šé€šå¸¸æ¡ç”¨ FIR filter, å› æ­¤æ¶æ§‹å¦‚ä¸‹:ç¬¦è™Ÿæœ‰é»ä¸åŒ, é€™æ˜¯å› ç‚ºåœ–æ˜¯æ¡ç”¨å¦ä¸€æœ¬æ›¸ Microphone Array Signal Processing Frequency Domainé‡å° filter-and-sum åš frequency transform å¾—åˆ°å¦‚ä¸‹: å¯¦éš›æ¶æ§‹åœ–å¦‚ä¸‹:ä¸€æ¨£ç¬¦è™Ÿæœ‰é»ä¸åŒ, é€™æ˜¯å› ç‚ºåœ–æ˜¯æ¡ç”¨å¦ä¸€æœ¬æ›¸ Microphone Array Signal Processing Frequency-wavenumber Response Functioné‡å° frequency domain çš„ array processing, æˆ‘å€‘å¯ä»¥å¸¶å…¥å…ˆå‰æ¨å¾—çš„ (1) å¾—åˆ°å¦‚ä¸‹: æ‰€ä»¥ $\\Upsilon(\\omega,\\mathbf{k})$ ç‰©ç†æ„ç¾©å°±æ˜¯é‡å° frequency $\\omega$ å’Œ wavenumber $\\mathbf{k}$ (æ§åˆ¶äº†è²æºå…¥å°„è§’åº¦ $\\theta$ ç­‰ç­‰çš„ç‰©ç†é‡) çš„ response. Beampatternwavenumber $\\mathbf{k}$ æ¯”è¼ƒæŠ½è±¡, å¦‚æœæˆ‘å€‘æ›æˆè§’åº¦ $\\theta$, $\\phi$ å°±æœƒç›´è§€å¾ˆå¤š, è€Œ beampattern åªæ˜¯é‡å° $\\Upsilon(\\omega,\\mathbf{k})$ æ›æˆç”¨è§’åº¦è€Œå·². æ‰€ä»¥ $B(\\omega:\\theta,\\phi)$ ç‰©ç†æ„ç¾©å°±æ˜¯é‡å° frequency $\\omega$ å’Œå…¥å°„è§’åº¦ $\\theta$, $\\phi$ çš„ response. Delay-and-sum BeampatternDelay-and-sum æƒ³æ³•å¾ˆç°¡å–®, å°±æ˜¯è£œå„Ÿæ¯å€‹ mic çš„ time delay è€Œå·². å› æ­¤æ‰€éœ€è¦çš„ filter $H(\\omega)$ å°±æ˜¯ array manifold vector çš„ conjugate å³å¯. å¦‚ä¸‹åœ–: ä½†é€™éº¼åšæœ‰å€‹ç¼ºé», å°±æ˜¯é«˜é »æ™‚é›–ç„¶é‡å°è²æºæ–¹å‘çš„ mainlobe è®Šçª„äº†, ä½†åŒæ™‚ sidelobe å»è®Šå¤šäº†. ä¹Ÿå°±æ˜¯åœ¨é«˜é »æ™‚, æŸäº›æ–¹å‘çš„è²æºæ¶ˆä¸æ‰. å¦‚ä¸‹åœ–: Fixed Beampatternç‚ºäº†ä¿®æ­£ä¸Šè¿° DS beamformer çš„å•é¡Œ, æˆ‘å€‘å¸Œæœ›å¾—åˆ° response-invariant broadband beamformer. å¸Œæœ›èƒ½æœ‰ä¸‹åœ–çš„çµæœ: ä¸­å¿ƒæ€æƒ³å¾ˆç°¡å–®, é‡å°æŸå€‹é »ç‡ $\\omega$ ä¾†æ±‚å‡ºç›¸å°æ‡‰çš„ $H$ ä½¿å¾— beampattern æœƒèˆ‡æˆ‘å€‘ desired beampattern æœ‰ least-sqaure å·®ç•°. ä»¥ä¸‹ $H(\\omega)$ æœƒçœç•¥ $\\omega$ ä¸å¯« çµè«–åˆ°é€™è£¡æˆ‘å€‘è¨è«–äº†é å ´çš„ signal model, é‡å° anechoic model æˆ‘å€‘æœ€çµ‚å°å‡ºäº† beampattern. åšç‚ºä¾‹å­æˆ‘å€‘ä½¿ç”¨ç°¡å–®çš„ delay-and-sum (DS) beamformer ä¾†çœ‹å®ƒçš„ beampattern é•·ä»€éº¼æ¨£. å¯ä»¥çœ‹åˆ°åœ¨é«˜é »æ™‚å¾ˆå¤šæ–¹å‘é‚„æ˜¯ç„¡æ³•å£“æŠ‘, å› æ­¤ä½¿ç”¨ least-square æ–¹æ³•æ‰¾å‡ºæ¯å€‹é »ç‡éœ€è¦çš„ spatial filter ä¾†é€¼è¿‘æˆ‘å€‘éœ€è¦çš„ beampattern. Reference Optimum Array Processing: Part IV of Detection, Estimation, and Modulation Theory by Harry L. Van Trees Microphone Array Signal Processing by Jocab Benesty Direction of Arrival Estimation Using the Parameterized Spatial Correlation Matrix","tags":[{"name":"array manifold vector","slug":"array-manifold-vector","permalink":"https://bobondemon.github.io/tags/array-manifold-vector/"},{"name":"beampattern","slug":"beampattern","permalink":"https://bobondemon.github.io/tags/beampattern/"},{"name":"anechoic model","slug":"anechoic-model","permalink":"https://bobondemon.github.io/tags/anechoic-model/"},{"name":"wavenumber","slug":"wavenumber","permalink":"https://bobondemon.github.io/tags/wavenumber/"}]},{"title":"Bayesian Learning Notes","date":"2018-12-20T14:39:42.000Z","path":"2018/12/20/Bayesian-Learning-Notes/","text":"æ‰è²»æˆ‘å­¸ç¿’ ML é€™éº¼ä¹…, æœ€è¿‘æ‰å®Œæ•´äº†è§£ Bayesian learning å¤§æ¶æ§‹, ä»¥åŠèˆ‡ MLE, MAP, Variational Inference, Sampling ä¹‹é–“çš„é—œè¯. é€™æ‰çµ‚æ–¼æœ‰äº†è¦‹æ¨¹åˆè¦‹æ—çš„æ¸¯è¦ºé˜¿! ç­†è¨˜æ•´ç†å¦‚ä¸‹ â€¦ åœ–ç‰‡ä¾†è‡ª wiki, æˆ‘ä¹Ÿå¥½æƒ³è¦é€™å€‹è£é£¾ç‡ˆ. å°±é€™éº¼ä¸€å€‹ Bayeâ€™s Rule, æ’èµ·äº†çµ±è¨ˆæ©Ÿå™¨å­¸ç¿’çš„åŸºçŸ³! Bayesian Learningçµ¦å®šè¨“ç·´é›† ($X,Y$) å’Œä¸€å€‹ probabilistic classifier $p(y|x,\\theta)$, åŒæ™‚å®šç¾©å¥½ prior distribution $p(\\theta)$. æ ¹æ“š Bayeâ€™s rule, Training stage å¦‚ä¸‹: $$\\begin{align} p(\\theta|X,Y)=\\frac{p(Y|X,\\theta)p(\\theta)}{\\color{red}{\\int p(Y|X,\\theta)p(\\theta)\\,d\\theta}} \\end{align}$$ Testing stage å¦‚ä¸‹: $$\\begin{align} p(y^*|x^*,X,Y)=\\color{red}{\\int p(y^*|x^*,\\theta)p(\\theta|X,Y)\\,d\\theta} \\end{align}$$ æ³¨æ„åˆ°é—œéµçš„å…©å€‹ç´…è‰²ç©åˆ†é€šå¸¸éƒ½æ˜¯ä¸å®¹æ˜“ç®—, æˆ–æ ¹æœ¬ç®—ä¸å‡ºä¾†. æ­¤æ™‚æˆ‘å€‘æœ‰å…©ç¨®é¸æ“‡: ä½¿ç”¨ Variational Inference æ‰¾å‡ºä¸€å€‹ $q(\\theta)$ ä¾†é€¼è¿‘ $p(\\theta|X,Y)$ ä½¿ç”¨ sampling æ–¹æ³•. ç†è§£ä¸€ä¸‹é€™å€‹ç©åˆ†çš„å½¢å¼, å¯ä»¥ç™¼ç¾é€™æ˜¯åœ¨ç®—æ ¹æ“šæŸå€‹æ©Ÿç‡åˆ†ä½ˆ$p(x)$è¨ˆç®—$f(x)$çš„æœŸæœ›å€¼. å› æ­¤, å¦‚æœæˆ‘å€‘ç›´æ¥æ ¹æ“š $p(x)$ sample å‡º $M$ å€‹ $x$, å°±å¯ä»¥ç”¨å¦‚ä¸‹çš„å¹³å‡ç®—å‡ºè¿‘ä¼¼å€¼äº†. $$\\begin{align} \\int p(x)f(x) \\,dx \\simeq \\frac{1}{M}\\sum_{i=1}^M f(x_i)\\mbox{, where }x_i \\sim p(x) \\end{align}$$ æˆ‘å€‘å¯èƒ½æœƒæƒ³, æ˜¯ä¸æ˜¯å¯ä»¥å°‡ Bayesian learning åšäº›ç°¡åŒ–ä¾†é¿æ‰ä¸Šè¿°ç´…è‰²ç©åˆ†? æ˜¯çš„, MLE å’Œ MAP å°±æ˜¯ç°¡åŒ–äº†å®Œæ•´çš„ Bayesian learning éç¨‹. ä¸‹é¢ä»‹ç´¹. MLE and MAPBayeâ€™s rule (å¼ (1)), åœ¨ ML ä¸­èˆ‰è¶³è¼•é‡, å¹¾ä¹æ˜¯æ‰€æœ‰çš„æ ¹æœ¬. é‡æ–°åˆ—å‡ºä¾†ä¸¦ç”¨ä¸åŒé¡è‰²åšå¼·èª¿ $$\\begin{align} \\color{orange}{p(\\theta|X,Y)}=\\frac{\\color{blue}{p(Y|X,\\theta)}\\color{green}{p(\\theta)}}{\\color{red}{\\int p(Y|X,\\theta)p(\\theta)\\,d\\theta}} \\end{align}$$ æ©˜è‰²ç¨±ç‚º posterior distribution, è—è‰²ç‚º likelihood, è€Œç¶ è‰²ç‚º prior distribution. æ³¨æ„åˆ°ç´…è‰²çš„æœŸæœ›å€¼åŸºæœ¬ç®—ä¸å‡ºä¾†, åœ¨é€™ç¨®æƒ…æ³ä¸‹, æˆ‘å€‘è¦æ€éº¼å¾—åˆ° posterior? MLEMLE (Maximum Likelihood Estimation) çš„æƒ³æ³•æ˜¯, æ—¢ç„¶ posterior ç®—ä¸å‡ºä¾†, é‚£ä¹¾è„†ç›´æ¥ç”¨ä¸€å€‹ $\\theta^*$ ä»£è¡¨æ•´å€‹ $p(\\theta|X,Y)$ åˆ†å¸ƒç®—äº†. è‡³æ–¼è¦æ‰¾å“ªä¸€é»å‘¢, å°±æ‰¾å° likelihood æœ€å¤§çš„é‚£é»å§! æ•¸å­¸é€™éº¼å¯«: $$\\begin{align} \\theta_{MLE}=\\arg\\max_\\theta p(Y|X,\\theta) \\end{align}$$ æ—¢ç„¶å·²ç¶“ç”¨ä¸€å€‹é»ä¾†ä»£è¡¨æ•´å€‹ posterior äº†, å› æ­¤åŸä¾†çš„ testing (2) å°±ä¸éœ€è¦ç©åˆ†äº†, testing stage ç›´æ¥å°±æ˜¯: $$\\begin{align} p(y^*|x^*,\\theta_{MLE}) \\end{align}$$ MAPMAP (Maximum A Posterior) estimation è·Ÿ MLE ç›¸åŒ, ä¹Ÿä½¿ç”¨ä¸€å€‹é»ä¾†ä»£è¡¨æ•´å€‹ posterior: $$\\begin{align} \\theta_{MP}=\\arg\\max_\\theta p(\\theta|X,Y) \\end{align}$$ æ„æ€æ˜¯ MAP ç›´æ¥ä½¿ç”¨ mode ä¾†ä»£è¡¨æ•´å€‹ posterior. å› æ­¤ testing stage ä¹Ÿå¦‚åŒ MLE æƒ…å½¢: $$\\begin{align} p(y^*|x^*,\\theta_{MP}) \\end{align}$$ ä¸éè°æ˜çš„è®€è€…æ‡‰è©²æœƒè¦ºå¾—å¾ˆç–‘æƒ‘, posterior ä¸æ˜¯å¾ˆé›£è¨ˆç®—, æˆ–æ ¹æœ¬ç®—ä¸å‡ºä¾†, é€™æ¨£æ€éº¼å¯èƒ½æ‰¾çš„åˆ° mode? æ˜¯çš„, ä¸€èˆ¬æƒ…å½¢ä¸‹æ˜¯æ‰¾ä¸å‡ºä¾†, ä½†æœ‰ä¸€å€‹ç‰¹æ®Šæƒ…æ³å«åš conjugate prior. conjugate prior æŒ‡çš„æ˜¯ prior èˆ‡ posterior å±¬æ–¼åŒä¸€å€‹ distribution family, ç­‰æ–¼æ˜¯å‘Šè¨´æˆ‘å€‘ posterior æ˜¯ä»€éº¼æ¨£çš„ distribution, å› æ­¤ç®—ä¸å‡ºä¾†çš„ç´…è‰²æœŸæœ›å€¼(å¼(4))ä¹Ÿæ ¹æœ¬æ²’å¿…è¦å»è¨ˆç®—, åªä¸éæ˜¯å€‹ normalization constant. å› æ­¤æ˜ç¢ºçŸ¥é“ posterior æ˜¯ä»€éº¼æ¨£çš„ distribution, æ‰¾ mode å°±å®¹æ˜“å¤šäº†. æ‰€ä»¥å°æ–¼ MAP ä¾†èªªæœ‰å“ªäº› distribution æ˜¯äº’ç‚º conjugate è®Šå¾—å¾ˆé‡è¦. æˆ‘å€‘å¯ä»¥å¾ wiki ä¸ŠæŸ¥åˆ°æ˜ç¢ºè³‡æ–™. åŸºæœ¬ä¸Š exponential family éƒ½æ˜¯. å®Œå…¨é¿æ‰ç´…è‰²ç©åˆ†é …äº†å—?å¾ˆå¤šæ¨¡å‹éƒ½å…·æœ‰ latent variable (ä¸€èˆ¬éƒ½ç”¨ $z$ è¡¨ç¤º) çš„å½¢å¼ ç¨å¾®èªªæ˜ä¸‹, ä¸€èˆ¬èªªçš„ latent variable æœƒéš¨è‘— data è®Šå¤§è€Œè®Šå¤§, è€Œ parameter $\\theta$ ä¸æœƒ. ä»¥ GMM ç‚ºä¾‹å­, latent variable æŒ‡æ¯ä¸€å€‹ observation æ˜¯å“ªä¸€å€‹ Gaussian ç”¢ç”Ÿå‡ºä¾†çš„é‚£å€‹ index, è€Œ parameter æ˜¯ Gaussian components çš„ mean, var, å’Œ mixture weights é›†åˆ. å¯ä»¥ä½¿ç”¨ EM algorithm ä¾†æ‰¾å‡º MLE æˆ– MAP . å…¶ä¸­ E-step ç‚º â€œä»¤ $q(z)$ ç­‰æ–¼ $p(z|x,\\theta^{odd})$â€, é€™åˆå›åˆ°å¦‚åŒå¼ (1) æ±‚ posterior æœƒé‡åˆ°åˆ†æ¯ç©åˆ†é …çš„å•é¡Œ. å¦‚æœæˆ‘å€‘çš„ $z$ çš„å€¼æœ‰é™å€‹çš„ (å¦‚ GMM, $z$ çš„å€¼å°±æ˜¯ component çš„ index), $p(z|x,\\theta^{odd})$ å¯ä»¥ç›´æ¥ç®—å‡ºä¾†. ä½†è¤‡é›œä¸€é»å°±ä¸è¡Œäº†, æ‰€ä»¥æƒ…æ³åˆè®Šå¾—è·ŸåŸä¾†çš„ Bayesian learning ä¸€æ¨£, å…©ç¨®é¸æ“‡: ä½¿ç”¨ Variational Inference, é€™æ™‚ç¨±ç‚º Variational EM. ä½¿ç”¨ sampling æ–¹æ³•. Sampling é€šå¸¸æ¡ç”¨ MCMC æ–¹å¼, é€™æ™‚ç¨±ç‚º MCMC EM. Summaryæ“·å–è‡ª Coursera çš„ Bayesian Methods for Machine Learning èª²ç¨‹æŠ•å½±ç‰‡å¦‚ä¸‹: (åœ–ä¸­çš„ $T$ æŒ‡çš„æ˜¯ latent variable)","tags":[{"name":"Bayesian Learning","slug":"Bayesian-Learning","permalink":"https://bobondemon.github.io/tags/Bayesian-Learning/"},{"name":"Conjugate Prior","slug":"Conjugate-Prior","permalink":"https://bobondemon.github.io/tags/Conjugate-Prior/"},{"name":"MLE","slug":"MLE","permalink":"https://bobondemon.github.io/tags/MLE/"},{"name":"MAP","slug":"MAP","permalink":"https://bobondemon.github.io/tags/MAP/"}]},{"title":"Gaussian Process used in Bayesian Optimization","date":"2018-12-09T10:46:36.000Z","path":"2018/12/09/Gaussian-Process-used-in-Bayesian-Optimization/","text":"ä¸Šäº† Coursera çš„ Bayesian Methods for Machine Learning, å…¶ä¸­æœ€å¾Œä¸€é€±çš„èª²ç¨‹ä»‹ç´¹äº† Gaussian processes &amp; Bayesian optimization è¦ºå¾—å¾ˆæœ‰æ”¶ç©«, å› ç‚ºåš ML æœ€ç—›è‹¦çš„å°±æ˜¯ hyper-parameter tuning, å¸¸è¦‹çš„æ–¹æ³•å°±æ˜¯æ‰‹å‹•èª¿, grid search or random search. ç¾åœ¨å¯ä»¥æœ‰ä¸€å€‹è¼ƒ â€œæ¨¡å‹â€ çš„ä½œæ³•: Bayesian optimization. ç‚ºäº†ç­è§£é€™å€‹éç¨‹, æˆ‘å€‘æœƒä»‹ç´¹å¦‚ä¸‹å…§å®¹ä¸¦åŒæ™‚ä½¿ç”¨ GPy and GPyOpt åšäº› toy example: Random Process and Gaussian Process Stationary and Wide-Sense Stationary (WSS) GP for regression GP for bayesian optimization è®“æˆ‘å€‘é€²å…¥ GP çš„é ˜åŸŸå§ Random Process (RP) and Gaussian Process (GP)Random process (RP) æˆ–ç¨± stochastic process å®šç¾©ç‚º [Def]: For any $x\\in\\mathbb{R}^d$ assign random variable $f(x)$ ä¾‹å¦‚ $d=1$ ä¸”æ˜¯é›¢æ•£çš„æƒ…å½¢, ($x\\in\\mathbb{N}$) å®šç¾©èªªæ˜å°æ–¼æ¯ä¸€å€‹ $x$, $f[x]$ éƒ½æ˜¯ä¸€å€‹ r.v. æ‰€ä»¥ $f[1]$, $f[2]$, â€¦ éƒ½æ˜¯ r.v.s. æ­¤ case é€šå¸¸æŠŠ $x$ ç•¶ä½œæ™‚é–“ $t$ ä¾†çœ‹. è€Œ Gaussian Process å®šç¾©ç‚º [Def]: Random process $f$ is Gaussian, if for any finite number points, their joint distribution is normal. Stationary and Wide-Sense Stationary (WSS)Stationaryä¸€å€‹ RP æ˜¯ stationary å®šç¾©å¦‚ä¸‹: [Def]: Random process is stationary if its finite-dimensional distributions depend only on relative position of the points ç°¡å–®èˆ‰ä¾‹: å–ä¸‰å€‹ r.v.s $(x_1,x_2,x_3)$ ä»–å€‘çš„ joint pdf æœƒè·Ÿ $(x_1+t,x_2+t,x_3+t)$ ä¸€æ¨¡ä¸€æ¨£$$\\begin{align} p(f(x_1),f(x_2),f(x_3))=p(f(x_1+t),f(x_2+t),f(x_3+t)) \\end{align}$$æ‰€ä»¥ pdf åªèˆ‡ç›¸å°ä½ç½®æœ‰é—œ, ç™½è©±è¬›å°±æ˜¯æˆ‘å€‘è§€å¯Ÿ joint pdf å¯ä»¥ä¸ç”¨åœ¨æ„çœ‹çš„æ˜¯å“ªå€‹å€æ®µçš„ä¿¡è™Ÿ, å› ç‚ºéƒ½æœƒä¸€æ¨£. é€²ä¸€æ­¥åœ°, å¦‚æœé€™å€‹ RP æ˜¯ GP çš„è©±, æˆ‘å€‘çŸ¥é“ joint pdf æ˜¯ normal, è€Œ normal åªç”± mean and variance totally æ±ºå®š, å› æ­¤ä¸€å€‹ GP æ˜¯ stationary åªè¦ mean and variance åªè·Ÿç›¸å°ä½ç½®æœ‰é—œå°±æœƒæ˜¯ stationary. åŸºæ–¼é€™æ¨£çš„æ¢ä»¶æˆ‘å€‘å¯ä»¥å¯«å‡ºä¸€å€‹ stationary GP çš„å®šç¾©: [Def]: Covariance matrix or Kernel åªè·Ÿç›¸å°ä½ç½®æœ‰é—œ, ä»¥ä¸‹ç‚ºä¸‰ç¨®å¸¸è¦‹çš„å®šç¾©æ–¹å¼ä¸ç®¡æ€æ¨£, é€šå¸¸ç›¸å°ä½ç½®è¿‘çš„ r.v. éƒ½æœƒå‡è¨­æ¯”è¼ƒç›¸é—œ, (é€™ä¹Ÿç¬¦åˆå¯¦éš›ç‹€æ³, è­¬å¦‚è²éŸ³è¨Šè™Ÿæ™‚é–“é»ç›¸è¿‘çš„ sample æœƒè¼ƒç›¸é—œ), ä¹Ÿå› æ­¤ kernel éƒ½æœƒé•·é¡ä¼¼ä¸‹é¢çš„æ¨£å­ æ”¯ç·š Wide-Sense Stationary (WSS)æœ¬æ®µå¯è·³é, ä¸»è¦æ˜¯ç‚ºäº†æ›´æ·±åœ°ç†è§£ stationary åšçš„è£œå…….WSS å®šç¾©ç‚º [Def]: Random Process is WSS if its finite-dimensional distributionâ€™s mean and variance depend only on relative position of the points æ³¨æ„ WSS èˆ‡ Stationary çš„å®šç¾©å·®ç•°. æº–ç¢ºä¾†èªª Stationary è¦æ±‚æ‰€æœ‰çš„ moments éƒ½åªèˆ‡ç›¸å°ä½ç½®æœ‰é—œ, ä½† WSS åªè¦æ±‚åˆ° first and second order moments. èªªæ˜äº† WSS å°‡ stationary çš„æ¢ä»¶æ”¾å¯¬. æ³¨æ„åˆ° WSS ä¸ä¸€å®šæ˜¯ stationary çš„ GP, é€™æ˜¯å› ç‚º WSS æ²’æœ‰è¦æ±‚ distribution å¿…é ˆæ˜¯ Normal.WSS, Stationary GP, Stationary RP ä¹‹é–“çš„é—œä¿‚å¯ä»¥é€™éº¼æè¿°:$$\\begin{align} \\mbox{Stationary GP}\\subset\\mbox{Stationary RP}\\subset\\mbox{WSS} \\end{align}$$ å…¶å¯¦ WSS èˆ‡æœ¬ç¯‡ä¸»è¦è¨è«–çš„ Bayesian Optimization æ²’æœ‰ç›´æ¥é—œä¿‚, æœƒæƒ³ä»‹ç´¹æ˜¯å› ç‚ºæ»¿è¶³ WSS çš„è©±, èƒ½ä½¿æˆ‘å€‘æ›´ç›´è¦ºçš„ â€œçœ‹å‡ºâ€ ä¸€å€‹è¨Šè™Ÿæ˜¯å¦å¯èƒ½æ˜¯ stationary. (å¦å¤– WSS åœ¨ Adaptive Filtering éå¸¸é‡è¦, ç›¸ç•¶æ–¼åŸºçŸ³çš„å­˜åœ¨)é¦–å…ˆä½¿ç”¨èª²ç¨‹çš„ stationary ç¯„ä¾‹: ä¸­é–“çš„åœ–æ˜é¡¯ä¸æ˜¯ stationary å› ç‚º mean éš¨è‘—ä½ç½®æ”¹è®Šä¸æ˜¯ constant, ä½†å·¦é‚Šå’Œå³é‚Šå°±çœŸçš„ä¸æ˜¯é‚£éº¼å®¹æ˜“çœ‹å‡ºä¾†äº†. é‚£éº¼ç©¶ç«Ÿæœ‰ä»€éº¼æ–¹æ³•è¼”åŠ©æˆ‘å€‘åˆ¤æ–· stationary å‘¢?WSS çš„ power-spectral density property èªªæ˜äº†ä¸€å€‹ signal å¦‚æœæ˜¯ WSS, å‰‡å®ƒçš„ Covariance matrix or Kernel (è¨Šè™Ÿè™•ç†é€šå¸¸ç¨± auto-correlation) çš„ DTFT æ­£å¥½ä»£è¡¨çš„ç‰©ç†æ„ç¾©å°±æ˜¯ power spectral density, è€Œå› ç‚º kernel ä¸æœƒå› ä½ç½®æ”¹è®Š, é€™å°è‡´äº†ä¸ç®¡æˆ‘å€‘åœ¨å“ªå€‹å€æ®µå–å‡ºä¸€å€‹ window çš„è¨Šè™Ÿ, å®ƒå€‘çš„ power spectral density éƒ½æœƒé•·ä¸€æ¨£. é€™å€‹æ€§è³ªå¯ä»¥è®“æˆ‘å€‘å¾ˆæ–¹ä¾¿çš„ â€œçœ‹å‡ºâ€ æ˜¯å¦æ˜¯ stationary. (ç°¡å–®è¬›å°±æ˜¯çœ‹ signal çš„ frequency domain æ˜¯å¦å› ç‚ºéš¨è‘—æ™‚é–“è€Œè®ŠåŒ–, è®Šçš„è©±å°±ä¸€å®šä¸æ˜¯ stationary) å¥½äº†, æ¥è‘—å›åˆ°ä¸»ç·šå». GP for regressionç›´æ¥ç¯€éŒ„èª²ç¨‹ slides, å› ç‚º stationary GP çš„ mean æ˜¯ const, å› æ­¤æˆ‘å€‘æ‰£æ‰ offset è®“å…¶ç‚º 0, ä¹‹å¾Œå†è£œå›å³å¯.åš Regression çš„ç›®çš„å°±æ˜¯ given $x$ å¦‚ä½•é æ¸¬ $f(x)$, è€Œæˆ‘å€‘æœ‰çš„ training data ç‚º $x_1, â€¦, x_n$ ä»¥åŠå®ƒå€‘ç›¸å°çš„ $f(x_1),â€¦,f(x_n)$. GP å°±å¯ä»¥å¾ˆæ¼‚äº®åœ°åˆ©ç”¨ conditional probability é æ¸¬ $f(x)$ ç”±æ–¼æ˜¯ GP, å°è‡´ä¸Šé¢è—è‰²éƒ¨åˆ†çµæœä»æ˜¯ Gaussian, å› æ­¤æˆ‘å€‘å¾—åˆ°Regression å…¬å¼: æœ‰æ™‚å€™æˆ‘å€‘çš„ observation $f(x)$ æ˜¯ noisy çš„, æ­¤æ™‚ç°¡å–®åœ°å° $f(x)$ åŠ ä¸Šä¸€å€‹ random Gaussain noise æœƒä½¿å¾—æˆ‘å€‘çš„ model robust äº›. ä¸Šé¢å…¬å¼éƒ½ä¸ç”¨æ”¹, åªè¦é‡å° kernel ä½œå¦‚ä¸‹æ›´å‹•å³å¯ GPy toolkit exampleæˆ‘å€‘ä½¿ç”¨ Gaussian process regression tutorial çš„ç¯„ä¾‹, ä½¿ç”¨ä¸Šç®—æ˜¯å¾ˆç›´è¦º, è®“æˆ‘å€‘ç°¡å–®å¯¦é©—ä¸€ä¸‹ 12345678910111213import numpy as npimport GPyimport matplotlib.pyplot as plt# Generate data points, where Y is noisyX = np.random.uniform(-3.,3.,(20,1))Y = np.sin(X) + np.random.randn(20,1)*0.2# Define kernel, we use RBFkernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)# Define GP regression modelm = GPy.models.GPRegression(X,Y,kernel,noise_var=1.)# See plotfig = m.plot()plt.show() Codes çš„çµæœå¦‚ä¸‹ [Note]: ä¸Šåœ–çš„ Mean å’Œ Confidence æŒ‡çš„æ˜¯ Regression å…¬å¼çš„ $\\mu$ and $\\sigma^2$ (å‰å¹¾å¼µæœ‰ç´…æ¡†çš„åœ–), å¦å¤–ä½¿ç”¨ GPy ç®— regression çµæœçš„è©±é€™éº¼ä½¿ç”¨1mu, sigma2 = m.predict(np.array([[1.0]])) åŸºæœ¬ä¸Š input æ˜¯ä¸€å€‹ shape=(batch_size,in_dim) çš„ array å¯ä»¥çœ‹åˆ°å°±ç®—æ˜¯ data point é™„è¿‘, æ‰€é¡¯ç¤ºçš„ y é‚„æ˜¯æœ‰éå¸¸å¤§çš„ uncertainty, é€™æ˜¯å› ç‚º observation noise çš„ variance å¯èƒ½å¤ªå¤§äº†, æˆ‘å€‘å¾ 1.0 æ”¹æˆ 0.04 (æ­£ç¢ºç­”æ¡ˆ) çœ‹çœ‹ å¯ä»¥çœ‹åˆ°æœ‰ data point çš„åœ°æ–¹ä¸ç¢ºå®šæ€§é™ä½å¾ˆå¤š, ä¸”ä¸ç¢ºå®šæ€§çœ‹èµ·ä¾†å¾ˆåˆç† (ç•¶ç„¶, å› ç‚ºæˆ‘å€‘ç”¨æ­£ç¢ºç­”æ¡ˆçš„ noise var)æ¥è‘—æˆ‘å€‘æ”¹ kernel çš„ lengthscale (æ§åˆ¶å¹³æ»‘ç¨‹åº¦) å¾ 1 ç¸®å°æˆ 0.5 æ‡‰è©²å¯ä»¥é æœŸ regression çš„ mean æœƒæ‰­æ›²æ¯”è¼ƒå¤§, çµæœå¦‚ä¸‹ çœ‹çœ‹ä¸€å€‹æ¥µç«¯æƒ…æ³, å°‡ kernel çš„ lengthscale é™åˆ°éå¸¸å°, é€™æœƒå°è‡´ kernel é€€åŒ–æˆ delta function, ä¹Ÿå°±æ˜¯é™¤äº†è‡ªå·±å¤§å®¶äº’ä¸ç›¸é—œ. æŸ¥çœ‹ regression å…¬å¼ (å‰å¹¾å¼µæœ‰ç´…æ¡†çš„åœ–), ç”±æ–¼ kernel é€€åŒ–æˆ delta function, k å‘é‡è¶¨è¿‘æ–¼ 0, æ‰€ä»¥ regression å…¬å¼çš„ mean è¶¨è¿‘æ–¼ 0, variance è¶¨è¿‘æ–¼ prior K(0). æˆ‘å€‘å°‡ lengthscale èª¿æ•´æˆ 0.02 å¾—åˆ°å¦‚ä¸‹çš„åœ– å¯ä»¥çœ‹åˆ° x ç¨å¾®é›¢é–‹ data point çš„åœ°æ–¹, åŸºæœ¬ mean å°±å›åˆ° 0, ä¸” variance å›åˆ° prior K(0) å¾é€™ç°¡å–®çš„å¯¦é©—æˆ‘å€‘ç™¼ç¾, é€™ä¸‰å€‹æ§åˆ¶åƒæ•¸:-RBF variance-RBF lengthscale-GPRegression noise_var è¨­ç½®ä¸å¥½, åŸºæœ¬å¾ˆæ‚²åŠ‡, é‚£æ€éº¼æ‰æ˜¯å°çš„? ä¸‹ä¸€æ®µæˆ‘å€‘ä»‹ç´¹ä½¿ç”¨æœ€ä½³åŒ–æ–¹å¼æ‰¾å‡ºæœ€å¥½çš„åƒæ•¸. Learning the kernel parametersç”±æ–¼éƒ½æ˜¯ normal, å› æ­¤ MLE ç›®æ¨™å‡½å¼å¯å¾®, å¯å¾®å°±ä½¿ç”¨ gradient ascent ä¾†æ±‚åƒæ•¸. èª²ç¨‹ slide å¦‚ä¸‹ GPy çš„ä½¿ç”¨å°±é€™éº¼ä¸€è¡Œ m.optimize(messages=True) çµæœå¦‚ä¸‹ GP for bayesian optimizationå•é¡Œå†æè¿°ä¸€ä¸‹, å°±æ˜¯èªªæ¨¡å‹æœ‰ä¸€å¤§å †åƒæ•¸ (ç¨± $x$) è¦èª¿æ•´, é¸æ“‡ä¸€çµ„åƒæ•¸å¯ä»¥å¾—åˆ°ä¸€å€‹ validation accuracy (ç¨± $f(x)$), æˆ‘å€‘å¸Œæœ›æ‰¾åˆ°ä¸€çµ„åƒæ•¸ä½¿å¾— $f(x)$ æœ€å¤§. é€™å€‹éº»ç…©ä¹‹è™•å°±åœ¨æ–¼æˆ‘å€‘å° $f(x)$ çš„è¡¨ç¤ºä¸€ç„¡æ‰€çŸ¥, åªèƒ½é€éæ¡æ¨£å¾—åˆ° $f(x)$, è€Œæ¯æ¬¡è¦å¾—åˆ°ä¸€å€‹æ¡æ¨£çš„ $f(x)$ éƒ½è¦ç¶“éæ¼«é•·çš„è¨“ç·´æ‰èƒ½å¾—åˆ°. åœ¨é€™ç¨®æƒ…å½¢ä¸‹, æ€éº¼é€éæœ€å°‘æ¡æ¨£é»å¾—åˆ°è¼ƒå¤§çš„ $f(x)$ å€¼å‘¢? å¤§çµ•å°±æ˜¯ç”¨ GP ä¾† approximate $f(x)$ åˆç†å—? æˆ‘å€‘é€™éº¼æƒ³, ç”±æ–¼ kernel ä¸€èˆ¬çš„å®šç¾©æœƒä½¿å¾—ç›¸è¿‘çš„æ¡æ¨£é»æœ‰è¼ƒé«˜çš„ç›¸é—œå€¼, ä¹Ÿå°±æ˜¯é¡ä¼¼çš„åƒæ•¸æœƒå¾—åˆ°è¼ƒç›¸é—œçš„ validation accuracy. é€™éº¼æƒ³çš„è©±å¤šå°‘æœ‰äº›åˆç†. å¦ä¸€å€‹å¥½è™•æ˜¯ä½¿ç”¨ GP å¯ä»¥å¸¶çµ¦æˆ‘å€‘æ©Ÿç‡åˆ†å¸ƒ, é€™ä½¿å¾—æˆ‘å€‘å¯ä»¥ä½¿ç”¨å„ç¨®è€ƒé‡ä¾†æ±ºå®šä¸‹ä¸€å€‹æ¡æ¨£é». ä¾‹å¦‚: æˆ‘å€‘å¯ä»¥è€ƒæ…®åœ¨é‚£äº›ä¸ç¢ºå®šæ€§è¼ƒå¤§çš„åœ°æ–¹è©¦è©¦çœ‹, å› ç‚ºèªªä¸å®šæœ‰æ›´é«˜çš„$f(x)$, æˆ–æ˜¯åœ¨å·²çŸ¥ç›®å‰ä¼°æ¸¬çš„ GP model ä¸‹æœ‰è¼ƒé«˜çš„ mean å€¼é‚£è£æ¡æ¨£. é€™å…©ç¨®æ–¹å¼ç¨±ç‚º â€œExplorationâ€ and â€œExploitationâ€ æ‰€ä»¥ Bayesian optimization ä¸»è¦å°±å…©å€‹éƒ¨åˆ†, Surrogate model (å¯ä»¥ä½¿ç”¨ GP) å’Œ Acquisition function: æ¼”ç®—æ³•å°±å¾ˆç›´è¦ºäº†, æ ¹æ“š Acquisition function å¾—åˆ°çš„æ¡æ¨£é» $x$ è¨ˆç®—å‡ºä¾† $f(x)$ å¾Œ, é‡æ–°æ›´æ–° GP (ä½¿ç”¨ MLE æ‰¾å‡ºæœ€å¥½çš„ GP åƒæ•¸æ›´æ–°), æ›´æ–°å¾Œç¹¼çºŒè¨ˆç®—ä¸‹å€‹æ¡æ¨£é». æˆ‘å€‘é‚„æœªèªªæ˜ Acquisition function æ€éº¼å®šç¾©, å¸¸ç”¨çš„æ–¹æ³•æœ‰ä¸‹é¢ä¸‰ç¨®: Maximum probability of improvement (MPI) Upper confidence bound (UCB) Expected improvement (EI), ç¶²è·¯ä¸Šèªªæœ€å¸¸è¢«ç”¨ Expected improvement (EI) å¯ä»¥åƒè€ƒé€™ç¯‡ blog æ­é…é€™å€‹ implementation, é€™è£¡å°±ä¸é‡è¤‡äº†. å€¼å¾—ä¸€æçš„æ˜¯ Acquisition function é€šå¸¸æœ‰å€‹åƒæ•¸ $\\xi$ å¯ä»¥æ§åˆ¶ Exploration å’Œ Exploitation çš„ tradeoff. æ¥è‘—æˆ‘å€‘ä½¿ç”¨ GPyOpt ç·´ç¿’ä¸€å€‹ toy example. GPyOpt toy exampleé¡ä¼¼ä¸Šé¢çš„ GP for regression çš„ç¯„ä¾‹, $x$ and $f(x)$ æˆ‘å€‘ç°¡å–®å®šç¾©å¦‚ä¸‹: 1234sample_num = 20offset = 10def probeY(x): # i.e. f(x) return np.sin(x) + np.random.randn()*0.2 + offset é€™æ¬¡æˆ‘å€‘å°‡ $f(x)$ æ•…æ„åŠ äº†ä¸€å€‹ offset, é›–ç„¶å°æ–¼ GP regression çš„å‡è¨­æ˜¯ mean=0, ä¸é GPyOpt é è¨­æœƒå° $f(x)$ å»æ‰ offset, æ‰€ä»¥å…¶å¯¦æˆ‘å€‘å¯ä»¥å¾ˆå®‰å…¨çš„ä½¿ç”¨ API. æ¥è‘—é—œéµç¨‹å¼ç¢¼å¦‚ä¸‹ 12345678bounds = [&#123;'name': 'var_1', 'type': 'continuous', 'domain': (-3.0,3.0)&#125;] # domain definitionmyBopt = GPyOpt.methods.BayesianOptimization(f=probeY, # function to optimize domain=bounds, # box-constraints of the problem normalize_Y=True, # normalize Y to mean = 0 (default) acquisition_type='EI', # acquisition function type (default) maximize=False, # do maixmization? (default=False) exact_feval = False)myBopt.run_optimization(max_iter) bounds æè¿°äº†æ¯ä¸€å€‹ probeY çš„ arguments. ç‰¹åˆ¥è¦èªªä¸€ä¸‹ exact_feval = False, é€™æ˜¯èªªæ˜ $f(x)$ æ˜¯ noisy çš„, æ‰€ä»¥æœƒæœ‰ noise variance å¯ä»¥ model (åƒè€ƒ 3. GP for regression çš„ regression å…¬å¼å«noiseçš„æƒ…å½¢), é€™åœ¨å¯¦éš›æƒ…æ³éå¸¸é‡è¦. æ›´å¤š BayesianOptimization åƒæ•¸æè¿° åƒè€ƒé€™ ä½¿ç”¨å¦‚ä¸‹æŒ‡ä»¤çœ‹ acquisition å’Œ regression function çš„çµæœ1myBopt.plot_acquisition() æ‰èŠ±1xå€‹æ¡æ¨£æ±‚å‡ºä¾†çš„ regression function å°±å¾ˆé€¼è¿‘çœŸå¯¦ç‹€æ³äº†, é‚„ä¸éŒ¯. å¦å¤–æ³¨æ„åˆ°é€™è£¡çš„ $f(x)$ å·²ç¶“å»æ‰ offset äº†.å†ä¾†ä½¿ç”¨å¦‚ä¸‹æŒ‡ä»¤çœ‹æ¯ä¸€æ¬¡æ¡æ¨£å€¼ä¹‹é–“çš„å·®ç•°, ä»¥åŠæ¡æ¨£é»çš„ $f(x)$1myBopt.plot_convergence() ç¬¬9æ¬¡æ¡æ¨£é–‹å§‹, æ¡æ¨£é» $x$ ä»¥åŠ $f(x)$ ä¹‹é–“åŸºæœ¬æ²’ä»€éº¼å·®ç•°äº†.è‹¥è¦æ‹¿åˆ°æ¡æ¨£éç¨‹çš„ $x$ and $f(x)$, å¯ä½¿ç”¨ myBopt.X å’Œ myBopt.Y XGBoost parameter tuningé‡å° XGBoost çš„åƒæ•¸é€²è¡Œæœ€ä½³åŒ– (å¯åƒè€ƒé€™ç¯‡ blog), é—œéµå°±åœ¨æ–¼ä¸Šé¢çš„ $probeY$ éœ€æ›¿æ›æˆè¨ˆç®—æŸå€‹æ¡æ¨£çš„ evaluation accuracy (å› æ­¤é‚„éœ€è¦è¨“ç·´). é—œéµç¨‹å¼ç¢¼å¦‚ä¸‹: 123456789101112131415161718192021222324252627282930313233343536from xgboost import XGBRegressorfrom sklearn.model_selection import cross_val_score... Some codes here# Score. Optimizer will try to find minimum, so we will add a \"-\" sign.def probeY(parameters): parameters = parameters[0] score = -cross_val_score( XGBRegressor(learning_rate=parameters[0], max_depth=int(parameters[2]), n_estimators=int(parameters[3]), gamma=int(parameters[1]), min_child_weight = parameters[4]), X, y, scoring='neg_mean_squared_error').mean() score = np.array(score) return score# Bounds (NOTE: define continuous variables first, then discrete!)bounds = [ &#123;'name': 'learning_rate', 'type': 'continuous', 'domain': (0, 1)&#125;, &#123;'name': 'gamma', 'type': 'continuous', 'domain': (0, 5)&#125;, &#123;'name': 'max_depth', 'type': 'discrete', 'domain': (1, 50)&#125;, &#123;'name': 'n_estimators', 'type': 'discrete', 'domain': (1, 300)&#125;, &#123;'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)&#125; ]np.random.seed(777)optimizer = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds, acquisition_type ='MPI', acquisition_par = 0.1, exact_eval=True)max_iter = 50max_time = 60optimizer.run_optimization(max_iter, max_time)optimizer.plot_convergence()optimizer.X[np.argmin(optimizer.Y)] èª²ç¨‹è®“æˆ‘å€‘æ¸¬è©¦äº† sklearn.datasets.load_diabetes() dataset, ä½¿ç”¨ GPyOpt å¯ä»¥è®“ XGBoost æ¯”é è¨­åƒæ•¸æœ‰ 9% çš„æå‡! é‚„æ˜¯å¾ˆä¸éŒ¯çš„. å†ä¾†å°±å¾ˆæœŸå¾…æ˜¯å¦èƒ½çœŸçš„åœ¨å·¥ä½œä¸Šå° DNN å¥—ç”¨äº†. Reference GPy and GPyOpt GPyOptâ€™s documentation can find APIs GPyOpt tutorial å¾ˆå¥½çš„ GPy and GPyOpt æ•¸å­¸å’Œç¯„ä¾‹ blog Acquisition function implementation WSS power-spectral density property https://www.imft.fr/IMG/pdf/psdtheory.pdf","tags":[{"name":"Gaussian Process","slug":"Gaussian-Process","permalink":"https://bobondemon.github.io/tags/Gaussian-Process/"},{"name":"Bayesian Optimization","slug":"Bayesian-Optimization","permalink":"https://bobondemon.github.io/tags/Bayesian-Optimization/"},{"name":"Stationary","slug":"Stationary","permalink":"https://bobondemon.github.io/tags/Stationary/"}]},{"title":"CTC Implementation Practice","date":"2018-10-16T12:25:10.000Z","path":"2018/10/16/CTC-Implementation-Practice/","text":"Credit æ˜¯æ­¤ç¯‡ DingKe ipynb çš„, ä»–å®Œæ•´å‘ˆç¾äº† CTC loss ä»¥åŠ gradient çš„è¨ˆç®—, éå¸¸æ£’!æ­¤ç­†è¨˜åŠ å…¥è‡ªå·±çš„èªªæ˜, ä¸¦ä¸”æœ€å¾Œä½¿ç”¨ tensorflow ä¾†é©—è­‰.é€™ç¯‡å¦ä¸€å€‹ä¸»è¦ç›®çš„ç‚ºæ”¹æˆå¯ä»¥ç·´ç¿’çš„æ ¼å¼ (#TODO tag). å› ç‚ºæˆ‘ç›¸ä¿¡æœ€å¥½çš„å­¸ç¿’æ–¹å¼æ˜¯è‡ªå·±é€ ä¸€æ¬¡è¼ªå­, æ‰€ä»¥å¯ä»¥çš„è©±, è«‹è©¦è‘—æŠŠ #TODO tag çš„éƒ¨åˆ†åšå®Œå§.æˆ‘å€‘åªå°ˆæ³¨åœ¨ CTC loss çš„ forward, backwark and gradient. Decoding éƒ¨åˆ†è«‹åƒè€ƒåŸä½œè€…çš„ ipynb. æœ€å¾Œä½¿ç”¨ tf.nn.ctc_loss and tf.gradients èˆ‡æˆ‘å€‘çš„è¨ˆç®—åšå°æ¯” å®Œæˆä»¥ä¸‹æ­¥é©Ÿ å®Œæˆ CTC_Practice.ipynb #TODO tag åƒè€ƒ CTC_Practice_Answer.ipynb Reference DingKe ipynb Sequence Modeling With CTC Graves CTC","tags":[{"name":"CTC","slug":"CTC","permalink":"https://bobondemon.github.io/tags/CTC/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://bobondemon.github.io/tags/TensorFlow/"}]},{"title":"Variational Inference and VAE Notes","date":"2018-09-18T14:21:05.000Z","path":"2018/09/18/Variational-Inference-Notes/","text":"å‰ä¸€é™£å­å­¸ç¿’äº† Variational Inference, å› ç‚ºè‡ªå·±è¨˜æ€§åªæœ‰ LSTM æ²’æœ‰ L, æ‰€ä»¥è¶•å¿«è¨˜ä¸‹ç­†è¨˜. å­¸å¾—é‚„æ˜¯å¾ˆç²—æ·º, åˆæ˜¯ä¸€å€‹å¤§å‘é˜¿.ç›£ç£å­¸ç¿’ä¸å¤–ä¹å°±æ˜¯ training å’Œ testing (inference). è€Œ inference åœ¨åšçš„äº‹æƒ…å°±æ˜¯åœ¨è¨ˆç®—å¾Œé©—æ¦‚ç‡ $p(z|x)$. åœ¨ PGM ä¸­é€šå¸¸æ˜¯ intractable, æˆ–è¦æ‰¾åˆ° exact solution çš„è¨ˆç®—è¤‡é›œåº¦å¤ªé«˜, é€™æ™‚ VI å°±æ´¾ä¸Šç”¨å ´äº†. VI ç°¡å–®è¬›å°±æ˜¯ç•¶ $p(z|x)$ ä¸å®¹æ˜“å¾—åˆ°æ™‚, å¯ä»¥å¹«ä½ æ‰¾åˆ°ä¸€å€‹å¾ˆå¥½çš„è¿‘ä¼¼, $q(z)$. æ”¾ä¸Šä¸€å¼µ NIPS 2016 VI tutorial çš„åœ–, éå¸¸å½¢è±¡åœ°è¡¨ç¤º VI åšçš„äº‹æƒ…: å°‡æ‰¾ $p(z|x)$ çš„å•é¡Œè½‰åŒ–æˆä¸€å€‹æœ€ä½³åŒ–å•é¡Œ. æ€éº¼çœ‹ä½œæœ€ä½³åŒ–å•é¡Œ?æˆ‘å€‘è¦æ‰¾åˆ°ä¸€å€‹ $q(z)$ å»é€¼è¿‘ $p(z|x)$, å› æ­¤éœ€è¦è¨ˆç®—å…©å€‹æ©Ÿç‡åˆ†ä½ˆçš„è·é›¢, è€Œ KL-divergence æ˜¯å€‹å¾ˆå¥½çš„é¸æ“‡ (é›–ç„¶ä¸æ»¿è¶³æ•¸å­¸ä¸Šçš„è·é›¢å®šç¾©). æ‰€ä»¥æˆ‘å€‘çš„ç›®æ¨™å°±æ˜¯å¸Œæœ› $KL(q(z)\\Vert p(z|x))$ æ„ˆå°æ„ˆå¥½, æ¥è‘—æˆ‘å€‘å° KL å®šç¾©é‡æ–°åšå¦‚ä¸‹çš„è¡¨é”: $$\\begin{align} KL\\left(q(z)\\Vert p(z|x)\\right)=-\\sum_z q(z)\\log\\frac{p(z|x)}{q(z)}\\\\ =-\\sum_z q(z)\\left[\\log\\frac{p(x,z)}{q(z)}-\\log p(x)\\right]\\\\ =-\\sum_z q(z)\\log\\frac{p(x,z)}{q(z)}+\\log p(x) \\end{align}$$ å¾—åˆ°é€™å€‹éå¸¸é‡è¦çš„å¼å­: $$\\begin{align} \\log p(x)=KL\\left(q(z)\\Vert p(z|x)\\right)+ \\color{red}{ \\sum_z q(z)\\log\\frac{p(x,z)}{q(z)} } \\\\ =KL\\left(q(z)\\Vert p(z|x)\\right)+ \\color{red}{ \\mathcal{L}(q) } \\\\ \\end{align}$$ ç‚ºä»€éº¼åšé€™æ¨£çš„è½‰æ›å‘¢? é€™æ˜¯å› ç‚ºé€šå¸¸ $p(z|x)$ å¾ˆé›£å¾—åˆ°, ä½†æ˜¯ complete likelihood $p(z,x)$ é€šå¸¸å¾ˆå¥½æ±‚.è§€å¯Ÿ (5), æ³¨æ„åˆ°åœ¨ VI çš„è¨­å®šä¸­ $\\log p(x)$ è·Ÿæˆ‘å€‘è¦æ‰¾çš„ $q(z)$ ç„¡é—œ, ä¹Ÿå°±é€ æˆäº† $\\log p(x)$ æ˜¯å›ºå®šçš„. ç”±æ–¼ $KL\\geq 0$, è®“ $KL$ æ„ˆå°æ„ˆå¥½ç­‰åŒæ–¼è®“ $\\mathcal{L}(q)$ æ„ˆå¤§æ„ˆå¥½. å› æ­¤ VI çš„ç›®æ¨™å°±æ˜¯è—‰ç”±æœ€å¤§åŒ– $\\mathcal{L}(q)$ ä¾†è¿«ä½¿ $q(z)$ æ¥è¿‘ $p(z|x)$. $\\mathcal{L}(q)$ å¯ä»¥çœ‹å‡ºä¾†æ˜¯ marginal log likelihood $\\log p(x)$ çš„ lower bound. å› æ­¤ç¨± variational lower bound æˆ– Evidence Lower BOund (ELBO). ELBO çš„ gradientæˆ‘å€‘åšæœ€ä½³åŒ–éƒ½éœ€è¦è¨ˆç®— objective function çš„ gradient. è®“è¦æ‰¾çš„ $q$ ç”±åƒæ•¸ $\\nu$ æ§åˆ¶, i.e. $q(z;\\nu)$, æ‰€ä»¥æˆ‘å€‘è¦æ‰¾ ELBO çš„ gradient å°±æ˜¯å° $\\nu$ å¾®åˆ†. $$\\begin{align} \\mathcal{L}(\\nu)=\\mathbb{E}_{z\\sim q}\\left[\\log p(x,z) - \\log q(z;\\nu)\\right]\\\\ \\Rightarrow \\nabla_{\\nu}\\mathcal{L}(\\nu)=\\nabla_{\\nu}\\left(\\mathbb{E}_{z\\sim q}\\left[\\log p(x,z) - \\log q(z;\\nu)\\right]\\right)\\\\ \\mbox{Note }\\neq \\mathbb{E}_{z\\sim q}\\left(\\nabla_{\\nu}\\left[\\log p(x,z) - \\log q(z;\\nu)\\right]\\right)\\\\ \\end{align}$$ æ³¨æ„ (8) ä¸èƒ½å°‡ Expectation èˆ‡ derivative äº¤æ›çš„åŸå› æ˜¯å› ç‚ºè¦å¾®åˆ†çš„ $\\nu$ èˆ‡è¦è¨ˆç®—çš„ Expectation åˆ†å¸ƒ $q$ æœ‰é—œ. ä¸‹é¢æœƒæåˆ°ä¸€å€‹å¾ˆé‡è¦çš„æŠ€å·§, Reparameterization trick, å°‡ Expectation èˆ‡ derivative äº¤æ›, è€Œäº¤æ›å¾Œæœ‰ä»€éº¼å¥½è™•å‘¢? ä¸‹é¢æåˆ°çš„æ™‚å€™å†èªªæ˜. å›åˆ° (7) å±•é–‹ Expectation ç¹¼çºŒè¨ˆç®— gradient, ç›´æ¥ç”¨ NIPS slide çµæœå¦‚ä¸‹: è¨ˆç®—ä¸€å€‹æ©Ÿç‡åˆ†ä½ˆçš„ Expectation å¯ç”¨ Monte Carlo method æ¡æ¨£, ä¾‹å¦‚æ¡æ¨£ $T$ å€‹ samples$$\\begin{align} \\mathbb{E}_{z\\sim q}f(z)\\approx\\frac{1}{T}\\sum_{t=1}^Tf(z)\\mbox{, where }z\\sim q \\end{align}$$ å› æ­¤ gradient å¯ä»¥é€™éº¼å¤§è‡´æ‰¾å‡ºä¾†, ä¸éé€™æ–¹æ³•æ‰¾å‡ºä¾†çš„ gradient èˆ‡çœŸå¯¦çš„ gradient å­˜åœ¨å¾ˆå¤§çš„èª¤å·®, æ›å¥è©±èªª, é€™å€‹è¿‘ä¼¼çš„ gradient variance å¤ªå¤§äº†. åŸå› å…©å€‹ $q$ æœ¬èº«å°±é‚„åœ¨ä¼°è¨ˆ, æœ¬èº«å°±ä¸æº–ç¢ºäº† Monte Carlo method æ¡æ¨£æ‰€é€ æˆçš„èª¤å·® ä¸‹ä¸€æ®µçš„ reparameterization trick å°±å¯ä»¥å»é™¤æ‰ä¸Šé¢ç¬¬ä¸€å€‹èª¤å·®, å› æ­¤ä¼°å‡ºä¾†çš„ gradient å°±ç©©å®šå¾ˆå¤š. Reparameterization Trickæˆ‘å€‘ç”¨ Gaussian èˆ‰ä¾‹, ä»¤ $q$ æ˜¯ Gaussian, $q(z;\\mu,\\sigma)=\\mathcal{N}(\\mu,\\sigma)$, å…¶ä¸­ $\\nu=${$\\mu,\\sigma$}, è€Œæˆ‘å€‘å…¶å¯¦å¯ä»¥çŸ¥é“ $z=\\mu+\\sigma \\epsilon$, where $\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})$. å› æ­¤:$$\\begin{align} \\mathcal{L}(\\nu)=\\mathbb{E}_{z\\sim q}\\left[\\log p(x,z)-\\log q(z;\\nu)\\right]\\\\ =\\mathbb{E}_{ \\color{red}{ \\epsilon\\sim \\mathcal{N}(0,\\mathbf{I}) } }\\left[\\log p(x, \\color{red}{ \\mu+\\sigma \\epsilon } )-\\log q( \\color{red}{ \\mu+\\sigma \\epsilon } ;\\nu)\\right] \\end{align}$$ é€™æ™‚å€™æˆ‘å€‘è¨ˆç®— ELBO çš„ gradient æ™‚, æˆ‘å€‘ç™¼ç¾ $\\nu$ èˆ‡ Expectation çš„åˆ†ä½ˆ, $\\mathcal{N}(0,\\mathbf{I})$, ç„¡é—œäº†! å› æ­¤ (7) å¥—ç”¨ä¸Šé¢çš„ trick å°±å¯ä»¥å°‡ Expectation èˆ‡ derivative äº¤æ›. çµæœå¦‚ä¸‹: $$\\begin{align} \\nabla_{\\mu}\\mathcal{L}(\\nu)=\\mathbb{E}_{\\epsilon\\sim \\mathcal{N}(0,\\mathbf{I})}\\left[\\nabla_{\\mu}\\left(\\log p(x,\\mu+\\sigma \\epsilon) - \\log q(\\mu+\\sigma \\epsilon;\\nu)\\right)\\right]\\\\ \\approx\\frac{1}{T}\\sum_{t=1}^T \\nabla_{\\mu}\\left( \\log p(x,\\mu+\\sigma \\epsilon) - \\log q(\\mu+\\sigma \\epsilon;\\nu) \\right)\\mbox{, where }\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})\\\\ \\end{align}$$ åœ¨ä¸Šä¸€æ®µè¨ˆç®— ELBO gradient æ‰€é€ æˆèª¤å·®çš„ç¬¬ä¸€é …åŸå› å°±ä¸å­˜åœ¨äº†, å› æ­¤æˆ‘å€‘ç”¨ reparameterization å¾—åˆ°çš„ gradient å…·æœ‰å¾ˆå°çš„ variance. é€™å€‹ github åšäº†å¯¦é©—, ç™¼ç¾ reperameterization çš„ç¢ºå¤§å¤§é™ä½äº†ä¼°è¨ˆçš„ gradient çš„ variance. $$\\begin{align} \\nabla_{\\mu}\\left(\\log p(x,\\mu+\\sigma \\epsilon) - \\log q(\\mu+\\sigma \\epsilon;\\nu)\\right) \\end{align}$$ æ€éº¼è¨ˆç®—å‘¢? æˆ‘å€‘å¯ä»¥ä½¿ç”¨ Tensorflow å°‡è¦è¨ˆç®— gradient çš„ function å¯«å‡ºä¾†, tf.gradients å°±èƒ½ç®— VAEVariational Inference æ€éº¼è·Ÿ Neural Network æ‰¯ä¸Šé—œä¿‚çš„? é€™å¯¦åœ¨å¾ˆç¥å¥‡.æˆ‘å€‘å…ˆä¾†çœ‹çœ‹ ELBO é™¤äº† (6) çš„å¯«æ³•, é‚„å¯ä»¥é€™éº¼è¡¨ç¤º: $$\\begin{align} \\mathcal{L}(\\nu)=\\mathbb{E}_{z\\sim q}\\left[\\log p(x,z) - \\log q(z;\\nu)\\right]\\\\ =\\mathbb{E}_{z\\sim q}\\left[ \\log p(x|z) + \\log p(z) - log q(z;\\nu) \\right]\\\\ =\\mathbb{E}_{z\\sim q}\\left[ \\log p(x|z)\\right] + \\mathbb{E}_{z\\sim q}\\left[ \\log \\frac{p(z)}{q(z;\\nu)}\\right]\\\\ =\\mathbb{E}_{z\\sim q}\\left[ \\log p(x|z)\\right] - KL(q(z;\\nu)\\|p(z))\\\\ \\end{align}$$ æˆ‘å€‘è®“ $p(x|z)$ è¢«åƒæ•¸ $\\theta$ æ‰€æ§åˆ¶, æ‰€ä»¥æœ€å¾Œ ELBO å¦‚ä¸‹:$$\\begin{align} \\mathcal{L}(\\nu,\\theta)=\\mathbb{E}_{z\\sim q}\\left[ \\log \\color{orange}{ p(x|z,\\theta) } \\right] - KL( \\color{blue}{ q(z;\\nu) } \\|p(z))\\\\ \\end{align}$$ è®“æˆ‘å€‘ç”¨åŠ›çœ‹ (19) ä¸€åˆ†é˜æ¥è‘—åœ¨ç”¨åŠ›çœ‹ (19) ä¸€åˆ†é˜æœ€å¾Œåœ¨ç”¨åŠ›çœ‹ (19) ä¸€åˆ†é˜ æœ‰çœ‹å‡ºä»€éº¼å—? â€¦ å¦‚æœæ²’æœ‰, è©¦è‘—å°ç…§ä¸‹é¢é€™å¼µåœ– Encoder å’Œ Decoder éƒ½åŒæ™‚ç”¨ NN ä¾†å­¸ç¿’, é€™è£¡ $\\nu$ å’Œ $\\theta$ åˆ†åˆ¥è¡¨ç¤º NN çš„åƒæ•¸, è€Œä½¿ç”¨ Reparameterization trick ä¾†è¨ˆç®— ELBO çš„ gradient (14) å°±ç›¸ç•¶æ–¼åœ¨åšé€™å…©å€‹ NN çš„ backprop. ä½†æ˜¯ä¸Šåœ–çš„ Encoder ç”¢ç”Ÿçš„æ˜¯ä¸€å€‹ pdf, è€Œçµ¦ Decoder çš„æ˜¯ä¸€å€‹ sample $z$, é€™è©²æ€éº¼ä¸²ä¸€èµ·? VAE çš„åšæ³•å°±æ˜¯å°‡ $q(z)$ è¨­å®šç‚º diagonal Gaussian, ç„¶å¾Œåœ¨é€™å€‹ diagonal Gaussian æ¡æ¨£å‡º $T$ å€‹ $z$ å°±å¯ä»¥ä¸Ÿçµ¦ Decoder. ä½¿ç”¨ diagonal Gaussian æœ‰å…©å€‹å¥½è™•: æˆ‘å€‘å¯ä»¥ç”¨ reparameterization trick, å› æ­¤æ¡æ¨£åªåœ¨æ¨™æº–é«˜æ–¯ä¸Šæ¡æ¨£, è‡ªç„¶åœ° Encoder çš„ output å°±æ˜¯ $\\mu$ å’Œ $\\sigma$ äº†. (19)çš„ KL é …ç›´æ¥å°±æœ‰ closed form solution, å…æ‰ç®— expectation (å‡è¨­$p(z)$ä¹Ÿæ˜¯Gaussiançš„è©±) æ ¹æ“š1, æ¶æ§‹æ”¹å‹•å¦‚ä¸‹: å°‡åŸä¾†çš„ ELBO (10) è½‰æˆ (19) ä¾†çœ‹çš„è©±, é‚„å¯ä»¥çœ‹å‡ºä¸€äº›è³‡è¨Š.ç•¶æœ€å¤§åŒ– (19) çš„æ™‚å€™ RHS ç¬¬ä¸€é …è¦æ„ˆå¤§æ„ˆå¥½ (likelihood æ„ˆå¤§æ„ˆå¥½), å› æ­¤é€™ä¸€é …ä»£è¡¨ reconstruct error æ„ˆå°æ„ˆå¥½. RHS ç¬¬äºŒé …, ä¹Ÿå°±æ˜¯ $KL(q(z;\\nu)\\Vert p(z))$ å‰‡è¦æ„ˆå°æ„ˆå¥½. å› æ­¤æœƒå‚¾å‘æ–¼è®“ $q(z;\\nu)$ æ„ˆæ¥è¿‘ $p(z)$ æ„ˆå¥½. é€™å¯ä»¥çœ‹åš regularization. ä½†æ˜¯åˆ¥å¿˜äº†ä¸€é–‹å§‹èªª VI çš„åšæ³•å°±æ˜¯è—‰ç”±æœ€å¤§åŒ– ELBO ä¾†è¿«ä½¿ $q(z;\\nu)$ æ¥è¿‘ $p(z|x)$, è€Œä¸Šé¢æ‰èªªæœ€å¤§åŒ– ELBO æœƒå‚¾å‘æ–¼è®“ $q(z;\\nu)$ æ¥è¿‘ $p(z)$.é€™ä¸²èµ·ä¾†å°±èªª $q(z;\\nu)$ æ¥è¿‘ $p(z|x)$ æ¥è¿‘ $p(z)$. åœ¨ VAE è«–æ–‡è£¡å°±å°‡ $p(z)$ ç›´æ¥è¨­å®šç‚º $\\mathcal{N}(0,\\mathbf{I})$. å› æ­¤æ•´å€‹ VAE è¨“ç·´å®Œçš„ Encoder çš„ $z$ åˆ†å¸ƒæœƒæœ‰é«˜æ–¯åˆ†å¸ƒçš„æƒ…å½¢. Conditional VAE (CVAE)åŸä¾†çš„ VAE ç„¡æ³•æ§åˆ¶è¦ç”ŸæˆæŸäº›é¡åˆ¥çš„åœ–åƒ, ä¹Ÿå°±æ˜¯éš¨æ©Ÿç”¢ç”Ÿ $z$ ä¸çŸ¥é“é€™æœƒå°æ‡‰åˆ°å“ªå€‹é¡åˆ¥. CVAE å¯ä»¥æ ¹æ“šæ¢ä»¶ä¾†ç”¢ç”Ÿåœ–åƒ, ä¹Ÿå°±æ˜¯é™¤äº†çµ¦ $z$ ä¹‹å¤–éœ€è¦å†çµ¦ $c$ (é¡åˆ¥) è³‡è¨Šä¾†ç”Ÿæˆåœ–åƒ. æ€éº¼è¾¦åˆ°çš„å‘¢? æ–¹æ³•ç°¡å–®åˆ°æˆ‘åš‡ä¸€è·³, çœ‹åŸæœ¬è«–æ–‡æœ‰é»è¿·è¿·ç³Šç³Š, ä½†é€™ç¯‡æ–‡ç« è§£é‡‹å¾—å¾ˆæ¸…æ¥š! ç°¡å–®ä¾†èªªå°‡åŸä¾†çš„æ¨å€’å…¨éƒ¨åŠ ä¸Š condition on $c$ çš„æ¢ä»¶. å¾ (4) å‡ºç™¼ä¿®æ”¹å¦‚ä¸‹: $$\\begin{align} \\log p(x \\color{red}{ | c } ) =KL\\left(q(z \\color{red}{ | c } )\\Vert p(z|x, \\color{red}{ c } )\\right)+ \\sum_z q(z \\color{red}{ | c } )\\log\\frac{p(x,z \\color{red}{ | c } )}{q(z \\color{red}{ | c } )} \\\\ \\end{align}$$ ç”¨æ¨å° VAE ä¸€æ¨¡ä¸€æ¨£çš„æµç¨‹, å…¶å¯¦ä»€éº¼éƒ½æ²’åš, åªæ˜¯å…¨éƒ¨ conditioned on $c$ å¾—åˆ° (19) çš„ condition ç‰ˆæœ¬ $$\\begin{align} \\mathcal{L}(\\nu,\\theta \\color{red}{ | c } )=\\mathbb{E}_{z\\sim q}\\left[ \\log \\color{orange}{ p(x|z,\\theta, \\color{red}{ c } ) } \\right] - KL( \\color{blue}{ q(z;\\nu \\color{red}{ | c } ) } \\|p(z))\\\\ \\end{align}$$ é€™èªªæ˜äº†æˆ‘å€‘åœ¨å­¸ Encoder å’Œ Decoder çš„ NN æ™‚å¿…é ˆåŠ å…¥ conditioned on $c$ é€™å€‹æ¢ä»¶! NN æ€éº¼åšåˆ°é€™é»å‘¢? å¾ˆæš´åŠ›, ç›´æ¥å°‡ class çš„ one-hot è·ŸåŸä¾†çš„ input concate èµ·ä¾†å°±ç•¶æˆæ˜¯ condition äº†. å› æ­¤ CVAE çš„æ¶æ§‹å¦‚ä¸‹: å¯¦ä½œç´°ç¯€å°±ä¸å¤šèªªäº†, ç›´æ¥åƒè€ƒ codes ç”±æ–¼æˆ‘å€‘çš„ condition æ˜¯ one-hot, å¦‚æœåŒæ™‚å°‡å…©å€‹ label è¨­å®šç‚º 1, æ˜¯ä¸æ˜¯å°±èƒ½ conditioned on two classes å‘¢? å¯¦é©—å¦‚ä¸‹ conditioned on â€˜0â€™ and â€˜4â€™ conditioned on â€˜1â€™ and â€˜3â€™ å¦å¤–, å¦‚æœçµ¦çš„ condition å€¼æ¯”è¼ƒå°, æ˜¯ä¸æ˜¯å°±å¯ä»¥ç”¢ç”Ÿæ¯”è¼ƒä¸æ˜¯é‚£éº¼ç¢ºå®šçš„ image å‘¢? æˆ‘å€‘å˜—è©¦ conditioned on â€˜4â€™ ä¸”å€¼å¾ 0.1 (weak) åˆ° 1.0 (strong), çµæœå¦‚ä¸‹: é€™å€‹ condition å€¼å¤§å°é‚„çœŸæœ‰åæ‡‰å¼·åº¦å‘¢! Neural network çœŸçš„å¾ˆç¥å¥‡é˜¿~ Mean Field VIè®“æˆ‘å€‘æ‹‰å› VI. Mean Field é€²ä¸€æ­¥é™åˆ¶äº† $q$ çš„ç¯„åœ, å®ƒå‡è¨­æ‰€æœ‰æ§åˆ¶ $q$ çš„åƒæ•¸ {$\\nu_i$} éƒ½æ˜¯äº’ç›¸ç¨ç«‹çš„, é€™æ¨£æ‰€å½¢æˆçš„å‡½æ•¸ç©ºé–“ç¨±ç‚º mean-field family. æ¥è‘—æ¡å– coordinate ascent æ–¹å¼, é‡å°æ¯å€‹ $\\nu_i$ ç¨ç«‹ update. é€™ç¨® fatorized çš„ $q$ ä¸€å€‹å•é¡Œæ˜¯ estimate å‡ºä¾†çš„åˆ†å¸ƒæœƒå¤ª compact, åŸå› æ˜¯æˆ‘å€‘ä½¿ç”¨çš„æŒ‡æ¨™æ˜¯ $KL(q|p)$, è©³ç´°åƒè€ƒ PRML Fig 10.2. æ”¾ä¸Š NIPS 2016 slides, ç¬¦è™Ÿæœƒè·Ÿæœ¬æ–‡æœ‰äº›ä¸åŒ, ä¸éç¸½çµå¾—å¾ˆå¥½: å¦å¤–æƒ³äº†è§£æ›´å¤š Mean Field VI æˆ–æ˜¯é€éä¾‹å­äº†è§£, æ¨è–¦ä»¥ä»¥ä¸‹å…©å€‹è³‡æ–™: Variational Inference tutorial series by Chieh Wu Variational Coin Toss by BjÃ¶rn Smedman Reference Variational Inference tutorial series by Chieh Wu Variational Inference: Foundations and Modern Methods (NIPS 2016 tutorial) Reparameterization Trick Goker Erdogan æœ‰å¾ˆå¥½çš„ VAE, VI æ–‡ç«  Conditional VAE åŸè«–æ–‡ Conditional VAE å¥½æ–‡ç«  Variational Coin Toss by BjÃ¶rn Smedman My CVAE TF Practice Appendix: EM è·Ÿ VI å¾ˆåƒé˜¿åœ¨ä¸€èˆ¬ EM çš„è¨­å®šä¸Š, æˆ‘å€‘æ˜¯å¸Œæœ›æ‰¾åˆ°ä¸€çµ„åƒæ•¸ $\\tilde{\\theta}$ å¯ä»¥è®“ marginal likelihood $\\log p(x|\\theta)$ æœ€å¤§, formally speaking: $$\\begin{align} \\tilde{\\theta}=\\arg\\max_\\theta \\log p(x|\\theta) \\end{align}$$ å¦‚åŒ (4) å’Œ (5), æ­¤æ™‚è¦æ±‚çš„è®Šæ•¸ä¸å†æ˜¯ $q$, è€Œæ˜¯ $\\theta$: $$\\begin{align} \\log p(x|\\theta)=KL\\left(q(z)\\Vert p(z|x,\\theta)\\right)+\\sum_z q(z)\\log\\frac{p(x,z|\\theta)}{q(z)}\\\\ =KL\\left(q(z)\\Vert p(z|x,\\theta)\\right)+ \\color{orange}{ \\mathcal{L}(q,\\theta) } \\\\ \\end{align}$$ æ­¤æ™‚çš„ $\\log p(x|\\theta)$ ä¸å†æ˜¯å›ºå®šçš„ (VIæ˜¯), è€Œæ˜¯æˆ‘å€‘å¸Œæœ›æ„ˆå¤§æ„ˆå¥½. è€Œæˆ‘å€‘çŸ¥é“ $\\mathcal{L}(q,\\theta)$ æ˜¯å®ƒçš„ lower bound é€™é»ä¸è®Š, å› æ­¤å¦‚æœ lower bound æ„ˆå¤§, å‰‡æˆ‘å€‘çš„ $\\log p(x|\\theta)$ å°±ç•¶ç„¶å¯èƒ½æ„ˆå¤§. é¦–å…ˆæ³¨æ„åˆ° (23) å’Œ (24) é‡å°ä»»ä½•çš„ $q$ å’Œ $\\theta$ ç­‰å¼éƒ½æˆç«‹, æˆ‘å€‘å…ˆå°‡ $\\theta$ ç”¨ $\\theta^{old}$ ä»¥åŠ $q(z)$ ç”¨ $p(z|x,\\theta^{old})$ ä»£å…¥å¾—åˆ°: $$\\begin{align} \\log p(x|\\theta^{old})= KL\\left(p(z|x,\\theta^{old})\\Vert p(z|x,\\theta^{old})\\right)+\\mathcal{L}(p(z|x,\\theta^{old}),\\theta^{old})\\\\ =0+\\mathcal{L}(p(z|x,\\theta^{old}),\\theta^{old})\\\\ \\leq\\max_{\\theta}\\mathcal{L}(p(z|x,\\theta^{old}),\\theta)\\\\ \\end{align}$$ æ¥è‘—æ±‚$$\\begin{align} \\theta^{new}=\\arg\\max_{\\theta} \\mathcal{L}(p(z|x,\\theta^{old}),\\theta) \\end{align}$$ å¦‚æ­¤ lower bound å°±è¢«æˆ‘å€‘æé«˜äº†.(28) å°±æ˜¯ EM çš„ M-step, è©³ç´°è«‹çœ‹ PRML Ch9.4 æˆ–åƒè€ƒä¸‹åœ–ç†è§£ â€œ$q(z)$ ç”¨ $p(z|x,\\theta^{old})$ ä»£å…¥â€ é€™å¥è©±å…¶å¯¦æœ‰å•é¡Œ, å› ç‚ºé—œéµä¸å°±æ˜¯ $p(z|x,\\theta)$ å¾ˆé›£æ±‚å—? é€™ä¼¼ä¹è®Šæˆäº†ä¸€å€‹é›ç”Ÿè›‹è›‹ç”Ÿé›çš„æƒ…æ³. (å°±æˆ‘ç›®å‰çš„ç†è§£) æ‰€ä»¥é€šå¸¸ EM è™•ç†çš„æ˜¯ discrete çš„ $z$, ç„¶å¾Œåˆ©ç”¨ $\\sum_z p(x,z|\\theta)$ ç®—å‡º $p(x|\\theta)$, æ¥è‘—å¾—åˆ°æˆ‘å€‘è¦çš„ $p(z|x,\\theta)$. ç­‰æ–¼æ˜¯ç›´æ¥ç°¡åŒ–äº†, ä½† VI ç„¡æ­¤é™åˆ¶.","tags":[{"name":"Variational Inference","slug":"Variational-Inference","permalink":"https://bobondemon.github.io/tags/Variational-Inference/"},{"name":"ELBO","slug":"ELBO","permalink":"https://bobondemon.github.io/tags/ELBO/"},{"name":"Variational Auto Encoder (VAE)","slug":"Variational-Auto-Encoder-VAE","permalink":"https://bobondemon.github.io/tags/Variational-Auto-Encoder-VAE/"}]},{"title":"Ensemble Algorithm Summary Notes","date":"2018-09-03T13:45:08.000Z","path":"2018/09/03/Ensemble-Algorithm-Summary-Notes/","text":"é€™æ˜¯ç”¨è‡ªå·±ç†è§£çš„æ–¹å¼æ•´ç†äº†æ—è»’ç”°è€å¸« ML èª²ç¨‹. å…¶ä¸­ Decision tree and Random Forest æ²’ç´€éŒ„. ä»¥å‰ç¬¬ä¸€æ¬¡æ¥è§¸åˆ° Adaboost çš„æ™‚å€™å°±è¢«å®ƒæ·±æ·±è‘—è¿·äº†, ç•¶æ™‚ face detection å¯å•†ç”¨ç®—æ³•ç„¡ä¸æ¡ç”¨ç¶“å…¸çš„ Viola and Jones adaboost method. åœ¨ç¾åœ¨ DNN æˆä¸»æµçš„æ™‚å€™, é›–ç„¶ adaboost å…‰ç’°å·²é€€å», ä½†åœ¨ data mining, data science é ˜åŸŸ boosting æ–¹æ³•ä»æ˜¯æœ€æˆåŠŸçš„ç®—æ³•ä¹‹ä¸€. åŸºæœ¬ä¸Šåœ¨ Kaggle æ¯”è³½å¯ä»¥çœ‹åˆ°ä¸»è¦å…©å¤§æ–¹æ³•, èˆ‰å‡¡è²éŸ³å½±åƒæ–‡å­—ç­‰ç­‰çš„è¾¨è­˜å°±æ˜¯ DNN, å…¶ä»–å‡¡æ˜¯ data mining ç›¸é—œçš„å°±å±¬ boosting (xgboost).æœ‰è¶£çš„æ˜¯, è¿‘å¹´ä¹Ÿæœ‰ç ”ç©¶äººå“¡ç”¨ ensemble çš„è§’åº¦çœ‹å¾… DNN, å¾é€™è§’åº¦å°±èƒ½ç†è§£ç‚ºä½•ä¸€è·¯å¾ highway network â€“&gt; skip layer resent â€“&gt; resnext çš„æ¶æ§‹æ¼”è®Š, ä»¥åŠç‚ºä½•æ•ˆæœé€™éº¼å¥½. å¯ä»¥åƒè€ƒ â€œæ·±åº¦ç¥ç»ç½‘ç»œä¸­æ·±åº¦ç©¶ç«Ÿå¸¦æ¥äº†ä»€ä¹ˆï¼Ÿâ€ å¾ˆç²¾å½©çš„è§£é‡‹, æˆ–æ˜¯ MSR 2017 é€™ç¯‡è«–æ–‡ Deep Convolutional Neural Networks with Merge-and-Run Mappings ç­†è¨˜å…§å®¹å¦‚ä¸‹: Bagging (or bootstrap) Adaboost æ¼”ç®—æ³•2.1 Adaboost large margin è§£é‡‹2.2 Adaboost exponential error è§£é‡‹ Additive Model (a framework) Gradient Boosting Adaboost as an additive model Gradient Boost Decision Tree (GBDT) å¾…ç ”ç©¶: XGBoost (Kaggle æ¯”è³½ç¥å™¨) Bagging (or bootstrap)é‚„è¨˜å¾—æˆ‘å€‘åœ¨ Why-Aggregation-Work é€™ç¯‡æåˆ°, ç•¶æˆ‘å€‘æœ‰å¾ˆå¤š weak learner ${g_t}$ æ™‚, è¦å¾—åˆ°ä¸€å€‹ strong learner $G$ æœ€ç°¡å–®çš„æ–¹æ³•å°±æ˜¯æŠ•ç¥¨(æˆ–å¹³å‡). æ‰€ä»¥ä¸€å€‹é—œéµå•é¡Œæ˜¯è¦æ€éº¼ç”¢ç”Ÿå¾ˆå¤šçš„ $g_t$?Bagging (or bootstrap) æä¾›äº†ä¸€å€‹ç°¡å–®çš„æ–¹æ³•: å‡è¨­ dataset $D$ æœ‰ $N$ ç­†è³‡æ–™, bagging å°±æ˜¯å¾ $D$ ä¸­é‡è¤‡æ¡æ¨£å‡º $Nâ€™$ ç­†, æˆ‘å€‘ç¨± $Dâ€™$, ç„¶å¾Œ $g_t$ å°±å¯ä»¥ç”¨ $Dâ€™$ è¨“ç·´å‡ºä¾†.æ—¢ç„¶ç¾åœ¨å¯ä»¥æ–¹ä¾¿åœ°ç”¢ç”Ÿå¾ˆå¤š ${g_t}$, ç„¶å¾Œå°± $G$ å°±æ¡ç”¨å¹³å‡æ–¹å¼, ensemble algorithm å°±çµæŸäº†?! ç•¶ç„¶æ²’æœ‰, åˆ¥å¿˜äº†æœ‰ä¸€å€‹å¾ˆé—œéµçš„ç‰¹æ€§æ˜¯, ç•¶ ${g_t}$ æ„è¦‹æ„ˆåˆ†æ­§æ™‚ç”¢ç”Ÿå‡ºä¾†çš„ $G$ æ•ˆæœæ„ˆå¥½!é‚£æˆ‘å€‘å°±å•äº†, bagging ä¸å°±æ¡æ¨£å—? æˆ‘æ€éº¼çŸ¥é“é€™æ¬¡æ¡æ¨£å‡ºä¾†çš„ $Dâ€™$ æ‰€è¨“ç·´å‡ºä¾†çš„ $g_t$ æœƒè·Ÿä¹‹å‰ä¸€æ¬¡çš„æ„è¦‹åˆ†æ­§?æˆ‘å€‘å°±æ˜¯èƒ½çŸ¥é“! (ç¥å¥‡å§) è¦äº†è§£ç‚ºä»€éº¼, æˆ‘å€‘å¿…é ˆå…ˆå°‡ bagging æ“´å±•ä¸€ä¸‹, æƒ³æˆæ˜¯å° weighted $D$ æ¡æ¨£, å…¶ä¸­æ¯ä¸€ç­†è³‡æ–™ $x_n$ çš„ weight $u_n$ ä»£è¡¨æŠ½ä¸­çš„æ©Ÿç‡. å¦‚æœ bagging æ˜¯å° weighted $D$ æ¡æ¨£çš„è©±, åœ¨ç¬¬ t è¼ªçš„ $g_t$ å¾—åˆ°æ–¹å¼å¦‚ä¸‹: $$\\begin{align} g_t=\\arg\\min_{h\\in \\mathcal{H}}\\left(\\sum_{n=1}^N u_n^{(t)} \\mathbb{I}[y_n\\neq h(x_n)] \\right) \\end{align}$$ å…¶ä¸­ $\\mathbb{I}[â€¦]$ è¡¨ç¤º indicator function, æ¢ä»¶ç‚º true å‰‡ return 1, otherwise return 0.æƒ³æ³•å°±æ˜¯æˆ‘å€‘è¦è¨­è¨ˆä¸€çµ„æ–°çš„æ¬Šé‡, è®“æ–°çš„æ¬Šé‡å°æ–¼ $g_t$ ä¾†èªªç›¸ç•¶æ–¼äº‚çŒœ, é€™æ¨£ç”¨æ–°æ¬Šé‡æ‰¾å‡ºçš„ $g_t+1$ å°±æœƒè·Ÿä¹‹å‰çš„æ„è¦‹åˆ†æ­§äº†. å…·é«”ä¾†èªª, æ–°æ¬Šé‡è¦æœ‰ä»¥ä¸‹çš„æ•ˆæœ: $$\\begin{align} \\frac{\\sum_{n=1}^N{u_n^{(t+1)} \\mathbb{I}[y_n\\neq g_t(x_n)]}}{\\sum_{n=1}^N{u_n^{(t+1)}}}=\\frac{1}{2} \\end{align}$$ ç‰©ç†æ„ç¾©å°±æ˜¯å°æ–¼ $g_t$ ä¾†èªª$$\\begin{align} \\mbox{for weak learner }g_t\\mbox{: }\\left(\\mbox{total }u_n^{(t+1)}\\mbox{ of incorrect}\\right)= \\left(\\mbox{total }u_n^{(t+1)}\\mbox{ of correct}\\right) \\end{align}$$ æ‰€ä»¥æ–°çš„æ¬Šé‡èª¿æ•´æ–¹å¼å…¶å¯¦å¾ˆç°¡å–®, ç”¨ä¸€å€‹ä¾‹å­è§£é‡‹. å‡å¦‚ $u_n^t$ incorrect åˆæ˜¯ 300, $u_n^t$ correct åˆæ˜¯ 500. æˆ‘å€‘åªè¦æŠŠä¹‹å‰çš„ $u_n^t$ incorrectéƒ¨åˆ†éƒ½ä¹˜ 500, è€Œ correct éƒ¨åˆ†ä¹˜ 300å°±å¯ä»¥äº†.æˆ–è€…æˆ‘å€‘é€™éº¼å¯«, å®šç¾© $\\epsilon_t=300/(300+500)$, å‰‡$$\\begin{align} u_n^{(t+1)}=u_n^{(t)}(1-\\epsilon_t) \\mbox{, if } y_n\\neq g_t(x_n)\\\\ u_n^{(t+1)}=u_n^{(t)}\\epsilon_t \\mbox{, if } y_n = g_t(x_n)\\\\ \\end{align}$$ æˆ–é€šå¸¸ä¹Ÿå¯ä»¥é€™éº¼è¨ˆç®— æ‰€ä»¥ç›®å‰ç‚ºæ­¢, æˆ‘å€‘å¯ä»¥ç”¨ bagging çš„æ–¹å¼ (å° weighted data) ç”¢ç”Ÿå‡ºçœ‹ä¼¼ç›¸ç•¶æ„è¦‹ä¸åŒçš„ $g_t$, é‚£æœ€å¾Œçš„ $G$ ç”¨å¹³å‡å°±å¯ä»¥äº†å—? å¯èƒ½ä¸å¤§å¥½, å› ç‚º $g_t$ æ˜¯é‡å°æŸä¸€ç¨®æ¬Šé‡çš„ dataset å¥½, ä¸ä»£è¡¨å°åŸä¾†æ²’æœ‰æ¬Šé‡ (æˆ–uniformæ¬Šé‡) çš„ dataset æ˜¯å¥½çš„.æ—¢ç„¶ç›´æ¥å¹³å‡å¯èƒ½ä¸å¤ å¥½, ä¸å¦‚å°±ç”¨ linear combination æ–¹å¼çµ„åˆ $g_t$ å§, ä¸éçµ„åˆçš„ coefficients æ˜¯éœ€è¦å·§æ€è¨­è¨ˆçš„. è€Œ Adaboost å°±è¨­è¨ˆå‡ºäº†ä¸€ç¨®çµ„åˆæ–¹å¼, èƒ½è­‰æ˜é€™ç¨®çµ„åˆæ–¹å¼æœƒä½¿å¾— training error æ”¶æ–‚è‡³0. (å¦ä¸€ç¨®ç”¨ additive model çš„è§£é‡‹æ–¹å¼ç‚ºé€™æ¨£çš„ coefficient è¨­è¨ˆæ–¹å¼ç›¸ç•¶æ–¼ç”¨ steepest descent ä¸¦é¸æ“‡æœ€ä½³çš„æ­¥é•·). é€™äº›æœƒåœ¨æ–‡ç« ä¸‹é¢èªªæ˜. Adaboost æ¼”ç®—æ³• Adaboost large margin è§£é‡‹ä¸€èˆ¬ä¾†èªª, model æ„ˆè¤‡é›œæ„ˆå®¹æ˜“ overfit, ä¸éå¾ˆç‰¹åˆ¥çš„æ˜¯ adaboost éš¨è‘— iteration çµåˆæ„ˆå¤š weak learners åè€Œä¸æœƒæœ‰å®¹æ˜“ overfit çš„ç¾è±¡. å…¶ä¸­ä¸€ç¨®è§£é‡‹æ–¹å¼æ˜¯ adaboost å…·æœ‰é¡ä¼¼ SVM çš„ large margin æ•ˆæœ.æˆ‘å€‘é¦–å…ˆåˆ†æä¸€ä¸‹ç¬¬ t+1 æ¬¡ iteration, dataset çš„ weights$$\\begin{align} u_n^{(t+1)}=u_n^{(t)}\\diamond_t^{-y_n g_t(x_n)}\\\\ =u_n^{(t)}\\exp (-y_n \\alpha_t g_t(x_n)) \\end{align}$$ æˆ‘å€‘é€™è£¡ä½¿ç”¨ binary classification ä¾†èªªæ˜, å…¶ä¸­ $y_n,g_t(x_n)\\in${-1,+1}, å¼ (6) å¯ä»¥å¾ä¸Šä¸€æ®µ â€œAdaboost æ¼”ç®—æ³•â€ çš„åœ–ä¸­æ­¥é©Ÿ2çš„ update å¼å­çœ‹å‡º. è€Œå¼ (7) å¾ $\\diamond_t$ å®šç¾©å¾—åˆ°.ä¸Šå¼å¯ä»¥ä¸€è·¯å±•é–‹åˆ°é–‹é ­ (iteration 1), å¦‚ä¸‹: $$\\begin{align} u_n^{(T+1)}=u_n^{(1)}\\prod_{t=1}^T \\exp (-y_n \\alpha_t g_t(x_n)) \\\\ =\\frac{1}{N}\\exp\\left(-y_n \\color{orange}{ \\sum_{t=1}^T \\alpha_t g_t(x_n) } \\right) \\end{align}$$ æœ‰ç™¼ç¾å—? æ©˜è‰²çš„éƒ¨åˆ†å…¶å¯¦å°±æ˜¯æˆ‘å€‘çš„ $G$ $$\\begin{align} G(x_n)=sign\\left( \\color{orange}{ \\sum_{t=1}^T \\alpha_t g_t(x_n) } \\right) \\end{align}$$ è€Œå¦‚æœå°‡ $\\alpha_t$ çœ‹æˆæ˜¯ t-th coefficient, $g_t(x_n)$ çœ‹æˆæ˜¯ t-th ç¶­åº¦çš„ç‰¹å¾µ, æ©˜è‰²éƒ¨åˆ†å°±ç­‰åŒæ–¼ unnormalized margin. (é™¤ä»¥ coefficients çš„ norm å°±æ˜¯ marginäº†)Adaboost å¯ä»¥è­‰æ˜ (with exponential decay) $$\\begin{align} \\sum_{n=1}^N u_n^{(t)}\\rightarrow 0\\mbox{, for }t\\rightarrow 0 \\end{align}$$ é€™æ„å‘³è‘—ä»€éº¼? èªªæ˜äº†éš¨è‘— iteration å¢åŠ , æ©˜è‰²çš„å€¼æœƒæ„ˆå¤§, ç­‰åŒæ–¼æˆ‘å€‘çš„ $G$ å°æ–¼è³‡æ–™çš„ margin æœƒæ„ˆå¤§.è­‰æ˜å¯åƒè€ƒ æèˆª çµ±è¨ˆå­¸ç¿’æ–¹æ³• p142 Adaboost exponential error è§£é‡‹å…¶å¯¦å–®çœ‹å¼ (9) æˆ‘å€‘å®Œå…¨å¯ä»¥æŠŠå®ƒç•¶æˆ error function. é‡å¯«ä¸€ä¸‹: $$\\begin{align} u_n^{(T+1)}=\\frac{1}{N}\\exp\\left(-y_n \\color{orange}{ \\sum_{t=1}^T \\alpha_t g_t(x_n) } \\right)\\\\ =\\frac{1}{N}\\exp\\left(-y_n \\color{orange}{ f_T(x_n) } \\right) \\end{align}$$ æ€éº¼èªªå‘¢? å…¶å¯¦æ©˜è‰²éƒ¨åˆ†æˆ‘å€‘å¯æƒ³æˆæ˜¯è©²ç­†è³‡æ–™ $x_n$ çš„åˆ†æ•¸, è¨˜åš $f_T(x_n)$, ç•¶ $y_n=+1$ æ™‚, å¦‚æœ $f_T(x_n)$ å¾ˆå°å‰‡æœƒå°è‡´ $\\exp(-y_n f_T(x_n))$ æœƒå¾ˆå¤§, åŒç†ç•¶ $y_n=-1$ æ™‚, å¦‚æœ $f_T(x_n)$ å¾ˆå¤§å‰‡æœƒå°è‡´ $\\exp(-y_n f_T(x_n))$ æœƒå¾ˆå¤§. å› æ­¤ $\\exp(-y_n f_T(x_n))$ å¯ä»¥ç•¶æˆ error function ä¾† minimize.è€Œå®ƒè·Ÿ 0-1 error function æœ‰å¦‚ä¸‹çš„é—œä¿‚: è€Œæˆ‘å€‘çŸ¥é“ Adaboost æ»¿è¶³å¼ (11), ç­‰åŒæ–¼èªªæ˜ exponential error æ”¶æ–‚. ç”±æ–¼ upper bound çš„é—œä¿‚ä¹Ÿå°è‡´äº† 0-1 error æ”¶æ–‚.è½åˆ°æœ‰å€‹æ–¹æ³•å¯ä»¥ä½¿ error è¿…é€Ÿæ”¶æ–‚åˆ° 0, é€™ä¸æ˜¯å¤ªå®Œç¾äº†å—? åˆ¥é«˜èˆˆå¾—å¤ªæ—©, å› ç‚ºé€™å€‹ error æ˜¯ inside error. æœ‰å­¸é ML çš„ç«¥é‹å°±æ‡‰è©²æœƒè­¦è¦ºåˆ°ç•¶ inside error ç‚º 0, æ„å‘³è‘—éå¸¸å®¹æ˜“ overfit! å¥½åœ¨å¯¦ä½œä¸Š Adaboost å»ä¸æ˜¯é‚£éº¼å®¹æ˜“ (åŸå› åœ¨ä¸Šä¸€æ®µ large margin çš„è§£é‡‹), é€™å°±å¸¶ä¾†äº†ä¸€å€‹å¥½è™•, å°±æ˜¯åœ¨ä½¿ç”¨ Adaboost çš„æ™‚å€™, æˆ‘å€‘å¯ä»¥å¾ˆæ”¾å¿ƒçš„ç›´æ¥è¨“ç·´å¤šæ¬¡ iteration, ç”šè‡³åˆ° inside error æ¥è¿‘ 0, æœ€å¾Œçš„ outside test ä¹Ÿä¸æœƒå£æ‰. é€™ç‰¹æ€§å€’æ˜¯æŒºæ–¹ä¾¿çš„. AdaBoost å°çµè«– æˆ‘å€‘å¸Œæœ›è—‰ç”±èåˆå¾ˆå¤š {$g_t$} ä¾†å¾—åˆ°å¼·å¤§çš„ $G$, åŒæ™‚æˆ‘å€‘çŸ¥é“ {$g_t$} ä¹‹é–“æ„è¦‹æ„ˆåˆ†æ­§æ„ˆå¥½.æ¯ä¸€å€‹ $g_t$ éƒ½æ˜¯æ ¹æ“šç•¶å‰ weighted dataset å¾—åˆ°çš„. åˆ©ç”¨èª¿æ•´è³‡æ–™æ¬Šé‡çš„æ–¹å¼ä¾†è®“ä¸Šä¸€æ¬¡çš„ $g_t$ è¡¨ç¾å¾ˆå·®, é€™æ¨£æ–°æ¬Šé‡çš„ dataset è¨“ç·´å‡ºä¾†çš„ $g$ å°±æœƒè·Ÿä¹‹å‰çš„çœ‹æ³•åˆ†æ­§.Adaboost å†åˆ©ç”¨ä¸€ç¨®é —ç‚ºå·§æ€çš„ç·šæ€§çµ„åˆæ–¹å¼ä¾†èåˆ {$g_t$}, æœ€çµ‚å¾—åˆ°å¼·å¤§çš„ $G$ Additive Model (a framework)é€™æ˜¯éå¸¸é‡è¦çš„ä¸€å€‹æ¡†æ¶, Adaboost åœ¨é€™æ¡†æ¶ä¸‹å¯è¦–ç‚ºå®ƒçš„ä¸€å€‹ special case, åŒæ™‚è‘—åçš„ Gradient Boost Decision Tree (GBDT) ä¹Ÿæ˜¯åŸºæ–¼æ­¤æ¡†æ¶ä¸‹çš„æ¼”ç®—æ³•. é€šå¸¸ supervised learning å°±æ˜¯åœ¨å­¸ç¿’ input and output ä¹‹é–“çš„ mapping function $f$, ç°¡å–®è¬›, ç›´æ¥å­¸ä¸€å€‹å¥½çš„ $f$ å¯èƒ½å¾ˆå›°é›£, æ‰€ä»¥ä¸å¦‚ä½¿ç”¨ greedy æ–¹å¼, å°±æ˜¯å¾ç›®å‰çš„ $f_t$ å‡ºç™¼, è€ƒæ…®æ€éº¼ä¿®æ­£ç¾åœ¨çš„ $f_t$ ä¾†ä½¿å¾— error æ›´å°. åš´è¬¹ä¸€é»æ•¸å­¸æè¿°å¦‚ä¸‹: è€ƒæ…® additive model$$\\begin{align} f_T(x)=\\sum_{t=1}^T \\alpha_t g_t(x) \\end{align}$$ å…¶ä¸­, $g_t(x)$ ç‚ºç¬¬ t æ¬¡å­¸åˆ°çš„ base learner, $\\alpha_t$ ç‚ºå®ƒçš„æ¬Šé‡.å®šç¾© $L(y,f(x))$ ç‚º loss (or error) function, æ‰€ä»¥æˆ‘å€‘è¦æ‰¾çš„ä¿®æ­£çš„ mapping function å¦‚ä¸‹: $$\\begin{align} (\\alpha_T,g_T)=\\arg\\min_{\\eta,h}\\sum_{n=1}^N L(y_n,f_{T-1}(x_n)+\\eta h(x_n)) \\end{align}$$ ç”¨ä¸Šå¼çš„æ–¹æ³•æ‰¾åˆ°è¦ä¿®æ­£çš„ mapping function å› æ­¤ mapping function æ›´æ–°å¦‚ä¸‹: $$\\begin{align} f_T(x)=f_{T-1}(x)+\\alpha_T g_T(x) \\end{align}$$ æˆ‘å€‘å¯ä»¥æƒ³æˆæ˜¯åœ¨å‡½æ•¸ç©ºé–“åš gradient descent. æ¯ä¸€æ¬¡å°±æ˜¯æ‰¾ä¸€å€‹ descent direction, åœ¨é€™è£¡å°±æ˜¯ $h$, ç„¶å¾Œè¨­å®šåˆé©çš„æ­¥é•· $\\eta$, é€™éº¼æƒ³å°±æ˜¯æœ€ä½³åŒ–çš„ gradient descent äº†. Gradient BoostingAdditive model framework å¾ˆç°¡å–®, é›£çš„åœ°æ–¹åœ¨é‚£å€‹ $\\arg\\min$ å¼ (15). è€Œ Gradient Boosting å¯ä»¥èªªæ˜¯ä¸€ç¨®æ˜ç¢ºå¯¦ç¾ Additive model çš„æ–¹å¼, æˆ‘å€‘å¯ä»¥å°‡ $\\eta$ å’Œ $h$ åˆ†é–‹æ‰¾, ä¾‹å¦‚å…ˆæ‰¾ $h$: $$\\begin{align} &amp;\\min_h\\sum_{n=1}^N L(y_n,f_{T-1}(x_n)+\\eta h(x_n))\\\\ &amp;\\mbox{by Taylor: }\\simeq \\min_h\\sum_{n=1}^N\\left(L(y_n,f_{T-1}(x_n))+\\eta h(x_n) \\color{red}{ \\left(\\frac{\\partial L(y_n,f)}{\\partial f}\\right) _{f=f_{T-1}} } \\right)\\\\ \\end{align}$$ Taylor å±•é–‹å¼é‚£é‚Šå¯ä»¥é€™éº¼æƒ³ $$\\begin{align} &amp;\\mbox{å°‡ }L(y_n, \\color{green}{ f_{T-1}(x_n) }+ \\color{blue}{ \\eta h(x_n) } )\\mbox{ çœ‹ä½œ }\\hat{L}( \\color{green}{ \\tilde{x} }+ \\color{blue}{ \\delta } )\\\\ &amp;\\mbox{å› æ­¤ by Taylor } \\simeq \\hat{L}( \\color{green}{\\tilde{x}} )+ \\color{blue}{\\delta} \\left(\\frac{\\partial \\hat{L}(x) }{\\partial x}\\right)_{x= \\color{green}{\\tilde{x}} } \\end{align}$$ ä¸Šé¢ç´…è‰²éƒ¨åˆ†åœ¨è¨ˆç®—çš„æ™‚å€™æ˜¯ä¸€å€‹å›ºå®šå€¼, æˆ‘å€‘å…ˆä»¤ç‚º $$\\begin{align} \\left(\\frac{\\partial L(y_n,f)}{\\partial f}\\right) _{f=f_{T-1}}= \\color{red}{-\\tilde{y}_n} \\end{align}$$ æ‰€ä»¥ (18) è®Šæˆ $$\\begin{align} &amp;= \\min_h\\sum_{n=1}^N\\left(L(y_n,f_{T-1}(x_n)) \\color{red}{-} \\eta h(x_n) \\color{red}{ \\tilde{y_n} } \\right)\\\\ &amp;\\mbox{å»æ‰èˆ‡}h\\mbox{ç„¡é—œé …ä¸¦è£œä¸Š}2=\\min_h \\sum_{n=1}^N \\left(-2h(x_n)\\tilde{y}_n\\right) \\end{align}$$ å¾ˆæ˜é¡¯, å¦‚æœ $h$ ç„¡é™åˆ¶, å‰‡è§£ç‚º $h=\\infty$, é€™é¡¯ç„¶ä¸æ˜¯æˆ‘å€‘è¦çš„, åœ¨ optimization çš„æ™‚å€™, æˆ‘å€‘éœ€è¦çš„åªæ˜¯ gradient çš„æ–¹å‘, è€Œä¸æ˜¯å¤§å°, å¤§å°å¯ä»¥ç”± stepsize æ§åˆ¶. ä¸éå¦‚æœåŠ ä¸Š $norm(h)=1$ æ¢ä»¶ä¸¦ä½¿ç”¨ Lagrange Multipliers æœƒè¼ƒè¤‡é›œ, å¯¦ä½œä¸Šæˆ‘å€‘å°±ç›´æ¥å°‡ $norm(h)$ ç•¶ä½œä¸€å€‹ penality åŠ åœ¨ loss è£¡å°±å¯ä»¥. å› æ­¤ (23) ä¿®æ”¹å¦‚ä¸‹: $$\\begin{align} =\\min_h \\sum_{n=1}^N \\left(-2h(x_n)\\tilde{y}_n+(h(x_n))^2\\right) \\end{align}$$ æ¹Šé½Šå¹³æ–¹é …æœƒè®Šæˆ (ä¹‹å‰åŠ çš„2æ˜¯ç‚ºäº†é€™è£¡æ¹Šå¹³æ–¹é …) $$\\begin{align} =\\min_h \\sum_{n=1}^N \\left( \\mbox{const}+\\left(h(x_n)-\\tilde{y}_n\\right)^2 \\right) \\end{align}$$ OK! åˆ°é€™è£¡æˆ‘å€‘ç™¼ç¾äº†ä¸€å€‹é‡è¦çš„è§£é‡‹, $h$ çš„æ‰¾æ³•å°±æ˜¯å° $\\tilde{y}_n$ åš sqaure error regression! å¾—åˆ° $g_T=h$ å¾Œ, é‚£éº¼æ­¥é•· $\\eta$ å‘¢? $$\\begin{align} \\alpha_T=\\min_{\\eta}\\sum_{n=1}^N L(y_n,f_{T-1}(x_n)+\\eta g_T(x_n))\\\\ \\end{align}$$ é€™å€‹è§£é€šå¸¸å¾ˆå¥½ç®—, ä»¤ $L$ å¾®åˆ†ç‚º 0 å³å¯, æ˜¯å€‹å–®è®Šé‡æ±‚è§£. åˆ°ç›®å‰ç‚ºæ­¢, æˆ‘å€‘å¯ä»¥å°‡æ•´å€‹ Gradient Boost æ¼”ç®—æ³•åˆ—å‡ºä¾†äº†: $$\\begin{align} &amp;\\mbox{1. Init }g_0(x)\\\\ &amp;\\mbox{2. For }t=1~T\\mbox{ do:}\\\\ &amp;\\mbox{3. }\\tilde{y}_n=-\\left(\\frac{\\partial L(y_n,f)}{\\partial f}\\right)_{f=f_{t-1}}\\mbox{, n=1~N}\\\\ &amp;\\mbox{4. }g_t=\\arg\\min_h\\left(h(x_n)-\\tilde{y}_n\\right)^2\\\\ &amp;\\mbox{5. }\\alpha_T=\\arg\\min_{\\eta}\\sum_{n=1}^N L\\left(y_n,f_{t-1}(x_n)+\\eta g_t(x_n)\\right)\\\\ &amp;\\mbox{6. }f_t(x)=f_{t-1}(x)+\\alpha_t g_t(x) \\end{align}$$ Adaboost as an additive modelå°‡ Adaboost å¥—ç”¨ additive model framework æ™‚æœƒæ˜¯ä»€éº¼æƒ…æ³?é¦–å…ˆ loss æ˜¯ exponential loss, ç„¶å¾Œä¸€æ¨£ç”¨ binary classification ä¾†èªªæ˜, å…¶ä¸­ $y_n,g_t(x_n)\\in${-1,+1}, å‰‡æˆ‘å€‘è¦æ‰¾çš„ $h$ å¦‚ä¸‹ (å°ç…§ (12) and (13) ä¸¦ä½¿ç”¨ additive model (14) çš„æ¶æ§‹): $$\\begin{align} g_T=\\min_h\\sum_{n=1}^N\\exp\\left(-y_n\\left(f_{T-1}(x_n)+\\eta h(x_n)\\right)\\right)\\\\ =\\min_h\\sum_{n=1}^N u_n^{(T)}\\exp(-y_n\\eta h(x_n))\\\\ \\simeq\\min_h\\sum_{n=1}^N u_n^{(T)}(1-y_n\\eta h(x_n))\\\\ =\\min_h\\sum_{n=1}^N u_n^{(T)}(-y_n h(x_n))\\\\ \\end{align}$$ (33) åˆ° (34) ä½¿ç”¨ $u_n^{(T)}$ çš„å®šç¾©, åƒè€ƒ (13). è€Œæœ€å¾Œçš„ (36) è¡¨æ˜äº†å¯¦éš›ä¸Šå°±æ˜¯é¸æ“‡è®“ training data åœ¨æ–°çš„ weighted dataset ä¸‹è¡¨ç¾æœ€å¥½çš„é‚£å€‹ $h$, å…·é«”åŸå› çœ‹ä¸‹åœ–.é€™ä¸æ­£æ˜¯ Adaboost é¸æ“‡ weak learner çš„æ–¹å¼å—? æœ€å¾Œåˆ¥å¿˜äº† stepsize, å°‡ (34) æ›ä¸€ä¸‹è®Šæ•¸, $h$ è®Š $\\eta$: $$\\begin{align} \\alpha_T=\\arg\\min_{\\eta}\\sum_{n=1}^N u_n^{(T)}\\exp(-y_n \\eta g_t(x_n))\\\\ \\end{align}$$ å…©ç¨®æƒ…æ³:$$\\begin{align} \\mbox{1. }y_n=g_t(x_n)\\mbox{: }u_n^{(T)}\\exp(-\\eta)\\\\ \\mbox{2. }y_n\\neq g_t(x_n)\\mbox{: }u_n^{(T)}\\exp(+\\eta)\\\\ \\end{align}$$ æ‰€ä»¥$$\\begin{align} \\alpha_T=\\arg\\min_{\\eta}\\left(\\sum_{n=1}^N u_n^{(T)}\\right) \\cdot \\left(\\left(1-\\epsilon_T\\right)\\exp\\left(-\\eta\\right)+\\epsilon_T\\exp\\left(+\\eta\\right)\\right) \\end{align}$$ ä»¤å¾®åˆ†ç‚º 0, æˆ‘å€‘å¯ä»¥å¾ˆå®¹æ˜“å¾—åˆ° $$\\begin{align} \\alpha_T = \\ln\\sqrt{\\frac{1-\\epsilon_T}{\\epsilon_T}} \\end{align}$$ é€™æ­£å¥½ä¹Ÿå°±æ˜¯ adaboost æ‰€è¨ˆç®—çš„æ–¹å¼! ç¸½çµä¸€ä¸‹, Adaboost åœ¨ additive model æ¡†æ¶ä¸‹, ç›¸ç•¶æ–¼ä½¿ç”¨ steepest gradient descent æ–¹å¼åœ¨å‡½æ•¸ç©ºé–“æ‰¾ weaker learner, ä¸¦ä¸”å°‡ stepsize æŒ‡å®šç‚ºæœ€ä½³æ­¥é•·. Gradient Boost Decision Tree (GBDT)Gradient Boost å¾ˆæ£’çš„ä¸€å€‹ç‰¹æ€§æ˜¯ error function æ²’é™å®š, ä¾‹å¦‚ä½¿ç”¨ exponential error å°±æ˜¯ adaboost, è€Œå¦ä¸€å€‹å¸¸ç”¨çš„æ˜¯ sqaure error.ç•¶ä½¿ç”¨ square error æ™‚, $\\tilde{y}_n$ å°±æœƒè®Šæˆ $(y_n-x_n)$ ä¹Ÿå°±æ˜¯ residual. å°ç…§ GradientBoost (27)~(32) ä¾†çœ‹, æˆ‘å€‘ç™¼ç¾æ•´å€‹æ¼”ç®—æ³•è®Šæˆå°æ¯ä¸€æ¬¡ iteration çš„ residual åš regression.å¦å¤–åœ¨å¯¦å‹™ä¸Š base learner å¸¸å¸¸ä½¿ç”¨ Decision Tree (å› ç‚º decision tree æœ‰å¾ˆå¤šå¥½è™•: å¯è§£é‡‹æ€§ã€è¨“ç·´å¿«ã€å¯è™•ç†ç¼ºå¤±è³‡æ–™â€¦), ä¸éé€™å°±è¦ç‰¹åˆ¥æ³¨æ„äº†, å› ç‚ºå¦‚æœé•·æˆ fully growed tree å°±ç›´æ¥æŠŠ residual regression åˆ° 0 äº†. å› æ­¤, decision tree éœ€è¦ regularization, è€Œå¯¦å‹™ä¸Šæ¡ç”¨ pruned tree. æ•´å€‹ GBDT ç¯€è‡ªèª²ç¨‹ slide å¦‚ä¸‹: XGBoosté€™ç¯‡æ–‡ç«  XGBoostçš„åŸç† ä»‹ç´¹å¾—å¾ˆå¥½ å¹¾å€‹é‡é»æ•´ç†, XGBoost åŸºæœ¬ä¸Šä¹Ÿæ˜¯ gradient boost çš„ä¸€ç¨®, æ¯”è¼ƒç‰¹åˆ¥çš„æ˜¯æ³°å‹’å±•å±•é–‹ (18) ä½¿ç”¨åˆ°äºŒéšå°å‡½æ•¸: $$\\begin{align} &amp;\\min_h\\sum_{n=1}^N L(y_n,f_{T-1}(x_n)+\\eta h(x_n))\\\\ &amp;\\simeq \\min_h\\sum_{n=1}^N\\left(L(y_n,f_{T-1}(x_n))+\\eta h(x_n) \\left(\\frac{\\partial L(y_n,f)}{\\partial f}\\right) _{f=f_{T-1}}\\\\ \\color{red} { +\\eta^2h^2(x_n)\\left(\\frac{\\partial^2 L(y_n,f)}{\\partial^2 f}\\right)_{f=f_{T-1}} } \\right)\\\\ &amp;=\\min_h\\sum_{n=1}^N \\left( L(y_n,f_{T-1}(x_n)) + \\eta h(x_n)\\mbox{Gradient}_n + \\frac{\\eta^2h^2(x_n)}{2}\\mbox{Hessian}_n \\right)\\\\ &amp;=\\min_h\\sum_{n=1}^N \\left( \\eta h(x_n)\\mbox{Gradient}_n + \\frac{\\eta^2h^2(x_n)}{2}\\mbox{Hessian}_n \\right)\\\\ \\end{align}$$ æœ€å¾Œå†åŠ ä¸Šä¸€å€‹ regularization term $$\\begin{align} &amp;=\\min_h\\sum_{n=1}^N \\left( \\eta h(x_n)\\mbox{Gradient}_n + \\frac{\\eta^2h^2(x_n)}{2}\\mbox{Hessian}_n \\right) + \\Omega(h)\\\\ \\end{align}$$ é‡å° (46) è¦æ‰¾åˆ°æœ€å¥½çš„ $h$, å¦‚æœä½¿ç”¨ Decision Tree, $\\Omega(h)$ å¯ä»¥ä½¿ç”¨æ¨¹çš„æ·±åº¦ã€è‘‰å­æ•¸é‡ã€è‘‰å­å€¼çš„å¤§å°ç­‰ç­‰è¨ˆç®—. ä½†é—œéµæ˜¯å¦‚ä½•æœ‰æ•ˆç‡åœ°æ‰¾åˆ°å¾ˆå¥½çš„ $h$, è€Œåœ¨ Decision Tree æ­¤å•é¡Œç›¸ç•¶æ–¼å¦‚ä½•æœ‰æ•ˆç‡çš„å° Tree åš splitting. XGBoost æ–‡ç« ä½¿ç”¨éå¸¸æœ‰æ•ˆç‡çš„è¿‘ä¼¼æ–¹æ³•, ä¸¦ä¸”è©²æ–¹æ³•å¯ä»¥å¾ˆå¥½çš„ä¸¦è¡ŒåŠ é€Ÿ. å°æ–¼ xgboost å°±åªç²—æ·ºçš„äº†è§£åˆ°é€™äº†, ä¹Ÿé‚„æ²’æœ‰çœŸçš„æœ‰ä»€éº¼èª¿æ•´çš„ç¶“é©—, å°±æŠŠé€™å€‹èª²é¡Œæ”¾åœ¨ todo list å§. Reference æ—è»’ç”°è€å¸« ML èª²ç¨‹ æèˆª çµ±è¨ˆå­¸ç¿’æ–¹æ³• Why-Aggregation-Work ä»¥å‰ Adaboost and face detection paper survey å…¶ä¸­Rapid object detection using a boosted cascade of simple features, 2001, cited 17597 æ·±åº¦ç¥ç»ç½‘ç»œä¸­æ·±åº¦ç©¶ç«Ÿå¸¦æ¥äº†ä»€ä¹ˆï¼Ÿ Deep Convolutional Neural Networks with Merge-and-Run Mappings XGBoostçš„åŸç† XGBoost: A Scalable Tree Boosting System","tags":[{"name":"bagging","slug":"bagging","permalink":"https://bobondemon.github.io/tags/bagging/"},{"name":"Adaboost","slug":"Adaboost","permalink":"https://bobondemon.github.io/tags/Adaboost/"},{"name":"Gradient Boost","slug":"Gradient-Boost","permalink":"https://bobondemon.github.io/tags/Gradient-Boost/"}]},{"title":"TF Notes (5), GRU in Tensorflow","date":"2018-07-30T15:29:01.000Z","path":"2018/07/30/TF-Notes-GRU-in-Tensorflow/","text":"å°ç­†è¨˜. Tensorflow è£¡å¯¦ä½œçš„ GRU è·Ÿ Colahâ€™s blog æè¿°çš„ GRU æœ‰äº›ä¸å¤ªä¸€æ¨£. æ‰€ä»¥åšäº†ä¸€ä¸‹ TF çš„ GRU çµæ§‹. åœ–æ¯”è¼ƒé†œ, æˆ‘ç›¡åŠ›äº†â€¦ XD TF çš„ GRU çµæ§‹ u å¯ä»¥æƒ³æˆæ˜¯åŸä¾† LSTM çš„ forget gate, è€Œ c è¡¨ç¤ºè¦åœ¨ memory cell ä¸­éœ€è¦è¨˜ä½çš„å…§å®¹. é€™å€‹è¦è¨˜ä½çš„å…§å®¹ç°¡å–®è¬›æ˜¯ç”¨ä¸€å€‹ gate (r) ä¾†æ§åˆ¶ä¹‹å‰çš„ state æœ‰å¤šå°‘æ¯”ä¾‹ä¿ç•™, concate input å¾Œåš activation transform å¾Œå¾—åˆ°. å¯ä»¥å°ç…§ä¸‹é¢ tf source codes. TF Source Codesrnn_cell_impl.py 12345678910111213141516171819def call(self, inputs, state): \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\" gate_inputs = math_ops.matmul( array_ops.concat([inputs, state], 1), self._gate_kernel) gate_inputs = nn_ops.bias_add(gate_inputs, self._gate_bias) value = math_ops.sigmoid(gate_inputs) r, u = array_ops.split(value=value, num_or_size_splits=2, axis=1) r_state = r * state candidate = math_ops.matmul( array_ops.concat([inputs, r_state], 1), self._candidate_kernel) candidate = nn_ops.bias_add(candidate, self._candidate_bias) c = self._activation(candidate) new_h = u * state + (1 - u) * c return new_h, new_h","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://bobondemon.github.io/tags/TensorFlow/"},{"name":"GRU","slug":"GRU","permalink":"https://bobondemon.github.io/tags/GRU/"}]},{"title":"(what is) Probabilistic Graphical Models","date":"2018-06-16T02:27:30.000Z","path":"2018/06/16/what-is-Probabilistic-Graphical-Model/","text":"æœ¬ç¯‡ä¸»è¦ä»‹ç´¹ä»€éº¼æ˜¯ PGM, ä»¥åŠä¸€å€‹å¾ˆé‡è¦çš„æ‡‰ç”¨ Part-of-Speech tagging. PGM çš„éƒ¨åˆ†ä¸»è¦åœç¹åœ¨ â€œå®ƒæ˜¯ä»€éº¼?â€ ä¹Ÿå°±æ˜¯ Koller èª²ç¨‹çš„ Representation. Inference ä¸è¨è«–, å› ç‚ºè‡ªå·±ä¹Ÿæ²’è®€å¾ˆæ·±å…¥ (æ±—), è€Œ Learning å°±ç›¸ç•¶æ–¼ ML è£¡çš„ training, æœƒåœ¨ä»‹ç´¹ POS æ™‚æ¨å°ä¸€ä¸‹. æ–‡ç« çµæ§‹å¦‚ä¸‹: What is Probabilistic Graphical Model (PGM)? What is Bayesian Network (BN)? What is Markov Network (MN)? (or Markov Random Field) What is Conditional Random Field (CRF)? Part-of-Speech (POS) Tagging References æ–‡é•·â€¦ What is Probabilistic Graphical Model (PGM)?å®ƒæ˜¯æè¿° pdf çš„ä¸€ç¨®æ–¹å¼, ä¸åŒçš„æè¿°æ–¹å¼å¦‚ directed/undirected graphical model, or Factor Graph æ‰€èƒ½æè¿°çš„ pdf ç¯„åœæ˜¯ä¸åŒçš„. (ref: PRML) å…¶ä¸­ P ä»£è¡¨æ‰€æœ‰ distributions çš„é›†åˆ, U å’Œ D åˆ†åˆ¥è¡¨ç¤º undirected å’Œ directed graphical models. ä»¥æœ‰å‘ç„¡å‘åœ–ä¾†åˆ†å¦‚ä¸‹: Directed Acyclic Graph (DAG): Bayesian Network Undirected Graph: Markov Network æ³¨æ„ BN é™¤äº† directed ä¹‹å¤–, é‚„éœ€è¦ acyclic. æœ‰äº†åœ–ä¹‹å¾Œ, æ€éº¼è·Ÿ distribution ç”¢ç”Ÿé€£çµçš„? ä¸‹é¢æˆ‘å€‘åˆ†åˆ¥ä»‹ç´¹ BN and MN. What is Bayesian Network (BN)?å°æ–¼ä¸€å€‹ä»»æ„çš„ distibution over variables $x_1,â€¦,x_V$ æˆ‘å€‘å¯ä»¥ç”¨åŸºæœ¬çš„ chain rule æ‹†è§£å¦‚ä¸‹: $$\\begin{align} p(x_{1:V})=p(x_1)p(x_2|x_1)p(x_3|x_{1:2})...p(x_V|x_{1:V-1}) \\end{align}$$ è®Šæ•¸çš„ order å¯ä»¥ä»»æ„æ’åˆ—, èˆ‰ä¾‹ä¾†èªª $$\\begin{align} p(x,y,z)\\\\ =p(x)p(y|x)p(z|x,y)\\\\ =p(x)p(z|x)p(y|x,z) \\end{align}$$ åŸºæ–¼é€™ç¨®æ‹†è§£æˆ‘å€‘å¯ä»¥å¾ˆè‡ªç„¶åœ°æƒ³åˆ°, ä¸å¦‚æŠŠæ¯å€‹è®Šæ•¸éƒ½ç•¶æˆ nodes, å†å°‡ conditioning çš„é—œä¿‚ç”¨ edges é€£èµ·ä¾†. å› æ­¤åŸºæœ¬å¯ä»¥é€™éº¼è¡¨é”: $$\\begin{align} p(x_{1:V}|G)=\\prod_{t=1}^{V}p(x_t|pa(x_t)) \\end{align}$$ å…¶ä¸­ $pa(x_t)$ è¡¨ç¤º node $x_t$ çš„ parent nodes. æˆ‘å€‘ç”¨å¼ (3) å’Œ (4) ç•¶ä¾‹å­å°±å¯ä»¥ç•«å‡ºå¦‚ä¸‹çš„åœ–: å¯ä»¥ç™¼ç¾åŒä¸€å€‹ pdf å¯ä»¥ç•«å‡ºå¤šå€‹ BN, å› æ­¤è¡¨é”æ–¹å¼ä¸æ˜¯å”¯ä¸€. Conditioning V.S. Independencyæ¥è‘—æˆ‘å€‘å¯èƒ½æœƒæƒ³, å¦‚æœæˆ‘å€‘å¸Œæœ›å° pdf åŠ ä¸€äº›ç¨ç«‹æ¢ä»¶å‘¢, è­¬å¦‚å¦‚æœå¸Œæœ› $x \\perp y$, æ˜¯ä¸æ˜¯å¯ä»¥ç›´æ¥å°‡åœ–ä¸­çš„ $x$ å’Œ $y$ çš„ edge æ‹”æ‰å°±å¯ä»¥äº†å‘¢? å…ˆç ´é¡Œ, ç­”æ¡ˆæ˜¯ä¸è¡Œ. åŒæ¨£ä»¥ä¸Šé¢çš„ä¾‹å­è§£é‡‹, å¦‚æœæˆ‘å€‘ç”¨æ‹”æ‰ edge çš„è©±, åœ–è®Šæˆ: äº‹å¯¦ä¸Šé€™å…©å€‹åœ–å·²ç¶“å„è‡ªè¡¨ç¤ºä¸åŒçš„ distribution äº†. ç‰¹åˆ¥è¦æ³¨æ„åœ¨å³åœ–ä¸­æ‹”æ‰ $x$ and $y$ çš„ edge æ²’æœ‰é€ æˆ $x \\perp y$. è§£é‡‹å¦‚ä¸‹: é‚£ç©¶ç«Ÿè©²å¦‚ä½•å¾ä¸€å€‹åœ–ç›´æ¥çœ‹å‡ºè®Šæ•¸ä¹‹é–“æ˜¯å¦ç¨ç«‹? ç‚ºäº†è§£ç­”é€™å€‹å•é¡Œ, æˆ‘å€‘å…ˆå¾ç°¡å–®çš„ä¸‰å€‹ nodes é–‹å§‹ Flow of Influenceä¸‰å€‹ nodes çš„ DAG åœ–æœ¬è³ªä¸Šå°±åˆ†ä»¥ä¸‹ä¸‰é¡, å…¶ä¸­ given çš„è®Šæ•¸æˆ‘å€‘é€šå¸¸ä»¥å¯¦å¿ƒåœ“è¡¨ç¤º æˆ‘å€‘å°±å€‹åˆ¥è¨è«– éœ€è¦ç‰¹åˆ¥æ³¨æ„çš„æ˜¯ case 3 çš„ v-structure, è¡Œç‚ºè·Ÿå…¶ä»–å…©ç¨®ç›¸å. ä¸€ç¨®å¥½è¨˜çš„æ–¹å¼æ˜¯, æˆ‘å€‘å‡è¨­ given çš„è®Šé‡æ˜¯ä¸€å€‹çŸ³é ­, è€Œ edges å¯ä»¥æƒ³æˆæ˜¯æ°´æµ, æ‰€ä»¥ given è®Šé‡å°±æŠŠæ°´æµæ“‹ä½, å› æ­¤æœƒé€ æˆç¨ç«‹. å”¯ä¸€å€‹ä¾‹å¤–å°±æ˜¯ v-structure, è¡Œç‚ºå‰›å¥½ç›¸å. Active Trail in BNæˆ‘å€‘å¯ä»¥å¾ˆå®¹æ˜“å°‡ä¸‰å€‹ nodes çš„ trail æ“´å±•æˆ $V$ å€‹ nodes çš„ trail. å› æ­¤å¯ä»¥å¾ˆæ–¹ä¾¿çš„è§€å¯ŸæŸæ¢ trail èµ·å§‹çš„ node èƒ½å¦å½±éŸ¿åˆ°æœ€å¾Œçš„ node. d-separationç¹¼çºŒæ“´å±•! æˆ‘å€‘å‡è¨­åœ¨ BN $G$ ä¸Š node $x$ and $y$ æœ‰ $N$ æ¢ trails. æˆ‘å€‘å‰‡å¯ä»¥è—‰ç”±æª¢æŸ¥æ¯æ¢ trail æ˜¯å¦ active æœ€çµ‚å°±æœƒçŸ¥é“ $x$ èƒ½å¦å½±éŸ¿åˆ° $y$. éœ€è¦æ³¨æ„çš„æ˜¯, é€™äº› d-separation æ¢ä»¶æˆ‘å€‘éƒ½å¯ä»¥ç›´æ¥å¾çµ¦å®šçš„ $G$ ä¸Šç›´æ¥è®€å‡ºä¾† (å°æ–¼ distribution æ²’æœ‰ä»»ä½•å‡è¨­), ç‚ºäº†æ–¹ä¾¿æˆ‘å€‘å®šç¾©ä»¥ä¸‹å…©å€‹ terms $$\\begin{align} CI(G)=\\{\\textbf{d-sep}(x,y|z)|x,y,z\\textbf{ in }G\\}\\\\ CI(p)=\\{(x \\perp y|z)|x,y,z\\textbf{ in }G\\}\\\\ \\end{align}$$ $CI(G)$ æ‰€åˆ—å‡ºçš„ statements æ˜¯ç”± d-sep æ‰€æä¾›, ä¹Ÿå°±æ˜¯èªªå¾ $G$ ç›´æ¥è®€å‡ºä¾†çš„, è€Œ $CI(p)$ æ‰æ˜¯çœŸçš„å°æ–¼ distribution $p$ ä¾†èªªæ‰€æœ‰æ¢ä»¶ç¨ç«‹çš„ statements. OK, åˆ°ç›®å‰ç‚ºæ­¢, çµ¦å®šä¸€å€‹ BN $G$, å’Œä¸€å€‹ distribution $p$ (æ³¨æ„ $p$ ä¸ä¸€å®šå¯ä»¥è¢« $G$ æ‰€è¡¨ç¤º), ä»–å€‘ä¹‹é–“çš„é—œä¿‚åˆ°åº•æ˜¯ä»€éº¼? ä¸‹é¢å°±è¦å¼•å‡ºéå¸¸é‡è¦çš„å®šç† Factorization and Independent çš„é—œä¿‚ä¾†èªªæ˜ Factorization and Independent ç™½è©±æ–‡: å‡è¨­ $p$ å‰›å¥½å¯ä»¥å¯«æˆ $G$ çš„ factorization å‹å¼ (å¼ (5)), å‰‡æ‰€æœ‰ $G$ æŒ‡å‡ºéœ€è¦ $\\perp$ çš„ statements (æ ¹æ“š d-sep æ‰€åˆ—), $p$ éƒ½æ»¿è¶³ ç™½è©±æ–‡: å‡è¨­æ‰€æœ‰ $G$ æŒ‡å‡ºéœ€è¦ $\\perp$ çš„ statements (æ ¹æ“š d-sep æ‰€åˆ—), $p$ éƒ½æ»¿è¶³, å‰‡ $p$ å¯ä»¥å¯«æˆ $G$ çš„ factorization å‹å¼ (å¼ (5)) æˆ‘å€‘ç”¨ PRML book è£¡ä¸€å€‹å…·é«”çš„æè¿°ä¾†èªªæ˜ Thm1 and Thm2 ä¹‹é–“çš„é—œä¿‚ çµ¦å®šä¸€å€‹ $G$, å°±å¥½åƒä¸€å€‹ç¯©å­ä¸€æ¨£, æ ¹æ“šå…©ç¨®æ–¹å¼ç¯©é¸ distribution $p$ å‰›å¥½å¯ä»¥å¯«æˆ $G$ çš„ factorization å‹å¼ (å¼ (5)) $G$ æŒ‡å‡ºéœ€è¦ $\\perp$ çš„ statements (æ ¹æ“š d-sep æ‰€åˆ—), å‰›å¥½ $p$ éƒ½æ»¿è¶³ ç”¨ä¸Šé¢å…©ç¨®ç¯©é¸æ–¹å¼æœ€å¾Œç¯©å‡ºä¾†çš„ distributions åˆ†åˆ¥ç¨±ç‚º $DF1$ and $DF2$ å…©å€‹ sets. å®šç†å‘Šè¨´æˆ‘å€‘å®ƒå€‘å¼åŒä¸€å€‹é›†åˆ! ExampleæŠŠä¸‹åœ–çš„ joint pdf å¯«å‡ºä¾†: ä½¿ç”¨å¼ (5) çš„æ–¹å¼å¯«ä¸€ä¸‹, è®€è€…å¾ˆå¿«å°±ç™¼ç¾, é€™ä¸å°±æ˜¯ HMM å—? What is Markov Network (MN)?Factorizationåœ¨è§£é‡‹ MN ä¹‹å‰, å…ˆäº†è§£ä¸€ä¸‹ä»€éº¼æ˜¯ (maximal) clique. å› æ­¤, æˆ‘å€‘å¯ä»¥ç”¨ maximal cliques ä¾†å®šç¾©ä¸€å€‹ MN. $$\\begin{align} p(x)=\\frac{1}{Z}\\prod_{c\\in\\mathcal{C}}\\psi_c(x_c) \\end{align}$$ $\\mathcal{C}$ æ˜¯ maximal cliques çš„é›†åˆ. ç„¶å¾Œ $Z$ æ˜¯ä¸€å€‹ normalization term, ç›®çš„ç‚ºä½¿ä¹‹æˆç‚º distribution. $$\\begin{align} Z=\\sum_x\\prod_{c\\in\\mathcal{C}}\\psi_c(x_c) \\end{align}$$ èˆ‰å€‹ä¾‹å­: ç”¨ç„¡å‘åœ–çš„æ–¹å¼ä¾†è¡¨é” distribution æœ‰ä¸€å€‹å¾ˆå¤§çš„å¥½è™•å°±æ˜¯åˆ¤æ–· Active Trail å’Œ separation è®Šå¾—éå¸¸éå¸¸ç°¡å–®! ç›´æ¥çœ‹ä¸‹åœ–çš„èªªæ˜ å¦‚åŒåœ¨ BN æ™‚çš„è¨è«–, çµ¦å®šä¸€å€‹ MN $H$, å’Œä¸€å€‹ distribution $p$ (æ³¨æ„ $p$ ä¸ä¸€å®šå¯ä»¥è¢« $H$ æ‰€è¡¨ç¤º), ä»–å€‘ä¹‹é–“çš„é—œä¿‚å¯ä»¥ç”± Factorization and Independent çš„å®šç†ä¾†èªªæ˜ Factorization and Independentæˆ‘å€‘ç›´æ¥æ“·å– Kevin Murphy æ›¸æ‰€åˆ—çš„å®šç†, Hammersley-Clifford å®šç† è·Ÿ BN ä¸€æ¨£, factorization iff independence, ä½†æœ‰ä¸€å€‹é‡è¦çš„ assumption, å°±æ˜¯ distribution å¿…é ˆ strictly positive (å¦‚ä¸Šåœ–ç´…è‰²æ¡†çš„éƒ¨åˆ†). æˆ‘å€‘ä¸€æ¨£ç”¨ PRML ç¯©å­çš„è§€å¿µä¾†å…·é«”åŒ–: æè¿°å°±è·³éäº†. Exampleç”±æ–¼æœ‰ $p(x)&gt;0$ çš„å‡è¨­åœ¨, å› æ­¤å¦‚æœå°‡ factor functions $\\psi(x_c)$ éƒ½ä½¿ç”¨ $exp$ ä¾†å®šç¾©çš„è©±, æ•´å€‹ product ç›¸ä¹˜å¾Œçš„ distribution å¿…å®šæ»¿è¶³ strictly positive. å› æ­¤ $exp$ å°±ä¸å¤±ç‚ºä¸€ç¨®æ–¹ä¾¿çš„ modeling æ–¹å¼äº† å–˜å£æ°£çš„çµè«–åˆ°é€™è£¡, æˆ‘å€‘å¯ä»¥ ç”¨ graph ç°¡å–®çš„è¡¨ç¤ºå‡º joint pdf (ç”¨ factorization). ä¹Ÿå¯ä»¥å¾ graph ä¸­çœ‹å‡º conditional independence (ç”¨ active tail, separation) å› æ­¤æˆ‘å€‘å¯ä»¥é‡å°è¦ model çš„å•é¡Œåˆ©ç”¨ graph ä¾†æè¿° joint pdf äº†. ä½†æ˜¯å…‰æè¿°å¥½ model æ²’ç”¨, æˆ‘å€‘é‚„éœ€è¦ inference (test) and learning (train). Inference éå¸¸æ¨è–¦çœ‹ PRML ch8, è¬›å¦‚ä½•å° tree graph åš sum-product algorithm (belief propagation) éå¸¸ç²¾å½©. æ¥è‘—å¦‚ä½•æ¨å»£åˆ°ä¸€èˆ¬ general graph å‰‡å¯ä»¥ä½¿ç”¨ junction tree algorithm (æ¨è–¦çœ‹é€™ç¯‡æ–‡ç« , è§£é‡‹éå¸¸æ£’!). ä¸Šè¿°å…©ç¨®æ–¹å¼éƒ½å±¬æ–¼ exact inference, å°æ–¼ä¸€äº›æƒ…å½¢ä»æœƒéœ€è¦ exponential time è¨ˆç®—, å› æ­¤æˆ‘å€‘éœ€è¦ variational inference æˆ– sampling çš„æ–¹å¼ç®— approximation. æœ€å¾Œæœ‰é—œ learning æˆ‘å€‘ä½¿ç”¨æ¥ä¸‹ä¾†çš„ POS tagging ç•¶ç¯„ä¾‹æ¨å°ä¸€ä¸‹. ä½†åˆ¥æ€¥, åœ¨è¬› POS ä¹‹å‰æˆ‘å€‘å¾—å…ˆè«‡ä¸€å€‹é‡è¦çš„æ±è¥¿, Conditional Random Field. What is Conditional Random Field (CRF)? å¦‚åŒä¸Šåœ–çš„èªªæ˜, åŸºæœ¬ä¸Š CRF ä»èˆŠæ˜¯ä¸€å€‹ MN, æœ€å¤§çš„å·®åˆ¥æ˜¯ normalization term å¦‚ä»Šä¸å†æ˜¯ä¸€å€‹ constant, è€Œæ˜¯ depends on conditioning çš„è®Šæ•¸ $x$. ä¸€å€‹åœ¨ sequence labeling å¸¸ç”¨çš„ CRF æ¨¡å‹æ˜¯ Linear-Chain CRF æœ‰äº†é€™äº›æ¦‚å¿µå¾Œæˆ‘å€‘å°±å¯ä»¥èªªèªª POS äº† Part-of-Speech (POS) Taggingæ“·å–è‡ªæå®æ¯…æ•™æˆä¸Šèª²æŠ•å½±ç‰‡ åŸºæœ¬ä¸Šå°±æ˜¯çµ¦å®šä¸€å€‹ word sequence $x$, æˆ‘å€‘å¸Œæœ›æ‰¾å‡ºå“ªä¸€å€‹è©æ€§æ¨™è¨»çš„ sequence $y$ æœƒä½¿å¾—æ©Ÿç‡æœ€å¤§. æ©Ÿç‡æœ€å¤§çš„é‚£å€‹ $y$ å°±æ˜¯æˆ‘å€‘è¦çš„è©æ€§æ¨™è¨»åºåˆ—. ä½¿ç”¨ç¾å­¸ç¾è³£çš„ PGM modeling çŸ¥è­˜, æˆ‘å€‘å¯ä»¥ä½¿ç”¨ BN or MN çš„æ–¹å¼æè¿°æ¨¡å‹ BN: Hidden Markov Model (HMM) MN: Linear chain CRF with log-linear model æœ‰å‘åœ– HMM æ–¹æ³•ä¸€æ¨£æ“·å–è‡ªæå®æ¯…æ•™æˆä¸Šèª²æŠ•å½±ç‰‡ é‚„è¨˜å¾—æœ¬æ–‡å‰é¢è¬› BN æ™‚çš„ HMM example å—? $y$ å°±æ˜¯è©æ€§, $x$ å°±æ˜¯å­—. HMM æ˜¯åœ¨ model çµ¦å®šè©æ€§åºåˆ—æƒ…å½¢ä¸‹çš„å­—åºåˆ— distribution. äº†è§£èªéŸ³è¾¨è­˜çš„ç«¥é‹é–€æ‡‰è©²å†ç†Ÿæ‚‰ä¸éäº†, åªä¸éé€™è£¡å•é¡Œæ¯”è¼ƒç°¡å–®, åœ¨èªéŸ³è¾¨è­˜è£¡, æˆ‘å€‘ä¸æœƒé‡å°æ¯å€‹ frame å»æ¨™è¨»å®ƒæ˜¯å±¬æ–¼å“ªä¸€å€‹ç™¼éŸ³çš„ state, å› æ­¤æ¨™è¨»å…¶å¯¦æ˜¯ hidden çš„. ä½†åœ¨é€™è£¡æ¯å€‹ word éƒ½æœƒæœ‰ä¸€å€‹å°æ‡‰æ­£ç¢ºç­”æ¡ˆçš„è©æ€§æ¨™è¨», æ²’æœ‰ hidden è³‡è¨Š, å› æ­¤ä¹Ÿä¸éœ€è¦ EM algorithm, ç°¡å–®çš„ counting å³å¯åšå®Œè¨“ç·´. that all â€¦ ç„¡å‘åœ– CRF æ–¹æ³•ç²¾ç¢ºèªªæ˜¯ Linear chain CRF with log-linear model æˆ‘å€‘æŠŠ log-linear model çš„ factor å¸¶å…¥ linear chain CRF ä¸­, æ³¨æ„å…¶ä¸­ $\\phi$ æ˜¯éœ€è¦å®šç¾©çš„ç‰¹å¾µå‡½æ•¸, æˆ‘å€‘é€™è£¡å…ˆå‡è¨­å¯ä»¥æŠ½å–å‡º $K$ ç¶­. å› æ­¤å¯ä»¥æ¨å°å¦‚ä¸‹ å¯¦ä½œä¸Šæˆ‘å€‘æœƒé‡å°æ™‚é–“ share weights, é€™æ˜¯å› ç‚ºå¥å­éƒ½æ˜¯é•·çŸ­ä¸ä¸€çš„, å¦ä¸€æ–¹é¢é€™æ¨£åšä¹Ÿå¯ä»¥å¤§é‡æ¸›å°‘åƒæ•¸é‡. æ‰€ä»¥æœ€å¾Œå¯ä»¥ç°¡åŒ–æˆä¸€å€‹ weigth vector $w$ å’Œæˆ‘å€‘åˆä½µçš„ç‰¹å¾µå‘é‡ $f(x,y)$ çš„ log-linear model. Learning ç›®æ¨™å‡½æ•¸å°±æ˜¯åœ¨æœ€å¤§åŒ– CRF çš„ likelihood. æ¡ç”¨ gradient method. è€Œ gradient çš„æ¨å°äº‹å¯¦ä¸Šä¹Ÿä¸å›°é›£, åªè¦èŠ±é»è€å¿ƒå³å¯äº†è§£ ä½†æ˜¯å…¶å¯¦æˆ‘èªªä¸å›°é›£åªèªªå°äº†ä¸€åŠ, ç´…è‰²çš„åœ°æ–¹äº‹å¯¦ä¸Šéœ€è¦è·‘ inference æ‰å¯ä»¥å¾—åˆ°, å¥½åœ¨ linear-chain æ¶æ§‹ä¸‹æ­£å¥½å¯ä»¥ç”¨ Viterbi åšå‰å‘å¾Œç®—è¨ˆç®—, é€™éƒ¨åˆ†çš„å¼å­å¯ä»¥è·Ÿ â€œæèˆª çµ±è¨ˆå­¸ç¿’æ–¹æ³•â€œ é€™æœ¬æ›¸çš„ p201 å¼ (11.34) éŠœæ¥ä¸Š, è©²å¼å¯«å‡ºäº†å‰å‘å¾Œå‘è¨ˆç®—. ToolCRF++ åšç‚ºèªéŸ³è¾¨è­˜çš„å¾Œè™•ç†ååˆ†å¥½ç”¨çš„å·¥å…·, in c++. ReferencesPGM åšå¤§ç²¾æ·±, é€™å€‹æ¡†æ¶å¾ˆå®Œæ•´ä¸”åš´è¬¹, å€¼å¾—æˆ‘å¾ŒçºŒèŠ±æ™‚é–“ç ”è®€, æœ‰æ©Ÿæœƒçœ‹èƒ½å¦å°‡ Koller çš„èª²ç¨‹ä¸Šéä¸€æ¬¡çœ‹çœ‹. é€šå¸¸é€™éº¼èªªå°±è¡¨ç¤º â€¦. hmmâ€¦ä½ æ‡‚å¾— Bishop PRML book Kevin Murphy book Junction Tree Algorithm æèˆª çµ±è¨ˆå­¸ç¿’æ–¹æ³• æå®æ¯…è€å¸« ML èª²ç¨‹","tags":[{"name":"Probabilistic Graphical Models","slug":"Probabilistic-Graphical-Models","permalink":"https://bobondemon.github.io/tags/Probabilistic-Graphical-Models/"},{"name":"Bayesian Network","slug":"Bayesian-Network","permalink":"https://bobondemon.github.io/tags/Bayesian-Network/"},{"name":"Markov Network","slug":"Markov-Network","permalink":"https://bobondemon.github.io/tags/Markov-Network/"},{"name":"Conditional Random Field","slug":"Conditional-Random-Field","permalink":"https://bobondemon.github.io/tags/Conditional-Random-Field/"},{"name":"POS tagging","slug":"POS-tagging","permalink":"https://bobondemon.github.io/tags/POS-tagging/"}]},{"title":"Kaldi Notes (1), I/O in C++ Level","date":"2018-05-31T15:32:43.000Z","path":"2018/05/31/Kaldi-Notes-IO-in-C-Level/","text":"Kaldi I/O C++ Level ç­†è¨˜, ä¸»è¦ä»‹ç´¹ä»¥ä¸‹å¹¾é», ä»¥åŠå®ƒå€‘åœ¨ Kaldi c++ è£¡å¦‚ä½•é—œè¯: æ¨™æº– low-level I/O for Kaldi Object XXXHolderé¡åˆ¥: ä¸€å€‹ç¬¦åˆæ¨™æº– low-level I/O çš„é¡åˆ¥ Kaldi Table Object: &lt;key,value&gt; pairs çµ„æˆçš„ Kaldi æ ¼å¼æª”æ¡ˆ (scp, ark), å…¶ä¸­ value ç‚º XXXHolder é¡åˆ¥ æ¨™æº– low-level I/O for Kaldi ObjectKaldi Object æœ‰è‡ªå·±çš„æ¨™æº– I/O ä»‹é¢:12345class SomeKaldiClass &#123; public: void Read(std::istream &amp;is, bool binary); void Write(std::ostream &amp;os, bool binary) const; &#125;; å› æ­¤å®šç¾©äº†è©² Kaldi Class å¦‚ä½•é‡å° istream è®€å– (ostream å¯«å…¥). åœ¨ Kaldi ä¸­, istream/ostream ä¸€èˆ¬æ˜¯ç”± Input/Output(åœ¨ util/kaldi-io.h è£¡å®šç¾©) é€™å€‹ class ä¾†é–‹å•Ÿçš„. é‚£ç‚ºä½•ä¸ç”¨ä¸€èˆ¬çš„ c++ iostream é–‹å•Ÿä¸€å€‹æª”æ¡ˆå‘¢? é€™æ˜¯å› ç‚º Kaldi æƒ³è¦æ”¯æ´æ›´å¤šæ¨£çš„æª”æ¡ˆé–‹å•Ÿæ–¹å¼, ç¨±ç‚º â€œExtended filenames: rxfilenames and wxfilenamesâ€œ. ä¾‹å¦‚å¯ä»¥å¾ stdin/stdout, pipe, file å’Œ file with offset è®€å–å¯«å…¥, è©³ç´°è«‹çœ‹æ–‡æª”çš„ â€œExtended filenames: rxfilenames and wxfilenamesâ€ éƒ¨åˆ†. æ‰€ä»¥ Input/Ouput Class æœƒè‡ªå‹•è§£æ rxfilenames/wxfilenames ç„¶å¾Œé–‹å•Ÿ istream/ostream. é–‹å•Ÿå¾Œ, Kaldi Object å°±å¯ä»¥é€éæ¨™æº–çš„ I/O ä»‹é¢å‘¼å« Read/Write æ–¹æ³•äº†. å®˜ç¶²ç¯„ä¾‹å¦‚ä¸‹:123456789101112&#123; // input. bool binary_in; Input ki(some_rxfilename, &amp;binary_in); my_object.Read(ki.Stream(), binary_in); // you can have more than one object in a file: my_other_object.Read(ki.Stream(), binary_in);&#125;// output. note, \"binary\" is probably a command-line option.&#123; Output ko(some_wxfilename, binary); my_object.Write(ko.Stream(), binary);&#125; æœ‰æ™‚å€™æœƒçœ‹åˆ°æ›´ç²¾ç°¡çš„å¯«æ³•å¦‚ä¸‹12345678int main(int argc, char *argv[]) &#123; ... std::string rxfilenames = po.GetArg(1); std::string wxfilenames = po.GetArg(2); SomeKaldiClass my_object; ReadKaldiObject(rxfilenames, &amp;my_object); WriteKaldiObject(my_object, wxfilenames, binary);&#125; å…¶ä¸­ ReadKaldiObject and WriteKaldiObject (defined in util/kaldi-io.h) çš„ä½œç”¨åªæ˜¯å°‡ Input/Output é–‹å•Ÿ xfilenames ç‚º iostream, ä¸¦å‚³çµ¦ my_object çš„æ¨™æº– I/O ä»‹é¢åŒ…è£èµ· ä¾†è€Œå·². æ“·å– define ç‰‡æ®µå¦‚ä¸‹: 12345678910111213141516171819template &lt;class C&gt; void ReadKaldiObject(const std::string &amp;filename, C *c) &#123; bool binary_in; Input ki(filename, &amp;binary_in); c-&gt;Read(ki.Stream(), binary_in);&#125;// Specialize the template for reading matrices, because we want to be able to// support reading 'ranges' (row and column ranges), like foo.mat[10:20].// ä¸Šé¢çš„ class C å¦‚æœæ˜¯ Matrix&lt;float&gt; or Matrix&lt;double&gt; çš„è©±, ä½¿ç”¨ä¸‹é¢å…©å€‹å®šç¾©// Note: é€™ç¨®æ–¹å¼æ˜¯ template çš„ specialization, åŒæ¨£åç¨±çš„ template function or class å¯ä»¥é‡è¤‡å‡ºç¾ï¼Œåªé‡å°æŸäº› type å®¢è£½åŒ–template &lt;&gt; void ReadKaldiObject(const std::string &amp;filename, Matrix&lt;float&gt; *m);template &lt;&gt; void ReadKaldiObject(const std::string &amp;filename, Matrix&lt;double&gt; *m);template &lt;class C&gt; inline void WriteKaldiObject(const C &amp;c, const std::string &amp;filename, bool binary) &#123; Output ko(filename, binary); c.Write(ko.Stream(), binary);&#125; Kaldi Table ObjectTable Object ä¸ç›´æ¥é€éæ¨™æº–çš„ Read/Write æ“ä½œ, æ˜¯å› ç‚º Table object çš„æ§‹æˆæ˜¯ç”± &lt;key,value&gt; pairs çµ„æˆçš„, è€Œ value æ‰æœƒæ˜¯ä¸€å€‹ç¬¦åˆæ¨™æº– Read/Write æ“ä½œçš„ object. é€™ç¨® table æ‰€éœ€è¦çš„è®€å¯«å¯èƒ½æœ‰å¾ˆå¤šæ–¹å¼, è­¬å¦‚ sequential access, random access ç­‰ç­‰, å› æ­¤å–®ç´”çš„ Read/Write æ¯”è¼ƒä¸èƒ½æ»¿è¶³éœ€æ±‚, æ›´éœ€è¦çš„æ˜¯è¦æœ‰ Next, Done, Key, Value ç­‰ç­‰çš„æ“ä½œæ–¹å¼. ä¾‹å¦‚ä»¥ä¸‹ç¯„ä¾‹: 12345678910111213141516std::string feature_rspecifier = \"scp:/tmp/my_orig_features.scp\", transform_rspecifier = \"ark:/tmp/transforms.ark\", feature_wspecifier = \"ark,t:/tmp/new_features.ark\";// there are actually more convenient typedefs for the types below,// e.g. BaseFloatMatrixWriter, SequentialBaseFloatMatrixReader, etc.TableWriter&lt;BaseFloatMatrixHolder&gt; feature_writer(feature_wspecifier);SequentialTableReader&lt;BaseFloatMatrixHolder&gt; feature_reader(feature_rspecifier);RandomAccessTableReader&lt;BaseFloatMatrixHolder&gt; transform_reader(transform_rspecifier);for(; !feature_reader.Done(); feature_reader.Next()) &#123; std::string utt = feature_reader.Key(); if(transform_reader.HasKey(utt)) &#123; Matrix&lt;BaseFloat&gt; new_feats(feature_reader.Value()); ApplyFmllrTransform(new_feats, transform_reader.Value(utt)); feature_writer.Write(utt, new_feats); &#125;&#125; ä¸»è¦æœ‰å¹¾ç¨® table classes:TableWriter, SequentialTableReader, RandomAccessTableReader ç­‰ç­‰, éƒ½å®šç¾©åœ¨ util/kaldi-table.h. æˆ‘å€‘å°±ä»¥ SequentialTableReader ä¾†èˆ‰ä¾‹. ä¸Šé¢çš„ç¯„ä¾‹ feature_reader å°±æ˜¯ä¸€å€‹ SequentialTableReader, ä»–çš„ &lt;key,value&gt; pairs ä¸­çš„ value å®šç¾©ç‚º BaseFloatMatrixHolder é¡åˆ¥ (ä¸€å€‹ç¬¦åˆæ¨™æº– low-level I/O çš„ Kaldi Class, ç­‰æ–¼æ˜¯å¤šä¸€å±¤åŒ…è£). XXXHolder (å¦‚ KaldiObjectHolder, BasicHolder, BasicVectorHolder, BasicVectorVectorHolder, â€¦) æŒ‡çš„æ˜¯ç¬¦åˆæ¨™æº– low-level I/O çš„ Kaldi Object, å› æ­¤é€™äº› XXXHolder éƒ½å¯ä»¥çµ±ä¸€é€é Read/Write ä¾†å‘¼å«. é€™äº› Holder çš„å®šç¾©åœ¨ util/kaldi-holder.h.å¦å¤– kaldi-holder.h æœ€å¾Œä¸€è¡Œæœƒ include kaldi-holder-inl.h. â€œ-inlâ€ æ„æ€æ˜¯ inline, é€šå¸¸æœƒæ”¾åœ¨ç›¸å°æ‡‰æ²’æœ‰ -inl çš„ .h æœ€å¾Œé¢, ç”¨ä¾†ç•¶ä½œæ˜¯ inline implementation ç”¨. SequentialTableReader çš„å®šç¾©åœ¨ â€œutil/kaldi-table.hâ€, æ“·å–è¦ä»‹ç´¹çš„ç‰‡æ®µ:1234567891011template&lt;class Holder&gt;class SequentialTableReader &#123; public: typedef typename Holder::T T; inline bool Done(); inline std::string Key(); T &amp;Value(); void Next(); private: SequentialTableReaderImplBase&lt;Holder&gt; *impl_;&#125; Done(), Next(), Key(), and Value() éƒ½å¯ä»¥å¾ feature_reader çœ‹åˆ°å¦‚ä½•ä½¿ç”¨, æ‡‰è©²å¾ˆç›´è¦º, è€Œ Holder çš„è§£é‡‹ä¸Šé¢èªªäº†. å‰©ä¸‹è¦èªªæ˜çš„æ˜¯é€™è¡Œ SequentialTableReaderImplBase&lt;Holder&gt; *impl_;. åœ¨å‘¼å« SequentialTableReader çš„ Next() æ™‚, ä»–å¯¦éš›ä¸Šå‘¼å«çš„æ˜¯ impl_ çš„ Next(). å®šç¾©åœ¨ util/kaldi-table-inl.h ç‰‡æ®µ: 12345template&lt;class Holder&gt;void SequentialTableReader&lt;Holder&gt;::Next() &#123; CheckImpl(); impl_-&gt;Next();&#125; impl_ çš„ class å®£å‘Šæ˜¯ â€œSequentialTableReaderImplBaseâ€, è©²é¡åˆ¥çš„è§’è‰²æ˜¯æä¾›ä¸€å€‹çˆ¶é¡åˆ¥, å¯¦éš›ä¸Šæœƒæ ¹æ“š impl_ çœŸæ­£çš„é¡åˆ¥å‘¼å«å…¶å°æ‡‰çš„ Next(), å°±æ˜¯å¤šå‹çš„ä½¿ç”¨. ç¾åœ¨å‡è¨­ impl_ çœŸæ­£çš„é¡åˆ¥æ˜¯ SequentialTableReaderArchiveImpl. æˆ‘å€‘å¯ä»¥åœ¨ util/kaldi-table-inl.h çœ‹åˆ°ä»–çš„ Next (line 531) å¯¦ä½œå¦‚ä¸‹:123456789virtual void Next() &#123; ... if (holder_.Read(is)) &#123; state_ = kHaveObject; return; &#125; else &#123; ... &#125;&#125; åˆ°é€™æ‰çœŸæ­£çœ‹åˆ°é€é XXXHolder ä½¿ç”¨ low-level I/O çš„ Read()! Kaldi Codes å“è³ªå¾ˆé«˜é˜¿, è¦èŠ±ä¸å°‘æ™‚é–“è®€, æœç„¶ c++ åº•å­é‚„æ˜¯å¤ªå·®äº†. References Kaldi Project","tags":[{"name":"Kaldi","slug":"Kaldi","permalink":"https://bobondemon.github.io/tags/Kaldi/"}]},{"title":"TF Notes (4), Deconvolution","date":"2018-05-09T11:59:12.000Z","path":"2018/05/09/TF-Notes-deconvolution/","text":"é€™ç¯‡æ˜¯å€‹å°ç·´ç¿’, å°±å…©é»: äº†è§£ä»€éº¼æ˜¯ deconvolution, ä¸¦åœ¨ tensorflow ä¸­æ€éº¼ç”¨ å¯¦ä½œä¸€å€‹ CNN AutoEncoder, Encoder ç”¨ conv2d, Decoder ç”¨ conv2d_transpose What is deconvolution?ç ´é¡Œ: Deconvolution çš„æ“ä½œå°±æ˜¯ kernel tranpose å¾Œçš„ convolution. ä½¿ç”¨æå®æ¯…è€å¸«çš„ä¸Šèª²å…§å®¹, å¦‚ä¸‹åœ–: å…¶å¯¦åœ–å·²ç¶“ååˆ†æ˜ç¢ºäº†, å› æ­¤ä¸å¤šè§£é‡‹. å¦å¤–åœ¨ tensorflow ä¸­, å‡è¨­æˆ‘å€‘çš„ kernel $W$ ç‚º W.shape = (img_h, img_w, dim1, dim2). å‰‡ tf.nn.conv2d(in_tensor,W,stride,padding) æœƒå°‡ (dim1,dim2) çœ‹æˆ (in_dim, out_dim). è€Œ tf.nn.conv2d_transpose(in_tensor,W,output_shape,stride) æœƒå°‡ (dim1,dim2) çœ‹æˆ (out_dim, in_dim), æ³¨æ„æ˜¯åéä¾†çš„. æœ‰å…©é»å¤šåšèªªæ˜: tf.nn.conv2d_transpose æœƒè‡ªå‹•å° $W$ åš transpose ä¹‹å¾Œå† convolution, å› æ­¤æˆ‘å€‘ä¸éœ€è¦è‡ªå·±åš transpose. tf.nn.conv2d_transpose éœ€è¦é¡å¤–æŒ‡å®š output_shape. æ›´å¤š conv/transpose_conv/dilated_conv with stride/padding æœ‰å€‹ éå¸¸æ£’çš„å¯è¦–åŒ– çµæœåƒè€ƒæ­¤ github CNN AutoEncoderçµæ§‹å¦‚ä¸‹åœ– ç›´æ¥å°‡ embedding å£“åˆ° 2 ç¶­, æ¯å€‹é¡åˆ¥çš„åˆ†å¸ƒæƒ…å½¢å¦‚ä¸‹: embedding æ˜¯ 128 ç¶­, ä¸¦ä½¿ç”¨ tSNE æŠ•å½±åˆ° 2 ç¶­ç•«åœ–å¦‚ä¸‹: Encoder å¦‚ä¸‹: 1234567891011121314151617181920def Encoder(x): print('Input x got shape=',x.shape) # (None,28,28,1) # Layer 1 encode: Input = (batch_num, img_height, img_width, cNum). Output = (batch_num, img_height/2, img_width/2, layer_dim['conv1']) layer1_en = tf.nn.relu(tf.nn.conv2d(x, weights['conv1'], strides=[1, 1, 1, 1], padding='SAME')) # Avg Pooling layer1_en = tf.nn.avg_pool(layer1_en, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') print('After Layer 1, got shape=',layer1_en.shape) # (None,14,14,32) # Layer 2 encode: Input = (batch_num, img_height/2, img_width/2, layer_dim['conv1']). Output = (batch_num, img_height/4, img_width/4, layer_dim['conv2']) layer2_en = tf.nn.relu(tf.nn.conv2d(layer1_en, weights['conv2'], strides=[1, 1, 1, 1], padding='SAME')) # Avg Pooling layer2_en = tf.nn.avg_pool(layer2_en, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') print('After Layer 2, got shape=',layer2_en.shape) # (None,7,7,64) # Layer embedded: Input = (batch_num, img_height/4 * img_width/4 * layer_dim['conv2']). Output = (batch_num, layer_dim['embedded']) flatten_in = flatten(layer2_en) embedded = tf.matmul(flatten_in,weights['embedded']) print('embedded has shape=',embedded.shape) return embedded Decoder å¦‚ä¸‹: 12345678910111213141516171819202122def Decoder(embedded): # API: tf.nn.conv2d_transpose = (value, filter, output_shape, strides, padding='SAME', ...) bsize = tf.shape(embedded)[0] # Layer embedded decode: Input = (batch_num, layer_dim['embedded']). Output = (batch_num, in_dim_for_embedded) embedded_t = tf.matmul(embedded,weights['embedded'],transpose_b=True) embedded_t = tf.reshape(embedded_t,[-1, 7, 7, layer_dim['conv2']]) print('embedded_t has shape=',embedded_t.shape) # Layer 2 decode: Input = (batch_num, 7, 7, layer_dim['conv2']). Output = (batch_num, 14, 14, layer_dim['conv1']) layer2_t = tf.nn.relu(tf.nn.conv2d_transpose(embedded_t,weights['conv2t'],[bsize, 14, 14, layer_dim['conv1']], [1, 2, 2, 1])) print('layer2_t has shape=',layer2_t.shape) # Layer 1 decode: Input = (batch_num, 14, 14, layer_dim['conv1']). Output = (batch_num, 28, 28, cNum) layer1_t = tf.nn.relu(tf.nn.conv2d_transpose(layer2_t,weights['conv1t'],[bsize, 28, 28, cNum], [1, 2, 2, 1])) print('layer1_t has shape=',layer1_t.shape) # Layer reconstruct: Input = batch_num x layer_dim['layer1']. Output = batch_num x img_dim. reconstruct = tf.nn.relu(tf.nn.conv2d(layer1_t, weights['reconstruct'], strides=[1, 1, 1, 1], padding='SAME')) - 0.5 print('reconstruct has shape=',reconstruct.shape) return reconstruct AutoEncoder ä¸²èµ·ä¾†å¾ˆå®¹æ˜“: 12345def AutoEncoder(x): embedded = Encoder(x) reconstruct = Decoder(embedded) return [embedded, reconstruct] å®Œæ•´ source codes åƒè€ƒä¸‹é¢ reference Reference æå®æ¯… deconvolution è§£é‡‹ tf.nn.conv2d_transpose èªªæ˜ conv/transpose_conv/dilated_conv with stride/padding å¯è¦–åŒ–: github æœ¬ç¯‡å®Œæ•´ source codes","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://bobondemon.github.io/tags/TensorFlow/"},{"name":"Computational Graph","slug":"Computational-Graph","permalink":"https://bobondemon.github.io/tags/Computational-Graph/"}]},{"title":"ROS in Self-driving Car system","date":"2018-04-15T11:05:29.000Z","path":"2018/04/15/ROS-in-Self-driving-Car-system/","text":"é€™æ˜¯ç¶“æ­·äº†æ¼«é•·çš„æ™‚é–“, æœ€å¾Œçš„ä¸€å“©è·¯äº†â€¦.å¾2016å¹´12æœˆé–‹å§‹, åˆ°2018å¹´4æœˆä¸­, èŠ±äº†æ•´æ•´ä¸€å¹´äº”å€‹æœˆ. å…¶å¯¦æˆ‘åŸå…ˆæ‰“ç®—åŠå¹´å‰å°±ç•¢æ¥­çš„, ä½†æ˜¯ä¸­é€”æœ‰ç‹€æ³, æ‰€ä»¥åªå¥½ term2 å®Œæˆå¾Œåœäº†åŠå¹´æ‰é–‹å§‹ term3, ä¹Ÿå› æ­¤åˆ°æ˜¨å¤©æ‰å‰›ç¢ºå®šç•¢æ¥­! è€Œæ˜¨å¤©å‰›å¥½ä¹ŸåƒåŠ äº† Udacity åœ¨ä¸­åœ‹å…©å‘¨å¹´çš„æœƒ, è¦‹åˆ°äº† David Sliver æœ¬äºº, ç®—æ˜¯ç•¢æ¥­çš„ä¸€å€‹å°ç´€å¿µ! æœ€å¾Œçš„ project æ¯”è¼ƒæœ‰åˆ¥æ–¼ä»¥å¾€, æ¡ç”¨ team work çš„æ–¹å¼. æˆ‘å€‘çš„ team å…±äº”äºº, team lead Franz Pucher å¾·åœ‹, Theodore King ç¾åœ‹, å’Œæˆ‘. ç–‘? å¦å¤–å…©å€‹å‘¢? å°æ–¼ project å®Œå…¨æ²’è²¢ç»â€¦æˆ‘ä¸æƒ³èªªäº†â€¦.= = ROS ç°¡ä»‹é—œæ–¼æ©Ÿå™¨äººæ§åˆ¶å’Œè‡ªå‹•è»Šéƒ½æœƒä½¿ç”¨ ROS (Robot Operating System), ROS ä¸€å®šè¦åƒè€ƒ ROS wiki. æœ¬æ¬¡ä½œæ¥­çš„ ROS ç³»çµ±æ“·å–èª²ç¨‹åœ–ç‰‡å¦‚ä¸‹: çœ‹ä¸æ‡‚æ²’é—œä¿‚, äº†è§£ ROS ä¸»è¦ä¸‰å€‹æ¦‚å¿µ: Node, Topic, Msg å°±æ¸…æ¥šä¸Šé¢çš„åœ–åœ¨å¹¹å˜›äº†. Node ç°¡å–®è¬›é¡ä¼¼æ–¼ class, å¯ä»¥è¨‚é–±æŸäº› Topic, å’Œç™¼é€ Msg åˆ°æŒ‡å®šçš„ Topic. èˆ‰ä¾‹ä¾†èªªç•¶æœ‰æŸå€‹ Node A ç™¼é€ä¸€å€‹ msg M åˆ°ä¸€å€‹ topic T æ™‚, å¦‚æœ Node B æœ‰è¨‚é–± topic T, å‰‡ Node B æœƒæ”¶åˆ° msg M, ä¸¦ä¸”åŸ·è¡Œé å…ˆè¨­å®šå¥½çš„ call back function. ç”¨ä»¥ä¸‹çš„ç¨‹å¼ç¯„ä¾‹èˆ‰ä¾‹: 1234567891011class TrafficLightDetector(object): def __init__(self): rospy.init_node('tl_detector') # è¦åœ¨é–‹é ­å°±å…ˆ init å¥½é€™æ˜¯ ros node ... # è¨‚é–±äº†ä¸€å€‹ topic '/current_pose', ä¸¦ä¸”å¦‚æœæœ‰ msg ç™¼é€åˆ°æ­¤ topic, æ­¤ node æœƒæ”¶åˆ°ä¸¦ä¸”å‘¼å« call back function self.pose_cb sub = rospy.Subscriber('/current_pose', PoseStamped, self.pose_cb, queue_size=1) # æ­¤ node æœƒç™¼é€ msg åˆ° topic '/traffic_waypoint' self.upcoming_red_light_pub = rospy.Publisher('/traffic_waypoint', Int32, queue_size=1) def pose_cb(self, msg): self.pose = msg.pose è¦æ³¨æ„çš„æ˜¯, ç”±æ–¼ topic é‹ä½œæ–¹å¼ç‚ºä¸€æ—¦æœ‰å…¶ä»– node ç™¼é€ msg åˆ°æ­¤ topic, æœ‰è¨‚é–±æ­¤ topic çš„ node çš„ call back function éƒ½æœƒè¢«å‘¼å«. é€™å°±æ„è¬‚è‘— topic å¦‚æœç™¼é€ msg å¤ªé »ç¹, å°è‡´è¨‚é–±çš„ node ç„¡æ³•åŠæ™‚æ¶ˆåŒ–, å‰‡ msg æœƒæ‰åŒ…. ä¸€ç¨®è§£æ±ºæ–¹å¼ç‚ºä½¿ç”¨ rospy.Rate æ§åˆ¶ç™¼é€çš„é »ç‡. ä½†æ˜¯å…¶å¯¦é‚„æœ‰å¦ä¸€ç¨®å‚³é€ msg çš„æ–¹å¼: Service ç°¡å–®è¬› Service çš„æ¦‚å¿µå°±æ˜¯ request and response, ä¸åŒæ–¼ topic, service æœƒå°‡å…©å€‹ node ç›´æ¥é€£æ¥èµ·ä¾†, ä¸€å€‹ç™¼èµ· request å¾Œ, æœƒç­‰å¦ä¸€å€‹ node response æ‰æœƒæ¥è‘—åšä¸‹å». ä¸€å€‹ç°¡å–®çš„èˆ‰ä¾‹å¦‚ä¸‹: 12345678910111213141516171819# éœ€æ³¨æ„ ServiceClassName è¦å…ˆåœ¨ package è£¡çš„ srv folder å®šç¾©å¥½class NodeA(object):... # æ‹¿åˆ°è©² service service = rospy.ServiceProxy('service_name',ServiceClassName) # æ‹¿åˆ°å¯ä»¥ request çš„ msg instance msg = ServiceClassNameRequest() # ä¿®æ”¹ msg æˆéœ€è¦çš„ç‹€æ…‹ ... # ç™¼èµ· request ä¸¦å¾—åˆ° response response = service(msg) class NodeB(object):... rospy.Service('service_name',ServiceClassName, self.handler_func) ... def handler_func(self, msg): # æ”¶åˆ° request çš„ msg, åœ¨æ­¤ handler function è² è²¬è™•ç†å¦‚ä½• response ... ä¸Šé¢çš„ç¯„ä¾‹ä½¿ç”¨äº†å…©å€‹ nodes, node A è² è²¬ç™¼èµ· request, è€Œ node B è² è²¬ response. å¦å¤–ç­†è¨˜ä¸€äº› ros å¸¸ç”¨çš„æŒ‡ä»¤å’ŒåŠŸèƒ½12345678910111213141516171819202122232425262728293031323334353637383940&gt;&gt; roscore # start ROS master# rosrun å¯ä»¥æŒ‡å®šè² è²¬è¦è·‘å“ªå€‹ node&gt;&gt; rosrun package_name node_name# node ä¸€å¤š, å¯ä»¥ä½¿ç”¨ roslauch ä¸€æ¬¡åŸ·è¡Œå¤šå€‹ nodes, ä½†æ˜¯è¦å¯«å¥½ launch file&gt;&gt; roslaunch launch/launchfile# åˆ—å‡º active çš„ nodes&gt;&gt; rosnode list# åˆ—å‡º active çš„ topics&gt;&gt; rostopic list# æŸ¥çœ‹æŸå€‹ topic&gt;&gt; rostopic info topic_name# å°‡ publish åˆ°æ­¤ topic çš„ msgs éƒ½å³æ™‚é¡¯ç¤ºåœ¨ terminal ä¸Š&gt;&gt; rostopic echo topic_name# ä¸€èˆ¬ä¾†èªª rospy.loginfo('info msg') æœƒé¡¯ç¤ºåœ¨ /rosout é€™å€‹ topic, å› æ­¤é©åˆ debug&gt;&gt; rostopic echo /rosout# æŸ¥çœ‹æŸå€‹ msg&gt;&gt; rosmsg info msg_name# build è‡ªå®šç¾©çš„ ros package&gt;&gt; cd ~/catkin_ws; catkin_make# æª¢æŸ¥ package çš„ dependency&gt;&gt; rosdep install -i package_name# å¦‚æœå°‡æŸå€‹ package åŠ å…¥åˆ°è‡ªå·±çš„ catkin_ws æ™‚, éœ€åŠ åˆ° catkin_ws/src è³‡æ–™å¤¾ä¸‹, ä¸¦ä¸”é‡æ–° make&gt;&gt; cd ~/catkin_ws/src&gt;&gt; git clone 'some packages'&gt;&gt; cd ~/catkin_ws&gt;&gt; catkin_make# Build å®Œå¾Œ, éœ€è¦ source æ‰å¯ä»¥å°‡ catkin_ws/src ä¸‹çš„æ‰€æœ‰ packages éƒ½åŠ åˆ° ros ä¸­&gt;&gt; source ~/catkin_ws/devel/setup.bash Debug çš„è©± rospy.loginfo, rospy.logwarn, rospy.logerr, rospy.logfatal å¾ˆå¥½ç”¨, å®ƒå€‘åˆ†åˆ¥æœƒè¢«è¨˜éŒ„åœ¨ä»¥ä¸‹å¹¾å€‹åœ°æ–¹: Self-Driving Car ROS Nodeså› æ­¤é€™æœ€å¾Œçš„ project ä¸»è¦å°±åˆ†æˆä¸‰å€‹éƒ¨åˆ† Perception:é€™éƒ¨åˆ†è² è²¬æ”¶åˆ° /image_color é€™å€‹ topic çš„å½±åƒå¾Œ, ä¾†æ‰¾å‡º traffic sign åœ¨å“ªè£¡ä¸¦ä¸”æ˜¯å“ªç¨®ç‡ˆè™Ÿ. ç›¸ç•¶æ–¼ term1 çš„ Vehicle Tracking, æˆ‘ä¸»è¦è² è²¬æ­¤éƒ¨åˆ†, ä½†æ˜¯æ²’æœ‰ä½¿ç”¨ç•¶æ™‚åš project çš„ sliding window + svm æ–¹æ³•. ä¸‹é¢æœƒè©³ç´°ä»‹ç´¹. Planning:è² è²¬æ ¹æ“šç›®å‰è»Šå­çš„ä½ç½®ä»¥åŠå¦‚æœæœ‰ç´…ç‡ˆçš„è©±, å¿…é ˆè¦åŠƒå¥½æ–°çš„è·¯å¾‘, ä¸¦å°‡æœŸæœ›çš„é€Ÿåº¦ä¸€ä½µç™¼é€çµ¦ Control. ç›¸ç•¶æ–¼ term3 çš„ Path Planning Control:æ ¹æ“šè¦ç•«çš„è·¯å¾‘å’Œé€Ÿåº¦, æ‰¾å‡ºå¯ä»¥å¯¦éš›æ“æ§çš„åƒæ•¸ (throttle, brake, steering). ç›¸ç•¶æ–¼ term2 çš„ Model Predictive Control. ä½†æˆ‘å€‘åœ˜éšŠæ²’æœ‰ç”¨ MPC, è€Œæ˜¯ä½¿ç”¨ PID control. Perception Traffic Lightç”±æ–¼å°å¼Ÿæˆ‘ä¸æ˜¯åš CV çš„, æ²’é€™éº¼å¤šå²å®³çš„èƒ½åŠ›, å› æ­¤ä¸€é–‹å§‹æˆ‘ä¹Ÿæ²’æ‰“ç®—è¨“å€‹ YOLO ä¹‹é¡çš„æ–¹æ³•. é‡é ­é–‹å§‹è¨“ç·´çš„è©±æˆ‘åªèƒ½å…ˆæƒ³åˆ°ä¸å¦‚ç”¨ä¸Šæ¬¡ project çš„ semantic segmantation æ–¹æ³•, å°‡èªç‚ºæ˜¯ traffic sign çš„éƒ¨åˆ†æ‰¾å‡ºä¾†, æ¥è‘—ç”¨ç°¡å–®çš„é¡è‰²å€åˆ†ä¸€ä¸‹å¥½äº†. training set æˆ‘ä½¿ç”¨ Bosch Traffic Light Dataset, å…±æœ‰ 5093 å¼µ images. å¾ˆå¤šå¼µå½±åƒå®Œå…¨æ²’æœ‰ traffic sign, å› æ­¤æˆ‘å°±å¿½ç•¥, ä¸¦ä¸”æœ‰äº› traffic sign å¯¦åœ¨å¤ªå°, é‚£ç¨®æƒ…æ³ä¹Ÿå¿½ç•¥, æœ€å¾Œç¯©é¸å‡º 548 å¼µæœ‰ traffic signs çš„å½±åƒä¸¦ä¸” resize æˆ 600x800, èˆ‰å€‹ä¾‹å¦‚ä¸‹: æ³¨æ„åˆ°ç”¨çš„ semantic segmentation æ–¹æ³•æ˜¯ pixel level çš„, ä¹Ÿå°±æ˜¯èªªæ¯å€‹ pixel éƒ½æœƒå»åˆ¤åˆ¥ yes/no traffic sign. è€Œæˆ‘å€‘çœ‹åˆ°å°±ç®—æ˜¯éƒ½æœ‰ traffic sign çš„å½±åƒäº†, å¯¦éš›ä¸Š pixel æ˜¯ traffic sign æ‰€å çš„æ¯”ä¾‹é‚„æ˜¯åä½, é€™è®“æˆ‘é–‹å§‹æœ‰é»æ‡·ç–‘æ˜¯å¦ DNN æœ‰èƒ½åŠ›åˆ†è¾¨å‡ºä¾†. ä½†æ˜¯â€¦.é‚„çœŸçš„å¯ä»¥! ç¾åœ¨æœ‰ç¨®æ„Ÿè¦º, æœ‰æ™‚å€™é‡å°è³‡æ–™ä¸å¹³å‡åšäº†ä¸€äº›æ–¹å¼è®“æ¯å€‹ class å¹³å‡ä¸€äº›, ä½†æ˜¯ DNN çš„æ•ˆæœå…¶å¯¦éƒ½æ²’å•¥æå‡, æ„Ÿè¦º DNN å°è³‡æ–™ä¸å¹³å‡çš„å•é¡Œè¼ƒä¸æ•æ„Ÿ ä¸éç”±æ–¼æ¨¡æ“¬å™¨çš„ traffic sign è·Ÿ Bosch çš„å·®å¤ªå¤š, å› æ­¤æ•ˆæœä¸å¤§å¥½. æˆ‘åªå¥½åŠ å…¥äº†ä¸€äº›æ¨¡å™¨å™¨ä¸‹çš„å½±åƒå»è¨“ç·´, çµæœå°±å¥½å¾ˆå¤šäº†. ä½†é‚„æ˜¯é‡åˆ°ä¸€å€‹å•é¡Œ, æˆ‘çš„ macbook æ²’æœ‰ GPU, è·‘ä¸€å¼µå½±åƒèŠ±äº† 120 secs, è€Œä¸€ç§’é˜ camera æœƒå‚³ä¾† 8 å¼µå½±åƒ! æ ¹æœ¬è™•ç†ä¸äº†, é—œéµæ˜¯ä¹Ÿä¸çŸ¥é“ Udacity å®ƒå€‘ç”¨è‡ªå·± GPU è·‘èµ·ä¾†æœƒå¤šå¿«. æ‰€ä»¥æˆ‘å°±å°‡å½±åƒé•·å¯¬å„ç¸®å°ä¸€åŠ, ç¸½é«”é€Ÿåº¦æœƒé™åˆ°åŸä¾†çš„ 1/4. å°±ç®—å¦‚æ­¤é‚„æ˜¯ç„¡æ³•é©—è­‰æ˜¯å¦å¤ å¿«. æˆ‘å€‘åœ˜éšŠå¡åœ¨é€™å€‹ç„¡æ³•é©—è­‰çš„ç‹€æ³å¾ˆä¹…, å°è‡´å¯èƒ½éœ€è¦ç”¨åˆ°å»¶é•·å››å‘¨çš„æƒ…å½¢. æœ€å¾Œåœ¨ teammate Theodore King çš„å¹«åŠ©ä¸‹, æˆ‘å€‘ä½¿ç”¨äº† tf çš„ object detection API, ä½¿ç”¨ mobilenet é€Ÿåº¦å¿«åˆ°é åŒ—é£›èµ·ä¾†. é€£ CPU è™•ç†ä¸€å¼µå½±åƒéƒ½åªéœ€è¦ä¸åˆ°1ç§’çš„æ™‚é–“! ä½•æ³ä½¿ç”¨ GPU. æœ€çµ‚ç¸½ç®—æœ‰é©šç„¡éšªéé—œäº†. æˆ‘ä¹‹å‰åšé‚£éº¼è¾›è‹¦å¹¹å˜› é–’èŠå…¶å¯¦ Udacity è¦åŠƒç›¸ç•¶æ£’äº†, ä¸»è¦å¹¾å€‹éƒ¨åˆ†éƒ½æœ‰åˆ†åˆ¥çš„å¯¦ä½œé, æœ€å¾Œä¾†å€‹å¤§ä¸€çµ±, çœŸçš„å¾ˆæœ‰æ„æ€. ä½†æˆ‘ä»è¦åæ§½çš„æ˜¯, æç’°å¢ƒå¤ªéº»ç…©äº†! æ¨¡æ“¬å™¨è·‘åœ¨ virtualbox ä¸Š, è€Œæˆ‘çš„ virtualbox window æ²’æ³•è£å¥½, åªèƒ½è£åœ¨ macbook, ä½† macbook åˆæ²’æœ‰ GPU, å°è‡´ä½¿ç”¨ deep learning çš„æ–¹æ³•å®Œå…¨ä¸çŸ¥å¤ ä¸å¤ å¿«! å¦å¤–, VM çš„ç’°å¢ƒæˆ‘é‚„æä¸å®šæ€éº¼è·Ÿ host share data, æå¾—æˆ‘åªå¥½ä¸Šå‚³é›²ç«¯å†ä¸‹è¼‰, æœ€å¾Œè¡°äº‹æ¥è¸µè€Œä¾†, VM ä¹Ÿæä¸å®šç¿»ç‰† (å°, æˆ‘åœ¨ç¶²è·¯é•·åŸçš„ç‰†å…§)â€¦..80%éƒ½åœ¨æç’°å¢ƒâ€¦.çœŸçš„å¾ˆç—›è‹¦ æ©, çµ‚æ–¼ç•¢æ¥­äº†â€¦ çµæŸäº†é€™æ¼«é•·çš„æ—…ç¨‹. åŸä»¥ç‚ºæˆ‘æœƒèˆˆå¥®å¾—ä¸å¾—äº†, ä¸éå¯èƒ½æ˜¯å› ç‚ºæœ€å¾Œ project æç’°å¢ƒå¤ªç—›è‹¦, åŠ ä¸Šé€™æ¨£å­çš„åœ˜éšŠåˆä½œå…¶å¯¦æ²’æœ‰ç´„æŸåŠ› (æœ‰å…©å€‹å®Œå…¨çš„å£Ÿå“¡), åè€Œè§£è„«æ„Ÿå£“éäº†é«˜èˆˆ. ä½†ç¸½çµä¾†èªª, é‚„æ˜¯å¾ˆæ„Ÿè¬ Udacity é™ªä¼´äº†æˆ‘ä¸€å¹´å¤š, ä¸¦ä¸”æœ‰äº†é€™éº¼æœ‰è¶£çš„ç¶“é©—! æœ‰æ©Ÿæœƒçš„è©±, æˆ‘é‚„æ˜¯æœƒç¹¼çºŒä¸Š Udacity å…¶ä»–èª²ç¨‹çš„. Reference Our github ROS wiki TrafficLight_Detection-TensorFlowAPI Semantic Segmantation Path Planning Model Predictive Control","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"ROS","slug":"ROS","permalink":"https://bobondemon.github.io/tags/ROS/"}]},{"title":"Udacity-Semantic-Segmentation","date":"2018-03-06T11:59:13.000Z","path":"2018/03/06/Udacity-Semantic-Segmentation/","text":"Udacity SDC term 3 ç¬¬äºŒå€‹ Project åšçš„æ˜¯ä½¿ç”¨ Deep Learning å­¸ç¿’è­˜åˆ¥ pixel ç­‰ç´šçš„è·¯é¢å€åŸŸ. ç°¡å–®è¬›å°±æ˜¯æœ‰å¦‚ä¸‹çš„ ground truth data, æ¨™ç¤ºå‡ºå“ªé‚Šæ˜¯æ­£ç¢ºçš„è·¯é¢, ç„¶å¾Œç”¨ Fully Convolutional Network å»å°æ¯å€‹ pixel åšè­˜åˆ¥. Fully-Convolutional-Network (FCN)ä¸»è¦æ˜¯å¯¦ä½œé€™ç¯‡è«–æ–‡ â€œFully Convolutional Networks for Semantic Segmentationâ€œ æ›è¨€ä¹‹, å…¨éƒ¨éƒ½æ˜¯ convolution layers, åŒ…å«ä½¿ç”¨ 1x1 convolution æ›¿æ›æ‰åŸä¾† Convnet çš„ fully-connected-layer, å’Œä½¿ç”¨ deconvolution åš upsampling. æ¶æ§‹åœ–å¦‚ä¸‹: åˆ†æˆ Encoder å’Œ Decoder éƒ¨åˆ†. Encoder ä½¿ç”¨ pre-trained å¥½çš„ VGG16 network, è² è²¬åšç‰¹å¾µæŠ½å–. æŠ½å–å‡ºä¾†çš„ç‰¹å¾µå¾Œ, æ¥ä¸Š deconvolution layers (éœ€è¨“ç·´) æ­å»ºè€Œæˆçš„ decoder part. æœ‰ä¸€å€‹ç‰¹åˆ¥ä¹‹è™•æ˜¯ä½¿ç”¨äº† skip æ–¹æ³•. é€™å€‹æ–¹æ³•æ˜¯åœ¨ decoder åš upsampling æ™‚, æœƒåŠ ä¸Šç•¶åˆç›¸å°æ‡‰å¤§å°çš„ Encoder layer è³‡è¨Š. é€™æ¨£åšè«–æ–‡è£¡æåˆ°æœƒå¢åŠ æ•´å€‹è­˜åˆ¥æ•ˆæœ. Resultsæ•ˆæœæœ‰é»è®“æˆ‘å°é©šè±”, å› ç‚ºåªä½¿ç”¨å°‘å°‘çš„ 289 å¼µåœ–ç‰‡å»è¨“ç·´è€Œå·². è·‘å‡ºä¾†çš„æ¸¬è©¦çµæœå¦‚ä¸‹: å¦å¤–é‚„æœ‰ä¸€é»æ˜¯ç¸±ä½¿å·²ç¶“æœ‰ dropout äº†, å¦‚æœæ²’æœ‰åŠ ä¸Š l2 regularization çš„è©±, æœƒ train ä¸å¥½! (l2 regularization çœŸè®“æˆ‘ç¬¬ä¸€æ¬¡çœ‹åˆ°æœ‰é€™éº¼é‡è¦), åŒæ¨£è¨­å®šä¸‹, æœ‰å’Œæ²’æœ‰ l2 regularization çš„å·®åˆ¥: Reference Fully Convolutional Networks for Semantic Segmentation Source code github","tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"}]},{"title":"Mixtures of Factor Analyzers","date":"2018-02-11T15:23:24.000Z","path":"2018/02/11/Mixtures-of-Factor-Analyzers/","text":"é€™ç¯‡ä½¿ç”¨ Bishop PRML çš„ notations, åŒä½¿åƒè€ƒ Zoubin Ghahramani and Geoffrey E. Hinton (æ²’éŒ¯, å°±æ˜¯é‚£ä½ Hiton, å¦å¤–, ç¬¬ä¸€ä½œè€…ä¹Ÿæ˜¯ç¥äººç´šåˆ¥, åŠæ©‹æ•™æˆ, Uber é¦–å¸­ç§‘å­¸å®¶) 1997 å¹´çš„è«–æ–‡ â€œThe EM Algorithm for Mixtures of Factor Analyzersâ€œ, å¯¦ä½œäº† Mixtures of Factor Analyzers, è‡¥æ§½! éƒ½20å¹´å»äº†! My python implementation, github. é—œæ–¼ EM çš„éƒ¨åˆ†æœƒæ¯”è¼ƒç²¾ç°¡, æƒ³çœ‹æ›´å¤šæè¿°æ¨è–¦ç›´æ¥çœ‹ PRML book. æ–‡ç« ä¸»è¦åˆ†ä¸‰å€‹éƒ¨åˆ† ä»€éº¼æ˜¯ Factor Analysis, ä»¥åŠå®ƒçš„ EM è§£ æ¨å»£åˆ° mixtures models èªè€…è­˜åˆ¥ä¸­å¾ˆé—œéµçš„ ivector ç©¶ç«Ÿè·Ÿ FA æœ‰ä»€éº¼é—œè¯? ç›´æ¥é€²å…¥æ­£é¡Œå§~ Factor Analysisä¸€è¨€ä»¥è”½ä¹‹, sub-space é™ç¶­. å‡è¨­æˆ‘å€‘éƒ½æ´»åœ¨é™°é­‚ä¸æ•£çš„ Gauss ä¸–ç•Œä¸­, æ‰€æœ‰ model éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒ. æˆ‘å€‘è§€å¯Ÿçš„è³‡æ–™ $x$ éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒ, ä¸”éƒ½æ˜¯é«˜ç¶­åº¦. ä½†å¯¦éš›ä¸Š $x$ é€šå¸¸åªç”±å°‘æ•¸å¹¾å€‹çœ‹ä¸åˆ°çš„è®Šæ•¸æ§åˆ¶, ä¸€èˆ¬ç¨±é€™äº›çœ‹ä¸åˆ°çš„è®Šæ•¸ç‚º latent variable $z$. å¦‚ä¸‹åœ–èˆ‰ä¾‹: æ‰€ä»¥æˆ‘å€‘çš„ä¸»è¦å•é¡Œå°±æ˜¯, æ€éº¼å° Gaussian distribution å»ºç«‹ sub-space æ¨¡å‹? ç­”æ¡ˆå°±æ˜¯ä½¿ç”¨ Linear Gaussian Model. ä¸€äº› notations å®šç¾©: $x$ è¡¨ç¤ºæˆ‘å€‘çš„ observation, ç¶­åº¦æ˜¯ $D$. $z$ æ˜¯æˆ‘å€‘çš„ latent variable, ç¶­åº¦æ˜¯ $K$. æˆ‘å€‘ä¸€èˆ¬éƒ½æœŸæœ› $K \\ll D$. $x$ and $z$ follow linear-Gaussian framework, æœ‰å¦‚ä¸‹çš„é—œä¿‚: $$\\begin{align} p(z)=N(z|0,I) \\\\ p(x|z)=N(x|Wz+\\mu,\\Psi) \\\\ \\end{align}$$ $W$ æ˜¯ä¸€å€‹ç·šæ€§è½‰æ›, å°‡ä½ç¶­åº¦çš„ latent space è½‰æ›åˆ°é«˜ç¶­åº¦çš„ observation space, å¦å¤– $\\Psi$ å¿…é ˆæ˜¯å°è§’çŸ©é™£. ç”±æ–¼æ˜¯å°è§’çš„é—œä¿‚, å› æ­¤ $\\Psi$ æ•æ‰äº† obaservation ç¶­åº¦çš„å„è‡ªè®Šç•°é‡, å› æ­¤ç¨±ç‚º uniquenesses, è€Œ $W$ å°±æ˜¯è² è²¬æ•æ‰å…±åŒé …, ç¨±ç‚º factor loading. æ›¸è£¡æœ‰ä¸€å€‹ç°¡å–®æ˜ç­çš„åœ–è§£é‡‹ä¸Šè¿°çš„æ¨¡å‹, æˆ‘å°±ä¸å¤šèªªäº†, è‡ªè¡Œçœ‹åœ–: å› ç‚ºæ˜¯ linear-Gaussian model, æ‰€ä»¥ marginal distribution ä¹Ÿæ˜¯ Gaussian: $$\\begin{align} p(x)=N(x|\\mu,C) \\\\ \\mbox{where } C=WW^T+\\Psi \\end{align}$$ åŒæ™‚, äº‹å¾Œæ©Ÿç‡ä¹Ÿæ˜¯ Gaussian $$\\begin{align} p(z|x)=N(z|GW^T\\Psi^{-1}(x-\\bar{x}),G^{-1}) \\\\ \\mbox{where } G=(I+W^T\\Psi^{-1}W)^{-1} \\end{align}$$ å®Œæ•´çš„ lineaer-Gaussian model å…¬å¼, from PRML book: æœ‰äº† $p(x)$ (å¼ 3) åŸºæœ¬ä¸Šæˆ‘å€‘å°±å¯ä»¥æ ¹æ“š training data ç®—å‡º likelihood, ç„¶å¾Œæ‰¾å‡ºä»€éº¼æ¨£çš„åƒæ•¸å¯ä»¥æœ€å¤§åŒ–å®ƒ. ä½†æ˜¯é€™è£¡çš„å•é¡Œæ˜¯å«æœ‰æœªçŸ¥è®Šæ•¸ $z$, é€™å€‹åœ¨ training data çœ‹ä¸åˆ°, å› ç‚ºæˆ‘å€‘åªçœ‹çš„åˆ° $x$. ä¸éåˆ¥æ“”å¿ƒ, EM æ¼”ç®—æ³•å¯ä»¥è™•ç†å«æœ‰æœªçŸ¥è®Šæ•¸æƒ…æ³ä¸‹çš„ maximal likelihood estimation. å¿˜äº†ä»€éº¼æ˜¯ EM, å¯ä»¥åƒè€ƒä¸€ä¸‹é€™. å¾ˆç²¾ç°¡çš„è¬›ä¸€ä¸‹å°±æ˜¯, æ‰¾åˆ°ä¸€å€‹è¼”åŠ©å‡½æ•¸ $Q$, è©²è¼”åŠ©å‡½æ•¸ä¸€å®šå°æ–¼åŸä¾†çš„ likelihood å‡½æ•¸, å› æ­¤åªè¦æ‰¾åˆ°ä¸€çµ„åƒæ•¸å¯ä»¥å°è¼”åŠ©å‡½æ•¸æœ€å¤§åŒ–, é‚£éº¼å°æ–¼åŸä¾†çš„ likelihood å‡½æ•¸ä¹Ÿæœƒæœ‰æå‡, é‡è¤‡ä¸‹å»å°±å¯ä»¥æŒçºŒæå‡, ç›´åˆ° local maximum.å¦å¤–è¼”åŠ©å‡½æ•¸å°±æ˜¯ â€œcomplete-data log likelihood and take its expectation with respect to the posterior distribution of the latent distribution evaluated using â€˜oldâ€™ parameter valuesâ€, æˆ‘çŸ¥é“å¾ˆç²—ç•¥, é‚„è«‹è‡ªè¡Œçœ‹ç­†è¨˜æˆ–æ˜¯ PRML Ch9. E-StepE-Step ä¸»è¦ç®—å‡ºåŸºæ–¼èˆŠåƒæ•¸ä¸‹çš„äº‹å¾Œæ©Ÿç‡çš„ä¸€éšäºŒéšçµ±è¨ˆé‡ é¦–å…ˆå°‡ç¬¦è™Ÿåšç°¡åŒ–, æ–¹ä¾¿å¾Œé¢çš„å¼å­æ›´ç°¡æ½” ($n$ æ˜¯è¨“ç·´è³‡æ–™çš„ index): $$\\mathbb{E}[z_n]\\equiv\\mathbb{E}_{z_n|x_n}[z_n] \\\\ \\mathbb{E}[z_nz_n^T]\\equiv\\mathbb{E}_{z_n|x_n}[z_nz_n^T] \\\\$$ äº‹å¾Œæ©Ÿç‡çš„ä¸€éšäºŒéšçµ±è¨ˆé‡å¦‚ä¸‹: $$\\begin{align} \\mathbb{E}[z_n] = GW^T\\Psi^{-1}(x_n-\\mu) \\\\ \\mathbb{E}[z_nz_n^T] = G + \\mathbb{E}[z_n] \\mathbb{E}[z_n]^T \\\\ \\mbox{where } G=(I+W^T\\Psi^{-1}W)^{-1} \\end{align}$$ å› ç‚ºäº‹å¾Œæ©Ÿç‡æ˜¯ Gaussian, æ‰€ä»¥ç”±å¼ (5) å¯ä»¥æ¨å¾—å¼ (7) å’Œ å¼ (8). M-Stepé€™ä¸€æ­¥å°±æ˜¯æœ€å¤§åŒ–è¼”åŠ©å‡½æ•¸ $Q$, å…¶ä¸­ $\\mu$ ç­‰æ–¼ sample mean, å¯ä»¥ç›´æ¥å¯«æ­»ä¸éœ€è¦ iteration. å¦å¤–å…©å€‹åƒæ•¸ update å¦‚ä¸‹: $$\\begin{align} W^{new}=\\left[\\sum_{n=1}^N (x_n-\\mu)\\mathbb{E}[z_n]^T\\right]\\left[\\sum_{n=1}^N \\mathbb{E}[z_nz_n^T]\\right]^{-1} \\\\ \\Psi^{new}=\\mbox{diag}\\left[S-W^{new}\\frac{1}{N}\\sum_{n=1}^N \\mathbb{E}[z_n](x_n-\\mu)^T\\right] \\end{align}$$ $S$ æ˜¯ sample covariance matrix (é™¤ N çš„é‚£å€‹ biased) Toy Exampleé»‘è‰²é‚£æ¢ç·šæ˜¯çœŸæ­£ç”¢ç”Ÿè³‡æ–™æ™‚çš„ $W$, å¯ä»¥ç•¶æˆæ­£ç¢ºç­”æ¡ˆ. ç´…è‰²çš„æ˜¯ FA ä¼°è¨ˆå‡ºä¾†çš„ $W$ å’Œ $p(x)$. å¯ä»¥ç™¼ç¾ $W$ æ²’æœ‰è·Ÿæ­£ç¢ºç­”æ¡ˆä¸€æ¨£, é€™æ˜¯å› ç‚ºæˆ‘å€‘åœ¨åš maximum likelihood çš„æ™‚å€™, åªé—œå¿ƒ $p(x)$, å› æ­¤å¯ä»¥æœ‰ä¸åŒçš„ latent space ç”¢ç”Ÿç›¸åŒçš„ $p(x)$. ç¯„ä¾‹ä¹Ÿä¸€ä½µæŠŠ probabilistic PCA åšå‡ºä¾†äº†, å¯ä»¥ç™¼ç¾ PPCA ç®—çš„ $W$ è·Ÿæ­£ç¢ºç­”æ¡ˆå¾ˆæ¥è¿‘, é€™æ˜¯å› ç‚ºæ­¤ç¯„ä¾‹çš„è³‡æ–™å…¶å¯¦æ˜¯æ ¹æ“š PPCA çš„æ¨¡å‹ç”¢ç”Ÿçš„, æ‰€ä»¥ PPCA è¼ƒæ¥è¿‘æ˜¯æ­£å¸¸. åŒæ™‚æˆ‘å€‘çœ‹åˆ° PPCA ä¼°è¨ˆå‡ºä¾†çš„ $p(x)$ å…¶å¯¦ä¹Ÿè·Ÿ FA ä¸€æ¨£, å†åº¦ä½è­‰ FA å…¶å¯¦ä¹Ÿæ²’ç®—éŒ¯, åªæ˜¯ä¸åŒçš„è¡¨é”æ–¹å¼. Mixtures of Factor Analyzerså°‡ FA å‡è¨­æœ‰å¤šå€‹ components çµ„æˆå°±è®Šæˆ MFA äº†, å…¶å¯¦å°±è·Ÿ GMM ä¸€æ¨£, å·®åˆ¥åœ¨æ–¼æˆ‘å€‘ç”¨äº† latent space å»å„åˆ¥ model æ¯å€‹ Gaussian Components è€Œå·²! è¦æ³¨æ„çš„æ˜¯, é€™æ™‚å€™çš„ latent variables ä¸åªæœ‰ $z$, é‚„æœ‰ $m$ (=1~M è¡¨ç¤ºæœ‰ $M$ å€‹ components), æˆ‘å€‘ç”¨ä¸‹æ¨™ $j$ è¡¨ç¤º component çš„ index. å¦å¤–, æ¯ä¸€å€‹ component, æœƒæœ‰å„è‡ªçš„ latent space, å› æ­¤æœ‰å„è‡ªçš„ $W_j$ å’Œ $\\mu_j$, ä½†æ˜¯å…¨éƒ¨çš„ components å…±ç”¨ä¸€å€‹ uniquenesses $\\Psi$. $$\\begin{align} p(x|z,m=j)=N(x|W_j z+\\mu_j,\\Psi) \\end{align}$$ å’Œ GMM ä¸€æ¨£, æ¯ä¸€å€‹ component éƒ½æœ‰ä¸€å€‹ weights, $\\pi_j$, åˆèµ·ä¾†æ©Ÿç‡æ˜¯1 E-Stepä¸€éšå’ŒäºŒéšçµ±è¨ˆé‡å¦‚ä¸‹: $$\\begin{align} \\color{red}{\\mathbb{E}[z_n|m=j]} = G_j W_j^T \\Psi^{-1}(x_n-\\mu_j) \\\\ \\color{red}{\\mathbb{E}[z_nz_n^T|m=j]} = G_j + \\mathbb{E}[z_n|m=j] \\mathbb{E}[z_n|m=j]^T \\\\ \\mbox{where } G_j=(I+W_j^T\\Psi^{-1}W_j)^{-1} \\end{align}$$ è€ŒçœŸæ­£çš„äº‹å¾Œæ©Ÿç‡ç‚º: $$\\begin{align} \\mathbb{E}[m=j,z_n] = h_{nj}\\mathbb{E}[z_n|m=j] \\\\ \\mathbb{E}[m=j,z_nz_n^T] = h_{nj}\\mathbb{E}[z_nz_n^T|m=j] \\\\ \\mbox{where } \\color{red}{h_{nj}}=\\mathbb{E}[m=j|x_n]\\propto p(x_n,m=j) \\end{align}$$ å°‡ (18) è§£é‡‹æ¸…æ¥šä¸€ä¸‹, åŸºæœ¬ä¸Šå°±æ˜¯è¨ˆç®—çµ¦å®šä¸€å€‹ $x_n$, å®ƒæ˜¯ç”± component $j$ æ‰€ç”¢ç”Ÿçš„æ©Ÿç‡æ˜¯å¤šå°‘. æˆ‘å€‘å¯ä»¥é€²ä¸€æ­¥æ¨å°å¦‚ä¸‹: $$\\begin{align} p(x_n,m=j)=p(m=j)p(x_n)\\\\ =\\pi_j N(x_n|\\mu_j,C_j=W_jW_j^T+\\Psi) \\end{align}$$ (19) åˆ° (20) çš„éƒ¨åˆ†å¯ä»¥ç”± (3) å’Œ (4) æ‰€çŸ¥é“çš„ marginal distribution $p(x)$ å¾—åˆ° åˆ°é€™è£¡, æ‰€æœ‰éœ€è¦çš„çµ±è¨ˆé‡, ç´…è‰²éƒ¨åˆ†, æˆ‘å€‘éƒ½å¯ä»¥ç®—å¾—äº†. M-Stepé€šé€šå¾®åˆ†ç­‰æ–¼é›¶, é€šé€šå¾®åˆ†ç­‰æ–¼é›¶, é€šé€šå¾®åˆ†ç­‰æ–¼é›¶ â€¦ å¾—åˆ°: $$\\begin{align} \\pi_j^{new}=\\frac{1}{N}\\sum_{n=1}^N h_{nj} \\\\ \\mu_j^{new}=\\frac{\\sum_{n=1}^N h_{nj}x_n}{\\sum_{n=1}^N h_{nj}} \\\\ W_j^{new}=\\left[\\sum_{n=1}^N h_{nj}(x_n-\\mu_j)\\mathbb{E}[z_n|m=j]^T\\right]\\left[\\sum_{n=1}^N h_{nj}\\mathbb{E}[z_nz_n^T|m=j]\\right]^{-1} \\\\ \\Psi^{new}=\\frac{1}{N}\\mbox{diag}\\left[ \\sum_{nj} h_{nj} \\left( (x_n-\\mu_j) - W_j^{new}\\mathbb{E}[z_n|m=j] \\right)(x_n-\\mu_j)^T \\right] \\end{align}$$ Toy Example åœ–æ‡‰è©²å¾ˆæ¸…æ¥šäº†, æœ‰æ­£ç¢º model åˆ° data é€™å€‹ MFA é‚„çœŸçš„ä¸å®¹æ˜“å¯¦ä½œ, å¯«èµ·ä¾†å¾ˆå¤šè¦æ³¨æ„çš„åœ°æ–¹, å¾ˆç‡’è…¦é˜¿! ä¸éåšå®Œäº†ä¹‹å¾Œé —æœ‰æˆå°±æ„Ÿ~ i-vectorå…¶å¯¦æœƒæƒ³å¯«é€™ç¯‡ä¸»è¦æ˜¯å› ç‚ºèªè€…è­˜åˆ¥ä¸­çš„ ivector, è€Œ ivector åŸºæœ¬ä¸Šå°±æ˜¯ä¸€å€‹ FA. åœ¨è¨ˆç®— ivector æ™‚, æˆ‘å€‘æœƒå…ˆä¼°è¨ˆ Universal Background Model (UBM), å…¶å¯¦å°±æ˜¯æ‰€æœ‰èªè€…çš„æ‰€æœ‰èªéŸ³ç‰¹å¾µç®—å‡ºä¾†çš„ GMM. ä»¥ä¸‹åœ–ç‚ºä¾‹, UBM æœ‰ä¸‰å€‹ mixtures, ç”¨æ·¡è—è‰²è¡¨ç¤º. è€Œé‡å°æŸä¸€ä½ speaker, å…¶ GMM ç‚ºæ©˜è‰². å‚³çµ±ä¸Šæˆ‘å€‘å°‡æ‰€æœ‰ mixture çš„ mean ä¸²æ¥æˆä¸€å€‹é•·çš„å‘é‡, å‰‡è©²å‘é‡å°±å¯ä»¥ç•¶ä½œæ˜¯è©² GMM æ¨¡å‹çš„ä¸€å€‹ä»£è¡¨, ä¸¦ç¨±ç‚º supervector ä¸ä¸€èµ·ä¸²æ¥ covariance matrix å—? weight å‘¢? ç•¶ç„¶ä¹Ÿå¯ä»¥å…¨éƒ¨éƒ½ä¸²æˆä¸€å€‹éå¸¸é•·çš„å‘é‡, ä½†ç ”ç©¶è¡¨æ˜ mean å‘é‡å°±è¶³å¤ äº† supervector ç¶­åº¦ç‚º mfcc-dim x mixtureæ•¸, å¾ˆå®¹æ˜“æœ‰ 40x1024 é€™éº¼é«˜ç¶­! å› æ­¤ ivector å°±æ˜¯åˆ©ç”¨ FA çš„æ–¹æ³•å°‡ supervector é™ç¶­. é‚£å…·é«”æ€éº¼åšå‘¢? é¦–å…ˆæˆ‘å€‘è¦å…ˆç”¨ä¸€å€‹å°æŠ€å·§å°‡ â€œå¤šå€‹ Gaussiansâ€ (æ³¨æ„ä¸æ˜¯ GMM, å› ç‚ºæ²’æœ‰mixture weightçš„æ¦‚å¿µ, æ¯ä¸€å€‹ Gaussianéƒ½åŒç­‰é‡è¦) è½‰æ›æˆä¸€å€‹ Gaussain. è¦‹åœ–å¦‚ä¸‹: æˆ‘å€‘å¯ä»¥å¾ˆå®¹æ˜“é©—è­‰å…©é‚Šæ˜¯ç­‰åƒ¹çš„. è½‰æ›æˆä¸€å€‹ Gaussian å¥½è™•å°±æ˜¯æˆ‘å€‘å¯ä»¥ç›´æ¥ä½¿ç”¨ FA é™ç¶­, è€Œ ivector å°±æ˜¯è©² FA çš„ latent variable $z$. å¦‚åŒ (2) çš„å®šç¾©: $$\\begin{align} p(x|z)=N(x|Wz+\\mu,\\Sigma) \\\\ \\end{align}$$ é€™è£¡çš„ $\\mu$ æ˜¯ UBM çš„ supervector, $\\Sigma$ å‰‡å¦‚åŒä¸Šåœ–çš„å®šç¾©, æ˜¯ä¸€å€‹ block diagonal matrix, æ¯ä¸€å€‹ block å°æ‡‰ä¸€å€‹ UBM mixture çš„ covariance matrix. å› æ­¤ $\\mu$ å’Œ $\\Sigma$ éƒ½æ˜¯ä½¿ç”¨ UBM çš„åƒæ•¸. é‡å°å¼ (25) å»æ›´ä»”ç´°äº†è§£å…¶æ‰€ä»£è¡¨çš„ç‰©ç†æ„ç¾©æ˜¯å¾ˆå€¼å¾—çš„, æ‰€ä»¥æˆ‘å€‘å¤šèªªä¸€é». ç”±æ–¼æˆ‘å€‘å·²ç¶“çŸ¥é“é€™æ¨£çš„ä¸€å€‹ Gaussian å¯¦éš›ä¸Šä»£è¡¨äº†åŸä¾† mfcc space çš„å¤šå€‹ Gaussians. æ‰€ä»¥é‡å°æŸä¸€å€‹ç‰¹å®šçš„ ivector $z^*$ ç”±å¼ (25) å¾—çŸ¥, ä»–æœ‰å¯èƒ½ä»£è¡¨äº†ä¸‹åœ–æ©˜è‰²çš„ä¸‰å€‹ Gaussians (ä¹Ÿå› æ­¤å¯èƒ½ä»£è¡¨äº†æŸä¸€å€‹ speaker çš„æ¨¡å‹): åˆ°ç›®å‰ç‚ºæ­¢æ‰€æè¿°çš„ ivector å¯¦éš›ä¸Šæ˜¯æ ¹æ“šè‡ªå·±çš„ç†è§£å°‡ 2005 å¹´ â€œEigenvoice Modeling with Sparse Training Dataâ€œ è£¡çš„ Proposition 1 (p348) çš„è¨­å®šæè¿°å‡ºä¾†. å¦‚æœ‰éŒ¯èª¤é‚„è«‹ä¾†ä¿¡æŒ‡æ­£. è©²è¨­å®šä¸­, æ¯ä¸€å€‹ mfcc vector éƒ½æœƒäº‹å…ˆè¢«æ­¸é¡å¥½å±¬æ–¼å“ªä¸€å€‹ mixture, ç­‰æ–¼ç¡¬åˆ†é¡. ä½†æ˜¯å…¶å¯¦ä¸¦ä¸éœ€è¦, ä¸€å€‹æ˜é¡¯çš„æ”¹é€²æ–¹æ³•å°±æ˜¯ä½¿ç”¨å¾Œé©—æ¦‚ç‡ä¾†åšè»Ÿåˆ†é¡. ç›´æ¥çœ‹åœ–: ç›®å‰çš„ ivector è¨ˆç®—éƒ½ä½¿ç”¨é€™ç¨®æ–¹å¼, ä¾‹å¦‚ Microsoft Research çš„ MSR Identity Toolbox. è©² toolbox ä½¿ç”¨ â€œA Straightforward and Efficient Implementation of the Factor Analysis Model for Speaker Verificationâ€œ çš„å¯¦ä½œæ–¹å¼, å¯ä»¥ç”±è«–æ–‡çš„å¼ (2),(5) çœ‹å‡ºä½¿ç”¨å¾Œé©—æ¦‚ç‡çš„è¨­å®š. æœ€å¾Œå¤šèªªä¸€äº›èªè€…è­˜åˆ¥çš„äº‹æƒ…. ivector ä¸»è¦æ˜¯é‡å°åŸé«˜ç¶­ç©ºé–“ (mfcc-dim x componentæ•¸é‡) åšé™ç¶­, è€Œæ²’æœ‰å»é‡å°èªè€…çš„è¨Šæ¯. æ‰€ä»¥å‚³çµ±æµç¨‹æœƒå†ç¶“é WCCN + LDA, è€Œ LDA å°±æœƒé‡å°åŒä¸€å€‹èªè€…ç›¡é‡é è¿‘, è€Œä¸åŒèªè€…ç›¡é‡æ‹‰é–‹. ç¶“é LDA å¾Œå°±å¯ä»¥ç”¨ $cos$ è¨ˆç®—ç›¸ä¼¼åº¦é€²è¡Œèªè€…ä¹‹é–“çš„æ‰“åˆ†. ä½†äº‹å¯¦ä¸Š, æ›´å¥½çš„åšæ³•æ˜¯ç”¨ä¸€å€‹ PLDA åšæ›´å¥½çš„æ‰“åˆ†. é—œæ–¼ PLDA è«‹åƒè€ƒé€™é‚ŠåŸå§‹æ–‡ç«  â€œProbabilistic Linear Discriminant Analysis for Inferences About Identityâ€œ, è€Œ PLDA æ›´æ˜¯èˆ‡æœ¬ç¯‡çš„ FA è„«é›¢ä¸äº†é—œä¿‚! ç¸½é«”ä¾†èªª FA, MFA å°æ–¼ç›®å‰çš„èªè€…è­˜åˆ¥ç³»çµ±ä»ç„¶ååˆ†é—œéµ, ç¸±ä½¿ç›®å‰ Kaldi ä½¿ç”¨äº†æ·±åº¦å­¸ç¿’æ›¿æ›äº† ivector, ä½†å¾Œç«¯ä»ç„¶æ¥ PLDA. Reference è‡ªå·±å¯¦ä½œçš„ Python MFA (å« Toy examples) github Zoubin Ghahramani and Geoffrey E. Hinton, The EM Algorithm for Mixtures of Factor Analyzers Bishop PRML ä»¥å‰çš„ EM ç­†è¨˜ ä»¥å‰çš„ GMM EM ç­†è¨˜ i-vector åŸå§‹è«–æ–‡ PLDA åŸå§‹è«–æ–‡ Eigenvoice Modeling with Sparse Training Data A Straightforward and Efficient Implementation of the Factor Analysis Model for Speaker Verification MSR Identity Toolbox","tags":[{"name":"Factor Analysis","slug":"Factor-Analysis","permalink":"https://bobondemon.github.io/tags/Factor-Analysis/"},{"name":"Expectation Maximization","slug":"Expectation-Maximization","permalink":"https://bobondemon.github.io/tags/Expectation-Maximization/"},{"name":"ivector","slug":"ivector","permalink":"https://bobondemon.github.io/tags/ivector/"}]},{"title":"Path-Planning-Udacity-Term3-Project1","date":"2018-02-06T15:38:48.000Z","path":"2018/02/06/Path-Planning-Udacity-Term3-Project1/","text":"åœäº†åŠå¹´ çš„ Udacity Self Driving Car (SDC) Program, çµ‚æ–¼åˆé–‹å§‹äº†. åšç‚º Term3 çš„ç¬¬ä¸€å€‹ Project, æˆ‘æŠ±è‘—é«˜åº¦çš„æœŸå¾…. ä¸éå®Œæˆå¾Œ, æœ‰é»å°å¤±æœ›. å¤±æœ›çš„åŸå› æ˜¯é€™å€‹ project è·Ÿèª²ç¨‹ä¸Šçš„é€£çµæ„Ÿè¦ºä¸æ˜¯é‚£éº¼æ˜é¡¯. ä¾‹å¦‚èª²ç¨‹ä¸Šæœ‰è¬›åˆ° A*, hybrid A* çš„ç®—æ³•, ä½† project æ˜¯æ¨¡æ“¬ highway drive, å› æ­¤ A* æ¯”è¼ƒä¸é©åˆ (é©åˆåœ¨ parking lot å ´æ™¯). å¦å¤–ä¹Ÿæœ‰æåˆ°æ€éº¼é™ä½ jerk (åŠ é€Ÿåº¦çš„å¾®åˆ†, ä¸»è¦æ˜¯ä¸èˆ’é©çš„ä¾†æº), ç•¶åƒè€ƒå…§å®¹æ˜¯å¾ˆå¥½, ä¸éåœ¨å¯« Project æ™‚æ„Ÿè¦ºä¹Ÿä¸å¤§éœ€è¦. é€™ç¯‡å°±æ˜¯å€‹ç´€éŒ„, æœƒå¾ˆæ°´. æ–¹æ³•å¾ˆç°¡å–®, ä¸€å¼µåœ–è§£æ±º: ego-car æ ¹æ“šè‡ªå·±æ‰€åœ¨çš„è»Šé“, æœ€å¤šå¯ä»¥æœ‰ä¸‰æ¢è·¯å¾‘é¸æ“‡, è·¯å¾‘å°±ç”¨ spline curve ç”¢ç”Ÿ, ç¢ºä¿å¤  smooth. åŒæ™‚æœ‰ sensor-fusion çš„è³‡æ–™å¯ä»¥çŸ¥é“å…¶ä»–è»Šå­çš„ç‹€æ³, ç„¶å¾Œåˆ©ç”¨ prediction model å»é æ¸¬å…¶ä»–è»Šçš„è·¯å¾‘ (æˆ‘å°±å–®ç´”ä½¿ç”¨ constant velocity ç·šæ€§è·¯å¾‘). å¦‚æœæœ‰ collision åœ¨æœªä¾†çš„ 1 or 1.5 ç§’, è©²è·¯å¾‘å°±ç„¡æ•ˆ. å¦å¤–, å¦‚æœæœ‰è»Šå­å¤ªé è¿‘, å°±æ¸›é€Ÿ. ego-car çš„æ¯å€‹è·¯å¾‘éƒ½æœƒæœ‰å„è‡ªçš„ cost, cost æ˜¯æ ¹æ“šä¸€äº›å–œå¥½, è­¬å¦‚å“ªä¸€æ¢è»Šé“å¯ä»¥è·‘å¾—æ¯”è¼ƒå¿«, å“ªä¸€æ¢è·¯å¾‘æ¯”è¼ƒä¸æœƒè·Ÿå…¶ä»–è»Šå­å¤ªæ¥è¿‘ç­‰ç­‰â€¦ é€™ Project æœ€éº»ç…©çš„å°±æ˜¯åœ¨è¨­è¨ˆ cost function, å’Œèª¿æ•´. (é‚„æœ‰ç†Ÿæ‚‰ project çš„ç¨‹å¼ç¢¼â€¦éº»ç…©é˜¿) å½±ç‰‡é€£çµ here. Project github here æ²’äº†, æ–‡ç« æ°´ä¸æ°´ ? å¥½æ°´é˜¿, çœŸå¿ƒè™›","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"}]},{"title":"Maximum Mutual Information in Speech Recognition","date":"2017-12-16T04:08:44.000Z","path":"2017/12/16/Maximum-Mutual-Information-in-Speech-Recognition/","text":"Maximum Mutual Information (MMI) åºåˆ—çš„é‘‘åˆ¥æ€§è¨“ç·´æ–¹æ³•å¾æ—©æœŸçš„ GMM-HMM, åˆ°ç¾ä»Šå°±ç®—ä½¿ç”¨äº†æ·±åº¦å­¸ç¿’åŒæ¨£ååˆ†æœ‰ç”¨, å¦‚ Kaldi chain model åœ¨ DNN-HMM çš„åŸºç¤ä¸ŠåŠ ä¸Šåºåˆ—é‘‘åˆ¥è¨“ç·´, æ€§èƒ½æœƒå†é€²ä¸€æ­¥æå‡. å‰ä¸€é™£å­è®€äº†ä¿æ£Ÿã€é„§åŠ›çš„é€™æœ¬ èªéŸ³è­˜åˆ¥å¯¦è¸, å°æˆ‘ä¾†èªªæ•´ç†å¾—æ»¿å¥½çš„, å°±æ˜¯æ•¸å­¸éƒ¨åˆ†çš„æ¨å°æœ‰é»ç°¡æ½”äº†äº›, æ‰€ä»¥é€™ç¯‡å°±åŸºæ–¼è©²æ›¸çš„æ¨å°, è£œé½Šäº†è¼ƒè©³ç´°çš„æ­¥é©Ÿ, ä¸¦ä¸”å˜—è©¦ä½¿ç”¨ Computational graph çš„æ–¹å¼ç†è§£ MMI çš„è¨“ç·´. é‚£éº¼å°±é–‹å§‹å§! ç”¨è‡ªå·±ç•«çš„ MMI çš„è¨ˆç®—åœ–è­œç•¶å°é¢å§ :) MMI æ•¸å­¸å®šç¾©å®šç¾©$o^m=o_1^m,...,o_t^m,...,o_{T_m}^m$æ˜¯è¨“ç·´æ¨£æœ¬è£¡ç¬¬ m å¥è©±çš„ observation (MFCC,fbank,â€¦) sequence, è©² sequence æœ‰ $T_m$ å€‹ observation vector. è€Œ$w^m=w_1^m,...,w_t^m,...,w_{N_m}^m$å‰‡æ˜¯è©²å¥è©±çš„æ­£ç¢º transcription, æœ‰ $N_m$ å€‹å­—. é€šé forced-alignment å¯ä»¥å¾—åˆ°ç›¸å°æ‡‰çš„ state sequence$s^m=s_1^m,...,s_t^m,...,s_{T_m}^m$MMI ç›®çš„å°±æ˜¯å¸Œæœ›æ¨¡å‹ç®—å‡ºçš„æ­£ç¢ºç­”æ¡ˆ sequence æ©Ÿç‡æ„ˆå¤§æ„ˆå¥½, åŒæ™‚éæ­£ç¢ºç­”æ¡ˆ (èˆ‡ä¹‹ç«¶çˆ­çš„å…¶ä»– sequences) çš„æ©Ÿç‡è¦æ„ˆå°æ„ˆå¥½, æ‰€ä»¥æ­£ç¢ºç­”æ¡ˆæ”¾åˆ†å­, éæ­£ç¢ºæ”¾åˆ†æ¯, æ•´é«”è¦æ„ˆå¤§æ„ˆå¥½. ç”±æ–¼è€ƒæ…®äº†ç«¶çˆ­ sequences çš„æœ€å°åŒ–, æ‰€ä»¥æ˜¯é‘‘åˆ¥æ€§è¨“ç·´. åˆæ­¤ç¨®æ–¹å§‹æ˜¯åŸºæ–¼æ•´å¥çš„ sequence è€ƒé‡, å› æ­¤æ˜¯åºåˆ—é‘‘åˆ¥æ€§è¨“ç·´. æ•¸å­¸å¯«ä¸‹ä¾†å¦‚ä¸‹:$$J_{MMI}(\\theta;S)=\\sum_{m=1}^M J_{MMI}(\\theta\\|o^m,w^m) \\\\ =\\sum_{m=1}^M \\log \\frac{ p(o^m\\|s^m,\\theta)^KP(w^m) }{ \\sum_w p(o^m\\|s^w,\\theta)^K P(w) }$$ ç‚ºäº†ç°¡å–®åŒ–, æˆ‘å€‘å‡è¨­åªæœ‰ä¸€æ¢è¨“ç·´èªéŸ³, æ‰€ä»¥å»æ‰ $m$ çš„æ¨™è¨˜, ç„¶å¾Œ $\\sum_m$ çœç•¥: $$\\begin{align} J_{MMI}(\\theta\\|o,w) =\\log \\frac{ p(o\\|s,\\theta)^KP(w) }{ \\sum_w p(o\\|s^w,\\theta)^K P(w) } \\end{align}$$ æ¥è‘—æˆ‘å€‘è¦ç®—é‡å° $\\theta$ çš„å¾®åˆ†, æ‰å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•: $$\\begin{align} \\triangledown_\\theta J_{MMI}(\\theta\\|o,w) =\\sum_t \\triangledown_{z_t^L}J_{MMI}(\\theta\\|o,w)\\frac{\\partial z_t^L}{\\partial\\theta} \\\\ =\\sum_t e_t^L\\frac{\\partial z_t^L}{\\partial\\theta} \\end{align}$$ å…¶ä¸­å®šç¾©$e_t^L=\\triangledown_{z_t^L}J_{MMI}(\\theta\\|o,w)$ èªéŸ³è²å­¸æ¨¡å‹ (AM) å‚³çµ±ä¸Šä½¿ç”¨ GMM ä¾† model, è€Œç¾åœ¨éƒ½æ˜¯åŸºæ–¼ DNN, å…¶ä¸­æœ€å¾Œçš„ output layer å‡è¨­ç‚ºç¬¬ $L$ å±¤: $z_t^L$, éäº† softmax ä¹‹å¾Œæˆ‘å€‘å®šç¾©ç‚º $v_t^L$, è€Œå…¶ index $r$, $v_t^L(r)=P(r|o_t)$ å°±æ˜¯çµ¦å®šæŸä¸€å€‹æ™‚é–“ $t$ çš„ observation $o_t$ æ˜¯ state $r$ çš„æ©Ÿç‡. è®€è€…åˆ¥ç·Šå¼µ, æˆ‘å€‘ç”¨ Computational graph çš„æ–¹å¼å°‡ä¸Šå¼ç›´æ¥ç•«å‡ºä¾†: MMI Computational Graph è¡¨é” ä¸Šåœ–ç”¨ computational graph æ¸…æ¥šçš„è¡¨é”äº†å¼ (3) çš„è¨ˆç®—, å› ç‚ºæ‰€æœ‰åƒæ•¸ $\\theta$ åœ¨æ‰€æœ‰çš„æ™‚é–“ $t$ ä¸Šæ˜¯å…±äº«çš„, å› æ­¤è¦ $\\sum_t$, ä¹Ÿå°±æ˜¯è¦ç´¯åŠ ä¸Šåœ–æ‰€æœ‰ç´…è‰²çš„ gradient path. è¨ˆç®— $\\partial z_t^L / \\partial\\theta$ å¾ˆå®¹æ˜“, å°±æ˜¯ DNN çš„è¨ˆç®—åœ–è­œçš„ gradient, å› æ­¤é‡é»å°±åœ¨å¦‚ä½•è¨ˆç®— $e_t^L$, è€Œæ•´å€‹ MMI æœ€æ ¸å¿ƒçš„åœ°æ–¹å°±æ˜¯åœ¨è¨ˆç®—é€™å€‹äº†! MMI æ•¸å­¸æ¨å°æˆ‘å€‘æŠŠ $e_t^L(i)$ (å°±æ˜¯$e_t^L$é€™å€‹å‘é‡çš„ç¬¬$i$å€‹element)è¨ˆç®—å¦‚ä¸‹: $$\\begin{align} e_t^L(i)=\\triangledown_{z_t^L(i)}J_{MMI}(\\theta\\|o,w) \\\\ =\\sum_r \\frac{\\partial J_{MMI}(\\theta\\|o,w)}{\\partial\\log p(o_t|r)}\\frac{\\partial\\log p(o_t|r)}{\\partial z_t^L(i)} \\end{align}$$ å…ˆè§£é‡‹ä¸€ä¸‹ $\\log p(o_t|r)$ é€™å€‹ term, å¯ä»¥é‡å¯«æˆ$$\\begin{align} \\log p(o_t|r)=\\log \\color{red}{p(r|o_t)} + \\log p(o_t) - \\log p(r) = \\log \\color{red}{v_t^L(r)} + \\log p(o_t) - \\log p(r) \\end{align}$$æ‰€ä»¥é€™å€‹ term æ˜¯è·Ÿ $v_t^L(r)$ ç›¸é—œçš„, è€Œç”±æ–¼ $v_t^L$ æ˜¯ $z_t^L$ ç¶“é softmax å¾—åˆ°, å› æ­¤å¼(5)æ‰æœƒæœ‰ $\\sum_r$.æ ¹æ“šå¼ (6), æˆ‘å€‘å¯ä»¥å¾ˆå¿«ç®—å¾—å¼ (5) çš„ç¬¬äºŒå€‹åˆ†å­åˆ†æ¯é …å¦‚ä¸‹:$$\\begin{align} \\frac{\\partial\\left[\\log v_t^L(r) + \\log p(o_t) - \\log p(r)\\right]}{\\partial z_t^L(i)}=\\frac{\\partial \\log v_t^L(r)}{\\partial z_t^L(i)} \\end{align}$$å¾ˆæ˜é¡¯å› ç‚º $\\log p(o_t)$ å’Œ $\\log p(r)$ éƒ½è·Ÿ $z_t^L(i)$ ç„¡é—œæ‰€ä»¥å»æ‰.ç‚ºäº†è¨ˆç®—å¼ (5) çš„ç¬¬ä¸€å€‹åˆ†å­åˆ†æ¯é …, æˆ‘å€‘æŠŠå…ˆæŠŠå¼ (1) çš„ log é …æ‹†é–‹:$$\\begin{align} J_{MMI}(\\theta\\|o,w)= K\\color{green}{\\log p(o\\|s,\\theta)}+\\color{blue}{\\log p(w)} - \\color{orange}{\\log\\left[\\sum_w p(o\\|s^w,\\theta)^K p(w)\\right]} \\end{align}$$æ‰€ä»¥$$\\begin{align} \\frac{\\partial J_{MMI}(\\theta\\|o,w)}{\\partial \\log p(o_t|r)}= K\\color{green}{ \\frac{\\partial\\log p(o\\|s,\\theta)}{\\partial \\log p(o_t|r)} } + \\color{blue}{ \\frac{\\partial\\log p(w)}{\\partial \\log p(o_t|r)} } - \\color{orange}{ \\frac{\\partial\\log\\left[\\sum_w p(o\\|s^w,\\theta)^K p(w)\\right]}{\\partial \\log p(o_t|r)} } \\end{align}$$ ç¶ è‰²éƒ¨åˆ†æ³¨æ„åˆ° $\\log p(o|s,\\theta)$ åœ¨ HMM çš„æƒ…æ³ä¸‹, æ˜¯çµ¦å®š state sequence çš„è§€æ¸¬æ©Ÿç‡å€¼, å› æ­¤åªæ˜¯æ¯å€‹ state æ™‚é–“é»çš„ emission probability, æ‰€ä»¥$$\\begin{align} \\log p(o\\|s,\\theta)= \\sum_{t&apos;} \\log p(o_{t&apos;}\\|s_{t&apos;},\\theta) \\end{align}$$è€Œåªæœ‰ $tâ€™=t$ æ™‚èˆ‡å¾®åˆ†é …æœ‰é—œ, å› æ­¤è®Šæˆ$$\\begin{align} \\frac{\\partial\\log p(o\\|s,\\theta)}{\\partial \\log p(o_t\\|r)}= \\frac{\\partial \\log p(o_t\\|s_t,\\theta)}{\\partial \\log p(o_t\\|r)}=\\delta(r=s_t) \\end{align}$$ è—è‰²éƒ¨åˆ†èˆ‡å¾®åˆ†é …ç„¡é—œï¼Œå› æ­¤$$\\begin{align} \\frac{\\partial\\log p(w)}{\\partial \\log p(o_t|r)}=0 \\end{align}$$ æ©˜è‰²éƒ¨åˆ†$$\\begin{align} \\frac{\\partial\\log\\left[\\sum_w p(o\\|s^w,\\theta)^K p(w)\\right]}{\\partial \\log p(o_t|r)}= \\frac{1}{\\sum_w p(o\\|s^w,\\theta)^K p(w)}\\times\\frac{\\partial \\sum_w \\color{red}{p(o\\|s^w,\\theta)}^K p(w)}{\\partial \\log p(o_t|r)} \\end{align}$$ ç´…è‰²çš„éƒ¨åˆ†å¦‚åŒä¸Šé¢ç¶ è‰²é …çš„è¨è«–, åªæœ‰æ™‚é–“é» $t$ æ‰è·Ÿå¾®åˆ†é …æœ‰é—œ, ä¸åŒçš„æ˜¯é€™æ¬¡æ²’æœ‰ $\\log$ å› æ­¤æ˜¯é€£ä¹˜, å¦‚æœ $s_t\\neq r$ æ•´æ¢ sequence çš„æ©Ÿç‡èˆ‡å¾®åˆ†é …ç„¡é—œ, å› æ­¤åªæœƒä¿ç•™ $s_t=r$ çš„é‚£äº› $w$ sequences.å¦å¤–,$\\frac{\\partial p(o_t\\|r)^K}{\\partial\\log p(o_t\\|r)} \\mbox{ å¯æƒ³æˆ } \\frac{\\partial e^{Kx}}{\\partial x} = Ke^{Kx}$ç¶œåˆä»¥ä¸Šè¨è«–æ©˜è‰²éƒ¨åˆ†ç‚º$$\\begin{align} \\frac{\\partial\\log\\left[\\sum_w p(o\\|s^w,\\theta)^K p(w)\\right]}{\\partial \\log p(o_t|r)}= K\\frac{\\sum_{w:s_t=r}p(o\\|s,\\theta)^K p(w)}{\\sum_w p(o\\|s^w,\\theta)^K p(w)} \\end{align}$$ å…¨éƒ¨å¸¶å…¥ä¸¦æ•´ç† $e_t^L(i)$å°‡ (11),(12),(14) ä»£å›åˆ° (9) æˆ‘å€‘å¾—åˆ°$$\\begin{align} \\frac{\\partial J_{MMI}(\\theta\\|o,w)}{\\partial \\log p(o_t|r)}= K\\left(\\delta(r=s_t)-\\frac{\\sum_{w:s_t=r}p(o\\|s,\\theta)^K p(w)}{\\sum_w p(o\\|s^w,\\theta)^K p(w)}\\right) \\end{align}$$ç¹¼çºŒå°‡ (15),(7) ä»£å›åˆ° (5) æˆ‘å€‘çµ‚æ–¼å¯ä»¥å¾—åˆ° $e_t^L(i)$ çš„çµæœäº†!$$\\begin{align} e_t^L(i)=\\sum_r K\\left(\\delta(r=s_t)-\\frac{\\sum_{w:s_t=r}p(o\\|s,\\theta)^K p(w)}{\\sum_w p(o\\|s^w,\\theta)^K p(w)}\\right) \\times \\frac{\\partial \\log v_t^L(r)}{\\partial z_t^L(i)} \\\\ = \\sum_r K\\left(\\delta(r=s_t)-\\color{red}{\\gamma_t^{DEN}(r)}\\right) \\times \\frac{\\partial \\log v_t^L(r)}{\\partial z_t^L(i)} \\\\ =K\\left(\\delta(i=s_t)-\\gamma_t^{DEN}(i)\\right) \\end{align}$$å…¶ä¸­ä¸€å€‹å¾ˆé‡è¦çš„å®šç¾©$$\\begin{align} \\gamma_t^{DEN}(r)=\\frac{\\sum_{w:s_t=r}p(o\\|s,\\theta)^K p(w)}{\\sum_w p(o\\|s^w,\\theta)^K p(w)} \\end{align}$$ç‰©ç†æ„ç¾©å°±æ˜¯æ™‚é–“$t$åœ¨ç‹€æ…‹$r$çš„æ©Ÿç‡! ç†è«–ä¸Šä¾†èªªæˆ‘å€‘è¦å–éæ‰€æœ‰å¯èƒ½çš„ word sequence $w$ ä¸¦æ±‚å’Œè¨ˆç®—, ä½†å¯¦éš›ä¸Šåªæœƒåœ¨ decoding æ™‚çš„ lattice ä¸Šè¨ˆç®—, ä»¥ç¯€çœæ™‚é–“. åˆ°ç›®å‰ç‚ºæ­¢æˆ‘å€‘ç®—å®Œäº† MMI æœ€å›°é›£çš„éƒ¨åˆ†äº†, å¾—åˆ° $e_t^L(i)$ å¾Œ (å¼(18))ï¼Œå‰©ä¸‹çš„å°±åªæ˜¯ follow ä¸Šåœ–çš„ MMI computational graph å»åš. æœ‰è®€è€…ä¾†ä¿¡è©¢å•å¼ (17) å¦‚ä½•æ¨å°è‡³ (18), éç¨‹å¦‚ä¸‹åœ–: (æŠ±æ­‰å·æ‡¶ä¸æ‰“ Latex äº†) çµè«–é‚„æœ‰ä¸€äº›å…¶ä»–è®Šç¨®å¦‚ boost MMI (bMMI)ã€MPEã€MCEç­‰ç­‰, å·®åˆ¥åªæ˜¯åœ¨æœ€å°åŒ–ä¸åŒçš„æ¨™è¨»ç²¾ç´°åº¦, æœ€é‡è¦çš„é‚„æ˜¯è¦å…ˆäº†è§£ MMI å°±å¯ä»¥å®¹æ˜“æ¨å»£äº†. é€™äº›éƒ½æœ‰ä¸€å€‹çµ±ä¸€çš„è¡¨é”æ³•å¦‚ä¸‹:$$\\begin{align} e_t^L(i)=K\\left(\\gamma_t^{DEN}(i)-\\gamma_t^{NUM}(i)\\right) \\end{align}$$æ³¨æ„åˆ°æ­£è² è™Ÿè·Ÿ (18) ç›¸å, å› ç‚ºåªæ˜¯ä¸€å€‹æœ€å¤§åŒ–æ”¹æˆæœ€å°åŒ–è¡¨ç¤ºè€Œå·². ä¸¦ä¸”å¤šäº†ä¸€å€‹åˆ†å­çš„ lattice è¨ˆç®—. Reference ä¿æ£Ÿã€é„§åŠ›: èªéŸ³è­˜åˆ¥å¯¦è¸ Ch8 Kaldi chain model","tags":[{"name":"Speech Recognition","slug":"Speech-Recognition","permalink":"https://bobondemon.github.io/tags/Speech-Recognition/"},{"name":"Maximum Mutual Information","slug":"Maximum-Mutual-Information","permalink":"https://bobondemon.github.io/tags/Maximum-Mutual-Information/"},{"name":"Computational Graph","slug":"Computational-Graph","permalink":"https://bobondemon.github.io/tags/Computational-Graph/"}]},{"title":"TF Notes (3), Computational Graph in Tensorflow","date":"2017-11-29T12:36:59.000Z","path":"2017/11/29/TF-Notes-Computational-Graph-in-Tensorflow/","text":"é€™ç¯‡ä»‹ç´¹ computational graph (è¨ˆç®—åœ–è­œ), ä¸»è¦ä¾†æºåƒè€ƒè‡ªæå®æ¯…æ•™æˆçš„èª²ç¨‹å…§å®¹. ä¸¦ä¸”æˆ‘å€‘ä½¿ç”¨ tensorflow çš„æ±‚å°å‡½æ•¸ tf.gradients ä¾†é©—è­‰ computational graph. æœ€å¾Œæˆ‘å€‘åœ¨ MNIST ä¸Šé©—è­‰æ•´å€‹ DNN/CNN çš„ backpropagation å¯ä»¥åˆ©ç”¨ computational graph çš„è¨ˆç®—æ–¹å¼è¨“ç·´. Computational Graphä¸»è¦å°±æˆªåœ–ææ•™æˆçš„æŠ•å½±ç‰‡, ä¸€å€‹ computational graph çš„ node å’Œ edge å¯ä»¥å®šç¾©å¦‚ä¸‹ å°æ–¼ chain rule çš„è©±, æˆ‘å€‘çš„è¨ˆç®—åœ–è­œå¯ä»¥é€™éº¼ç•« å…¶å¯¦å°±æ˜¯ chain rule ç”¨é€™æ¨£çš„åœ–å½¢è¡¨ç¤º. æ¯”è¼ƒè¦æ³¨æ„çš„å°±æ˜¯ case 2 çš„æƒ…æ³, ç”±æ–¼ $x$ and $y$ éƒ½æœƒè¢« $s$ å½±éŸ¿, å› æ­¤è¨ˆç®— gradients æ™‚è¦ç´¯åŠ å…©æ¢è·¯å¾‘. å†ä¾†å¦ä¸€é …è¦æ³¨æ„çš„æ˜¯å¦‚æœæœ‰ share variables æˆ‘å€‘çš„è¨ˆç®—åœ–è­œè©²æ€éº¼è¡¨ç¤ºå‘¢ ? èˆ‰ä¾‹ä¾†èªªå¦‚ä¸‹çš„å‡½å¼$y=x\\cdot e^{x^2}$ è¨ˆç®—åœ–è­œç•«å‡ºä¾†é•·é€™æ¨£ ç°¡å–®ä¾†èªªæŠŠç›¸åŒè®Šæ•¸çš„ nodes ä¸Šæ‰€æœ‰çš„è·¯å¾‘éƒ½ç›¸åŠ èµ·ä¾†. ä¸Šé¢çš„ç¯„ä¾‹å°±æ˜¯è¨ˆç®— $\\frac{\\partial y}{\\partial x}$ æ™‚, æœ‰ä¸‰æ¢è·¯å¾‘æ˜¯å¾ node $x$ å‡ºç™¼æœ€çµ‚æœƒå½±éŸ¿åˆ° node $y$ çš„, è®€è€…æ‡‰è©²å¯ä»¥å¾ˆå®¹æ˜“çœ‹å‡ºä¾†. å¦å¤–å¦‚æœåˆ†åˆ¥è¨ˆç®—é€™ä¸‰æ¢è·¯å¾‘, å…¶å¯¦å¾ˆå¤š edges çš„æ±‚å°çµæœæœƒé‡è¤‡, å› æ­¤å¾ $x$ å‡ºç™¼è¨ˆç®—åˆ° $y$ æœƒå¾ˆæ²’æœ‰æ•ˆç‡, æ‰€ä»¥åéä¾† (Reverse mode) å¾ root ($y$) å‡ºç™¼, åå‘æ‰¾å‡ºè¦æ±‚çš„ nodes ($x$) å°±å¯ä»¥é¿å…å¾ˆå¤šé‡è¤‡é‹ç®—. Verify with Tensorflowè€ƒæ…®ä»¥ä¸‹ç¯„ä¾‹, å…¶ä¸­ $&lt;,&gt;$ è¡¨ç¤ºå…§ç©, $a$, $b$, å’Œ $1$ éƒ½æ˜¯å±¬æ–¼ $R^3$ çš„å‘é‡. å®ƒçš„è¨ˆç®—åœ–è­œå¦‚ä¸‹: åœ¨ Tensorflow ä¸­, tf.gradients å¯ä»¥å¹«åŠ©è¨ˆç®— gradients. èˆ‰ä¾‹ä¾†èªªå¦‚æœæˆ‘å€‘è¦è¨ˆç®— $\\frac{\\partial e}{\\partial c}$, æˆ‘å€‘åªè¦é€™æ¨£å‘¼å«å³å¯ ge_c=tf.gradients(ys=e,xs=c). ç‚ºäº†æ–¹ä¾¿, æˆ‘å€‘å°‡ $\\frac{\\partial y}{\\partial x}$ åœ¨ç¨‹å¼è£¡å‘½åç‚º gy_x. ä¸‹é¢é€™æ®µ codes è¨ˆç®—å‡ºä¸Šåœ– 5 å€‹ edges çš„ gradients: 123456789101112131415161718import tensorflow as tfimport numpy as npa = tf.placeholder(tf.float32, shape=(1,3))b = tf.placeholder(tf.float32, shape=(1,3))c = a + bd = b + 1e = tf.matmul(c,d,transpose_b=True)ge_c, ge_d = tf.gradients(ys=e,xs=[c,d])gc_a, gc_b = tf.gradients(ys=c,xs=[a,b])gd_b = tf.gradients(ys=d,xs=b)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) gec, ged, gca, gcb, gdb = sess.run([ge_c, ge_d, gc_a, gc_b, gd_b],feed_dict=&#123;a:[[2,1,0]],b:[[1,2,3]]&#125;) print('ge_c=&#123;&#125;\\nge_d=&#123;&#125;\\ngc_a=&#123;&#125;\\ngc_b=&#123;&#125;\\ngd_b=&#123;&#125;'.format(gec, ged, gca, gcb, gdb)) è¨ˆç®—çµæœç‚º 12345ge_c=[[ 2. 3. 4.]]ge_d=[[ 3. 3. 3.]]gc_a=[[ 1. 1. 1.]]gc_b=[[ 1. 1. 1.]]gd_b=[array([[ 1., 1., 1.]], dtype=float32)] å¯ä»¥è‡ªå·±æ‰‹ç®—é©—è­‰ä¸€ä¸‹, çµæœç•¶ç„¶æ˜¯å°çš„ (ä½¿ç”¨ Jacobian matrix è¨ˆç®—) æ‰€ä»¥æˆ‘å€‘å¦‚æœè¦å¾—åˆ° $\\frac{\\partial e}{\\partial b}$, æˆ‘å€‘åªè¦ç®— ge_c*gc_b + ge_d*gd_b å°±å¯ä»¥äº†. ä¸éé€™æ¨£è‡ªå·±æŠŠç›¸åŒè·¯å¾‘åšç›¸ä¹˜ï¼Œä¸åŒè·¯å¾‘åšç›¸åŠ , å¤ªéº»ç…©äº†! å…¶å¯¦æœ‰æ›´å¥½çš„æ–¹æ³•. å°æ–¼åŒä¸€æ¢è·¯å¾‘åšç›¸ä¹˜, tf.gradients æœ‰ä¸€å€‹ arguments æ˜¯ grad_ys å°±å¯ä»¥å¾ˆå®¹æ˜“åšåˆ°. tf.gradients(ys=,xs=,grad_ys=) ä»¥ä¸‹åœ–ä¾†èªªæ˜ ä½†äº‹å¯¦ä¸Šæ ¹æœ¬ä¹Ÿä¸ç”¨é€™éº¼éº»ç…©, é™¤éæ˜¯é‡åˆ°å¾ˆç‰¹æ®Šçš„ç‹€æ³, å¦å‰‡æˆ‘å€‘ç›´æ¥å‘¼å« tf.gradients(c,a), tensorflow å°±æœƒç›´æ¥å¹«æˆ‘å€‘æŠŠåŒæ¨£è·¯å¾‘çš„ gradients åšç›¸ä¹˜, ä¸åŒè·¯å¾‘çš„ gradients çµæœåšç›¸åŠ äº†! æ‰€ä»¥ä¸Šé¢å°±ç›´æ¥å‘¼å« tf.gradients(c,a) å…¶å¯¦ä¹Ÿå°±ç­‰æ–¼ gb_a2 äº†. æœ€å¾Œå›åˆ°é–‹å§‹çš„ e=&lt;a+b,b+1&gt; çš„ç¯„ä¾‹, å¦‚æœè¦è¨ˆç®— $\\frac{\\partial e}{\\partial b}$, ç…§åŸæœ¬æä¾›çš„ codes éœ€è¦è¨ˆç®—ä¸‰æ¢è·¯å¾‘å„è‡ªç›¸ä¹˜å¾Œå†ç›¸åŠ , å…¶å¯¦åªè¦ç›´æ¥å‘¼å« ge_b=tf.gradients(e,b) å°±å®Œæˆé€™ä»¶äº‹äº† (ge_c*gc_b + ge_d*gd_b) MNIST ç”¨è¨ˆç®—åœ–è­œè¨ˆç®— back propagationDNN çš„è¨ˆç®—åœ–è­œç‚ºäº†æ¸…æ¥šäº†è§£ Neural network çš„ backpropagation å¦‚ä½•ç”¨ computational graph ä¾†è¨ˆç®— gradients ä¸¦é€²è€Œ update åƒæ•¸, æˆ‘å€‘ä¸ä½¿ç”¨ tf.optimizer å¹«æˆ‘å€‘è‡ªå‹•è¨ˆç®—. ä¸€å€‹ 3 layers fo MLP-DNN çš„è¨ˆç®—åœ–è­œæˆ‘å€‘å¯ä»¥é€™æ¨£è¡¨ç¤º: åœ–è£¡çš„åƒæ•¸ç›´æ¥å°æ‡‰äº†ç¨‹å¼ç¢¼è£¡çš„å‘½å, å› æ­¤å¯ä»¥å¾ˆæ–¹ä¾¿å°ç…§. å…¶ä¸­ tensorflow è£¡åƒæ•¸çš„åå­—è·Ÿæ•¸å­¸ä¸Šçš„å°æ‡‰å¦‚ä¸‹: $$\\begin{align} gll=\\frac{\\partial \\mbox{loss}}{\\partial \\mbox{logits}} \\\\ gly2=\\frac{\\partial \\mbox{logits}}{\\partial y2}gll \\\\ gy2y1=\\frac{\\partial y2}{\\partial y1}gly2 \\\\ gy1y0=\\frac{\\partial y1}{\\partial y0}gy2y1 \\\\ (glw3,glb3)=(\\frac{\\partial \\mbox{logits}}{\\partial w3}gll,\\frac{\\partial \\mbox{logits}}{\\partial b3}gll) \\\\ (gy2w2,gy2b2)=(\\frac{\\partial y2}{\\partial w2}gly2,\\frac{\\partial y2}{\\partial b2}gly2) \\\\ (gy1w1,gy1b1)=(\\frac{\\partial y1}{\\partial w1}gy2y1,\\frac{\\partial y1}{\\partial b1}gy2y1) \\\\ (gy0w0,gy0b0)=(\\frac{\\partial y0}{\\partial w0}gy1y0,\\frac{\\partial y0}{\\partial b0}gy1y0) \\end{align}$$ ç›¸å°æ‡‰çš„ tensorflow ä»£ç¢¼å¦‚ä¸‹:12345678910111213141516gll = tf.gradients(ys=loss,xs=logits)gly2 = tf.gradients(ys=logits,xs=y2,grad_ys=gll)gy2y1 = tf.gradients(ys=y2,xs=y1,grad_ys=gly2)gy1y0 = tf.gradients(ys=y1,xs=y0,grad_ys=gy2y1)glw3 = tf.gradients(ys=logits,xs=w3,grad_ys=gll)glb3 = tf.gradients(ys=logits,xs=b3,grad_ys=gll)gy2w2 = tf.gradients(ys=y2,xs=w2,grad_ys=gly2)gy2b2 = tf.gradients(ys=y2,xs=b2,grad_ys=gly2)gy1w1 = tf.gradients(ys=y1,xs=w1,grad_ys=gy2y1)gy1b1 = tf.gradients(ys=y1,xs=b1,grad_ys=gy2y1)gy0w0 = tf.gradients(ys=y0,xs=w0,grad_ys=gy1y0)gy0b0 = tf.gradients(ys=y0,xs=b0,grad_ys=gy1y0) ç”¨åœ–ä¾†è¡¨ç¤ºç‚º: Tensorflow ç¨‹å¼ç¢¼ç”¨ä¸Šé¢ä¸€æ®µçš„æ–¹å¼è¨ˆç®—å‡ºæ‰€éœ€åƒæ•¸çš„ gradients å¾Œ, update ä½¿ç”¨æœ€å–®ç´”çš„ steepest descent, é€™éƒ¨åˆ†ç¨‹å¼ç¢¼å¦‚ä¸‹ 12345678910111213update_w3 = tf.assign_add(w3,-rate*glw3[0])update_b3 = tf.assign_add(b3,-rate*glb3[0])update_w2 = tf.assign_add(w2,-rate*gy2w2[0])update_b2 = tf.assign_add(b2,-rate*gy2b2[0])update_w1 = tf.assign_add(w1,-rate*gy1w1[0])update_b1 = tf.assign_add(b1,-rate*gy1b1[0])update_w0 = tf.assign_add(w0,-rate*gy0w0[0])update_b0 = tf.assign_add(b0,-rate*gy0b0[0])training_operation = [update_w3, update_b3, update_w2, update_b2, update_w1, update_b1, update_w0, update_b0] å®Œæ•´ç¨‹å¼ç¢¼å¦‚ä¸‹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171import osimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.contrib.layers import flattenfrom tensorflow.examples.tutorials.mnist import input_datafrom sklearn.utils import shuffle\"\"\"Data Loading\"\"\"dataPath='../dataset/MNIST_data/'mnist = input_data.read_data_sets(dataPath, one_hot=True)# read the images and reformat the image shape from [img_num,img_height,img_width] to [img_num,img_height,img_width,1]img_width = 28img_height = 28images = mnist.train.imagesimg_num, _ = images.shapeimages = np.reshape(images,(img_num,img_height,img_width))images = images[...,np.newaxis]print('(Input to CNN) Images with shape &#123;&#125;'.format(images.shape))# read the labelslabels1Hot = mnist.train.labelsprint('(Input to CNN) labels1Hot.shape = &#123;&#125;'.format(labels1Hot.shape))labels = np.argmax(labels1Hot,axis=1)labels = labels[...,np.newaxis]print('labels.shape = &#123;&#125;'.format(labels.shape))n_classes = len(np.unique(labels))# load the validation setimages_valid = mnist.validation.imagesimg_num_valid = len(images_valid)images_valid = np.reshape(images_valid,(img_num_valid,img_height,img_width))images_valid = images_valid[...,np.newaxis]labels1Hot_valid = mnist.validation.labelsprint('Having %d number of validation images' % img_num_valid)# plotting sample imagesplt.figure(figsize=(15,5))for i in np.arange(2*7): random_idx = np.random.randint(0,img_num) plt.subplot(2,7,i+1) plt.imshow(images[random_idx][...,0],cmap='gray') plt.title(labels[random_idx][0])\"\"\"First define the hyper-parameters\"\"\"# Hyper-parametersEPOCHS = 30BATCH_SIZE = 512rate = 0.01depth_list = [512, 256, 128]cNum = 1\"\"\"Define the input output tensors\"\"\"# using one-hot decodingx = tf.placeholder(tf.float32, (None, img_height, img_width, cNum))one_hot_y = tf.placeholder(tf.int32, (None, n_classes))#one_hot_y = tf.one_hot(y, n_classes)\"\"\"Define the graph and construct it\"\"\"z0 = flatten(x)w0 = tf.get_variable('w0', shape=[img_width*img_height, depth_list[0]], initializer=tf.random_uniform_initializer(-0.1,0.1))b0 = tf.get_variable('b0', [depth_list[0]], initializer=tf.zeros_initializer)y0 = tf.nn.xw_plus_b(z0, w0, b0)z1 = tf.nn.relu(y0)w1 = tf.get_variable('w1', shape=[depth_list[0], depth_list[1]], initializer=tf.random_uniform_initializer(-0.1,0.1))b1 = tf.get_variable('b1', [depth_list[1]], initializer=tf.zeros_initializer)y1 = tf.nn.xw_plus_b(z1, w1, b1)z2 = tf.nn.relu(y1)w2 = tf.get_variable('w2', shape=[depth_list[1], depth_list[2]], initializer=tf.random_uniform_initializer(-0.1,0.1))b2 = tf.get_variable('b2', [depth_list[2]], initializer=tf.zeros_initializer)y2 = tf.nn.xw_plus_b(z2, w2, b2)z3 = tf.nn.relu(y2)w3 = tf.get_variable('w3', shape=[depth_list[2], n_classes], initializer=tf.random_uniform_initializer(-0.1,0.1))b3 = tf.get_variable('b3', [n_classes], initializer=tf.zeros_initializer)logits = tf.nn.xw_plus_b(z3, w3, b3)cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,logits=logits)loss = tf.reduce_mean(cross_entropy)\"\"\"Define gradients\"\"\"gll = tf.gradients(ys=loss,xs=logits)gly2 = tf.gradients(ys=logits,xs=y2,grad_ys=gll)gy2y1 = tf.gradients(ys=y2,xs=y1,grad_ys=gly2)gy1y0 = tf.gradients(ys=y1,xs=y0,grad_ys=gy2y1)glw3 = tf.gradients(ys=logits,xs=w3,grad_ys=gll)glb3 = tf.gradients(ys=logits,xs=b3,grad_ys=gll)gy2w2 = tf.gradients(ys=y2,xs=w2,grad_ys=gly2)gy2b2 = tf.gradients(ys=y2,xs=b2,grad_ys=gly2)gy1w1 = tf.gradients(ys=y1,xs=w1,grad_ys=gy2y1)gy1b1 = tf.gradients(ys=y1,xs=b1,grad_ys=gy2y1)gy0w0 = tf.gradients(ys=y0,xs=w0,grad_ys=gy1y0)gy0b0 = tf.gradients(ys=y0,xs=b0,grad_ys=gy1y0)update_w3 = tf.assign_add(w3,-rate*glw3[0])update_b3 = tf.assign_add(b3,-rate*glb3[0])update_w2 = tf.assign_add(w2,-rate*gy2w2[0])update_b2 = tf.assign_add(b2,-rate*gy2b2[0])update_w1 = tf.assign_add(w1,-rate*gy1w1[0])update_b1 = tf.assign_add(b1,-rate*gy1b1[0])update_w0 = tf.assign_add(w0,-rate*gy0w0[0])update_b0 = tf.assign_add(b0,-rate*gy0b0[0])training_operation = [update_w3, update_b3, update_w2, update_b2, update_w1, update_b1, update_w0, update_b0]\"\"\"Define accuracy evaluation\"\"\"# calculate the average accuracy by calling evaluate(X_data, y_data)correct_prediction = tf.equal(tf.argmax(logits, axis=1), tf.argmax(one_hot_y, axis=1))accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))def evaluate(X_data, y_data): num_examples = len(X_data) total_accuracy = 0 sess = tf.get_default_session() for offset in range(0, num_examples, BATCH_SIZE): batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE] accuracy = sess.run(accuracy_operation, feed_dict=&#123;x: batch_x, one_hot_y: batch_y&#125;) total_accuracy += (accuracy * len(batch_x)) return total_accuracy / num_examples \"\"\"Run Session\"\"\"### Train your model here.import timeif not os.path.isdir('./models'): os.makedirs('./models')#saver = tf.train.Saver()accumulate_time = 0.0with tf.Session() as sess: sess.run(tf.global_variables_initializer()) num_examples = img_num print(\"Training...\") print() train_accuracy = np.zeros(EPOCHS) validation_accuracy = np.zeros(EPOCHS) for i in range(EPOCHS): stime = time.time() acc_train_accuracy = 0 X_train, y_train = shuffle(images, labels1Hot) for offset in range(0, num_examples, BATCH_SIZE): end = offset + BATCH_SIZE batch_x, batch_y = X_train[offset:end], y_train[offset:end] sess.run(training_operation, feed_dict=&#123;x: batch_x, one_hot_y: batch_y&#125;) etime = time.time() accumulate_time += etime - stime validation_accuracy[i] = evaluate(images_valid, labels1Hot_valid) print(\"EPOCH &#123;&#125; ...\".format(i+1)) print(\"Validation Accuracy = &#123;:.3f&#125;\".format(validation_accuracy[i])) print() print('Cost time: ' + str(accumulate_time) + ' sec.') è¨“ç·´çµæœå¦‚ä¸‹: 1234567891011121314151617EPOCH 1 ...Validation Accuracy = 0.553EPOCH 2 ...Validation Accuracy = 0.698EPOCH 3 ...Validation Accuracy = 0.771... ç•¥EPOCH 28 ...Validation Accuracy = 0.936EPOCH 29 ...Validation Accuracy = 0.936EPOCH 30 ...Validation Accuracy = 0.936 é€™é€Ÿåº¦æœç„¶æ˜é¡¯æ¯”ç”¨ Adam æ…¢å¾ˆå¤š, ä½†è‡³å°‘èªªæ˜äº†æˆ‘å€‘çš„ç¢ºä½¿ç”¨ Computational graph çš„è¨ˆç®—æ–¹å¼å®Œæˆäº† back propagation! çµè«–Tensorflow ä½¿ç”¨è¨ˆç®—åœ–è­œçš„æ¡†æ¶ä¾†è¨ˆç®—å‡½æ•¸çš„ gradients, ä¸€æ—¦é€™æ¨£åš, ç¥ç¶“ç¶²è·¯çš„ backprop å¾ˆè‡ªç„¶äº†. äº‹å¯¦ä¸Š, æ‰€æœ‰æµè¡Œçš„æ¡†æ¶éƒ½é€™éº¼åš, å°±é€£ Kaldi åŸå…ˆåœ¨ nnet2 ä¸æ˜¯, ä½†åˆ° nnet3 ä¹Ÿæ”¹ç”¨è¨ˆç®—åœ–è­œä¾†å¯¦ä½œ. Reference æå®æ¯… Computational Graph tf.gradientsèªªæ˜ Colahâ€™s Blog","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://bobondemon.github.io/tags/TensorFlow/"},{"name":"Computational Graph","slug":"Computational-Graph","permalink":"https://bobondemon.github.io/tags/Computational-Graph/"}]},{"title":"Notes for KKT Conditions","date":"2017-11-14T13:36:40.000Z","path":"2017/11/14/Notes-for-KKT-Conditions/","text":"2011å¹´è‡ªå·±åšçš„ç­†è¨˜, æ”¾ä¸Šä¾†ä»¥å…æª”æ¡ˆä¸Ÿå¤±, ä¹Ÿæ–¹ä¾¿éš¨æ™‚åƒè€ƒ. åƒè€ƒè‡ª â€œNumerical Optimizationâ€ by Jorge Nocedal and Stephen J. Wright. ä½†æ˜¯æ‰“ç®—åªç”¨ Lagrange Multiplier Theorem ç†è§£ KKT. :) å°±åƒæ˜¯ä¸€èˆ¬å¾®ç©åˆ†è£¡å­¸åˆ°çš„ä¸€æ¨£, å°æ–¼ä¸€å€‹å‡½å¼ $f(x)$ è‹¥ $x^\\ast$ ç‚ºä¸€ minimal/maximum point, å‰‡å¿…è¦æ¢ä»¶ç‚º $fâ€™(x^\\ast)=0$. è€Œåœ¨ constraint optimization ç‰ˆæœ¬å¿…è¦æ¢ä»¶è®Šæˆ KKT conditions. èªªæ›´æ¸…æ¥šä¸€é»å°±æ˜¯, è‹¥ $x^\\ast$ ç‚ºä¸€ minimal/maximum point (+æ»¿è¶³æŸäº›ç¥ç§˜æ¢ä»¶) , å‰‡å¿…è¦æ¢ä»¶ç‚ºåœ¨ $x^\\ast$ æ»¿è¶³ KKT Conditions. ç¥ç§˜æ¢ä»¶ç¨±ç‚º Constraint Qualifications, å¸¸è¦‹çš„ç‚º LICQ, åœ¨ Convex opt è£¡ç‚º Slaterâ€™s condition. wiki KKT å…·é«”ä¾†èªªï¼Œæˆ‘å€‘è¦æ¢è¨çš„æ˜¯å°æ–¼ä»¥ä¸‹çš„å•é¡Œï¼Œå¦‚æœ $x^\\ast$ ç‚ºä¸€ minimal point ä¸”æ»¿è¶³å¼ (2) çš„æ¢ä»¶, å‰‡æœƒç™¼ç”Ÿä»€éº¼äº‹æƒ… (æˆ‘å€‘æ‰¾çš„æ˜¯å¿…è¦æ¢ä»¶) $$\\begin{align} \\min f(x) \\\\ \\mbox{subject to } \\begin{array}{rcl} c_i(x)=0,i \\in \\mathbf{E} \\\\ c_i(x)\\geq 0, i \\in \\mathbf{I} \\\\ \\end{array} \\end{align}$$ Descent Directionä¸€èˆ¬é€™æ¨£çš„å•é¡Œä¸æœƒæœ‰ closed form solution, å› æ­¤æœƒä½¿ç”¨æ•¸å€¼æœ€ä½³åŒ–çš„æ–¹å¼, æ‰¾å‡ºä¸€å€‹ sequence $(x_k)$ ä¾†é€¼è¿‘ $x^\\ast$. å•é¡Œæ˜¯å¦‚ä½•è®“é€™æ¨£çš„ sequence é€¼è¿‘ä¸€å€‹ (local) minimum? ä¸€å€‹å˜—è©¦æ˜¯è‡³å°‘å…ˆè®“æ‰¾åˆ°çš„æ¯ä¸€å€‹ $x_k$ éƒ½æ¯”å‰ä¸€æ­¥æ›´å¥½. æ›å¥è©±èªªå°±æ˜¯è¦ä¿è­‰æ‰¾åˆ°çš„ $x_k$ æ»¿è¶³$f(x_k)&lt;f(x_{k-1})$ æœ‰äº†é€™å€‹æƒ³æ³•, å†ä¾†å°±æ˜¯è©²æ€éº¼æ‰¾ä¸‹ä¸€å€‹é», æˆ–æ˜¯èªª, åŸºæ–¼ç¾åœ¨çš„é» $x_k$, è©²å¾€å“ªå€‹æ–¹å‘ $d$, èµ°å¤šé  $t$? ä¹Ÿå› æ­¤ï¼Œæˆ‘å€‘ä¹Ÿå°±è¡ç”Ÿäº†ä¸€å€‹å•é¡Œ, å¾€å“ªå€‹æ–¹å‘èµ°å‡½æ•¸å€¼æœƒä¿è­‰ä¸‹é™ (descent direction)? Descent direction ä¿è­‰äº†åœ¨è©²æ–¹å‘ä¸Šåªè¦ä¸è¦èµ°å¤ªå¤§æ­¥, ç›®æ¨™å‡½æ•¸å€¼ä¸€å®šæœƒä¸‹é™, åéä¾†èªª, å¦‚æœ $x^\\ast$ å·²ç¶“æ˜¯ (local) minimum äº†, åœ¨è©²é»ä¸Šä¸æ‡‰è©²å­˜åœ¨ descent direction. åŸºæ–¼ä¸Šè¿°çš„è¨è«–, æˆ‘å€‘æœ‰å¿…è¦äº†è§£æ¸…æ¥š descent direction. å®šç¾©å¦‚ä¸‹ [Def]:ä»¤ $f \\in C^1(\\mathbb{R}^n,\\mathbb{R})$, æˆ‘å€‘ç¨± $d$ ç‚º $x_0$ çš„ä¸€å€‹ descent direction å¦‚æœæ»¿è¶³: $\\exists t&gt;0$, such that $f(x_0+sd)&lt;f(x_0),\\forall s \\leq t$ å…¶å¯¦å¾ˆå®¹æ˜“è­‰å¾—: åªè¦è©²æ–¹å‘ $d$ è·Ÿ gradient $\\triangledown f(x_0)$ æ–¹å‘ç›¸å, å°±æœƒæ˜¯ $x_0$ çš„ä¸€å€‹ descent direction [Thm1]:ä»¤ $f \\in C^1(\\mathbb{R}^n,\\mathbb{R})$, å¦‚æœæ»¿è¶³ $\\triangledown f(x_0)^Td&lt;0$ å‰‡ $d$ å°±æœƒæ˜¯ $x_0$ çš„ä¸€å€‹ descent direction [Pf]: ç”±å¾®åˆ†çš„å®šç¾©å‡ºç™¼$$\\lim_{t\\rightarrow 0^+}\\frac{f(x_0+td)-f(x_0)-\\triangledown f(x_0)^Ttd}{\\parallel td \\parallel}=0 \\\\ \\Rightarrow \\lim_{t\\rightarrow 0^+}\\frac{f(x_0+td)-f(x_0)}{t \\parallel d \\parallel}=\\triangledown f(x_0)^T\\frac{d}{\\parallel d \\parallel} \\\\ \\Rightarrow \\lim_{t\\rightarrow 0^+}\\frac{f(x_0+td)-f(x_0)}{t}=\\triangledown f(x_0)^Td&lt;0 \\\\ \\Rightarrow \\exists t&gt;0,s.t.,f(x_0+sd)-f(x_0)&lt;0,for\\forall s \\leq t \\\\ \\Rightarrow \\exists t&gt;0,s.t.,f(x_0+sd)&lt;f(x_0),for\\forall s \\leq t$$ å¾ˆæ˜é¡¯ steepest descent $d=-\\triangledown f(x_0)$ æ˜¯ descent direction. å…¶å¯¦åªè¦æ»¿è¶³é€™ç¨®å½¢å¼ $d=-B\\triangledown f(x_0)$ ç•¶ $B$ æ˜¯æ­£å®šï¼Œå°±æœƒæ˜¯ descent direction. è€Œç•¶ B å®šç¾©ç‚º $\\triangledown ^2 f(x_0)$ (Hessian Matrix æ˜¯åŠæ­£å®š, é€šå¸¸æ˜¯ full rank å°±æœƒæ­£å®š), é€™ç¨®å½¢å¼å°±æ˜¯ç‰›é “æ³• $d=âˆ’\\triangledown ^2 f(x_0)\\triangledown f (x_0)$ ä¸éæˆ‘å€‘ä»Šå¤©è¦è™•ç†çš„æ˜¯ constrained opt, æœƒæœ‰ç­‰å¼æˆ–ä¸ç­‰å¼çš„æ¢ä»¶, å› æ­¤æˆ‘å€‘çš„æœå°‹ç©ºé–“åªèƒ½åœ¨æ»¿è¶³é€™äº›æ¢ä»¶ä¸‹å»æœå°‹, ç¨±è©²ç©ºé–“ç‚º feasible set = {x|xæ»¿è¶³æ‰€æœ‰(2)å¼çš„æ¢ä»¶}. å¯ä»¥æƒ³åƒ, åœ¨ feasible set çš„é™åˆ¶ä¸‹, èƒ½æœå°‹çš„ direction æœƒè¢«é™åˆ¶. å› æ­¤ â€œNumerical Optimizationâ€ é€™æœ¬æ›¸å°±å±•é–‹äº†ä¸€ç³»åˆ—çš„è¨è«–å’Œè­‰æ˜, å¯ä»¥å¾—åˆ°åœ¨é€™å€‹ feasible set ä¸‹, é€™äº› èƒ½æœå°‹çš„æ–¹å‘(æˆ‘å€‘ç¨±ç‚º limiting direction)æ‰€æ§‹æˆçš„é›†åˆ ç©¶ç«Ÿé•·ä»€éº¼æ¨£. ä¸”ç™¼ç”Ÿåœ¨æœ€ä½³è§£ä¸Šçš„ limiting directions éƒ½ä¸æœƒæ˜¯ descent direction (åˆç†, ä¸ç„¶å°±æ‰¾åˆ°æ›´ä½³çš„è§£äº†). æ­¤å¤–, çœ‹èª²æœ¬çš„è©±, æœƒç¹æ›´å¤§ä¸€åœˆæ‰æœƒçŸ¥é“ä»€éº¼æ˜¯ KKT Conditions (ä½†æ˜¯ç›¸ç•¶åš´è¬¹ä¸”è±å¯Œ). ç‚ºäº†æ¸…æ¥šäº†è§£ KKT, æˆ‘å€‘ç¹éèª²æœ¬çš„æ–¹æ³•, å®Œå…¨æ¡ç”¨å¾®ç©åˆ†å­¸éçš„ Lagrange Multiplier Theorem ä¾†èªªæ˜. äº†è§£ KKT Conditionsé™åˆ¶æ¢ä»¶ç‚ºç­‰å¼å…¶å¯¦ KKT çš„è¡¨é”å…¨éƒ¨åœç¹åœ¨ Lagrange Multiplier Theorem ä¸Š. ä¸€èˆ¬èª²æœ¬ä¸Šè¬›çš„éƒ½æ˜¯ç­‰å¼æ¢ä»¶, æˆ‘å€‘åˆ—å‡ºé«˜ç¶­èª²æœ¬è£é ­çš„å®šç†:ä¸æƒ³æ‰“ Latex äº† &gt;&lt;, è²¼åœ–å¥½äº† [Thm2]: Lagrange Multiplier Theorem è€ƒæ…®ä»¥ä¸‹å•é¡Œ $$\\min f(x) \\\\ \\mbox{subject to } \\begin{array}{rcl} c(x)=0 \\\\ \\end{array}$$ æˆ‘å€‘å¯ä»¥å¾—åˆ°, è‹¥ $x^\\ast$ ç‚ºä¸€å€‹ local minimum, ç”± Thm2 çŸ¥é“, æ»¿è¶³ $\\triangledown f(x^\\ast)=\\lambda\\triangledown c(x^\\ast)$, for some $\\lambda$æ­¤æ™‚çš„ $\\lambda$ æ­£è² éƒ½æœ‰å¯èƒ½, ä¹Ÿå°±èªªæ˜äº†å…©å€‹ gradients æ˜¯å¹³è¡Œçš„. ç”¨åœ–ä¾†èªªæ˜å¦‚ä¸‹: é™åˆ¶æ¢ä»¶ç‚ºä¸ç­‰å¼è€ƒæ…®ä»¥ä¸‹å•é¡Œ $$\\min f(x) \\\\ \\mbox{subject to } \\begin{array}{rcl} c(x)\\geq 0 \\\\ \\end{array}$$ ç•¶ $x^\\ast$ ç‚ºä¸€å€‹ local minimum æœƒç™¼ç”Ÿä»€éº¼äº‹? åˆ†æˆå…©ç¨®æƒ…æ³è¨è«–: $c(x^\\ast)=0$ $c(x^\\ast)&gt;0$ ç¬¬ä¸€ç¨®æƒ…æ³å°±é€€åŒ–æˆæ¢ä»¶ç‚ºç­‰å¼çš„æƒ…å½¢. å› æ­¤å­˜åœ¨ $\\lambda$ æ»¿è¶³ $\\triangledown f(x^\\ast)=\\lambda\\triangledown c(x^\\ast)$. å¦‚æœ $\\lambda&lt;0$, å°è‡´ $\\triangledown c(x^\\ast)$ è·Ÿ $\\triangledown f(x^\\ast)$ åæ–¹å‘çš„è©±, $\\triangledown c(x^\\ast)^T\\triangledown f(x^\\ast)&lt;0$ å°è‡´ $\\triangledown c(x^\\ast)$ è®Šæˆä¸€å€‹ desent direction.å‰‡è¡¨ç¤ºæˆ‘å€‘å¯ä»¥æ‰¾åˆ°ä¸€å€‹æ–¹å‘ä½¿å¾—ç›®æ¨™å‡½æ•¸å€¼ä¸‹é™ä¸”åŒæ™‚è®“æ¢ä»¶å‡½æ•¸å€¼ä¸Šå‡(å› æ­¤ä»ç„¶æ˜¯ feasible), é‚£éº¼èˆ‡ $x^\\ast$ æ˜¯ local minimum çŸ›ç›¾. å› æ­¤å¾—åˆ°çš„çµè«–æ˜¯ $\\triangledown c(x^\\ast)$ è·Ÿ $\\triangledown f(x^\\ast)$ åŒæ–¹å‘, i.e., $\\lambda\\geq 0$. åœ–ç¤ºå¦‚ä¸‹: ç¬¬äºŒç¨®æƒ…æ³æ˜¯é€€åŒ–æˆ unconstrained opt, å› ç‚º $x^\\ast$ æ˜¯åœ¨ feasible set å…§, æ›å¥è©±èªª $x^\\ast$ æ˜¯ feasible set çš„ interior point. æ—¢ç„¶æ˜¯ unconstrained opt, ä¸” $x^\\ast$ ç‚º local minimum, å‰‡è¡¨ç¤º $\\triangledown f(x^\\ast)=0$, æ‰€ä»¥ç•¶ç„¶ä¹Ÿå¯ä»¥å¯«æˆ $\\triangledown f(x^\\ast)=\\lambda\\triangledown c(x^\\ast)$ åªä¸éæ­¤æ™‚çš„ $\\lambda=0$ æ‰€ä»¥ä¸ç®¡æ˜¯ç¬¬ä¸€ç¨®æˆ–æ˜¯ç¬¬äºŒç¨®æƒ…å½¢, æˆ‘å€‘éƒ½å¯ä»¥å¯«æˆ å­˜åœ¨ $\\lambda\\geq 0$ æ»¿è¶³ $\\triangledown f(x^\\ast)=\\lambda\\triangledown c(x^\\ast)$ KKT Conditionsåˆ°é€™è£¡ç‚ºæ­¢, æˆ‘å€‘åŸºæœ¬ä¸Šå·²ç¶“å¯ä»¥åˆ—å‡º KKT äº†: [Thm3]: Karushâ€Kuhnâ€Tucker conditions[Pf]:Condition 1 åªæ˜¯èªªæ˜å…·æœ‰ Lagrange Multiplier çš„è¡¨é”æ–¹å¼: $\\triangledown f(x^\\ast)=\\sum_i{\\lambda_i\\triangledown c_i(x^\\ast)}$Condition 2,3 æ˜¯èªªæ˜ $x^\\ast$ æ˜¯ feasible point, é€™æ˜¯å»¢è©±Condition 4 èªªæ˜ è‹¥æ¢ä»¶ç‚ºä¸ç­‰å¼, ç›¸å°æ‡‰çš„ Lagrange Multipliers å¿…é ˆå¤§æ–¼ç­‰æ–¼0, æˆ‘å€‘åœ¨ä¸Šä¸€æ®µè¨è«–äº†Condition 5 ç¨±ç‚º complementarity slackness (æˆ‘çŸ¥é“å¾ˆé›£å¿µâ€¦), é€™éœ€è¦ç¨å¾®èªªæ˜ä¸€ä¸‹å¦‚æœ $c_i$ æ˜¯ç­‰å¼æ¢ä»¶, å‰‡ $c_i(x^\\ast)=0$, å› æ­¤æ»¿è¶³ Condition 5å¦‚æœ $c_i$ æ˜¯ä¸ç­‰å¼æ¢ä»¶, ä½†æ˜¯ $c_i(x^\\ast)=0$, åŒæ¨£ä¹Ÿæ»¿è¶³ Condition 5æœ€å¾Œä¸€ç¨®æƒ…æ³æ˜¯ $c_i$ æ˜¯ä¸ç­‰å¼æ¢ä»¶, ä¸” $c_i(x^\\ast)&gt;0$. é‚„è¨˜å¾—æˆ‘å€‘ä¸Šé¢é‡å°æ­¤ç¨®æƒ…å½¢çš„è¨è«–å—? æˆ‘å€‘æœƒä»¤ä»–çš„ $\\lambda_i=0$, æ‰€ä»¥é‚„æ˜¯æ»¿è¶³ Condition 5. é€™è£¡æ²’æœ‰æåˆ°ä¸€ä»¶äº‹æƒ…å°±æ˜¯ LICQ, å…¨å Linear Independent Constraint Qualification, å¯åƒè€ƒ wiki KKT. LICQ æ¢ä»¶ç‚º: å°æ–¼æŸä¸€é» feasible point x, æ‰€æœ‰ç­‰å¼æ¢ä»¶ (åŒ…å«é‚£äº›ä¸ç­‰å¼æ¢ä»¶ä½†å‰›å¥½åœ¨ x è®Šæˆç­‰å¼) åœ¨ x é€™é»çš„ gradients éƒ½æ˜¯ç·šæ€§ç¨ç«‹. é€™å€‹æ¢ä»¶æ­£å¥½å¯ä»¥å¾ [Thm2]: Lagrange Multiplier Theorem è£¡é¢çœ‹å‡ºä¾†, Thm2 èªªæ˜å¦‚æœç­‰å¼æ¢ä»¶çš„ gradients éƒ½ç·šæ€§ç¨ç«‹, å¯ä»¥æŠŠ $\\mu=1$, å› æ­¤å¯ä»¥å¯«æˆ Condition 1: $\\triangledown f(x^\\ast)=\\sum_i{\\lambda_i\\triangledown c_i(x^\\ast)}$, ä¹Ÿå› æ­¤å¯ä»¥æ»¿è¶³ KKT. èª²æœ¬è£¡çš„è­‰æ³•èª²æœ¬è£¡çš„è­‰æ˜å¯¦åœ¨é —è¿‚è¿´, ä½†æ˜¯æä¾›äº†å¾ˆè±å¯Œå’Œæ·±åˆ»çš„ç†è§£. é€™è£¡é‚„æ˜¯åŠªåŠ›è¨˜éŒ„ä¸‹ä¾†å§! {æ•¸å­¸å¤š, è¬¹æ…æœç”¨} æˆ‘å€‘åˆ†æˆ5å€‹æ­¥é©Ÿä¾†è¨è«–: Limiting directions Limiting direction èˆ‡ Local minimum çš„é—œè¯ Limiting directions çš„é›†åˆ, å°±ç¨±ç‚º F å§ LICQ æˆç«‹æ™‚, â€œLimiting directions éƒ½ä¸æ˜¯ descent directionâ€ èˆ‡ â€œLagrange Multipliersâ€ çš„ç­‰åƒ¹é—œä¿‚ ä¸²èµ·ä¾†è®Šæˆ KKT 1. Limiting directionsç›´è§€ä¾†èªª, å°æ–¼æŸä¸€é» $x_0$ (ç•¶ç„¶å±¬æ–¼ feasible set) ç”¨åœ¨ feasible set ä¸­çš„æŸæ¢è·¯å¾‘å»é€¼è¿‘å®ƒ, è€Œé€¼è¿‘çš„æœ€å¾Œæ–¹å‘å°±æ˜¯ limiting direction. å¦å¤–, ä¸€å€‹ sequence ${z_k}$ éƒ½å±¬æ–¼ feasible set , éƒ½ä¸ç­‰æ–¼ $x_0$, ä¸”æœ€å¾Œé€¼è¿‘ $x_0$, æˆ‘å€‘ç¨±ç‚º feasible sequence. [Def]:è‹¥æ»¿è¶³ä»¥ä¸‹æ¢ä»¶ç¨± $d$ æ˜¯ $x_0$ çš„ limiting direction. (ç•¶ç„¶ $x_0$ æ˜¯ feasible point)å­˜åœ¨ä¸€å€‹ feasible sequence $(z_k)_k$ ä½¿å¾—è©² sequence æœ‰ä¸€å€‹ subsequence$$\\exists (z_{k_j})_j \\mbox{ such that } d = \\lim\\frac{(z_{k_j}-x_0)}{\\parallel z_{k_j}-x_0\\parallel}$$ å¾å®šç¾©ä¸Šæˆ‘å€‘å¯ä»¥çŸ¥é“ limiting direction é•·åº¦ç‚º 1, å› ç‚ºæˆ‘å€‘åªåœ¨ä¹æ–¹å‘. å¦å¤–è¦ç‰¹åˆ¥èªªå­˜åœ¨ä¸€å€‹ subsequence æ˜¯å› ç‚º feasible sequence ä¸æœƒåªæœ‰ä¸€å€‹ limiting direction. ä¾‹å­å¦‚ä¸‹: 2. Limiting direction èˆ‡ Local minimum çš„é—œè¯æ–‡ç« é–‹é ­æœ‰èªªæ˜, â€œå¦‚æœ $x^\\ast$ å·²ç¶“æ˜¯ (local) minimum äº†, åœ¨è©²é»ä¸Šä¸æ‡‰è©²å­˜åœ¨ descent direction.â€ å°æ–¼ constrained opt çš„ç‰ˆæœ¬ç›¸ç•¶æ–¼ â€œå¦‚æœ $x^\\ast$ å·²ç¶“æ˜¯ (local) minimum äº†, å®ƒçš„ limiting directions éƒ½ä¸èƒ½æ˜¯ descent direction.â€ ç”¨æ•¸å­¸å¯«å‡ºä¾†å¦‚ä¸‹: [Thm4]:å·²çŸ¥ $x^\\ast$ æ˜¯ä¸€å€‹ local minimum, å‰‡å®ƒæ‰€æœ‰çš„ limiting direction $d$ éƒ½æ»¿è¶³ $\\triangledown f(x^\\ast)^Td \\geq 0$ ç›´è§€ä¸Šå¦‚æœä¸æ»¿è¶³, æˆ‘å€‘å°±å¯ä»¥æ‰¾åˆ°ä¸€å€‹ feasible sequence å¾è€Œå¾—åˆ°è©² limiting direction æœƒæ˜¯ä¸€å€‹ descent direction, å› æ­¤èˆ‡ $x^\\ast$ æ˜¯ local minium çŸ›ç›¾.æˆ‘å€‘åœ¨ç­‰ä¸‹çš„ç¬¬4å€‹æ­¥é©Ÿå¯ä»¥çœ‹åˆ°æ­¤æ¢ä»¶ â€œæ‰€æœ‰çš„ limiting direction $d$ éƒ½æ»¿è¶³ $\\triangledown f(x^\\ast)^Td \\geq 0$â€ ç­‰åƒ¹æ–¼ KKT Conditions çš„è¡¨é”æ–¹å¼. å› æ­¤ Thm4 å¯ä»¥é‡å¯«æˆ â€œå·²çŸ¥ $x^\\ast$ æ˜¯ä¸€å€‹ local minimum, å‰‡æ»¿è¶³ KKT Conditionsâ€, åœ¨æœ€å¾Œç¬¬5æ­¥æœƒä¸²èµ·ä¾†. 3. Limiting directions çš„é›†åˆ (F) [Def]: Active Setå°æ–¼æŸä¸€ feasible point $x_0$, å®ƒçš„ active set $\\mathbf{A}(x_0)$ å®šç¾©ç‚º$\\mathbf{A}(x_0) = \\mathbf{E} \\cup \\{i \\in \\mathbf{I} | c_i(x_0)=0 \\}$ [Def]: LICQå¦‚æœä»¥ä¸‹é›†åˆç‚ºç·šæ€§ç¨ç«‹é›†, å‰‡ç¨± LICQ åœ¨ $x_0$ æˆç«‹$\\{\\triangledown c_i(x_0), i \\in \\mathbf{A}(x_0) \\}$ å…¶å¯¦æˆ‘å€‘åœ¨ä¸Šé¢çš„è¨è«–éƒ½æœ‰ä½¿ç”¨é€™å…©å€‹å®šç¾©, é€™è£¡åªä¸éç”¨æ•¸å­¸è¡¨ç¤ºæ–¹ä¾¿ç­‰ä¸‹çš„è¨è«–.æŸä¸€é»å®ƒçš„æ‰€æœ‰ limiting direction çš„é›†åˆ ($F$) å¦‚ä¸‹: [Thm5]:å°æ–¼æŸä¸€ feasible point $x_0$,$$F=\\left\\{ \\begin{array}{c|r} d &amp; \\begin{array}{rcl} d^T\\triangledown c_i(x_0)=0,i \\in \\mathbf{E} \\\\ d^T\\triangledown c_i(x_0) \\geq 0, i \\in \\mathbf{A}(x_0) \\cap \\mathbf{I} \\\\ \\parallel d \\parallel = 1\\\\ \\end{array} \\end{array} \\right\\}$$ ç‚ºäº†ä¸æ¨¡ç³Šç„¦é», è­‰æ˜å°±è·³é, æƒ³çœ‹çš„ç«¥é‹é–€å°±æŸ¥ä¸€ä¸‹èˆŠçš„ç­†è¨˜ å¦å¤–, å®šç¾© $F_1=\\alpha F$, for $\\alpha\\geq 0$ (æ‰€ä»¥æ˜¯ convex cone). å› æ­¤ $F1$ åªä¸éæ˜¯æŠŠ $\\parallel d \\parallel =1$ çš„æ¢ä»¶å»èª¿. 4. LICQ æˆç«‹æ™‚, é—œéµçš„ç­‰åƒ¹é—œä¿‚æˆ‘å€‘ä»¥ä¸‹éƒ½å‡è¨­ LICQ æˆç«‹, é€™éº¼åšå°±å¯ä»¥å¾ˆæ–¹ä¾¿åœ°è®“ limiting direction çš„é›†åˆç”¨ $F1$ ä¾†è¡¨ç¤º. é‚„è¨˜å¾—åœ¨ â€œ2. Limiting direction èˆ‡ Local minimum çš„é—œè¯â€ æœ‰æåˆ°æˆ‘å€‘å¸Œæœ›æ‰¾åˆ°æŸä¸€ feasible point $x_0$ çš„ $F1$ éƒ½ä¸æ˜¯ descent direction, å› æ­¤è©²é»å°±å¾ˆæœ‰å¯èƒ½æ˜¯æˆ‘è¦æ‰¾çš„ local optimum. è€Œé€™ä¸€å€‹æ¢ä»¶ â€œæŸä¸€ feasible point $x_0$ çš„ $F1$ éƒ½ä¸æ˜¯ descent directionâ€ å…¶å¯¦èˆ‡ Lagrange Multipliers æ¯æ¯ç›¸é—œ, ä¹Ÿå› æ­¤è·Ÿ KKT conditions æœƒç”¢ç”Ÿé€£çµ. ä¸‹é¢å®šç†å¯ä»¥è­‰æ˜é€™å€‹æ¢ä»¶å¯ä»¥ç­‰åƒ¹æ–¼ KKT condition çš„è¡¨é”æ–¹å¼. [Thm6]:å°æ–¼æŸä¸€ feasible point $x_0$, Let $\\mathbf{A}(x_0)=(1â€¦m)$, $\\mathbf{A}^T=[\\triangledown c_1(x_0)â€¦\\triangledown c_m(x_0)]$ å‰‡$$\\triangledown f(x-0)^Td\\geq 0,\\forall d \\in F1 \\Leftrightarrow\\\\ \\exists \\lambda \\in \\mathbb{R}^m \\mbox{ where } \\lambda_i \\geq 0 \\forall i \\in \\mathbf{A}(x_0) \\cap \\mathbf{I} \\mbox{, such that } \\triangledown f(x_0)=\\sum_{i=1}^m \\lambda_i \\triangledown c_i(x_0)=\\mathbf{A}^T$$ åŒæ¨£è·³é, è­‰æ˜å¯æŸ¥çœ‹èˆŠçš„ç­†è¨˜ æˆ‘å€‘å¯ä»¥ä»”ç´°å°ç…§ä¸€ä¸‹ä¸Šé¢çš„ Lagrange Multiplier é‚£å€‹æ¢ä»¶, å…¶å¯¦å®ƒè·Ÿ â€œ[Thm3]: Karushâ€Kuhnâ€Tucker conditionsâ€ æ˜¯ä¸€æ¨£çš„, åªå·®åœ¨ä¸€å€‹åœ°æ–¹å°±æ˜¯ complementarity slackness æ²’æœ‰æ˜ç¢ºå¯«å‡ºä¾†, ä½†æˆ‘å€‘çŸ¥é“ä¸€å®šå­˜åœ¨ $\\lambda$ å¯ä»¥æ»¿è¶³. å› æ­¤é€™å€‹ Lagrange Multiplier çš„æ¢ä»¶ä¹Ÿå°±æ˜¯ KKT çš„è¡¨é”æ–¹å¼. 5. ä¸²èµ·ä¾†è®Šæˆ KKTè…¦è¢‹å·®ä¸å¤šéƒ½æ‰“çµäº†, ç›®å‰ç‚ºæ­¢åˆ°åº•å¾—åˆ°äº†ä»€éº¼é—œä¿‚? æˆ‘å€‘ä¾†æ•´ç†ä¸€ä¸‹ Thm4 å‘Šè¨´æˆ‘å€‘ä¸€å€‹æœ€ä½³è§£ä¸€å®šæœƒä½¿å¾—å®ƒçš„ limiting directions éƒ½ä¸æ˜¯ descent direction.Thm5 å‘Šè¨´æˆ‘å€‘ limiting directions çš„é›†åˆå…¶å¯¦å°±æ˜¯ $F1$ (or $F$).Thm6 å‘Šè¨´æˆ‘å€‘å°æ–¼ä»»ä¸€å€‹ $F1$ çš„ direction, éƒ½ä¸æ˜¯ descent direction, ç­‰åŒæ–¼æ»¿è¶³ KKT çš„è¡¨é”æ–¹å¼. å°‡ Thm4,5,6 ä¸²èµ·ä¾†è®Šæˆ: ä¸€å€‹æœ€ä½³è§£æ»¿è¶³ KKT çš„è¡¨é”æ–¹å¼. (ç•¶ç„¶å‰ææ˜¯æœ‰æ»¿è¶³ LICQ) æ‰“é€™ç¯‡ç´¯åˆ°ä¸æƒ³æœ‰çµè«–çš„çµè«–ä¸æƒ³æœ‰çµè«–äº†, ä¹¾è„†ä¾†ç¢ç¢å¿µå§. æœ€ä½³åŒ–æ˜¯æˆ‘å”¸æ›¸æœŸé–“å¾ˆæ„›çš„ä¸€é–€ç§‘ç›®, ç•¶æ™‚æ„ˆæ˜¯å”¸å®ƒ, æ„ˆæ˜¯ä¸æ‡‚. ä»¥å‰ä¹Ÿå¾ˆæ„›çœ‹ Stephen P. Boyd çš„ convex opt èª²ç¨‹, ä½†ç¾åœ¨è…¦è¢‹è£¡ä¼¼ä¹åªå‰©æ•™æˆåå­—å’Œèª²ç¨‹åå­—äº†. å–”å°äº†, æˆ‘é‚„è¨˜å¾—ä¸€ä»¶äº‹æƒ…, å°±æ˜¯åœ¨ convex å•é¡Œæ™‚, KKT condition æœƒè®Šæˆ å……è¦æ¢ä»¶. è‡³æ–¼ç´°ç¯€, æ©â€¦ [å¾…è£œå……]: æˆ‘æœ‰æ‰¾åˆ°ç•¶æ™‚çš„ç­†è¨˜é—œæ–¼ convex å•é¡Œä¸‹çš„ KKT conditions, ä»¥åŠå®ƒçš„ dual problem è¨è«–. åªèƒ½èªª: 1. å­¸ç”Ÿå¯ä»¥å¾ˆè‡ªç”±æŒæ§è‡ªå·±çš„æ™‚é–“, å·¥ä½œå¾Œçš„æ™‚é–“éƒ½æ˜¯é›¶ç¢çš„é˜¿! æ ¹æœ¬æ²’æ³•é•·æ™‚é–“æ­»å—‘æŸä¸€æ¨£å­¸ç§‘! 2. ç•¶ç¢¼è¾²å·¥ç¨‹å¸«æ•¸å­¸çœŸçš„æœƒé€€æ­¥, ç¢¼è¾²å‹ç¢¼è¾²çš„å¥½, ä½†å¸Œæœ›è‡ªå·±ä¹Ÿåˆ¥å¿˜è¨˜é‡è¦çš„æ•¸å­¸è§€å¿µäº†. Reference Numerical Optimization 2nd edition, Jorge Nocedal ç­†è¨˜ for the proof of Thm5,6","tags":[{"name":"Nonlinear Constraint Optimization","slug":"Nonlinear-Constraint-Optimization","permalink":"https://bobondemon.github.io/tags/Nonlinear-Constraint-Optimization/"},{"name":"KKT","slug":"KKT","permalink":"https://bobondemon.github.io/tags/KKT/"}]},{"title":"TF Notes (2), Speedup and Benchmark with Two GPU Cards","date":"2017-11-01T12:28:49.000Z","path":"2017/11/01/TF-Notes-Speedup-and-Benchmark-with-Two-GPU-Cards/","text":"é€™ç¯‡æ–‡ç« å¯¦ä½œäº†å®˜ç¶²çš„ åŒæ­¥å¼ data Parallelism æ–¹æ³• refï¼Œä¸¦ä¸”èˆ‡åŸæœ¬åªç”¨ä¸€å¼µGPUåšå€‹æ¯”è¼ƒã€‚å¯¦é©—åªä½¿ç”¨å…©å¼µå¡ï¼Œå¤šå¼µå¡æ–¹æ³•ä¸€æ¨£ã€‚ä¸»è¦æ¶æ§‹å¦‚ä¸‹åœ– by TF å®˜ç¶²: å…©å¼µå¡ç­‰æ–¼æ˜¯æŠŠä¸€æ¬¡è¦è¨ˆç®—çš„ mini-batch æ‹†æˆå…©åŠçµ¦å…©å€‹ (ç›¸åŒçš„) models å»ä¸¦è¡Œè¨ˆç®— gradientsï¼Œç„¶å¾Œå†äº¤ç”± cpu çµ±ä¸€æ›´æ–° modelã€‚è©³ç´°è«‹è‡ªè¡Œåƒè€ƒå®˜ç¶²ã€‚ä¸‹é¢ç›´æ¥ç§€ Codes å’Œçµæœã€‚ Machine Spec.GPU å¡ç‚º Tesla K40c CPU ç‚º Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz å–® GPU è·‘ MNISTç›´æ¥ä¸Š Codes 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201import gzipimport osimport tempfileimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.contrib.layers import flattenfrom tensorflow.examples.tutorials.mnist import input_datafrom sklearn.utils import shuffle\"\"\"Data Loading\"\"\"dataPath='../dataset/MNIST_data/'mnist = input_data.read_data_sets(dataPath, one_hot=True)# read the images and reformat the image shape from [img_num,img_height,img_width] to [img_num,img_height,img_width,1]img_width = 28img_height = 28images = mnist.train.imagesimg_num, _ = images.shapeimages = np.reshape(images,(img_num,img_height,img_width))images = images[...,np.newaxis]print('(Input to CNN) Images with shape &#123;&#125;'.format(images.shape))# read the labelslabels1Hot = mnist.train.labelsprint('(Input to CNN) labels1Hot.shape = &#123;&#125;'.format(labels1Hot.shape))labels = np.argmax(labels1Hot,axis=1)labels = labels[...,np.newaxis]print('labels.shape = &#123;&#125;'.format(labels.shape))n_classes = len(np.unique(labels))# load the validation setimages_valid = mnist.validation.imagesimg_num_valid = len(images_valid)images_valid = np.reshape(images_valid,(img_num_valid,img_height,img_width))images_valid = images_valid[...,np.newaxis]labels1Hot_valid = mnist.validation.labelsprint('Having %d number of validation images' % img_num_valid)# plotting sample imagesplt.figure(figsize=(15,5))for i in np.arange(2*7): random_idx = np.random.randint(0,img_num) plt.subplot(2,7,i+1) plt.imshow(images[random_idx][...,0],cmap='gray') plt.title(labels[random_idx][0])\"\"\"First define the hyper-parameters\"\"\"# Hyper-parametersEPOCHS = 30BATCH_SIZE = 512rate = 0.001drop_out_keep_prob = 0.5ksize = 5cnn_depth_list = [16, 32]mlp_depth_list = [256, 128]cNum = 1\"\"\"Define the input output tensors\"\"\"# using one-hot decodingx = tf.placeholder(tf.float32, (None, img_height, img_width, cNum))one_hot_y = tf.placeholder(tf.int32, (None, n_classes))#one_hot_y = tf.one_hot(y, n_classes)keep_prob = tf.placeholder(tf.float32) # probability to keep units\"\"\"Define the graph and construct it\"\"\"class MNISTCNN: def __init__(self, ksize, cnn_depth_list, mlp_depth_list, img_height, img_width, cNum, n_classes): self._ksize = ksize self._cnn_depth_list = cnn_depth_list self._mlp_depth_list = mlp_depth_list self._img_height = img_height self._img_width = img_width self._cNum = cNum self._n_classes = n_classes self._mu = 0 self._sigma = 0.1 def create(self,x,keep_prob): conv = self._conv(x, self._cNum, self._ksize, self._cnn_depth_list[0], 'conv1') # Pooling. Input = 24x24xlayer_depth['layer_1']. Output = 12x12xlayer_depth['layer_1']. conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') for lidx in range(1,len(self._cnn_depth_list)): conv = self._conv(conv, self._cnn_depth_list[lidx-1], self._ksize, self._cnn_depth_list[lidx], 'conv&#123;&#125;'.format(lidx+1)) conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') fc = flatten(conv) bsize, fc_in_dim = fc.shape fc = self._fc(fc,fc_in_dim,self._mlp_depth_list[0],'fc1') fc = tf.nn.dropout(fc, keep_prob) # dropout for lidx in range(1,len(self._mlp_depth_list)): fc = self._fc(fc,self._mlp_depth_list[lidx-1],self._mlp_depth_list[lidx],'fc&#123;&#125;'.format(lidx+1)) fc = tf.nn.dropout(fc, keep_prob) # dropout with tf.variable_scope('logits') as scope: logits_w = tf.get_variable('logits_w', shape=[self._mlp_depth_list[-1],self._n_classes],\\ initializer=tf.random_uniform_initializer(-0.1,0.1)) logits_b = tf.get_variable('logits_b', shape=[self._n_classes],\\ initializer=tf.zeros_initializer) logits = tf.nn.xw_plus_b(fc, logits_w, logits_b, name=scope.name) print(logits.shape) return logits def _conv(self, x, in_depth, ksize, out_depth, scope_name, relu=True): bsize,h,w,cNum = x.shape assert(h-(ksize-1)&gt;=1) assert(w-(ksize-1)&gt;=1) with tf.variable_scope(scope_name) as scope: # Create tf variables for the weights and biases weights = tf.get_variable('weights', shape=(ksize, ksize, in_depth, out_depth),\\ initializer=tf.random_normal_initializer(self._mu,self._sigma)) biases = tf.get_variable('biases', shape=(out_depth),initializer=tf.zeros_initializer) out = tf.nn.conv2d(x, weights, strides=[1, 1, 1, 1], padding='VALID',name=scope.name) + biases if relu: # Apply ReLu non linearity relu = tf.nn.relu(out) return relu else: return out def _fc(self, x, num_in, num_out, scope_name, relu=True): \"\"\"Create a fully connected layer.\"\"\" with tf.variable_scope(scope_name) as scope: # Create tf variables for the weights and biases weights = tf.get_variable('weights', shape=[num_in, num_out],\\ initializer=tf.random_uniform_initializer(-0.1,0.1)) biases = tf.get_variable('biases', [num_out],\\ initializer=tf.zeros_initializer) # Matrix multiply weights and inputs and add bias out = tf.nn.xw_plus_b(x, weights, biases, name=scope.name) if relu: # Apply ReLu non linearity relu = tf.nn.relu(out) return relu else: return out mnistCNN = MNISTCNN(ksize, cnn_depth_list, mlp_depth_list, img_height, img_width, cNum, n_classes)logits = mnistCNN.create(x,keep_prob)\"\"\"Define loss and optimizer\"\"\"cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,logits=logits)loss_operation = tf.reduce_mean(cross_entropy)optimizer = tf.train.AdamOptimizer(learning_rate = rate)training_operation = optimizer.minimize(loss_operation)# Define accuracy evaluation# calculate the average accuracy by calling evaluate(X_data, y_data)correct_prediction = tf.equal(tf.argmax(logits, axis=1), tf.argmax(one_hot_y, axis=1))accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))def evaluate(X_data, y_data): num_examples = len(X_data) total_accuracy = 0 sess = tf.get_default_session() for offset in range(0, num_examples, BATCH_SIZE): batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE] accuracy = sess.run(accuracy_operation, feed_dict=&#123;x: batch_x, one_hot_y: batch_y, keep_prob: 1.0&#125;) total_accuracy += (accuracy * len(batch_x)) return total_accuracy / num_examples \"\"\"Run Session\"\"\"### Train your model here.import timeif not os.path.isdir('./models'): os.makedirs('./models')#saver = tf.train.Saver()accumulate_time = 0.0with tf.Session() as sess: sess.run(tf.global_variables_initializer()) num_examples = img_num print(\"Training...\") print() train_accuracy = np.zeros(EPOCHS) validation_accuracy = np.zeros(EPOCHS) for i in range(EPOCHS): stime = time.time() acc_train_accuracy = 0 X_train, y_train = shuffle(images, labels1Hot) for offset in range(0, num_examples, BATCH_SIZE): end = offset + BATCH_SIZE batch_x, batch_y = X_train[offset:end], y_train[offset:end] sess.run(training_operation, feed_dict=&#123;x: batch_x, one_hot_y: batch_y, keep_prob: drop_out_keep_prob&#125;) etime = time.time() accumulate_time += etime - stime validation_accuracy[i] = evaluate(images_valid, labels1Hot_valid) print(\"EPOCH &#123;&#125; ...\".format(i+1)) print(\"Validation Accuracy = &#123;:.3f&#125;\".format(validation_accuracy[i])) print() print('Cost time: ' + str(accumulate_time) + ' sec.') åŒæ­¥å¼ data Parallelism åœ¨å…©å¼µ GPU è·‘ MNISTä¸€æ¨£ç›´æ¥ä¸Š Codes 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287import gzipimport osimport tempfileimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.contrib.layers import flattenfrom tensorflow.examples.tutorials.mnist import input_datafrom sklearn.utils import shuffle\"\"\"Data Loading\"\"\"dataPath='../dataset/MNIST_data/'mnist = input_data.read_data_sets(dataPath, one_hot=True)# read the images and reformat the image shape from [img_num,img_height,img_width] to [img_num,img_height,img_width,1]img_width = 28img_height = 28images = mnist.train.imagesimg_num, _ = images.shapeimages = np.reshape(images,(img_num,img_height,img_width))images = images[...,np.newaxis]print('(Input to CNN) Images with shape &#123;&#125;'.format(images.shape))# read the labelslabels1Hot = mnist.train.labelsprint('(Input to CNN) labels1Hot.shape = &#123;&#125;'.format(labels1Hot.shape))labels = np.argmax(labels1Hot,axis=1)labels = labels[...,np.newaxis]print('labels.shape = &#123;&#125;'.format(labels.shape))n_classes = len(np.unique(labels))# read the labelslabels1Hot = mnist.train.labelsprint('(Input to CNN) labels1Hot.shape = &#123;&#125;'.format(labels1Hot.shape))labels = np.argmax(labels1Hot,axis=1)labels = labels[...,np.newaxis]print('labels.shape = &#123;&#125;'.format(labels.shape))n_classes = len(np.unique(labels))# load the validation setimages_valid = mnist.validation.imagesimg_num_valid = len(images_valid)images_valid = np.reshape(images_valid,(img_num_valid,img_height,img_width))images_valid = images_valid[...,np.newaxis]labels1Hot_valid = mnist.validation.labelsprint('Having %d number of validation images' % img_num_valid)plt.figure(figsize=(15,5))for i in np.arange(2*7): random_idx = np.random.randint(0,img_num) plt.subplot(2,7,i+1) plt.imshow(images[random_idx][...,0],cmap='gray') plt.title(labels[random_idx][0])\"\"\"First define the hyper-parameters\"\"\"# Hyper-parametersEPOCHS = 30BATCH_SIZE = 512rate = 0.001drop_out_keep_prob = 0.5ksize = 5cnn_depth_list = [16, 32]mlp_depth_list = [256, 128]cNum = 1\"\"\"Define the graph and construct it\"\"\"class MNISTCNN: def __init__(self, ksize, cnn_depth_list, mlp_depth_list, img_height, img_width, cNum, n_classes): self._ksize = ksize self._cnn_depth_list = cnn_depth_list self._mlp_depth_list = mlp_depth_list self._img_height = img_height self._img_width = img_width self._cNum = cNum self._n_classes = n_classes self._mu = 0 self._sigma = 0.1 def create(self,x,keep_prob): conv = self._conv(x, self._cNum, self._ksize, self._cnn_depth_list[0], 'conv1') # Pooling. Input = 24x24xlayer_depth['layer_1']. Output = 12x12xlayer_depth['layer_1']. conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') for lidx in range(1,len(self._cnn_depth_list)): conv = self._conv(conv, self._cnn_depth_list[lidx-1], self._ksize, self._cnn_depth_list[lidx], 'conv&#123;&#125;'.format(lidx+1)) conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') fc = flatten(conv) bsize, fc_in_dim = fc.shape fc = self._fc(fc,fc_in_dim,self._mlp_depth_list[0],'fc1') fc = tf.nn.dropout(fc, keep_prob) # dropout for lidx in range(1,len(self._mlp_depth_list)): fc = self._fc(fc,self._mlp_depth_list[lidx-1],self._mlp_depth_list[lidx],'fc&#123;&#125;'.format(lidx+1)) fc = tf.nn.dropout(fc, keep_prob) # dropout with tf.variable_scope('logits') as scope: with tf.device('/cpu:0'): logits_w = tf.get_variable('logits_w', shape=[self._mlp_depth_list[-1],self._n_classes],\\ initializer=tf.random_uniform_initializer(-0.1,0.1)) logits_b = tf.get_variable('logits_b', shape=[self._n_classes],\\ initializer=tf.zeros_initializer) logits = tf.nn.xw_plus_b(fc, logits_w, logits_b, name=scope.name) print(logits.shape) return logits def _conv(self, x, in_depth, ksize, out_depth, scope_name, relu=True): bsize,h,w,cNum = x.shape assert(h-(ksize-1)&gt;=1) assert(w-(ksize-1)&gt;=1) with tf.variable_scope(scope_name) as scope: with tf.device('/cpu:0'): # Create tf variables for the weights and biases weights = tf.get_variable('weights', shape=(ksize, ksize, in_depth, out_depth),\\ initializer=tf.random_normal_initializer(self._mu,self._sigma)) biases = tf.get_variable('biases', shape=(out_depth),initializer=tf.zeros_initializer) out = tf.nn.conv2d(x, weights, strides=[1, 1, 1, 1], padding='VALID',name=scope.name) + biases if relu: # Apply ReLu non linearity relu = tf.nn.relu(out) return relu else: return out def _fc(self, x, num_in, num_out, scope_name, relu=True): \"\"\"Create a fully connected layer.\"\"\" with tf.variable_scope(scope_name) as scope: with tf.device('/cpu:0'): # Create tf variables for the weights and biases weights = tf.get_variable('weights', shape=[num_in, num_out],\\ initializer=tf.random_uniform_initializer(-0.1,0.1)) biases = tf.get_variable('biases', [num_out],\\ initializer=tf.zeros_initializer) # Matrix multiply weights and inputs and add bias out = tf.nn.xw_plus_b(x, weights, biases, name=scope.name) if relu: # Apply ReLu non linearity relu = tf.nn.relu(out) return relu else: return out mnistCNN = MNISTCNN(ksize, cnn_depth_list, mlp_depth_list, img_height, img_width, cNum, n_classes)# Averaging gradients for all tower models on GPUdef average_gradients(tower_grads): \"\"\"Calculate the average gradient for each shared variable across all towers. Note that this function provides a synchronization point across all towers. Args: tower_grads: List of lists of (gradient, variable) tuples. The outer list is over individual gradients. The inner list is over the gradient calculation for each tower. Returns: List of pairs of (gradient, variable) where the gradient has been averaged across all towers. \"\"\" average_grads = [] for grad_and_vars in zip(*tower_grads): # Note that each grad_and_vars looks like the following: # ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN)) grads = [] for g, _ in grad_and_vars: # Add 0 dimension to the gradients to represent the tower. expanded_g = tf.expand_dims(g, 0) # Append on a 'tower' dimension which we will average over below. grads.append(expanded_g) # Average over the 'tower' dimension. grad = tf.concat(axis=0, values=grads) grad = tf.reduce_mean(grad, 0) # Keep in mind that the Variables are redundant because they are shared # across towers. So .. we will just return the first tower's pointer to # the Variable. v = grad_and_vars[0][1] grad_and_var = (grad, v) average_grads.append(grad_and_var) return average_grads# Construct model for each GPU, where variables are shared/updated by CPUwith tf.device('/cpu:0'): optimizer = tf.train.AdamOptimizer(learning_rate = rate)# Calculate the gradients for each model tower.tower_grads = []logits_list = []feed_x = []feed_one_hot_y = []keep_prob = tf.placeholder(tf.float32) # probability to keep unitswith tf.variable_scope(tf.get_variable_scope()): for i in range(2): with tf.device('/gpu:%d' % i): x = tf.placeholder(tf.float32, (None, img_height, img_width, cNum)) feed_x.append(x) one_hot_y = tf.placeholder(tf.int32, (None, n_classes)) feed_one_hot_y.append(one_hot_y) logits = mnistCNN.create(x,keep_prob) logits_list.append(logits) cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,logits=logits) loss_op = tf.reduce_mean(cross_entropy) tf.get_variable_scope().reuse_variables() # Calculate the gradients for each batch of data on this model tower. grads = optimizer.compute_gradients(loss_op) # Keep track of the gradients across all towers. tower_grads.append(grads)with tf.device('/cpu:0'): # We must calculate the mean of each gradient. Note that this is the # synchronization point across all towers. grads = average_gradients(tower_grads) # Apply the gradients to adjust the shared variables. apply_gradient_op = optimizer.apply_gradients(grads) training_op = apply_gradient_op \"\"\"Prediction/Inference Part\"\"\"# Define accuracy evaluation, calculate the average accuracy by calling evaluate(X_data, y_data)# Using model that in the First GPU to calculatecorrect_prediction = tf.equal(tf.argmax(logits_list[0], axis=1), tf.argmax(feed_one_hot_y[0], axis=1))accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))def evaluate(X_data, y_data): num_examples = len(X_data) total_accuracy = 0 sess = tf.get_default_session() for offset in range(0, num_examples, BATCH_SIZE): batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE] accuracy = sess.run(accuracy_operation, feed_dict=&#123;feed_x[0]: batch_x, feed_one_hot_y[0]: batch_y, keep_prob: 1.0&#125;) total_accuracy += (accuracy * len(batch_x)) return total_accuracy / num_examples \"\"\"Run Session\"\"\"# &#123;feed_x[0]:batch_x_1, feed_x[1]:batch_x_2,\\# feed_one_hot_y[0]:batch_y_1, feed_one_hot_y[1]:batch_y_1, keep_prob:drop_out_keep_prob&#125;def gen_feed_dict(batch_x, batch_y, drop_out_keep_prob): assert(len(batch_x)==len(batch_y)) assert(len(batch_x)%2==0) data_num = int(len(batch_x)/2) rtn_dict = &#123;&#125; rtn_dict[feed_x[0]] = batch_x[:data_num] rtn_dict[feed_x[1]] = batch_x[data_num:] rtn_dict[feed_one_hot_y[0]] = batch_y[:data_num] rtn_dict[feed_one_hot_y[1]] = batch_y[data_num:] rtn_dict[keep_prob] = drop_out_keep_prob return rtn_dict ### Train your model here.import timeif not os.path.isdir('./models'): os.makedirs('./models')#saver = tf.train.Saver()accumulate_time = 0.0with tf.Session() as sess: sess.run(tf.global_variables_initializer()) num_examples = img_num print(\"Training...\") print() train_accuracy = np.zeros(EPOCHS) validation_accuracy = np.zeros(EPOCHS) stime = time.time() for i in range(EPOCHS): stime = time.time() acc_train_accuracy = 0 X_train, y_train = shuffle(images, labels1Hot) for offset in range(0, num_examples, BATCH_SIZE): end = offset + BATCH_SIZE batch_x, batch_y = X_train[offset:end], y_train[offset:end] feed_dict = gen_feed_dict(batch_x, batch_y, drop_out_keep_prob) sess.run(training_op, feed_dict=feed_dict) etime = time.time() accumulate_time += etime - stime validation_accuracy[i] = evaluate(images_valid, labels1Hot_valid) print(\"EPOCH &#123;&#125; ...\".format(i+1)) print(\"Validation Accuracy = &#123;:.3f&#125;\".format(validation_accuracy[i])) print('Cost time: ' + str(accumulate_time) + ' sec.') å¹¾å€‹æ³¨æ„è™•: è¨˜å¾—å»ºç«‹ variables (tf.get_variable) æ™‚è¦ä½¿ç”¨ with tf.device(&#39;/cpu:0&#39;): ç¢ºä¿è®Šé‡æ˜¯å­˜åœ¨ cpu å…§ å¯ä»¥è·‘ä¸€å°æ®µ code: 12with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess: sess.run(tf.global_variables_initializer()) ä¾†è§€å¯Ÿè®Šé‡æ˜¯å¦æ­£ç¢ºæ”¾åœ¨ cpu ä¸Šã€‚ å»¶çºŒ 2. è‹¥ä½¿ç”¨ jupyter notebook å¯ä»¥é€™æ¨£åš jupyter notebook &gt; outputlogï¼ŒåŸ·è¡Œå®Œ 2. çš„ code æ¥è‘— cat outputlog | grep &#39;cpu&#39; è§€å¯Ÿè®Šé‡æ˜¯å¦å­˜åœ¨ã€‚ ä½¿ç”¨ collections (å¦‚ä¸‹) ä¾†ç¢ºèªè®Šæ•¸æœ‰æ­£ç¢ºåˆ†äº« (é¤Šæˆå¥½ç¿’æ…£)123trainable_collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)global_collection = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)print('Without Scope: len(trainable_collection)=&#123;&#125;; len(global_collection)=&#123;&#125;'.format(len(trainable_collection),len(global_collection))) Benchmark Results batch size = 128 æ™‚ï¼Œä½¿ç”¨å…©å¼µ GPU èŠ±çš„æ™‚é–“ç‚ºä¸€å¼µçš„ 0.78 å€ã€‚è€Œ batch size = 512 æ™‚çš„æ•ˆæœæ›´æ˜é¡¯ï¼Œç‚º 0.69 å€ã€‚ ä¸€é»å°çµè«–é€™ç¨®åŒæ­¥çš„æ¶æ§‹é©åˆåœ¨ batch size å¤§çš„æ™‚å€™ï¼Œæ•ˆæœæœƒæ›´æ˜é¡¯ã€‚å¯¦é©—èµ·ä¾†å…©å¼µå¡åœ¨ 512 batch size èŠ±çš„æ™‚é–“åœ¨ä¸€å¼µå¡çš„ 0.7 å€ã€‚ä¸éç›¸æ¯”ä½¿ç”¨å…©å¼µå¡ï¼Œä¸€å¼µå¡å…¶å¯¦æœ‰ä¸€é»å„ªå‹¢æ˜¯åœ¨è®Šé‡å…¨éƒ¨æ”¾åœ¨ GPU ä¸Šï¼Œå› æ­¤çœå»äº† CPU &lt;â€“&gt; GPU çš„å‚³è¼¸ä»£åƒ¹ã€‚é€™ä¹Ÿæ˜¯ä¸»è¦åªåˆ° 0.7 å€ï¼Œè€Œæ²’æœ‰æ¥è¿‘ 0.5 å€çš„é—œéµåŸå› ã€‚ Reference Tensorflow å®˜ç¶² åŒæ­¥å¼ data Parallelism æ–¹æ³• Tensorflow github cifar10_multi_gpu_train.py","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://bobondemon.github.io/tags/TensorFlow/"}]},{"title":"A Toy Example for Teacher Student Domain Adaptation","date":"2017-10-22T02:19:54.000Z","path":"2017/10/22/A-Toy-Example-for-Teacher-Student-Domain-Adaptation/","text":"çœ‹äº†é€™ç¯‡ 2017 Microsoft AI and Research çš„æ–‡ç«  â€œLarge-Scale Domain Adaptation via Teacher-Student Learningâ€œ è¦ºå¾—æ»¿æœ‰æ„æ€çš„ï¼ŒåŠ ä¸Šå¾ˆå®¹æ˜“å¯¦ä½œï¼Œå› æ­¤å°±åˆ†æä¸€ä¸‹é€™ç¯‡çš„å¯è¡Œæ€§ã€‚ è¨­è¨ˆäº†ä¸€å€‹ MNIST Toy Example ä¾†å±•ç¤º T/S Learning çš„èƒ½åŠ›ï¼Œè‡ªå·±ä¹Ÿæƒ³çŸ¥é“é€™å€‹æ–¹æ³•æœ‰å¤šå¯é ã€‚ç›¸é—œçš„å¯¦é©— code è«‹åƒè€ƒ github TS Learning Methodsä»‹ç´¹ä¸€ä¸‹ TS Learning çš„æ–¹æ³•ã€‚ä»–è¦è§£æ±ºçš„å•é¡Œæè¿°å¦‚ä¸‹ å‡è¨­æˆ‘å€‘å·²ç¶“æœ‰äº†ä¸€å€‹è¨“ç·´å¥½çš„èªéŸ³è¾¨è­˜æ¨¡å‹ï¼Œç¾åœ¨è¦è¾¨è­˜é å ´çš„è²éŸ³ï¼ŒåŸ Domain (è¿‘å ´éŒ„è£½çš„è²éŸ³)ï¼Œå¯èƒ½æ•ˆæœå°±æœƒä¸å¥½ã€‚è¦è§£æ±ºæœ€ç›´æ¥çš„æ–¹æ³•å°±æ˜¯é‡æ–°éŒ„è£½é å ´èªæ–™ï¼ŒéŒ„è£½çš„éç¨‹ä¸­å¾ˆå®¹æ˜“å¯ä»¥å–å¾—åŒæ™‚æœ‰è¿‘å ´å’Œé å ´æœªæ¨™è¨˜çš„èªæ–™ (æ”¾å…©å€‹éº¥å…‹é¢¨ï¼Œä¸€å€‹è¿‘ä¸€å€‹é )ï¼Œä¸éé—œéµæ˜¯æ¨™è¨˜æˆæœ¬å¤ªé«˜ã€‚å› æ­¤é€™ç¯‡å°±æ˜¯æƒ³åˆ©ç”¨æœªæ¨™è¨˜çš„èªæ–™ç›´æ¥é‡å°åŸ Domain çš„æ¨¡å‹ Adapt åˆ°æ–°çš„ Domain ä¸Šã€‚ ä»¥ä¸Šé¢è«–æ–‡ä¸­çš„åœ–ä¾†èªªï¼Œå·¦é‚Š Teacher network åªèƒ½åœ¨ Source Domain æœ‰å¥½çš„è¾¨è­˜èƒ½åŠ›ï¼Œç›®æ¨™æ˜¯å¸Œæœ›å¾—åˆ°å³é‚Šçš„ Student network èƒ½åœ¨ Target Domain é‡å°åŒæ¨£å•é¡Œä¹Ÿæœ‰å¥½çš„è¾¨è­˜èƒ½åŠ›ã€‚è«–æ–‡æ–¹æ³•æ˜¯ä¸€é–‹å§‹å…ˆå°‡ Teacher network æ‹·è²ä¸€ä»½çµ¦ Student network ï¼Œæ¥è‘—å°±é–‹å§‹é¤µ parallel data çµ¦å…©å€‹ networksã€‚ æ‰€è¬‚ parallel data æ„æ€æ˜¯ç›¸åŒçš„è³‡æ–™ä¾†æºï¼Œä½†æ˜¯åœ¨ä¸åŒ domain è’é›†ï¼Œä¾‹å¦‚åŒä¸€å€‹äººè¬›åŒä¸€å¥è©±ï¼Œä¸€å€‹è¿‘å ´éº¥å…‹é¢¨è’é›†åˆ°ï¼Œå¦ä¸€å€‹é å ´è’é›†åˆ°ã€‚ç›®æ¨™å‡½å¼å°±æ˜¯å¸Œæœ›å…©å€‹ network çš„å¾Œé©—æ¦‚ç‡ç›¸åŒ (å…©è€…çš„å¾Œé©—æ¦‚ç‡å¹³æ–¹èª¤å·®ç‚º0)ï¼Œè€Œæˆ‘å€‘åªæ›´æ–° Student networkã€‚åœ¨å¯¦ä½œä¸Šä¸æœƒä½¿ç”¨å¾Œé©—æ¦‚ç‡ä¾†è¨ˆç®—å…©å€‹ network çš„èª¤å·®ï¼Œæœƒä½¿ç”¨æœªç¶“é softmax çš„é‚£å±¤ï¼Œä¹Ÿå°±æ˜¯ä¸€èˆ¬èªªçš„ logits ä¾†è¨ˆç®—ã€‚åŸå› ç°¡å–®èªªæ˜å¦‚ä¸‹: softmax æœƒå°‡åŒæ¨£æ˜¯ negative çš„é¡åˆ¥çš„æ©Ÿç‡éƒ½å£“åˆ°å¾ˆä½ï¼Œä½†æ˜¯ negative examples ä¹Ÿæœ‰åˆ†å¥½å£ï¼Œè®€è€…å¯ä»¥è©¦è©¦ [10,2,1] ç¶“é softmax å¾Œï¼Œ 2 è·Ÿ 1 ä¹‹é–“çš„å·®ç•°æœƒè¢«æŠ¹å¹³ã€‚å› æ­¤å¥½çš„åšæ³•æ˜¯ï¼Œä¸è¦ä½¿ç”¨ softmax ï¼Œè€Œæ˜¯ä½¿ç”¨ logitsã€‚ Hinton åœ¨é€™ç¯‡è«–æ–‡è£¡ä¿®æ”¹äº† softmax å‡½å¼ï¼Œå¤šäº†ä¸€å€‹ temperature $T$ï¼Œè«–æ–‡è£¡æ¨å°é€™æ¨£ä¿®æ”¹çš„ softmaxï¼Œå…¶å¯¦è·Ÿç›®æ¨™å‡½å¼ä½¿ç”¨ logits çš„å¹³æ–¹èª¤å·®æ˜¯ä¸€æ¨£çš„ (åœ¨ â€œTè·Ÿlogitså·®ç•°å¾ˆå¤§â€ ä¸” â€œlogitsçš„åˆ†å¸ƒå‡å€¼ç‚º0â€ çš„æ¢ä»¶ä¸‹) é€™æ¨£åšçš„ç‰©ç†æ„ç¾©å°±ç›¸ç•¶æ–¼ï¼Œå°‡ â€œæŸè²éŸ³çš„é å ´è¡¨ç¾åœ¨ Student network çœ¼è£¡â€ï¼Œè¦–ç‚ºè·Ÿ â€œè©²è²éŸ³çš„è¿‘å ´è¡¨ç¾åœ¨ Teacher network çœ¼è£¡â€ èªå®šç‚ºç›¸åŒä¸€ä»¶äº‹æƒ…ã€‚å› æ­¤å°±ä¸éœ€è¦é‡å° data åšæ¨™è¨˜äº†ï¼Œåªéœ€è¦æ‹¿åˆ°é€™æ¨£çš„ä¸€å¤§å † parallel data å°±å¯ä»¥ï¼Œè€Œé€™å¾ˆå®¹æ˜“ã€‚ é™„ä¸Šè«–æ–‡ä¸Šçš„æ­¥é©Ÿå¦‚ä¸‹: æ¼”ç®—æ³•å°±é€™æ¨£è€Œå·²ï¼Œå¾ˆå–®ç´”å§ã€‚ä½†æ˜¯ç©¶ç«Ÿæœ‰å¤šé æ™®? å¥½å¥‡å¿ƒä¸‹ï¼Œå°±ç”¨ MNIST è¨­è¨ˆäº† toy exampleï¼Œå°±æ˜¯æ¥ä¸‹ä¾†çš„å…§å®¹å›‰ã€‚ MNIST Toy Example for TS Learningå¯¦é©—è¨­å®š and Teacher Networké¦–å…ˆè¨­å®šå…©å€‹ Domain ç‚º: ä¸€å€‹åŸåœ– (åŸä¸–ç•Œ)ï¼Œå¦ä¸€å€‹ä¸Šä¸‹é¡›å€’çš„åœ– (ä¸Šä¸‹é¡›å€’çš„ä¸–ç•Œ)ã€‚ Teacher network æ˜¯ä¸€å€‹å¾ˆç°¡å–®çš„ â€œ6â€ å’Œ â€œ9â€ çš„è¾¨è­˜å™¨ï¼Œç•¶ç„¶æ˜¯åœ¨åŸä¸–ç•Œè¨“ç·´å¥½çš„ã€‚å¦‚æœç›´æ¥æ‹¿ teacher network å»çœ‹é¡›å€’çš„ 6ï¼ŒæœŸæœ›å®ƒèªå‡ºä¸€æ¨£æ˜¯ 6 æ˜¯è¾¨è­˜ä¸å‡ºä¾†çš„! (åŒæ¨£æœŸæœ› teacher network çœ‹å‡ºé¡›å€’çš„ 9 ä»ç„¶æ˜¯ 9 ä¹Ÿæ˜¯è¾¦ä¸åˆ°çš„) ä¹‹æ‰€ä»¥æœƒé¸ 6 å’Œ 9ï¼Œæ˜¯å› ç‚ºå°±ç®—ä¸Šä¸‹é¡›å€’ï¼Œé¡›å€’çš„ 6 å’Œæ­£å‘çš„ 9 çœ‹èµ·ä¾†ä»ç„¶æ˜¯ä¸åŒçš„! åŒæ¨£çš„ï¼Œé¡›å€’çš„ 9 å’Œæ­£å‘çš„ 6 ä¸€æ¨£çœ‹èµ·ä¾†ä¸åŒ ! æˆ‘å€‘å¾—åˆ°çš„ Teacher network è¾¨è­˜æƒ…æ³å¦‚ä¸‹: 12345678910Training...EPOCH 1 ...Train Accuracy = 0.967; Flip Accuracy = 0.098EPOCH 2 ...Train Accuracy = 0.999; Flip Accuracy = 0.151EPOCH 3 ...Train Accuracy = 0.999; Flip Accuracy = 0.110 æ˜é¡¯çœ‹åˆ°è¾¨è­˜ç‡æ¥è¿‘ 100%ï¼Œä½†æ˜¯ä¸€æ—¦ä¸Šä¸‹é¡›å€’ï¼Œè¾¨è­˜ç‡åªå‰© 10%ã€‚æœ‰æ„æ€çš„æ˜¯ï¼Œç”±æ–¼æˆ‘å€‘åªæœ‰å…©å€‹é¡åˆ¥ï¼Œå°æ–¼ä¸Šä¸‹é¡›å€’çš„è¾¨è­˜ç‡å‰©10%å¯ä»¥çœ‹åš: é¡›å€’çš„ 6ï¼Œæœƒè¢«èªæˆ 9ï¼Œè€Œé¡›å€’çš„ 9 æœƒè¢«èªç‚º 6ã€‚ä½†äº‹å¯¦ä¸Šï¼Œé¡›å€’çš„ 6 å’Œ 9 é‚„æ˜¯ä¸ä¸€æ¨£ã€‚ Student network è¨“ç·´æˆ‘å€‘å°‡ MNIST å…¶ä»–å½±åƒä¸Šä¸‹é¡›å€’ï¼Œåšå‡º parallel datasetï¼Œç„¶å¾ŒæŒ‰ç…§è«–æ–‡çš„åšæ³•åš unsupervised trainingã€‚æœ‰è¶£çš„æ˜¯å¾—åˆ°çµæœå¦‚ä¸‹: 12345678910111213141516171819EPOCH 1 ...Acc loss = 3.871242271944786Train Accuracy = 0.156; Flip Accuracy = 0.998EPOCH 2 ...Acc loss = 0.40557907682784994Train Accuracy = 0.101; Flip Accuracy = 0.999EPOCH 3 ...Acc loss = 0.3005437100890939Train Accuracy = 0.103; Flip Accuracy = 0.999EPOCH 4 ...Acc loss = 0.2651689475203995Train Accuracy = 0.097; Flip Accuracy = 0.999EPOCH 5 ...Acc loss = 0.23342516055794454Train Accuracy = 0.116; Flip Accuracy = 0.999 Student network å¯ä»¥æˆåŠŸè¾¨è­˜ é¡›å€’çš„ 6 å’Œé¡›å€’çš„ 9 äº†! æ³¨æ„ï¼Œæˆ‘å€‘å¾ä¾†æ²’æœ‰çµ¦é Student network é¡›å€’çš„ 6 å’Œé¡›å€’çš„ 9 é€™äº›è¨“ç·´è³‡æ–™! ä½†æ˜¯ç¾åœ¨å®ƒæœ‰èƒ½åŠ›è¾¨è­˜é€™å…©ç¨®åœ–äº†! ä½†æ˜¯åŒæ¨£çš„ï¼Œå¦‚æœçµ¦ student network çœ‹ä¸€å€‹æ­£å‘çš„ 6ï¼Œåœ¨ä»–çš„çœ¼å“©ï¼Œçœ‹èµ·ä¾†å°±å¦‚åŒ teacher network çœ‹åˆ° 9 ä¸€æ¨£ã€‚ ä¹Ÿå°±æ˜¯èªªï¼ŒStudent network å¤±å»äº†åŸ Domain çš„è¾¨è­˜èƒ½åŠ›ã€‚ é€™èˆ‡è«–æ–‡åŸä½œè€…çš„çµè«–ä¸å¤§ä¸€æ¨£ã€‚ ç”¨ parallel data éç›£ç£å­¸ç¿’åˆ°åº•å­¸åˆ°äº†ä»€éº¼? çµ¦ T/S ç¶²è·¯çœ‹éå¾ˆå¤šå¾ˆå¤šçš„ parallel data å¾Œï¼ŒTeacher çœ¼è£¡çš„åœ–ï¼Œåœ¨ Student çœ¼è£¡çœ‹èµ·ä¾†å°±åéä¾†ï¼Œåä¹‹äº¦ç„¶ã€‚å› æ­¤é€™æ™‚å€™å¦‚æœçµ¦ Student network çœ‹ä¸€å€‹ â€œæ­£å‘çš„6â€ï¼Œå®ƒæœƒèªç‚º: å•Š!é€™åœ¨ Teacher çœ¼è£¡çœ‹åˆ°çš„æ˜¯ä¸€å€‹é¡›å€’çš„ 6 ã€‚(è€Œ teacher network æœƒå°‡é¡›å€’çš„ 6 çœ‹åšæ˜¯ 9) å› æ­¤æˆ‘èªç‚ºï¼ŒStudent netowrk å¾ˆå®¹æ˜“å¤±å»åŸå…ˆ domain çš„è¾¨è­˜èƒ½åŠ›ï¼Œå°±åƒé€™å€‹ä¾‹å­ student network ç„¡æ³•èªå‡ºæ­£å‘çš„ 6 ä¸€æ¨£ã€‚ Summaryå¦‚ä½•è®“ä¸€å€‹ network åŒæ™‚æœ‰åŸ Domain å’Œæ–° Domain çš„è¾¨è­˜èƒ½åŠ›å‘¢ ? ä»¥ä¸Šé¢çš„ toy example ç‚ºä¾‹ï¼Œå°±æ˜¯è¾¨è­˜å…©å€‹ classes class 1: 6 and é¡›å€’çš„6class 2: 9 and é¡›å€’çš„9 æœ€ç›´è¦ºçš„åšæ³•ï¼Œå°±æ˜¯ T and S models éƒ½è·‘ä¸€æ¬¡è¾¨è­˜ï¼Œç„¶å¾Œå°‡å…©å€‹å¾Œé©—æ¦‚ç‡åŠ èµ·ä¾†å¾Œç®— argmaxã€‚ç¼ºé»å°±æ˜¯ model size ç«‹é¦¬è®Šæˆå…©å€ã€‚ æ€éº¼è®“æ¨¡å‹ size ä¸è¦è®Šæˆå…©å€å‘¢? ç°¡å–®æƒ³äº†ä¸€å€‹æ–¹å¼ï¼Œå°±æ˜¯è®“ student model æ”¹æˆé€™æ¨£çš„æ¨¡å‹: å…¶ä¸­ M model çš„éƒ¨åˆ†è² è²¬å°‡ ä¸Šä¸‹é¡›å€’çš„ domain è½‰æ›æˆåŸ domain çš„ inputï¼Œç„¶å¾Œé€™æ¨£çš„ input å°±å¯ä»¥åŸå°ä¸å‹•åœ°ç”¨ teacher model å»è¾¨è­˜ã€‚å‰›å¥½é€™å€‹å•é¡Œå…¶å¯¦ç”¨ä¸€å€‹ permuation matrix å¯ä»¥åšä¸Šä¸‹é¡›å€’ï¼Œå› æ­¤å¯¦é©—ä¸Šå°±ç›´æ¥ä½¿ç”¨ä¸€å€‹ linear layer (æ²’æœ‰ activation function)ï¼Œç•¶ç„¶ backprob ç®—å‡ºä¾†çš„ä¸æœƒæ­£å¥½æ˜¯ permutation matrix å°±æ˜¯äº†ã€‚ æ”¶æ–‚æƒ…æ³å¦‚ä¸‹: åŸºæœ¬ä¸Šæ¯”åŸå…ˆè¦æ…¢ï¼Œå› ç‚ºåŸä¾†æ˜¯æ‰€æœ‰çš„ weights éƒ½å¯ä»¥èª¿æ•´ï¼Œè€Œç¾åœ¨åªèƒ½å‹•ä¸€å€‹ linear layer 12345678910111213141516171819EPOCH 1 ...Acc loss = 9.52696829760659Train Accuracy = 0.460; Flip Accuracy = 0.806EPOCH 2 ...Acc loss = 3.6580730849143146Train Accuracy = 0.364; Flip Accuracy = 0.955EPOCH 3 ...Acc loss = 2.454553008463332Train Accuracy = 0.304; Flip Accuracy = 0.980EPOCH 4 ...Acc loss = 1.823352760733923Train Accuracy = 0.277; Flip Accuracy = 0.988EPOCH 5 ...Acc loss = 1.4707165408316494Train Accuracy = 0.235; Flip Accuracy = 0.992 é€™æ¨£åšæ³•é›–ç„¶ model size å°äº†å¾ˆå¤šï¼Œä½†æ˜¯è¦åŒæ™‚è¾¨è­˜æ­£çš„å’Œé¡›å€’çš„ä»ç„¶è¦è·‘å…©éçš„ modelã€‚ æœ‰æ²’æœ‰æ–¹æ³•çµåˆ TS learning unsupervised çš„æ–¹å¼ï¼Œä¸”åŒæ™‚å…¼é¡§å…©é‚Šçš„ domain è¾¨è­˜èƒ½åŠ›å‘¢? å°±å†æ€è€ƒçœ‹çœ‹å›‰ã€‚ Reference Large-Scale Domain Adaptation via Teacher-Student Learning Distilling the Knowledge in a Neural Network Toy Example github","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Adaptation","slug":"Adaptation","permalink":"https://bobondemon.github.io/tags/Adaptation/"}]},{"title":"Word Embeddings (Encoder-Decoder æ¶æ§‹)","date":"2017-09-07T13:22:53.000Z","path":"2017/09/07/Word-Embeddings-and-Encoder-Decoder-Neural-Net/","text":"From Sparse Vector to Embeddings with Encoderâ€“Decoder Structure æ±‚ Embeddings Encoderâ€“Decoder çµæ§‹ å­—å…¸å‘é‡è‹¥æˆ‘å€‘å­—å…¸è£¡æœ‰ $N$ å€‹ words, ç¬¬ $i$ å€‹å­— $w^i$ æ‡‰è©²æ€éº¼è¡¨ç¤ºå‘¢? é€šå¸¸ä½¿ç”¨ one-hot vector ä¾†è¡¨ç¤º: æŠŠ $w^i$ è®Šæˆä¸€å€‹é•·åº¦ $N$ çš„å‘é‡ $x^i$ã€‚ æ­å–œ! æœ‰äº† vector æˆ‘å€‘å°±å¯ä»¥å¥—ç”¨æ•¸å­¸æ¨¡å‹äº†ã€‚ å•é¡Œæ˜¯é€™æ¨£çš„å‘é‡å¤ªç¨€ç–äº†ï¼Œå°¤å…¶æ˜¯ç•¶å­—å…¸éå¸¸å¤§çš„æ™‚å€™ã€‚ ç¨€ç–å‘é‡å°æ–¼æ¨¡å‹è¨“ç·´å¾ˆæ²’æœ‰æ•ˆç‡ã€‚ æˆ‘å€‘éœ€è¦è½‰æ›åˆ°æ¯”è¼ƒç·Šå¯†çš„å‘é‡ï¼Œé€šå¸¸ç¨±ç‚º embeddingã€‚ ä¸‹åœ–èˆ‰ä¾‹å°‡ $x$ å°æ‡‰åˆ°å®ƒçš„ç·Šå¯†å‘é‡ $e$, ç·Šå¯†å‘é‡æœ‰ embed_dim ç¶­åº¦ å…ˆå‡è¨­å·²çŸ¥å¦‚ä½•å°æ‡‰åˆ°ç·Šå¯†å‘é‡å·²çŸ¥ä¸€å€‹ N * embed_dim çš„çŸ©é™£ $E$ï¼Œç¬¬ $i$ å€‹ row $e^i$ å°±æ˜¯ $w^i$ çš„ embeddingã€‚ æˆ‘å€‘å°±å¯ä»¥ä½¿ç”¨ $e$ ä¾†ä»£æ›¿åŸå…ˆçš„ç¨€ç–å‘é‡ $x$ é€²è¡Œè¨“ç·´ï¼Œè®“è¨“ç·´æ›´å¥½æ›´å®¹æ˜“ã€‚ ä»¥ä¸€å€‹èªè¨€æ¨¡å‹ä¾†èªªï¼Œä½¿ç”¨ LSTM æ¨¡å‹å¦‚ä¸‹: æ©ï¼Œé€™æ¨£å¤§åŠŸå‘Šæˆï¼Œæˆ‘å€‘çš„æ¨¡å‹å¯ä»¥é †åˆ©è¨“ç·´ â€¦. ?? ä¸å°ï¼Œ$E$ é€™å€‹ lookup table æ€éº¼æ±ºå®š? Lookup Table ä½¿ç”¨çŸ©é™£ç›¸ä¹˜ç­”æ¡ˆæ˜¯è®“æ¨¡å‹è‡ªå·±è¨“ç·´æ±ºå®šã€‚è¦æ›´äº†è§£å…§éƒ¨é‹ä½œï¼Œæˆ‘å€‘å…ˆå°‡ lookup table ä½¿ç”¨çŸ©é™£ç›¸ä¹˜çš„æ–¹å¼ä¾†çœ‹ã€‚ æ‰€ä»¥ä½¿ç”¨ lookup table LSTM çš„èªè¨€æ¨¡å‹è®Šæˆå¦‚ä¸‹ ç­‰ç­‰ï¼ŒçŸ©é™£ç›¸ä¹˜ä¸å°±è·Ÿ neural net ä¸€æ¨£å—? é€™æ¨£çœ‹èµ·ä¾†é€™å€‹ lookup table $E$ å°±æ˜¯ä¸€å±¤çš„é¡ç¥ç¶“ç¶²è·¯è€Œå·² (æ²’æœ‰ activation function)ã€‚ æˆ‘å€‘ç”¨ LL (Linear Layer) ä¾†ä»£è¡¨ï¼Œ$E$ å°±æ˜¯ LL çš„ weight matrixã€‚ è¡¨ç¤ºæˆ neural net çš„æ–¹å¼ï¼Œæˆ‘å€‘å°±ç›´æ¥å¯ä»¥ Backprob è¨“ç·´å‡º LL çš„ weight $E$ äº†ã€‚è€Œ $E$ å°±æ˜¯æˆ‘å€‘è¦æ‰¾çš„ embeddingsã€‚ Tensorflow ä¸­åšé€™æ¨£çš„ lookup table å¯ä»¥ä½¿ç”¨ tf.nn.embedding_lookup()ã€‚ Embedding çš„ä½œæ³•å¯åƒè€ƒ tf å®˜ç¶²æ­¤è™•ã€‚ LLå¾ˆå¼±æ€éº¼è¾¦?åªç”¨ä¸€å±¤ç·šæ€§çµ„åˆ (LL) å°±æƒ³æŠŠç‰¹å¾µæ“·å–åšåˆ°å¾ˆå¥½ï¼Œä¼¼ä¹æœ‰é»ç°¡åŒ–äº†ã€‚ æ²’éŒ¯ï¼Œæˆ‘å€‘éƒ½çŸ¥é“ï¼Œç‰¹å¾µæ“·å–æ˜¯ Deep neural net çš„æ‹¿æ‰‹å¥½æˆ²ï¼Œæ‰€ä»¥æˆ‘å€‘å¯ä»¥å°‡ LL æ›æˆå¼·å¤§çš„ CNNã€‚ é€™ç¨®å…ˆç¶“éä¸€å±¤ç‰¹å¾µæ“·å–ï¼Œå†åšè¾¨è­˜ï¼Œå…¶å¯¦è·Ÿ Encoder â€“ Decoder çš„æ¶æ§‹ä¸€æ¨£ã€‚ éƒ½æ˜¯å…ˆç¶“é Encoder åšå‡º embeddingsï¼Œæ¥è‘—ä½¿ç”¨ Embeddings decode å‡ºçµæœã€‚ Encoder å¦‚æœä¹Ÿæ¡ç”¨ RNN çš„è©±åŸºæœ¬ä¸Šå°±æ˜¯ sequence-to-sequence çš„æ¶æ§‹äº†ã€‚ åŸºæœ¬ä¸Šæ‹“å±•ä¸€ä¸‹ï¼Œå°åœ–æˆ–å½±åƒåš Encodeï¼Œè€Œ Decoder è² è²¬è§£ç¢¼å‡ºæè¿°çš„æ–‡å­—ã€‚æˆ–æ˜¯èªè¨€ç¿»è­¯ï¼ŒèªéŸ³è¾¨è­˜ï¼Œéƒ½å¯ä»¥é€™éº¼çœ‹å¾…ã€‚ Reference Embedding tf å®˜ç¶² link Sequence to sequence learning link Udacity lstm github colah lstm","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Embedding","slug":"Embedding","permalink":"https://bobondemon.github.io/tags/Embedding/"}]},{"title":"AutoEncoder","date":"2017-08-26T08:38:22.000Z","path":"2017/08/26/AutoEncoder/","text":"ä½¿ç”¨ MNIST and notMNIST åšäº†ä¸€å€‹ AutoEncoder with Fully Connected DNN çš„å¯¦é©—ã€‚ ä¾åºå°‡å¯¦é©—çµæœæ ¹æ“šå¦‚ä¸‹æ­¥é©Ÿé¡¯ç¤ºå‡ºä¾†ï¼Œç¨‹å¼ç¢¼å¯ä»¥åƒè€ƒ [github] Data Loading and Plotting AutoEncoder Graph Constructiona. Define the input output tensorsb. Define the graph and construct itc. Define loss and optimizer Run Session Show some reconstructed images Plot Embeddings Do Image Generation by Decoder Data Loading and PlottingMNIST training data æœ‰ 55000 ç­†è³‡æ–™ï¼Œæ˜¯ä¸€å€‹ 28x28 çš„ imageï¼Œå€¼çš„ç¯„åœæ˜¯ [0~1]ï¼Œå› æ­¤æœƒå° input éƒ½æ¸›å» 0.5 æ­£è¦åŒ–ã€‚ è€Œ notMNIST æ•´ç†éå¾Œæœ‰ 200000 ç­†ï¼ŒåŒæ¨£ä¹Ÿæ˜¯ 28x28 çš„ imageï¼Œä½†å€¼çš„ç¯„åœå·²ç¶“æ˜¯ [-0.5~0.5]ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæ­¤è³‡æ–™é‚„åƒé›œè‘—ä¸€äº›éŒ¯èª¤ï¼Œå¦‚ä¸‹åœ–å°±å¯ç™¼ç¾ï¼Œç¬¬äºŒåˆ—çš„ç¬¬äºŒå€‹æ‡‰ç‚º Jï¼Œä½†æ˜¯æ¨™è¨˜æ˜¯ Aã€‚å› æ­¤ notMNIST ç›¸å°ä¾†èªªå¾ˆæŒ‘æˆ°ï¼Œä½†æˆ‘å€‘ä¸€æ¨£å¯ä»¥çœ‹åˆ° AutoEncoder ä¹Ÿæœƒåšå‡ºä¸€äº›åˆç†çš„å£“ç¸®ã€‚ AutoEncoder Graph ConstructionDefine the input output tensorsInput x èˆ‡ Output y éƒ½æ˜¯ä¸€æ¨£ (æ²’æœ‰è¦åš Denoise AutoEncoder)ï¼Œå…¶ä¸­ code æ˜¯å»ºç«‹ Decoder æ™‚çš„ input tensorã€‚ 1234x = tf.placeholder(tf.float32, (None, img_dim))y = tf.placeholder(tf.float32, (None, img_dim))embedding_dim = 2code = tf.placeholder(tf.float32, (None, embedding_dim)) Define the graph and construct ité‡å° Encoder å’Œ Decoder éƒ½ä½¿ç”¨åŒä¸€çµ„åƒæ•¸ï¼Œé€™æ¨£çš„å¥½è™•æ˜¯åƒæ•¸é‡ç›´æ¥å°‘ç´„ä¸€åŠï¼ŒåŒæ™‚æ¸›å°‘ overfitting çš„æ©Ÿæœƒã€‚ç•¶ç„¶æˆ‘å€‘æ²’æœ‰ç†ç”±ä¸€å®šè¦å°‡åƒæ•¸ç¶å†ä¸€èµ·ï¼Œå¯ä»¥å„è‡ªç”¨è‡ªå·±çš„æ–¹æ³• (åƒæ•¸ã€æ¨¡å‹çµæ§‹) å» Encode å’Œ Decocdeã€‚çµæ§‹å¦‚ä¸‹: Define loss and optimizeræ³¨æ„åˆ° loss çš„å®šç¾©é™¤äº†åŸä¾†çš„å½±åƒé‡å»ºèª¤å·®ä¹‹å¤–ï¼Œé‚„å¤šäº†ä¸€å€‹ embeddings çš„ l2-normã€‚é€™æ˜¯ç‚ºäº†å¸Œæœ›åœ¨ embedding space ä¸Š encode ä¹‹å¾Œéƒ½æ¥è¿‘ 0ï¼Œæ¸›å°‘é‚£ç¨®å¾ˆå¤§çš„ outliers å‡ºç¾ã€‚åƒè€ƒæå®æ¯… Deep AutoEncoder 123loss_op = tf.reduce_sum(tf.pow(tf.subtract(reconstruct_auto, y), 2.0)) + l2_weight* tf.reduce_sum(tf.pow(embedded_auto, 2.0))optimizer = tf.train.AdamOptimizer(learning_rate = rate)training_op = optimizer.minimize(loss_op) Run SessionAdam optimizer è·‘äº† 100 å€‹ epochs Show some reconstructed imageséš¨æ©Ÿé¸å¹¾å€‹ MNSIT çš„é‡å»ºåœ–: éš¨æ©Ÿé¸å¹¾å€‹ notMNSIT çš„é‡å»ºåœ–: å¯ä»¥çœ‹åˆ° notMNIST æœç„¶é›£å¤šäº†ã€‚ Plot EmbeddingsMNIST é‡å°æ‰€æœ‰ training data æ±‚å¾—çš„ 2-d embeddings å¦‚ä¸‹: notMNIST é‡å°æ‰€æœ‰ training data æ±‚å¾—çš„ 2-d embeddings å¦‚ä¸‹: å¦‚æœåªè¦åšåˆ° unsupervised dimension reduction çš„è©±ï¼Œä½¿ç”¨ t-SNE æ±‚å¾—çš„ embedding æœƒæ¯”ä¸Šåœ–éƒ½å¥½çœ‹å¾ˆå¤šã€‚ä½† t-SNE æ²’æœ‰ Decoderï¼Œç„¡æ³•çµ¦å®šä¸€å€‹ embedding å»æ±‚å›åŸå…ˆçš„ imageã€‚è€Œé€™ç¨® Encoder - Decoder çµæ§‹å°±ç›¸å°å½ˆæ€§å¾ˆå¤šã€‚ t-SNE çš„ MNIST åœ–å¦‚ä¸‹: Do Image Generation by Decoderæˆ‘å€‘é‡å° Embedding Space çš„ä¸€å€‹å€åŸŸå»ç­‰è·å–å‡ºå¾ˆå¤šé»ï¼Œç„¶å¾Œä½¿ç”¨ Decoder å» decode å‡º image ä¾†ã€‚ MNIST çš„ç¯„åœé¸æ“‡ç‚ºï¼Œ x è»¸å’Œ y è»¸ [-1~1] é–“éš” 0.2ï¼Œå…± 100 å€‹é»ã€‚(å¯åƒè€ƒä¸Šé¢ embedding space äº†è§£é¸æ“‡çš„ç¯„åœ) notMNIST çš„ç¯„åœé¸æ“‡ç‚ºï¼Œ x è»¸å’Œ y è»¸ [-2~2] é–“éš” 0.2ï¼Œå…± 400 å€‹é»ã€‚(å¯åƒè€ƒä¸Šé¢ embedding space äº†è§£é¸æ“‡çš„ç¯„åœ) å¯ä»¥ç™¼ç¾ embedding space çš„å…©å€‹ç¶­åº¦å…·æœ‰æŸäº›æ„ç¾©åœ¨! Reference æå®æ¯… Deep AutoEncoder Distill t-SNE Reducing the Dimensionality of Data with Neural Networks (Hinton 2006) æœ¬æ–‡ä¹‹ [github]","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"auto-encoder","slug":"auto-encoder","permalink":"https://bobondemon.github.io/tags/auto-encoder/"}]},{"title":"Notes for Model Predictive Control","date":"2017-06-28T12:01:19.000Z","path":"2017/06/28/ModelPredictiveControl/","text":"å¾ä¸€é–‹å§‹æ±ºå®šä¸Šèª²å¾Œï¼Œç¶“éäº†åŠå¹´çµ‚æ–¼ä¾†åˆ° Udacity Term2 æœ€å¾Œä¸€å€‹ Project äº†ã€‚åªèƒ½èªªç›¡é‡è®“è‡ªå·±æŠŠæ¯ä¸€å€‹åšçš„ project éƒ½å¯«ä¸€ç¯‡ blog è¨˜éŒ„ï¼Œä½†é€™é™£å­æ™‚é–“çœŸçš„ä¸å¤ ç”¨ï¼Œæ‰€ä»¥é€™ç¯‡å°±å¾ high level çš„è§’åº¦ç€è¦½ä¸€ä¸‹å…§å®¹ã€‚ ç›®çš„æˆ‘å€‘ç”¨ä¸Šåœ–ä¾†èªªæ˜ç›®çš„ï¼ŒMPC è¦åšçš„äº‹æƒ…ï¼Œå°±æ˜¯çµ¦å®šä¸€å€‹æŒ‡å®šçš„ reference trajectory (é»ƒè‰²çš„æ›²ç·šï¼Œé€šå¸¸ç”¨ä¸€å€‹ 3rd polynomail è¡¨ç¤º)ï¼Œæˆ‘å€‘ç¶“ç”± motion model ä¾†è¨ˆç®—å‡ºæœ€ä½³çš„æ§åˆ¶ ($(\\delta,a)$åˆ†åˆ¥è¡¨ç¤ºè»Šå­è¼ªå­çš„è§’åº¦è·ŸåŠ é€Ÿåº¦)ï¼Œæœ€ä½³çš„æ„æ€å°±æ˜¯é€™æ¨£çš„æ§åˆ¶æœƒç”¢ç”Ÿå‡ºä¸€å€‹ predicted trajectory (ç¶ è‰²çš„æ›²ç·š) ä½¿å¾—è·Ÿ reference trajectory cost æœ€å°ã€‚é€™å°±ç­‰æ–¼å°‡å•é¡Œè½‰æ›æˆä¸€å€‹ nonlinear constraint optimization problem äº†ã€‚å¦å¤–å‰›æ‰æåˆ°çš„æ§åˆ¶é … $(\\delta,a)$ï¼Œå…¶ä¸­çš„ $\\delta$ ç‚ºä¸‹åœ–çš„ Wheel Orientation è§’åº¦:è€Œ $a$ è¡¨ç¤ºåŠ é€Ÿåº¦ï¼Œæ­£å€¼æ˜¯è¸©æ²¹é–€ï¼Œè² å€¼æ˜¯è¸©ç…è»Šã€‚é€™é‚Šæˆ‘å€‘ç•¶ç„¶å‡è¨­æ²¹é–€å’Œç…è»ŠåŒæ™‚åªæœƒæœ‰ä¸€å€‹å­˜åœ¨å•¦ï¼Œé–‹è»ŠæŠ€è¡“æ²’é€™éº¼å¥½ã€‚ Motion Model é€™ 6 å€‹ states $(x,y,\\psi,v,cte,e\\psi)$ åˆ†åˆ¥è¡¨ç¤º (è»Šå­xåº§æ¨™, è»Šå­xåº§æ¨™, è»Šå­headingè§’åº¦, è»Šå­é€Ÿåº¦, Cross Track Error, Error of è»Šå­è§’åº¦)CTE æˆ–ç¨± XTE æ˜¯ reference position è·Ÿ actual position ä¹‹é–“çš„èª¤å·® åŒç† $e\\psi$ å°±æ˜¯ reference çš„è§’åº¦è·Ÿå¯¦éš›è§’åº¦çš„å·®å€¼äº†ï¼Œæ³¨æ„åˆ°ï¼Œç”±æ–¼ reference trajectory å¯èƒ½æ˜¯ä¸€å€‹ 3rd polynomailï¼Œæˆ‘å€‘å¯ä»¥ç®—åˆ‡ç·šä¾†æ±‚å¾— reference çš„è§’åº¦ã€‚ Tools of Nonlinear Constraint Optå…©å€‹ä¸»è¦çš„ tool: IpoptInterior Point OPTimizationï¼Œç”¨ä¾†è§£ nonlinear constraint opt å•é¡Œã€‚ CppADåœ¨ä½¿ç”¨ Ipopt çš„æ™‚å€™ï¼Œéœ€è¦è¨ˆç®— function çš„ gradientsï¼Œè€Œ CppAD å¯ä»¥å¹«æˆ‘å€‘è‡ªå‹•è¨ˆç®—ã€‚ ä¸€å€‹å¾ˆæ£’çš„ä½¿ç”¨å…©å€‹ tools è§£ opt å•é¡Œçš„ç¯„ä¾‹: link Consider with Latencyé€šå¸¸ä¸‹äº†ä¸€é“ actuator å‘½ä»¤ (ä¾‹å¦‚åŠ é€Ÿåº¦è¦å¤šå°‘ã€è¼ªå­è§’åº¦è¦å¤šå°‘)ï¼Œåˆ°å¯¦éš›ä¸Šè»Šå­é‹ä½œæœƒæœ‰ä¸€å€‹ delayï¼Œè€Œ Udacity simulator è¨­å®šé€™å€‹ latency æ˜¯ 0.1 secondã€‚ é€™å€‹ latency åœ¨è»Šå­é€Ÿåº¦è¼ƒå¿«çš„æ™‚å€™ï¼Œå½±éŸ¿æœƒå¾ˆå¤§ï¼Œå°è‡´è»Šå­ç„¡æ³•æ­£ç¢ºé–‹å®Œã€‚ä¸€å€‹ç°¡å–®çš„è§£æ³•å°±æ˜¯æˆ‘å€‘åˆ©ç”¨ motion model å»é æ¸¬ç¶“é latency å¾Œçš„è»Šå­ statesï¼Œç„¶å¾Œå¾Œé¢æ‰€æœ‰æµç¨‹éƒ½ä¸€æ¨¡ä¸€æ¨£å³å¯ã€‚ Results [Video] With considering latency: [Video] Without considering latency: Referencemy github ç›®å‰è§£é–æˆå°±","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"Model Predictive Control","slug":"Model-Predictive-Control","permalink":"https://bobondemon.github.io/tags/Model-Predictive-Control/"},{"name":"Nonlinear Constraint Optimization","slug":"Nonlinear-Constraint-Optimization","permalink":"https://bobondemon.github.io/tags/Nonlinear-Constraint-Optimization/"}]},{"title":"Structure Perceptron and Structure SVM","date":"2017-05-20T01:41:27.000Z","path":"2017/05/20/Structure-Perceptron-and-Structure-SVM/","text":"è¨˜å¾—ç•¶å¹´å¿µåšçš„æ™‚å€™ï¼Œå°æ–¼SVMé —æœ‰æ„›ï¼Œä¹Ÿè¦ºå¾—æŒæ¡åº¦å¾ˆé«˜æƒ¹ï¼Œå°±æ˜¯ kernel method + convex optimization çš„å®Œç¾åˆé«”ã€‚ç›´åˆ°æŸå¤©çœ‹åˆ° structureSVMï¼Œçœ‹äº†è€åŠå¤©å¯¦åœ¨ä¸å¾—è¦é ˜ï¼Œç•¶æ™‚å°±æ”¾ä¸‹æ²’å†ç®¡äº†ã€‚å¤šå¹´å¾Œ (2015)ï¼Œå‰›å¥½å°å¤§æå®æ¯…æ•™æˆæ•™çš„èª²ç¨‹æœ€å¾Œä¸€å ‚ Project demoï¼Œæœ‰è«‹æˆ‘å€‘éƒ¨é–€ä»‹ç´¹åšçš„ä¸€äº›å…§å®¹çµ¦å­¸ç”Ÿï¼Œæ‰çœ‹åˆ°äº†å¼·å¤§çš„æè€å¸«çš„èª²ç¨‹å…§å®¹ã€‚ä»–æ‰€æ•™çš„ structure learning/svm å¯¦åœ¨æœ‰å¤ æ¸…æ¥šï¼Œåˆéå¸¸ generalï¼ŒçœŸçš„æ˜¯å¼·åˆ°çˆ†! æœ¬äººåˆå¹´è¼•ï¼Œåˆè¬™è™›ï¼Œæˆ‘çš„æ–°å¶åƒé˜¿!é™„ä¸Šä¸€å¼µæˆ‘èˆ‡æ–°å¶åƒçš„åˆç…§â€¦ XD ä»¥ä¸‹å…§å®¹ç‚ºç­†è¨˜ç”¨ï¼Œæ–¹ä¾¿æ—¥å¾Œå›æƒ³ï¼Œä¾†æº å¤§éƒ½æ˜¯æè€å¸«çš„å…§å®¹ã€‚ A General Framework (Energy-based Model)ä¸€èˆ¬ä¾†èªª ML è¦å­¸ç¿’çš„æ˜¯ $f:\\mathcal{X}\\rightarrow\\mathcal{Y}$ é€™æ¨£çš„ä¸€å€‹ mapping functionï¼Œä½¿å¾—åœ¨å­¸ç¿’åˆ°ä¹‹å¾Œï¼Œèƒ½å¤ å°æ–¼æ–°çš„ input $x$ æ±‚å¾—é æ¸¬çš„ $y=f(x)$ã€‚ç°¡å–®çš„æƒ…æ³æ˜¯æ²’å•é¡Œï¼Œä¾‹å¦‚ binary classificationã€multi-class classification æˆ– regressionã€‚ä½†æ˜¯è¬ä¸€è¦é æ¸¬çš„æ˜¯è¤‡é›œå¾—å¤šçš„ outputï¼Œè­¬å¦‚ $\\mathcal{Y}$ æ˜¯ä¸€å€‹ treeã€bounding boxã€æˆ– sequenceï¼ŒåŸä¾†çš„æ¶æ§‹å°±å¾ˆé›£å®šç¾©äº†ã€‚ æ‰€ä»¥å°‡è¦å­¸çš„å•é¡Œæ”¹æˆå¦‚ä¸‹çš„æ¶æ§‹ã€‚ Training: $F: \\mathcal{X} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$ Inference: Given an object $x$, $\\tilde{y}=argmax_y F(x,y)$ $F$ å¯ä»¥æƒ³æˆç”¨ä¾†è¨ˆç®— $(x,y)$ çš„åŒ¹é…åº¦ã€‚è€Œé€™æ¨£çš„ function ä¹Ÿç¨±ç‚º Energy-based modelã€‚å¥½äº†ï¼Œå®šç¾©æˆé€™æ¨£çœ‹èµ·ä¾†æ²’ä»€éº¼ä¸åŒï¼Œè©²æœ‰çš„å•é¡Œé‚„æ˜¯åœ¨ï¼Œé‚„æ˜¯æ²’è§£æ±ºã€‚æ²’é—œä¿‚ï¼Œæˆ‘å€‘ç¹¼çºŒçœ‹ä¸‹å»ï¼Œå…ˆæŠŠä¸‰å€‹é‡è¦çš„å•é¡Œåˆ—å‡ºä¾†ã€‚ Problem 1: æ€éº¼å®šç¾© $F(x,y)$ ? Problem 2: æ€éº¼è§£æ±º $argmax_y$ ? Problem 3: æ€éº¼è¨“ç·´ $F(x,y)$ ? é€™äº›å•é¡Œåœ¨æŸç¨®æƒ…æ³æœƒè®Šå¾—å¾ˆå¥½è§£ï¼Œä»€éº¼æƒ…æ³å‘¢? è‹¥æˆ‘å€‘å°‡ $F(x,y)$ å®šç¾©æˆ Linear Model (Problem 1 ç”¨ linear å®šç¾©)ï¼Œæˆ‘å€‘ç™¼ç¾è¨“ç·´è®Šå¾—å¾ˆå®¹æ˜“ (Problem 3 å¥½è§£) !! ç–‘?! Problem 2å‘¢? å…ˆç•¶ä½œå·²è§£å§ï¼Œã„ã„ã€‚ Linear Model of $F(x,y)=w\\cdot \\phi(x,y)$æˆ‘å€‘å…ˆå‡è£ Problem 2 å·²è§£ (Problem 2 è¦èƒ½è§£ depends on å•é¡Œçš„domainï¼Œå’Œfeatureçš„å®šç¾©)ï¼Œæˆ‘å€‘ä¾†çœ‹ä¸€ä¸‹è¦æ€éº¼è¨“ç·´é€™æ¨£çš„ linear modelã€‚é¦–å…ˆç”¨æè€å¸«èª²ç¨‹çš„ç¯„ä¾‹ (è¾¨è­˜åˆéŸ³) çš„ä¾‹å­èˆ‰ä¾‹ï¼Œå…¶ä¸­ $y$ æ˜¯ä¸€å€‹ bounding box:é€™å€‹ä¾‹å­æœ‰å…©å€‹ training pairs: $(x^1,\\hat{y}^1)$ å’Œ $(x^2,\\hat{y}^2)$ï¼Œæˆ‘å€‘å¸Œæœ›æ±‚å¾—ä¸€å€‹ $w$ ä½¿å¾—ç´…è‰²çš„åœ“åœˆæŠ•å½±åˆ° $w$ ä¸Šå¾Œè¦å¤§æ–¼æ‰€æœ‰è—è‰²çš„åœ“åœˆã€‚åŒç†ï¼Œç´…è‰²çš„æ˜Ÿæ˜Ÿè¦å¤§æ–¼æ‰€æœ‰è—è‰²çš„æ˜Ÿæ˜Ÿã€‚å…¶å¯¦æˆ‘å€‘ä»”ç´°æƒ³æƒ³ï¼Œé€™å•é¡Œè·Ÿ perceptron learning éå¸¸é¡ä¼¼ï¼Œperceptron learning åœ¨åšçš„æ˜¯ binary classificationï¼Œè€Œå¦‚æœæŠŠæ¯ä¸€ç­† training data $(x^i,\\hat{y}^i)$ å’Œ $(x^i,y:y\\neq\\hat{y}^i)$ ç•¶ä½œæ˜¯ positive and negative classesï¼Œå‰›å¥½å°±æ˜¯ä¸€å€‹ bineary classification problem (é›–ç„¶ä¸åŒç­† training data æœƒæœ‰å„è‡ªçš„ positive and negative è³‡æ–™ï¼Œä½†ä¸å½±éŸ¿æ•´å€‹å•é¡Œ)æ‰€ä»¥å¦‚æœæœ‰è§£ (linear separable)ï¼Œå‰‡æˆ‘å€‘å¯ä»¥ä½¿ç”¨ Structure Perceptron åœ¨æœ‰é™æ­¥é©Ÿå…§æ±‚è§£ã€‚ Structure Perceptron è­‰æ˜çš„æ¦‚å¿µè·Ÿ perceptron ä¸€æ¨£ï¼Œå°±æ˜¯å‡è¨­æœ‰è§£ï¼Œè§£ç‚º $\\hat{w}$ï¼Œè¦æ±‚æ¯ä¸€æ¬¡çš„ update $w^k$ï¼Œæœƒè·Ÿ $\\hat{w}$ æ„ˆä¾†æ„ˆæ¥è¿‘ï¼Œä¹Ÿå°±æ˜¯ $$\\begin{align} cos\\rho_k = \\frac{\\hat{w}\\cdot w^k}{\\Vert{\\hat{w}}\\Vert\\cdot\\Vert{w^k}\\Vert} \\end{align}$$ è¦æ„ˆå¤§æ„ˆå¥½!ä½†æˆ‘å€‘ä¹ŸçŸ¥é“ $cos$ æœ€å¤§å°± 1ï¼Œå› æ­¤å°±æœ‰ upper boundï¼Œæ‰€ä»¥æœƒåœ¨æœ‰é™æ­¥é©Ÿæå®šã€‚è©³ç´°æ¨å€’æ­¥é©Ÿå¯åƒè€ƒæè€å¸«è¬›ç¾©ï¼Œæˆ–çœ‹ perceptron çš„æ”¶æ–‚è­‰æ˜ã€‚ Cost Functionç”¨ cost function çš„è§’åº¦ä¾†èªªï¼Œå…¶å¯¦ perceptron è™•ç†çš„ cost æ˜¯è¨ˆç®—éŒ¯èª¤çš„æ¬¡æ•¸ï¼Œå¦‚æœå°‡ cost çš„ function ç•«å‡ºä¾†çš„è©±ï¼Œæœƒæ˜¯ step functionï¼Œè€Œç„¡æ³•åšå¾®åˆ†æ±‚è§£ã€‚å› æ­¤é€šå¸¸æœƒå°‡ cost function æ”¹æˆå¯å¾®åˆ†çš„æ–¹å¼ï¼Œä¾‹å¦‚ linear or quadratic or what ever continuous functionã€‚æ”¹æˆå¯å¾®åˆ†å°±æœ‰å¾ˆå¤šå¥½è™•äº†ï¼Œå¯ä»¥é‡å° cost function åšå¾ˆå¤šéœ€è¦çš„ä¿®æ”¹ï¼Œé€™äº›ä¿®æ”¹åŒ…æ‹¬ 1. å°ä¸åŒçš„éŒ¯èª¤æœ‰ä¸åŒçš„æ‡²ç½° 2. åŠ å…¥ regularization term â€¦ ç­‰ç­‰ï¼Œæˆ‘å€‘ç­‰ä¸‹æœƒè«‡åˆ°ã€‚ Picture is from Duda Pattern Classification å·¦åœ–å°±æ˜¯åŸä¾†çš„ perceptron costï¼Œè€Œå³åœ–å°±æ˜¯å°‡ cost æ”¹æˆ linear costã€‚Linear cost å¯å®šç¾©å¦‚ä¸‹:$$\\begin{align} C=\\sum_{n=1}^N C^n \\\\ C^n=(max_y[w\\cdot\\phi(x^n,y)])-w\\cdot\\phi(x^n,\\hat{y}^n) \\end{align}$$æ‰€ä»¥ï¼Œå°±gradient descentä¸‹å»å§ï¼Œè·ŸåŸä¾†çš„ perceptron learning æ”¹ cost function ä¸€æ¨£ã€‚ è®“éŒ¯èª¤çš„ç¨‹åº¦èƒ½è¡¨ç¾å‡ºä¾†é€™æ˜¯ä»€éº¼æ„æ€å‘¢? åŸä¾†çš„ cost function å°æ–¼æ¯ä¸€å€‹éŒ¯èª¤çš„æƒ…å½¢éƒ½ä¸€è¦–åŒä»ï¼Œä¹Ÿå°±æ˜¯åœ¨æ‰¾é‚£å€‹ $w$ çš„æ™‚å€™ï¼Œåªè¦éŒ¯èª¤çš„ä¾‹å­æŠ•å½±åœ¨ $w$ ä¸Šæ¯”æ­£ç¢ºçš„é‚„è¦å°å°±å¥½ï¼Œä¸åœ¨å¿½å°å¤šå°‘ï¼Œä½†äº‹å¯¦ä¸ŠéŒ¯èª¤æœƒæœ‰å¥½å£ä¹‹åˆ†ã€‚ä¸‹é¢æ˜¯ä¸€å€‹æè€å¸«çš„ä¾‹å­ï¼Œä¾‹å¦‚å³é‚Šé»ƒè‰²çš„æ¡†æ¡†é›–ç„¶è·Ÿæ­£ç¢ºç­”æ¡ˆç´…æ¡†æ¡†ä¸åŒ (æ‰€ä»¥è¢«ç•¶æˆéŒ¯èª¤çš„ä¾‹å­)ï¼Œä½†æœ‰å¤§è‡´ä¸Šéƒ½æŠ“åˆ°åˆéŸ³çš„è‡‰äº†ï¼Œå› æ­¤æˆ‘å€‘å¯ä»¥å…è¨±ä»–è·Ÿæ­£ç¢ºç­”æ¡ˆè¼ƒæ¥è¿‘ã€‚å› æ­¤ cost function å¯ä»¥ä¿®æ”¹ä¸€ä¸‹: $$\\begin{align} C=\\sum_{n=1}^N C^n \\\\ C^n=max_y[w\\cdot\\phi(x^n,y)+\\triangle(\\hat{y}^n,y)]-w\\cdot\\phi(x^n,\\hat{y}^n) \\end{align}$$ $\\triangle(\\hat{y}^n,y)$ å®šç¾©äº†é€™å€‹éŒ¯èª¤çš„ä¾‹å­é¡å¤–çš„ cost (éœ€&gt;=0)ï¼Œä»¥ bounding box è€Œè¨€ï¼Œèˆ‰ä¾‹ä¾†èªªå…©å€‹ set A and Bï¼Œ$\\triangle(A,B)$ å¯å®šç¾©ç‚º $1-/frac{A \\cap B}{A \\cup B}$ã€‚ä¸ééœ€è¦ç‰¹åˆ¥ä¸€æçš„æ˜¯ï¼Œå¤šå¢åŠ é€™å€‹é¡å¤–çš„å®šç¾©ï¼Œæœ‰å¯èƒ½ä½¿å¾—åŸä¾†å®¹æ˜“è§£çš„ $argmax_y$ (Problem 2) è®Šå¾—ç„¡æ³•è§£ï¼Œæ‰€ä»¥è¦æ³¨æ„ã€‚ Minimize the upper boundå¾ˆæœ‰è¶£çš„ä¸€é»æ˜¯ï¼Œåœ¨æˆ‘å€‘å¼•å…¥äº† $\\triangle(\\hat{y}^n,y)$ (ç¨±ç‚º margin, åœ¨å¾Œé¢è¬›åˆ° structure SVM å¯ä»¥çœ‹å¾—å‡ºä¾†) å¾Œï¼Œå¯ä»¥ç”¨å¦ä¸€å€‹è§€é»ä¾†çœ‹é€™å€‹å•é¡Œã€‚ å‡è¨­æˆ‘å€‘å¸Œæœ›èƒ½å°‡ $Câ€™$ æœ€å°åŒ–: $$\\begin{align} \\tilde{y}^n=argmax_y{w\\cdot \\phi(x^n,y)} \\\\ C&apos;=\\sum_{n=1}^N{\\triangle(\\hat{y}^n,\\tilde{y}^n)} \\end{align}$$ çµæœæˆ‘å€‘ç™¼ç¾å…¶å¯¦ $\\triangle(\\hat{y}^n,\\tilde{y}^n)\\leq C^n$ï¼Œå› è€Œè®Šæˆ è€Œæˆ‘å€‘ä¸Šé¢éƒ½æ˜¯åœ¨æœ€å°åŒ– $C$ï¼Œæ‰€ä»¥å…¶å¯¦æˆ‘å€‘åœ¨åšçš„äº‹æƒ…å°±æ˜¯åœ¨æœ€å°åŒ– $Câ€™$ çš„ upper boundã€‚ä¸Šç•Œçš„è­‰æ˜å¦‚ä¸‹:é€™ç¨®è—‰ç”±æœ€ä½³åŒ– upper bound çš„æ–¹å¼ï¼Œåœ¨ adaboost ä¹Ÿè¦‹éã€‚æ™®éä¾†èªªï¼ŒåŸä¾†çš„å¼å­ä¸å®¹æ˜“æœ€ä½³åŒ–çš„æ™‚å€™ï¼Œæˆ‘å€‘è—‰ç”±å®šç¾©ä¸€å€‹å®¹æ˜“æœ€ä½³åŒ–çš„upper boundï¼Œç„¶å¾Œæœ€å°åŒ–å®ƒã€‚å¦å¤–ï¼ŒEM æ¼”ç®—æ³•ä¹Ÿæœ‰é¡ä¼¼çš„æ¦‚å¿µã€‚ Regularizationç›´æ¥åŠ å…¥ norm-2 regularization:$$\\begin{align} C=\\frac{1}{2}\\Vert{w}\\Vert ^2+\\lambda\\sum_{n=1}^N C^n \\\\ C^n=max_y[w\\cdot\\phi(x^n,y)+\\triangle(\\hat{y}^n,y)]-w\\cdot\\phi(x^n,\\hat{y}^n) \\end{align}$$ Structure SVMå…ˆè¬›çµè«–: ä¸Šé¢ Linear Model æœ€å¾Œçš„ cost function (åŒ…å«marginal and regularization terms) å°±æ˜¯ç­‰åƒ¹æ–¼ SVMã€‚åŸå…ˆå•é¡Œ P1: Find $w$ that minimize $C$$$\\begin{align} C=\\frac{1}{2}\\Vert{w}\\Vert ^2+\\lambda\\sum_{n=1}^N C^n \\\\ C^n=max_y[w\\cdot\\phi(x^n,y)+\\triangle(\\hat{y}^n,y)]-w\\cdot\\phi(x^n,\\hat{y}^n) \\end{align}$$ æ”¹å¯«å¾Œçš„å•é¡Œ P2: Find $w$ that minimize $C$$$\\begin{align} C=\\frac{1}{2}\\Vert{w}\\Vert ^2+\\lambda\\sum_{n=1}^N C^n \\\\ For \\forall{y}: C^n\\geq w\\cdot\\phi(x^n,y)+\\triangle(\\hat{y}^n,y)-w\\cdot\\phi(x^n,\\hat{y}^n) \\end{align}$$ è§€å¯Ÿ P2ï¼Œæˆ‘å€‘æ³¨æ„åˆ°çµ¦å®šä¸€å€‹ $w$ æ™‚ï¼Œå®ƒæœ€å°çš„ $C^n$ æ‡‰è©²æœƒæ˜¯ä»€éº¼å‘¢? (æ‰¾æœ€å°æ˜¯å› ç‚ºæˆ‘å€‘è¦ minimize $C$) è­¬å¦‚æˆ‘è¦æ±‚ $x\\leq{ 5,1,2,10 }$ é€™å€‹å¼å­çš„ $x$ æœ€å°æ˜¯å¤šå°‘ï¼Œå¾ˆæ˜é¡¯å°±æ˜¯ $x=max{ 5,1,2,10 }$ã€‚å› æ­¤å¼ P2 çš„å¼ (13) å¯ä»¥å¯«æˆ P1 çš„å¼ (11)ã€‚å¯«æˆ P2 æœ‰ä»€éº¼å¥½è™•? é¦–å…ˆå°‡ $C^n$ æ”¹æˆ $\\epsilon^n$ï¼Œç„¶å¾Œå†ç¨å¾®æ”¹å¯«ä¸€ä¸‹å¾—åˆ°å¦‚ä¸‹çš„å•é¡Œ: å•é¡Œ P3: Find $w,\\epsilon^n,\\epsilon^2,â€¦,\\epsilon^N$ that minimize $C$$$C=\\frac{1}{2}\\Vert{w}\\Vert ^2+\\lambda\\sum_{n=1}^N \\epsilon^n \\\\ For \\forall{y}\\neq{\\hat{y}^n}: w\\cdot (\\phi(x^n,\\hat{y}^n)-\\phi(x^n,y))\\leq \\triangle (\\hat{y}^n,y)-\\epsilon^n,\\epsilon^n\\leq 0$$ æ³¨æ„åˆ°ï¼Œå°æ–¼ä¸€å€‹ n-th training pair $(x^n,\\hat{y}^n)$ å’Œçµ¦å®šä¸€å€‹ $y\\neq\\hat{y}^n$ ä¾†èªªï¼Œæˆ‘å€‘éƒ½æœƒå¾—åˆ°ä¸€å€‹ linear constraintã€‚å¯ä»¥å°‡ä¸Šé¢å¼å­çš„ constant ç”¨ a, bä¾†è¡¨ç¤ºè®Šæˆ:$w\\cdot a \\leq b - \\epsilon^n \\\\$ ç™¼ç¾äº†å—? å°æ–¼è®Šæ•¸ $w$ å’Œ $\\epsilon^n$ ä¾†èªªï¼Œé€™å°±æ˜¯ä¸€å€‹ linear constraintã€‚ çœ¼å°–çš„è®€è€…ï¼Œå¯èƒ½å°±æœƒè¦ºå¾— P3 å¾ˆçœ¼ç†Ÿã€‚æ²’éŒ¯!å®ƒè·Ÿ SVM é•·å¾ˆåƒ! è®“æˆ‘å€‘ä¾†è·Ÿ SVM çš„ Primal form (ä¸æ˜¯ dual form) åšå€‹æ¯”è¼ƒå§ã€‚å¯ä»¥ç™¼ç¾æœ‰å…©é»ä¸åŒï¼ŒåŸ SVM from wiki åˆ—å‡ºå¦‚ä¸‹: Margin term çš„ä¸åŒï¼ŒP3 çš„ margin æ¯”è¼ƒ generalï¼Œå¯ä»¥æ ¹æ“šæ¯å€‹ negative case éƒ½æœ‰è‡ªå·±çš„ marginï¼Œè€ŒåŸä¾† binary SVM çš„ margin æ˜¯å®šç‚º 1ã€‚ Constraint å€‹æ•¸çš„ä¸åŒï¼ŒåŸ SVM å€‹æ•¸ç‚º training data çš„å€‹æ•¸ï¼Œä½†æ˜¯ P3 çš„å€‹æ•¸ç‚ºç„¡çª®å¤šå€‹ã€‚ å‘¼! æ‰€ä»¥ P3 é€™å€‹å•é¡Œï¼Œå°±æ˜¯ SVM çš„ general ç‰ˆæœ¬ï¼Œæˆ‘å€‘ä¹Ÿç¨±ä¹‹ç‚º Structure SVMï¼Œé€™è£¡çµ‚æ–¼è·Ÿ SVM é€£çµä¸Šäº†! Cutting Plane AlgorithmåŸå…ˆ SVM æœ‰é™çš„ constraint ä¸‹ï¼Œæˆ‘å€‘ç›´æ¥ç”¨ä¸€å€‹ QP solverå¯ä»¥å¾ˆå¿«è™•ç†æ‰ã€‚ä½†åœ¨ Structure SVM æœ‰ç„¡çª®å¤šçš„ constraints ç©¶ç«Ÿè¦æ€éº¼è§£? æ˜¯å€‹å•é¡Œã€‚é¦–å…ˆè§€å¯Ÿåˆ°ï¼Œå…¶å¯¦å¾ˆå¤š constraints éƒ½æ˜¯ç„¡æ•ˆçš„ã€‚ä¾‹å¦‚:æ‰€ä»¥é€™å€‹æ¼”ç®—æ³•ç­–ç•¥å°±æ˜¯å¾ä¸€å€‹ç©ºçš„ working set $\\mathbb{A}^n$ å‡ºç™¼ï¼Œæ¯æ¬¡ iteration éƒ½æ‰¾ä¸€å€‹æœ€ violate çš„ constraint åŠ é€²å»ï¼Œç›´åˆ°ç„¡æ³•å†åŠ å…¥ä»»ä½•çš„ constraint ç‚ºæ­¢ã€‚é€™è£¡å…¶å¯¦æœ‰å…©å€‹å•é¡Œè¦è¨è«–ï¼Œç¬¬ä¸€å€‹æ˜¯ä»€éº¼æ˜¯æœ€ violate çš„ constraint? ç¬¬äºŒå€‹æ˜¯ï¼Œé€™æ¼”ç®—æ³•æœƒæ”¶æ–‚å—? é›£é“ä¸æœƒæ°¸é éƒ½æ‰¾å¾—åˆ° violate çš„ constraint ä¸€ç›´åŠ å…¥å—?æˆ‘å€‘å…ˆæŠŠæ¼”ç®—æ³•åˆ—å‡ºä¾†ï¼Œå†ä¾†è¨è«–ä¸Šé¢é€™å…©å€‹å•é¡Œã€‚ Most Violated Constraintç›´æ¥ç§€æè€å¸«çš„æŠ•å½±ç‰‡æ³¨æ„åˆ°åœ¨ Degree of Violation çš„æ¨å°ä¸­ï¼Œæ‰€æœ‰èˆ‡è®Šæ•¸ $y$ ç„¡é—œçš„éƒ¨åˆ†å¯ä»¥å»æ‰ã€‚å› æ­¤æˆ‘å€‘æœ€å¾Œå¯ä»¥å¾—åˆ°æ±‚ Most Violated Constraint å°±æ˜¯åœ¨æ±‚ Problem 2 ($argmax_y$)ã€‚æ³¨æ„åˆ°å…¶å¯¦æˆ‘å€‘ä¸€ç›´ â€œå…ˆå‡è£ Problem 2 å·²è§£â€ Convergence?è«–æ–‡ä¸­è­‰æ˜å¦‚æœè®“ violate çš„æ¢ä»¶æ˜¯å¿…é ˆè¶…éä¸€å€‹ threshold æ‰ç®— violatedï¼Œå‰‡æ¼”ç®—æ³•æœƒåœ¨æœ‰é™æ­¥é©Ÿå…§æ”¶æ–‚ã€‚åš´è¬¹çš„æ•¸å­¸è­‰æ˜è¦åƒè€ƒ paperã€‚ æœ€å¾Œçš„éº»ç…©: Problem 2 argmaxé€™ç¯‡å¯¦åœ¨æ‰“å¤ªé•·äº†ï¼Œä»¥è‡³æ–¼æˆ‘æƒ³çœç•¥é€™å€‹åœ°æ–¹äº† (æ·š)ï¼Œäº‹å¯¦ä¸Šè§£ Problem 2 å¿…é ˆçœ‹å•é¡Œæœ¬èº«æ˜¯ä»€éº¼ï¼Œä»¥ POS (Part-Of-Speech) tagging ä¾†èªªï¼ŒProblem 2 å¯ç”¨ Viterbi æ±‚è§£ã€‚è€Œé€™ä¹Ÿå°±æ˜¯ææ•™æˆä¸‹ä¸€å€‹èª²ç¨‹ Sequence Labeling Problemã€‚POS å¦‚ä½•å°æ‡‰åˆ° Structure Learning å¯¦åœ¨éå¸¸ç²¾å½©! çœŸçš„ä¸å¾—ä¸ä½©æœé€™äº›äººçš„æ™ºæ…§! æœ‰èˆˆè¶£çš„è®€è€…è«‹ä¸€å®šè¦çœ‹ææ•™æˆçš„æŠ•å½±ç‰‡å…§å®¹! ç°¡å–®ç­†è¨˜ä¸€ä¸‹: POS ä½¿ç”¨ HMM æ–¹å¼ä¾† modelï¼Œä¾‹å¦‚ä¸€å¥è©± x = â€œJohn saw the sawâ€ å°æ‡‰åˆ°è©æ€§ y = â€œPN V D Nâ€ã€‚ç„¶å¾ŒæŠŠè©æ€§ç•¶ä½œ state, word ç•¶ä½œ observationï¼Œå°±æ˜¯ä¸€å€‹å…¸å‹çš„ HMM çµæ§‹ã€‚æ¥è‘—ä½¿ç”¨ Conditional Random Field (CRF) å°‡ $log P(x,y)$ å°æ‡‰åˆ° $w\\cdot\\phi(x,y)$ çš„å½¢å¼ï¼Œåœ¨ $P(x,y)$ æ˜¯ç”± HMM å®šç¾©çš„æƒ…å½¢ä¸‹ï¼Œæˆ‘å€‘å¯ä»¥å¯«å‡ºç›¸å°æ‡‰çš„ $\\phi(x,y)$ è©²å¦‚ä½•å®šç¾©ã€‚å› æ­¤å°±è½‰æˆä¸€å€‹ structure learning çš„æ ¼å¼äº†ã€‚è©³ç´°è«‹åƒè€ƒæè€å¸«èª²ç¨‹è¬›ç¾©ã€‚ å½©è›‹ æˆ‘å¿ƒæ„›çš„æ™å¯¶è²ä¸‰æ­²ç”Ÿæ—¥å¿«æ¨‚! é€™å¹¾å¤©æœƒæœ‰ä¸€å€‹å¾ˆé‡å¤§çš„æ±ºå®šç™¼ç”Ÿ! Reference Hung-yi Lee ML courses Perceptron Learning Convergence Proof Duda Pattern Classification structureSVM åŸå§‹è«–æ–‡","tags":[{"name":"Structure SVM","slug":"Structure-SVM","permalink":"https://bobondemon.github.io/tags/Structure-SVM/"},{"name":"Structure Perceptron","slug":"Structure-Perceptron","permalink":"https://bobondemon.github.io/tags/Structure-Perceptron/"},{"name":"Hung-yi Lee","slug":"Hung-yi-Lee","permalink":"https://bobondemon.github.io/tags/Hung-yi-Lee/"}]},{"title":"çµ±ä¸€çš„æ¡†æ¶ Bayes Filter","date":"2017-05-10T14:15:16.000Z","path":"2017/05/10/Bayes-Filter-for-Localization/","text":"Bayes Filter Introductionå‰å¹¾ç¯‡è¨è«–äº†å¾ˆå¤š Kalman Filter ä»¥åŠå®ƒç›¸é—œçš„è®Šå½¢ï¼Œå¦‚: EKF and UKFã€‚é€™äº›æ–¹æ³•æˆ‘å€‘éƒ½å¯ä»¥æ”¾åœ¨ Bayes Filter çš„æ¡†æ¶ä¸‹ä¾†çœ‹ï¼Œé€™éº¼åšçš„è©±ï¼ŒKF å°±åªæ˜¯å…¶ä¸­ä¸€å€‹ç‰¹ä¾‹äº† (éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒçš„æƒ…å½¢)ã€‚è€Œå¦‚æœæˆ‘å€‘åªè€ƒæ…®å¹¾å€‹é›¢æ•£é»çš„æ©Ÿç‡ï¼Œä¸¦ç”¨è’™åœ°å¡ç¾…æ³•ä¾†æ¨¡æ“¬å–æ¨£çš„è©±ï¼Œé€™ç¨®å¯¦ä½œæ–¹å¼å°±æœƒæ˜¯ Particle Filter ã€‚æ‰€ä»¥æŒæ¡äº† Bayes Filter èƒŒå¾Œçš„é‹ä½œæ–¹å¼å°æ–¼ç†è§£é€™äº›æ–¹æ³•æ˜¯å¾ˆæœ‰å¹«åŠ©çš„ã€‚ä¸€äº›è®Šæ•¸çš„æ„ç¾©ä»ç„¶è·Ÿå‰å¹¾ç¯‡ä¸€æ¨£: z: measurementï¼Œä¹Ÿå°±æ˜¯æˆ‘å€‘å¯¦éš›ä¸Šç¶“ç”± sensor å¾—åˆ°çš„æ¸¬é‡å€¼ (æœƒæœ‰noise) x: stateï¼Œæˆ‘å€‘å¸Œæœ›ä¼°è¨ˆå‡ºä¾†çš„å€¼ï¼Œåœ¨ Localization ä¸€èˆ¬å°±æ˜¯åº§æ¨™å€¼ ç™¼ç¾äº†å—? åœ¨ä¸Šåœ–å³ KF çš„å…©å€‹æ­¥é©Ÿ: Measurement Update å’Œ State Prediction å¯¦éš›ä¸Šå°±æ˜¯ä¸Šåœ–å·¦é‚Šçš„å…©å€‹æ•¸å­¸å¼é—œä¿‚ã€‚æ­é…ä¸‹åœ–æ–‡å­—ä¸€èµ·çœ‹ï¼ŒMeasurement Update ç†è§£ç‚ºå¾—åˆ°ä¸€å€‹è§€å¯Ÿå€¼ $z$ å¾Œï¼Œæˆ‘å€‘ç”¨ Bayes Rule å¯ä»¥ä¼°æ¸¬å‡º state $x$ çš„äº‹å¾Œæ©Ÿç‡ $P(x|z)$ï¼Œè€Œè©²äº‹å¾Œæ©Ÿç‡ç¶“ç”± motion model (eg. CTRV) å¯ä»¥ä¼°æ¸¬å‡ºä¸‹ä¸€å€‹æ™‚é–“é»çš„ x æ©Ÿç‡åˆ†ä½ˆ $P(xâ€™)$ (æ­¤æ­¥é©Ÿç‚º State Prediction)ã€‚å¾—åˆ°æ–°çš„ $P(xâ€™)$ å°±å¯ä»¥ç•¶æˆä¸‹ä¸€å€‹æ™‚é–“é»çš„äº‹å‰æ©Ÿç‡ï¼Œæ‰€ä»¥ Bayes rule å°±å¯ä»¥æ¥è‘—ä¸‹å»é‡è¤‡æ­¤ loopã€‚ èˆ‡ Maximum a Posteriori (MAP) Adaptation çš„é—œä¿‚äº‹å¯¦ä¸Šï¼Œé€™æ¨£çš„æ¡†æ¶ä¹Ÿè·Ÿ MAP Adaptation æ¯æ¯ç›¸é—œ! ä¾‹å¦‚ç•¶äº‹å‰æ©Ÿç‡æ˜¯æŸäº›ç‰¹åˆ¥çš„æ©Ÿç‡åˆ†ä½ˆ (exponential family)ï¼Œç¶“ç”± Bayes rule å¾—åˆ°çš„äº‹å¾Œæ©Ÿç‡ï¼Œå®ƒçš„æ©Ÿç‡åˆ†ä½ˆæœƒè·Ÿäº‹å‰æ©Ÿç‡æ˜¯åŒä¸€é¡å‹çš„ï¼Œ(ä¾‹å¦‚éƒ½æ˜¯ Gaussian)ã€‚è€Œé€™æ¨£çš„é¸æ“‡æˆ‘å€‘ç¨±ç‚º conjugate priorã€‚ç”±æ–¼ â€œäº‹å¾Œâ€ èˆ‡ â€œäº‹å‰â€ æ©Ÿç‡æ˜¯åŒä¸€ç¨®é¡å‹çš„æ©Ÿç‡åˆ†ä½ˆï¼Œå› æ­¤æŠŠ â€œäº‹å¾Œæ©Ÿç‡â€ åœ¨ç•¶æˆä¸‹ä¸€æ¬¡è³‡æ–™ä¾†è‡¨æ™‚çš„ â€œäº‹å‰æ©Ÿç‡â€ ä¹Ÿå°±å¾ˆè‡ªç„¶äº†! é€™å°±æ˜¯ MAP Adaptation çš„æ ¸å¿ƒæ¦‚å¿µï¼Œèˆ‡ Bayes filter ä¸€æ¨¡ä¸€æ¨£é˜¿! Localization è©³ç´°å®šç¾©å¥½çš„ï¼Œæˆ‘å€‘ä¾†é‡å° Localization è©³ç´°è§£é‡‹å§ï¼Œåè©å®šç¾©å¦‚ä¸‹: è§€æ¸¬å€¼ (time 1~t)ã€æ§åˆ¶ (time 1~t)ã€å’Œåœ°åœ– $m$ éƒ½æ˜¯å‡è¨­å·²çŸ¥ï¼Œæˆ‘å€‘æ‰€ä¸çŸ¥çš„(è¦ä¼°æ¸¬çš„)æ˜¯ç›®å‰ time t çš„ç‹€æ…‹å€¼ $x$ã€‚èˆ‰ä¾‹ä¾†èªªï¼Œä¸€å€‹ä¸€ç¶­çš„åœ°åœ–å¦‚ä¸‹:è€Œè§€æ¸¬å€¼ $z_{1:t}$ å¦‚ä¸‹:å¯ä»¥çŸ¥é“æ¯ä¸€å€‹æ™‚é–“é»çš„è§€æ¸¬å€¼æ˜¯ä¸€å€‹ dimension ç‚º k çš„å‘é‡ã€‚ æ•´å€‹ Localization çš„ç›®çš„å°±æ˜¯è¦è¨ˆç®—å°æ–¼ä½ç½® $x$ æˆ‘å€‘æœ‰å¤šå°‘ä¿¡å¿ƒåº¦ï¼Œåš´è¬¹åœ°èªªï¼Œæˆ‘å€‘å°±æ˜¯è¦è¨ˆç®—å¦‚ä¸‹:$$\\begin{align} bel(x_t)=p(x_t|z_{1:t},u_{1:t},m) \\end{align}$$ æ„æ€æ˜¯åœ¨å·²çŸ¥ç›®å‰æ‰€æœ‰çš„è§€æ¸¬å€¼ã€æ§åˆ¶ã€å’Œåœ°åœ–çš„æƒ…æ³ä¸‹ï¼Œä½ç½® $x_t$ çš„æ©Ÿç‡æ˜¯å¤šå°‘ï¼Œçœ‹æ•¸å­¸å¼å­çš„è©±ï¼Œé€™ä¸å°±æ­£å¥½å°±æ˜¯ äº‹å¾Œæ©Ÿç‡ å—? æ‰€ä»¥ä¸Šé¢çš„ Bayes filter æ¶æ§‹å°±æœ‰ç™¼æ®çš„ç©ºé–“äº†ã€‚å¦å¤–ä¸€æçš„æ˜¯ï¼Œå¦‚æœå°‡åœ°åœ– $m$ ä¹Ÿç•¶æˆæœªçŸ¥çš„è©±ï¼Œå°±æ˜¯ SLAM æ¼”ç®—æ³•äº†ã€‚(é‚„æ²’æœ‰æ©Ÿæœƒå»è®€é€™å€‹æ¼”ç®—æ³•)ä¸‹åœ–æ˜¯ä¸€å€‹ä¸€ç¶­çš„ç¤ºæ„åœ–:ä½†æ˜¯è¦è¨ˆç®—é€™æ¨£çš„äº‹å¾Œæ©Ÿç‡ï¼Œå¿…é ˆè¦è€ƒæ…®å¾ä¸€é–‹å§‹åˆ°ç›®å‰æ™‚é–“é»çš„æ‰€æœ‰è§€æ¸¬å€¼å’Œæ§åˆ¶ï¼Œé€™æ¨£çš„è³‡æ–™é‡å¯¦åœ¨å¤ªå¤§ï¼Œè¨ˆç®—æœƒéå¸¸æ²’æœ‰æ•ˆç‡ã€‚å› æ­¤ï¼Œå¦‚æœèƒ½åªè€ƒæ…®ç›®å‰çš„è§€æ¸¬å€¼å’Œæ§åˆ¶ï¼Œä¸¦ç”¨ä¸Šä¸€å€‹æ™‚é–“çš„çš„äº‹å¾Œæ©Ÿç‡å°±èƒ½æ¨ç®—å‡ºä¾†çš„è©±ï¼Œå‹¢å¿…æœƒéå¸¸æœ‰æ•ˆç‡ã€‚ç°¡å–®ä¾†è¬›ï¼Œæˆ‘å€‘å¸Œæœ›ç”¨éè¿´çš„æ–¹å¼: è€ƒæ…® $bel(x_{t-1})$ å’Œç›®å‰çš„è§€æ¸¬å€¼ $z_t$ å’Œæ§åˆ¶ $u_t$ å°±èƒ½æ¨ç®— $bel(x)$ã€‚é€™å°±å¿…é ˆè¦ç°¡åŒ–ä¸Šé¢ $bel(x_t)$ åŸå§‹çš„å®šç¾©äº†ï¼Œè¦å¦‚ä½•é”åˆ°å‘¢? éœ€å€ŸåŠ© First-order Markov Assumption ã€‚ First-order Markov Assumption ç°¡åŒ– believe å‡è¨­ç›®å‰çš„æ™‚é–“é»ç‚º $t$ï¼Œæˆ‘å€‘çŸ¥é“è¦è¨ˆç®—çš„ believe $bel(x_t)$ ä»£è¡¨äº‹å¾Œæ©Ÿç‡ï¼Œå†å¥—ç”¨ Bayes rule ä¹‹å¾Œï¼Œå¯ä»¥å¾—åˆ°ä¸Šé¢çš„è¡¨ç¤ºã€‚ äº‹å¾Œæ©Ÿç‡ (Believe): ç‰¹åˆ¥æŠŠæ™‚é–“é» t çš„è§€æ¸¬å€¼å¾åŸå…ˆå®šç¾©æ‹‰å‡ºä¾†ï¼Œé€™æ˜¯è¦å¼·èª¿æˆ‘å€‘åœ¨å¾—åˆ°æœ€æ–°çš„è§€æ¸¬å€¼ $z_t$ å¾Œï¼Œå¸Œæœ›å»è¨ˆç®—æœ€æ–°çš„ believe äº‹å‰æ©Ÿç‡ (Motion Model): ç¨±ç‚º Motion Model æ˜¯å› ç‚ºå‡è¨­æˆ‘å€‘ç›®å‰åœ¨æ™‚é–“é» $t-1$ï¼Œæ¥è‘—æ‹¿åˆ°ä¸‹ä¸€æ¬¡çš„æ§åˆ¶ $u_t$ å¾Œï¼Œæˆ‘å€‘å¸Œæœ›ä¼°æ¸¬å‡ºä¸‹ä¸€æ¬¡çš„ç‹€æ…‹å€¼ $x_t$ æ˜¯ä»€éº¼ã€‚æœ‰çœ‹éå‰å¹¾ç¯‡çš„è®€è€…æ‡‰è©²é¦¬ä¸Šå°±èƒ½æƒ³åˆ°ï¼Œå¯ä»¥åˆ©ç”¨ CTRV ä¹‹é¡çš„ motion model å»è¨ˆç®—ã€‚ è§€æ¸¬å€¼æ©Ÿç‡ (Observation Model): é€™å€‹æ˜¯è¦è¨ˆç®—ç•¶ä¸‹çš„è§€æ¸¬å€¼çš„æ©Ÿç‡åˆ†ä½ˆï¼Œé€™éƒ¨åˆ†é€šå¸¸å°±æ˜¯ç¶“ç”± sensor data å¾—åˆ°å¾Œï¼Œæˆ‘å€‘å‡è¨­æ˜¯é«˜æ–¯åˆ†å¸ƒä¾†è¨ˆç®—ã€‚ Motion Model éè¿´ æˆ‘å€‘ç™¼ç¾åˆ°ï¼Œæœ€å¾Œä¸€è¡Œçš„çµæœï¼Œå°ç…§æœ¬æ–‡ç¬¬ä¸€å¼µåœ–çš„ State Prediction å¼å­æ˜¯ä¸€æ¨£çš„æ„æ€ï¼Œå·®åˆ¥åªåœ¨ä¸€å€‹æ˜¯é€£çºŒä¸€å€‹æ˜¯é›¢æ•£ã€‚å¦ä¸€å€‹å·®åˆ¥æ˜¯ï¼Œæ­¤å¼å­æ˜é¡¯å¯«å‡ºå¯ä»¥ç”¨ä¸Šä¸€æ¬¡çš„äº‹å¾Œæ©Ÿç‡åšéè¿´ï¼Œæ‰€ä»¥ç¬¬ä¸€å¼µåœ–çš„ Measurement Update è—è‰²ç®­é ­å°±é€™éº¼ä¾†çš„ã€‚ Observation Model ç°¡åŒ– Bayes Filter Summaryé‡æ–°æ•´ç†ä¸€ä¸‹ç¶“ç”± â€œMotion Model éè¿´â€ å’Œ â€œObservation Model ç°¡åŒ–â€ éå¾Œçš„äº‹å¾Œæ©Ÿç‡ $bel(x_t)$ï¼Œçµæœå¦‚ä¸‹åœ–å·¦ã€‚ (ä¸‹åœ–å³åªæ˜¯åˆ—å‡ºæœ¬æ–‡æœ€é–‹å§‹çš„ Bayes Filter å¼å­ä¾†åšå°ç…§)ã€‚çµè«–æ˜¯æˆ‘å€‘èŠ±äº†é‚£éº¼å¤§çš„åŠ›æ°£ï¼Œç”¨ä¸Šäº† 1st Markov Assumption å»è™•ç† Localization çš„éè¿´å¼å­å’Œç°¡åŒ–ï¼Œçµæœä¸æ„å¤–åœ°å°±å¦‚åŒé–‹å§‹çš„ Bayes Filter ä¸€æ¨£ã€‚ å¦å¤–ï¼Œå¯¦ä½œä¸Šå¦‚æœæ‰€æœ‰çš„ pdf éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒçš„è©±ï¼Œçµæœå°±æ˜¯ Kalman Filterã€‚è€Œå¦‚æœé€é sampling é›¢æ•£çš„ç‹€æ…‹ä½ç½®çš„è©±ï¼Œçµæœå°±æœƒæ˜¯ Particle Filterã€‚é€™éƒ¨åˆ†å°±å…ˆä¸å¤šèªªæ˜äº†ã€‚(é™„ä¸Šèª²ç¨‹ä¸€å¼µæˆªåœ–) æœ‰é—œ Particle Filter çš„å¯¦ä½œï¼Œåœ¨ Udacity Term2 Project3 ä¸­æˆ‘å€‘å¯¦ä½œä¸€å€‹äºŒç¶­åœ°åœ–çš„ localizationã€‚ç›¸é—œ Codes å¯åœ¨ç­†è€… github ä¸­æ‰¾åˆ°ã€‚ Reference Udacity ä¸Šèª²å…§å®¹ MAP Adaptaion éƒ¨åˆ†è©³ç´°å¯åƒè€ƒ: Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains","tags":[{"name":"Bayes Filter","slug":"Bayes-Filter","permalink":"https://bobondemon.github.io/tags/Bayes-Filter/"},{"name":"Localization","slug":"Localization","permalink":"https://bobondemon.github.io/tags/Localization/"},{"name":"Markov Localization","slug":"Markov-Localization","permalink":"https://bobondemon.github.io/tags/Markov-Localization/"},{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"}]},{"title":"Notes for Unscented Kalman Filter","date":"2017-04-12T12:50:16.000Z","path":"2017/04/12/Unscented-Kalman-Filter-Notes/","text":"è³‡æ–™ç‚º Udacity èª²ç¨‹å…§å®¹ã€‚äº‹å¯¦ä¸Š UKF æŒºå›‰å—¦çš„ï¼Œå–®ç´”çœ‹æœ¬æ–‡æ‡‰è©²ç„¡æ³•ç†è§£ï¼Œå¿…é ˆæ­é…å‰å…©ç¯‡ KF and EKF å’Œ CTRVã€‚ä¸»è¦æ˜¯ç­†è¨˜ç”¨ï¼Œè®“è‡ªå·±å¯ä»¥æ ¹æ“šæ–‡ç« å®Œæ•´å¯¦åšå‡ºä¾†ã€‚ ä¸€åˆ‡çš„ä¸€åˆ‡éƒ½ä¾†è‡ªæ–¼ Kalman Filter çš„ State-Space model å‡è¨­ï¼Œæˆ‘å€‘ä¾†ç¨å¾®å›é¡§ä¸€ä¸‹ã€‚ $$\\begin{align} x_k = F_kx_{k-1}+\\nu_k \\\\ z_k = H_kx_k+\\omega_k&Tab;\\\\ \\end{align}$$ å¼(1)è¡¨ç¤ºç‹€æ…‹å€¼ $x$ æ»¿è¶³ç·šæ€§çš„éè¿´é—œä¿‚å¼ï¼Œè€Œå¼(2)è¡¨ç¤ºè§€æ¸¬å€¼ $z$ æ˜¯ç•¶ä¸‹ç‹€æ…‹å€¼çš„ç·šæ€§é—œä¿‚å¼ã€‚é€™å€‹ç·šæ€§çš„é—œä¿‚å¼æ˜¯ç‚ºäº†ä½¿å¾—æˆ‘å€‘çš„é«˜æ–¯åˆ†å¸ƒåœ¨è½‰æ›å¾Œä»ç„¶æ»¿è¶³é«˜æ–¯åˆ†å¸ƒæ‰€åšçš„å‡è¨­ã€‚ä½†å¯¦éš›ä¸Šå¸¸å¸¸ä¸æ»¿è¶³ç·šæ€§çš„é—œä¿‚ï¼Œä¾‹å¦‚å‡è¨­æˆ‘å€‘çš„ $x$ åŒ…å«äº† Cartesian coordinate çš„åº§æ¨™ä½ç½®å’Œé€Ÿåº¦çš„è³‡è¨Šï¼Œä½†æ˜¯ RADAR çš„è§€æ¸¬å€¼ $z$ å»æ˜¯ç”¨ Polar coordinate ä¾†è¡¨ç¤ºï¼Œå°±æœƒæœ‰ä¸€å€‹éç·šæ€§çš„åº§æ¨™è½‰æ›ã€‚å¦ä¸€å€‹æœƒé€ æˆéç·šæ€§çš„æƒ…æ³æ˜¯ç™¼ç”Ÿåœ¨å¼(1)ï¼Œä¹Ÿå°±æ˜¯æˆ‘å€‘å¦‚æœä½¿ç”¨æ›´ç²¾ç¢ºçš„ motion modelï¼Œå¦‚ CTRVã€‚EKF è§£æ±ºçš„æ–¹æ³•æ˜¯ç”¨ Jacobian åšç·šæ€§çš„é€¼è¿‘ï¼Œä½†æ˜¯éç·šæ€§çš„é—œä¿‚å¼å¦‚æœä¸€è¤‡é›œï¼Œç®— Jacobian å°±æœƒå¤ªè¤‡é›œä¸”é€ æˆé‹ç®—é€Ÿåº¦è®Šæ…¢ã€‚å› æ­¤ï¼Œæœ¬ç¯‡è¦ä»‹ç´¹çš„ Unscented KF æœ‰ç›¸å°ç°¡å–®çš„è¾¦æ³•ï¼Œä¸¦ä¸”é‹ç®—é€Ÿåº¦å¿«ï¼Œä¸”å¯¦éš›æ•ˆæœå¥½ã€‚UKF æ¦‚å¿µä¸Šæ€éº¼åšå‘¢? æˆ‘å€‘çœ‹ä¸Šåœ–å°±å¯äº†è§£ï¼Œé¦–å…ˆåŸå§‹çš„é«˜æ–¯åˆ†å¸ƒ(ä¸Šé¢çš„ç´…è‰²æ©¢åœ“)ï¼Œç¶“ç”±éç·šæ€§è½‰æ› $f$ å¾Œå¾—åˆ°çš„ â€œå¯¦éš›åˆ†ä½ˆâ€ ç‚ºä¸‹é¢çš„é»ƒè‰²æ›²ç·šï¼Œè€Œè©²å¯¦éš›åˆ†å¸ƒçš„ mean å’Œ covariance matrix æ‰€å½¢æˆçš„çš„é«˜æ–¯åˆ†å¸ƒç‚ºä¸‹é¢çš„ç´…è‰²æ©¢åœ“ï¼Œä½†æ˜¯æˆ‘å€‘ä¸å®¹æ˜“å¾—åˆ°! é‚£éº¼æ€éº¼é€¼è¿‘ä¸‹é¢çš„ç´…è‰²æ©¢åœ“å‘¢? UKF åšæ³•å°±æ˜¯åœ¨ä¸Šåœ–é¸æ“‡ä¸€äº›ä»£è¡¨çš„é»ï¼Œç¨±ç‚º Sigma Pointsï¼Œç¶“é $f$ è½‰æ›å¾Œï¼Œå¯ä»¥å¾—åˆ°ä¸‹é¢çš„æ˜Ÿæ˜Ÿï¼Œç„¶å¾Œå°±å¯ä»¥æ ¹æ“šé€™äº›è½‰æ›å¾Œçš„æ˜Ÿæ˜Ÿå»è¨ˆç®—ä»–å€‘çš„ mean å’Œ covariance matrixï¼Œè€Œå¾—åˆ°è—è‰²çš„æ©¢åœ“ã€‚é‚£éº¼æˆ‘å€‘é¦¬ä¸Šé–‹å§‹èªªæ˜å¦‚ä½•è¨­å®š Sigma Points å§ã€‚ Sigma Points é¸æ“‡å‡è¨­ state dimension ç‚º $n_x$ï¼ŒSigma Points å°±é¸æ“‡ $2n_x+1$ å€‹é»ã€‚æˆ‘å€‘ä»¥ $n_x=2$ ä¾†èˆ‰ä¾‹èªªæ˜æœƒæ¯”è¼ƒæ¸…æ¥šï¼Œè€Œæ“´å±•åˆ°æ›´é«˜çš„ç¶­åº¦ä¹Ÿå°±éå¸¸ trivial äº†ã€‚ å¯ä»¥çŸ¥é“æˆ‘å€‘éœ€é¸æ“‡5å€‹é»($2n_x+1$)ï¼Œç¬¬ä¸€å€‹é»æ˜¯ mean vectorï¼Œæ¥è‘—é‡å°æ¯ä¸€å€‹ dimension éƒ½æ ¹æ“š mean vector å‘è©² dimension å»åšæ­£è² æ–¹å‘çš„ perturbï¼Œè€Œ $\\lambda$ è¡¨ç¤ºè¦ perturb å¤šé (ä½¿ç”¨è€…çµ¦å®šçš„å€¼)ã€‚ä½†æ˜¯è¦ç‰¹åˆ¥æ³¨æ„çš„æ˜¯ï¼Œé€™è£¡çš„ perturb dimension å¿…é ˆæ˜¯æ­£è¦åŒ–å¾Œçš„æ–¹å‘ (Whitening)ï¼Œå¦å‰‡è‹¥åŸä¾†çš„é«˜æ–¯åˆ†å¸ƒæŸä¸€å€‹æ–¹å‘ç‰¹åˆ¥å¤§(æƒ³åƒä¸€å€‹å¾ˆæ‰çš„æ©¢åœ“)ï¼Œä½¿ç”¨åŸä¾†çš„ covariance matrix å°±æœƒè¢«è©²æ–¹å‘ dominateã€‚ä¸Šä¾‹çš„ sigma points å¦‚ä¸‹: CTRV Sigma Pointsæˆ‘å€‘ä¾†çœ‹ CTRV model ä¸‹çš„ sigma points é¸æ“‡ï¼Œå…¶ä¸­ state vector and noise term åˆ†åˆ¥å®šç¾©å¦‚ä¸‹ $$\\begin{align} x= \\left( \\begin{array}{clr} p_x \\\\ p_y \\\\ v \\\\ \\psi \\\\ \\dot{\\psi} \\end{array} \\right) \\end{align}$$ $$\\begin{align} v_k= \\left[ \\begin{array}{center} v_{a,k} \\\\ v_{\\ddot{\\psi},k} \\end{array} \\right]\\\\ v_{a,k}\\sim N(0,\\sigma_a^2),v_{a,k}\\sim N(0,\\sigma_{\\ddot{\\psi}}^2) \\\\ Q=E[v_k,v_k^T]= \\left[ \\begin{array}{clr} \\sigma_a^2 &amp; 0 \\\\ 0 &amp; \\sigma_{\\ddot{\\psi}}^2 \\\\ \\end{array} \\right] \\end{align}$$ $v_k$ çš„ç¬¬ä¸€å€‹ term æ˜¯åŠ é€Ÿåº¦çš„ noiseï¼Œè€Œç¬¬äºŒå€‹è¡¨ç¤º yaw rate çš„è®ŠåŒ–ç‡ã€‚ç”±æ–¼åŸå§‹çš„ state recursion é‚„åƒé›œäº† $Stochastic_k$ é€™æ¨£çš„ vector (åƒè€ƒå¼(7)and(8))ï¼Œå› æ­¤è¦è¨ˆç®—ä»–å€‘çš„ covariance matrix æœƒå¤ªé›£æ! (å› ç‚ºæˆ‘å€‘éœ€è¦çŸ¥é“ covariance matrix æ‰èƒ½å°æ¯å€‹ whitening å¾Œçš„ç¶­åº¦å» perturb å–é») $$\\begin{align} x_{k+1}=x_k+Deterministic_k+ \\left[ \\begin{array}{center} \\frac{1}{2}(\\Delta{t})^2cos(\\psi_k)\\cdot v_{a,k} \\\\ \\frac{1}{2}(\\Delta{t})^2sin(\\psi_k)\\cdot v_{a,k} \\\\ \\Delta{t}\\cdot v_{a,k} \\\\ \\frac{1}{2}(\\Delta{t})^2\\cdot v_{\\ddot{\\psi},k} \\\\ \\Delta{t}\\cdot v_{\\ddot{\\psi},k} \\end{array} \\right]\\\\ x_{k+1}=x_k+Deterministic_k+Stochastic_k \\end{align}$$ æ¯”è¼ƒç°¡å–®çš„ä½œæ³•æ˜¯å°‡ noise term (å¼(4)) ç•¶æˆ state vector çš„å¦å¤–çš„ç¶­åº¦ï¼Œä¸»è¦çš„å¥½è™•æ˜¯ covariance matrix å°±è®Šå¾—å¾ˆå®¹æ˜“è¨ˆç®—äº†ã€‚ç„¶å¾Œä¸€æ¨£ç”¨ä¸Šè¿°çš„æ–¹å¼ç”¢ç”Ÿ Sigma Pointsã€‚å› æ­¤æ•´å€‹æµç¨‹å¦‚ä¸‹åœ–: å¯ä»¥çœ‹åˆ°åŸæœ¬ç¶­åº¦å¾5è®Šæˆ7ï¼Œå› æ­¤è¦ç”¢ç”Ÿ15é»çš„ sigma pointsï¼Œè€Œ augmentated state vector çš„ covariance matrix è®Šå¾—å¾ˆå®¹æ˜“å®šç¾©ã€‚ Sigma Points Predictionç”¢ç”Ÿäº†é€™äº› sigma points ä¹‹å¾Œï¼Œæˆ‘å€‘å°±å¯ä»¥é€éå¼(7)ï¼Œåš nonlinear recursion åˆ°ä¸‹ä¸€å€‹æ™‚é–“é»çš„ state vector (æ³¨æ„åˆ° noise term ä¹Ÿè¢« sigma points å–æ¨£äº†ï¼Œæ‰€ä»¥å¯ä»¥å¸¶å…¥å¼(7)ä¸­)! Mean and Covariance of Sigma Pointsé‚„è¨˜å¾—å—? å°‡ sigma point transform å¾Œï¼Œæˆ‘å€‘ä¸‹ä¸€æ­¥å°±æ˜¯è¦ä¼°è¨ˆå‡º mean å’Œ covarianceï¼Œå¿˜è¨˜çš„åŒé‹å€‘å¯ä»¥çœ‹ä¸€ä¸‹æœ¬æ–‡æœ€é–‹å§‹çš„åœ– (è—è‰²çš„é«˜æ–¯åˆ†å¸ƒ)ã€‚åŸºæœ¬ä¸Šæ ¹æ“šä¸€äº› data points ç®—å®ƒå€‘çš„é«˜æ–¯åˆ†å¸ƒéå¸¸ç°¡å–®ï¼Œä½†æ˜¯ç”±æ–¼æˆ‘å€‘ç•¶åˆå–çš„ sigma points å®ƒå€‘ä¹‹é–“æœ¬ä¾†çš„æ©Ÿç‡å°±ä¸åŒï¼Œå› æ­¤åœ¨è¨ˆç®—è½‰æ›å¾Œçš„é«˜æ–¯åˆ†å¸ƒå¿…é ˆè¦è€ƒæ…®æ¯å€‹é»çš„æ¬Šé‡ã€‚æ¬Šé‡çš„è¨­å®šæœ‰ä¸åŒæ–¹æ³•ï¼Œèª²ç¨‹ç›´æ¥å»ºè­°ä¸‹é¢çš„è¨­å®šï¼Œæ‰€ä»¥æ²’ç‰¹åˆ¥è¦èªªæ˜çš„ï¼Œå°±ç…§å…¬å¼è¨ˆç®—è€Œå·²: Measurement Predictionå°æ–¼ RADAR ä¾†èªªå¼(2)ä¹Ÿæ˜¯ä¸€å€‹éç·šæ€§çš„é—œä¿‚ï¼Œå› æ­¤ä¹Ÿå¯ä»¥ç”¨ sigma points çš„æ–¹æ³•ä¾†é€¼è¿‘ã€‚å‡è¨­æˆ‘å€‘åœ¨æ™‚é–“é» $k$ å–çš„ sigma points ç‚º $x$ï¼Œç¶“ééç·šæ€§ state recursion å¾Œå¾—åˆ°æ™‚é–“é» $k+1$ çš„ sigma points ç‚º $xâ€™$ï¼Œæˆ‘å€‘å¯ä»¥ç›´æ¥å°‡ $xâ€™$ ç•¶ä½œæ–°å–çš„ sigma pointsï¼Œæ‹¿ä¾†åš measurement éç·šæ€§è½‰æ› $zâ€™=h(xâ€™)+w$ï¼Œç„¶å¾Œä¸€æ¨£ç”¨ä¸Šé¢çš„å…¬å¼ç®—ä¸€ä¸‹ measurement space çš„é«˜æ–¯åˆ†å¸ƒå³å¯ã€‚RADAR çš„ $h()$ å®šç¾©å¦‚ä¸‹: $$\\begin{align} z=h(x)= \\left( \\begin{array}{clr} \\rho \\\\ \\phi \\\\ \\dot{\\rho} \\end{array} \\right) = \\left( \\begin{array}{clr} \\sqrt{p_x^2+p_y^2} \\\\ \\arctan(p_y/p_x) \\\\ \\frac{p_xcos(\\psi)v+p_ysin(\\psi)v}{\\sqrt{p_x^2+p_y^2}} \\end{array} \\right) \\end{align}$$ ç¨å¾®è¦æ³¨æ„çš„æ˜¯ï¼Œè¨ˆç®— covariance æ™‚é ˆè€ƒæ…® noise çš„ covariance (ä¸‹åœ–ç´…è‰²æ¡†èµ·ä¾†çš„åœ°æ–¹)ï¼Œé€™è·Ÿè¨ˆç®— state space ä¸­çš„é«˜æ–¯åˆ†å¸ƒä¸åŒã€‚é€™æ˜¯å› ç‚ºåœ¨ measurement space æ˜¯å…©å€‹ independent çš„é«˜æ–¯åˆ†å¸ƒç›¸åŠ  (ä¸€å€‹æ˜¯ sigma point ä¼°å‡ºä¾†çš„ï¼Œå¦ä¸€å€‹æ˜¯ noise çš„é«˜æ–¯)ï¼Œcovariance å°±æ˜¯ç›¸åŠ è€Œå·²ã€‚ å¦å¤–å°æ–¼ LIDAR ä¾†èªª measurement çš„è½‰æ›æ˜¯ç·šæ€§é—œä¿‚ï¼Œæ‰€ä»¥ä¸ä½¿ç”¨ sigma point çš„æ–¹æ³•ï¼Œå› æ­¤åœ¨è™•ç†å…©ç¨® sensor data æ™‚ï¼Œè¨˜å¾—å€åˆ†ä¸€ä¸‹ caseã€‚ Measurement Updateçµ‚æ–¼ä¾†åˆ°æœ€å¾Œçš„æ­¥é©Ÿäº†ã€‚æˆ‘å€‘è²»ç›¡åƒè¾›è¬è‹¦æ ¹æ“šæ™‚é–“é» $k$ çš„ state vector ä¼°è¨ˆå‡ºäº†æ™‚é–“é» $k+1$ çš„ measurement å€¼ï¼Œè€Œæ­¤æ™‚æˆ‘å€‘åœ¨æ™‚é–“é» $k+1$ ä¹Ÿæ”¶åˆ°äº†çœŸæ­£çš„ sensor data measurementã€‚å› æ­¤åŒæ¨£å¯ä»¥ä½¿ç”¨ KF çš„æµç¨‹å»è¨ˆç®—æ‰€æœ‰çš„ update! åŸå› æ˜¯æˆ‘å€‘å…¶å¯¦å…¨éƒ¨éƒ½é«˜æ–¯åŒ–äº† (é€é sigma points æ–¹æ³•)ã€‚ ç´…è‰²æ¡†èµ·ä¾†è™•ç‚ºè·Ÿä»¥å‰ä¸åŒçš„åœ°æ–¹ï¼Œè®Šæˆè¦è¨ˆç®— cross-correlation of â€œMeasurement Prediction é‚£å€‹ section çš„ç¬¬äºŒå¼µåœ–é‚£å…©æ’çš„ vectorsâ€ å¿ƒå¾—å…¶å¯¦æ¦‚å¿µä¸¦ä¸å›°é›£ï¼Œä½†æ˜¯é —å¤šè¨ˆç®—æµç¨‹å’Œç¬¦è™Ÿï¼ŒåŒæ™‚ä¹Ÿå¿…é ˆå…ˆäº†è§£ Kalman Filter å’Œ CTRV motion modelï¼Œä¸‹ä¸€æ­¥å°±å¯¦ä½œ Project å§! é™„ä¸Š predict çš„çµæœ:","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"Unscented Kalman Filter","slug":"Unscented-Kalman-Filter","permalink":"https://bobondemon.github.io/tags/Unscented-Kalman-Filter/"}]},{"title":"CTRV Motion Model","date":"2017-04-11T14:15:41.000Z","path":"2017/04/11/CTRV-Motion-Model/","text":"Motion Models è³‡æ–™ç‚º Udacity èª²ç¨‹å…§å®¹ åœ¨ä¸Šä¸€ç¯‡ EKF ä¸­ï¼Œæˆ‘å€‘å…¶å¯¦å‡è¨­çš„æ˜¯ constant velocity model (CV)ï¼Œä¹Ÿå°±æ˜¯å¦‚ä¸‹çš„é—œä¿‚å¼$$\\begin{align} x_k = Fx_{k-1}+\\nu_k \\\\ x_k= \\left( \\begin{array}{clr} p_x \\\\ p_y \\\\ v_x \\\\ v_y \\end{array} \\right), F= \\left( \\begin{array}{clr} 1 &amp; 0 &amp; \\Delta{t} &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; \\Delta{t} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{array} \\right) \\end{align}$$æ­£å¥½æ»¿è¶³ Kalman Filter ä¸­ State-space model çš„å‡è¨­ï¼Œä½†é€™æ¨£çš„ motion model å¾ˆæ˜é¡¯å¤ªå–®ç´”äº†ï¼Œå› ç‚ºè»Šå­ç¸½æ˜¯åœ¨è®Šé€Ÿä¸”è½‰å½ã€‚å› æ­¤çœŸå¯¦åœ¨ä½¿ç”¨çš„æ™‚å€™ä¸æœƒç”¨ CV modelï¼Œé‚£æœƒç”¨ä»€éº¼å‘¢? ä»¥ä¸‹ç‚ºå¹¾ç¨®å¯ç”¨çš„: constant turn rate and velocity magnitude model (CTRV) constant turn rate and acceleration (CTRA) constant steering angle and velocity (CSAV) constant curvature and acceleration (CCA) Udacity åœ¨é€™æ¬¡çš„ project ä¸­è®“æˆ‘å€‘ä½¿ç”¨äº† CTRVï¼Œè€Œæ­¤ model çš„ state vector $x$ å®šç¾©å¦‚ä¸‹:$$\\begin{align} x= \\left( \\begin{array}{clr} p_x \\\\ p_y \\\\ v \\\\ \\psi \\\\ \\dot{\\psi} \\end{array} \\right) \\end{align}$$å…¶ä¸­ $p_x,p_y$ æ˜¯ $x,y$ åº§æ¨™ä½ç½®ï¼Œ$v$ æ˜¯é€Ÿåº¦çš„ magnitudeï¼Œ$\\psi$ æ˜¯é€Ÿåº¦çš„å‘é‡èˆ‡æ°´å¹³è»¸çš„å¤¾è§’ç¨± yaw angelï¼Œæœ€å¾Œçš„ $\\dot{\\psi}$ å‰‡æ˜¯è©²å¤¾è§’çš„è®ŠåŒ–ç‡ç¨± yaw rateã€‚è€Œ CTRV å‡è¨­çš„æ˜¯ $v$ å’Œ $\\dot{\\psi}$ æ˜¯ constantã€‚è€Œæ­¤ model å·²ä¸æ˜¯ä¸€å€‹ç·šæ€§ç³»çµ±äº†ï¼Œä¹Ÿå°±æ˜¯ç„¡æ³•ç”¨ matrix ä¾†è¡¨é”ï¼Œæ‰€ä»¥æˆ‘å€‘å°‡å¼(1)æ”¹ç‚ºå¦‚ä¸‹çš„è¡¨é”æ–¹å¼:$$\\begin{align} x_{k+1} = f(x_k,\\nu_k) \\end{align}$$å¦‚ä½•å°‡ function $f$ å¯«æˆéè¿´å¼å­å‘¢? è«‹çœ‹ä¸‹ä¸€æ®µ CTRV State Vector Recursionæˆ‘å€‘å…ˆå¿½ç•¥ noise $\\nu_k$ é€™é …ï¼Œæ™šé»å†åŠ å›ä¾†ã€‚State vector éš¨æ™‚é–“è®ŠåŒ–çš„å¼å­å¦‚ä¸‹:$$\\begin{align} x_{k+1}=x_k+\\int_{t_k}^{t_{k+1}}{ \\left[ \\begin{array} \\\\ \\dot{p}_x(t) \\\\ \\dot{p}_y(t) \\\\ \\dot{v}(t) \\\\ \\dot{\\psi}(t) \\\\ \\ddot{\\psi}(t) \\end{array} \\right] }dt\\\\ x_{k+1}=x_k+ \\left[ \\begin{array}{center} \\int_{t_k}^{t_{k+1}}{v(t)\\cdot cos(\\psi(t))}dt \\\\ \\int_{t_k}^{t_{k+1}}{v(t)\\cdot sin(\\psi(t))}dt \\\\ 0 \\\\ \\dot{\\psi}_k\\cdot\\Delta{t} \\\\ 0 \\end{array} \\right] \\end{align}$$æ³¨æ„åˆ° CTRV çš„å‡è¨­ $v$ å’Œ $\\dot{\\psi}$ æ˜¯ constantï¼Œä¹Ÿå°±æœƒé€ æˆå¼(5)ä¸­ $\\dot{v}(t)=\\ddot{\\psi(t)}=0$ï¼Œä¸”å¾æ™‚é–“ $k$ åˆ° $k+1$ çš„ $\\dot{\\psi}(t)$ éƒ½ç­‰æ–¼ $\\dot{\\psi}_k$ï¼Œä¹Ÿå› æ­¤å¾—åˆ°å¼(6)ã€‚ä½†æ˜¯æˆ‘å€‘ä»ç„¶è¦è™•ç†å¼(6)å‰å…©é …çš„ç©åˆ†ï¼Œé¦–å…ˆä¸€æ¨£åŸºæ–¼CTRVå‡è¨­ $v(t)=v_k$ å°æ–¼æ™‚é–“ $k$ åˆ° $k+1$ éƒ½æ˜¯ä¸€æ¨£ï¼Œæ‰€ä»¥æåˆ°ç©åˆ†å¤–é¢ã€‚ç„¶å¾Œç”±æ–¼ yaw rate æ˜¯ constantï¼Œå› æ­¤ $\\psi(t)$ å¯ä»¥æ˜ç¢ºè¡¨ç¤ºå‡ºä¾†ï¼Œç¸½ä¹‹æ”¹å¯«å¦‚ä¸‹:$$\\begin{align} x_{k+1}=x_k+ \\left[ \\begin{array}{center} v_k\\int_{t_k}^{t_{k+1}}{cos(\\psi_k+\\dot{\\psi}_k\\cdot(t-t_k))}dt \\\\ v_k\\int_{t_k}^{t_{k+1}}{sin(\\psi_k+\\dot{\\psi}_k\\cdot(t-t_k))}dt \\\\ 0 \\\\ \\dot{\\psi}_k\\cdot\\Delta{t} \\\\ 0 \\end{array} \\right] \\end{align}$$ç„¶å¾Œæ²’ä»€éº¼å¥½èªªçš„ï¼Œå°±ç©å®ƒå§:$$\\begin{align} x_{k+1}=x_k+ \\left[ \\begin{array}{center} \\frac{v_k}{\\dot{\\psi}_k}(sin(\\psi_k+\\dot{\\psi}_k\\Delta{t})-sin(\\psi_k)) \\\\ \\frac{v_k}{\\dot{\\psi}_k}(-cos(\\psi_k+\\dot{\\psi}_k\\Delta{t})+cos(\\psi_k)) \\\\ 0 \\\\ \\dot{\\psi}_k\\cdot\\Delta{t} \\\\ 0 \\end{array} \\right] =x_k+Deterministic_k \\end{align}$$é€™é‚Šæœ‰ä¸€å€‹å¯¦ä½œä¸Šéœ€è¦é¿å…çš„åœ°æ–¹ï¼Œå°±æ˜¯ç•¶ $\\dot{\\psi}_k=0$ æ™‚ï¼Œä¸Šå¼çš„ç¬¬1,2é …æœƒé™¤0ã€‚ä¸éæˆ‘å€‘çŸ¥é“ç•¶ $\\dot{\\psi}_k=0$ è¡¨ç¤ºè»Šå­æ˜¯ç›´ç›´å¾€å‰é–‹ï¼Œyaw angleä¸æœƒæ”¹è®Šï¼Œå› æ­¤å¯¦éš›ä¸Šå¯ä»¥ç”¨å¦‚ä¸‹ä¾†è¨ˆç®—:$$\\begin{align} x_{k+1}=x_k+ \\left[ \\begin{array}{center} v_kcos(\\psi_k)\\Delta{t} \\\\ v_ksin(\\psi_k)\\Delta{t} \\\\ 0 \\\\ \\dot{\\psi}_k\\cdot\\Delta{t} \\\\ 0 \\end{array} \\right] =x_k+Deterministic&apos;_k \\end{align}$$ Recursion With Noise TermNoise term $v_k$ é€™è£¡æ˜¯å‡è¨­å¦‚ä¸‹:$$\\begin{align} v_k= \\left[ \\begin{array}{center} v_{a,k} \\\\ v_{\\ddot{\\psi},k} \\end{array} \\right] \\end{align}$$ ç¬¬ä¸€å€‹ term æ˜¯åŠ é€Ÿåº¦çš„ noiseï¼Œè€Œç¬¬äºŒå€‹è¡¨ç¤º yaw rate çš„è®ŠåŒ–ç‡ã€‚è€ƒæ…®å¦‚æœæœ‰é€™å…©é … noises çš„è©±ï¼Œä¸¦ä¸”å‡è¨­æ™‚é–“ $k$ åˆ° $k+1$ é€™å…©å€‹ noises çš„å€¼æ˜¯å›ºå®šçš„ï¼Œé‚£éº¼ state vector æœƒè®Šæˆå¦‚ä¸‹:$$\\begin{align} x_{k+1}=x_k+Deterministic_k+ \\left[ \\begin{array}{center} \\frac{1}{2}(\\Delta{t})^2cos(\\psi_k)\\cdot v_{a,k} \\\\ \\frac{1}{2}(\\Delta{t})^2sin(\\psi_k)\\cdot v_{a,k} \\\\ \\Delta{t}\\cdot v_{a,k} \\\\ \\frac{1}{2}(\\Delta{t})^2\\cdot v_{\\ddot{\\psi},k} \\\\ \\Delta{t}\\cdot v_{\\ddot{\\psi},k} \\end{array} \\right]\\\\ x_{k+1}=x_k+Deterministic_k+Stochastic_k \\end{align}$$ç¬¬ä¸‰é …æ˜¯é€Ÿåº¦ $v$ æœƒè¢«åŠ é€Ÿåº¦ $v_{a,k}$ é€™ç¨® noise æ€éº¼å½±éŸ¿ï¼Œæ‰€ä»¥å¾ˆæ˜é¡¯æ˜¯ç·šæ€§å¢åŠ ï¼ŒåŒç†ç¬¬å››å’Œç¬¬äº”é …ä¹Ÿå¾ˆå®¹æ˜“å¾—åˆ°ã€‚ç¬¬ä¸€å’Œç¬¬äºŒé …ï¼Œ$x$ and $y$ çš„ä½ç½®é€™è£¡å°±æ¯”è¼ƒéº»ç…©ï¼Œå› æ­¤æ¡ç”¨çš„æ˜¯ä¸€å€‹è¿‘ä¼¼è€Œå·²ã€‚é€™é‚Šå‡è¨­ yaw rate æ²’æœ‰å¤ªé«˜çš„æƒ…æ³ä¸‹ï¼Œä¸‹åœ–çš„å…©å€‹ç´…è‰²åœˆåœˆä½ç½®æ‡‰è©²æ˜¯å¾ˆæ¥è¿‘ï¼Œå› æ­¤æˆ‘å€‘å¯ä»¥è€ƒæ…®èµ°ç›´ç·šçš„ç´…è‰²åœˆåœˆä½ç½®ï¼Œä¹Ÿå°±å¾—åˆ°äº†(11)ç¬¬ä¸€äºŒé …çš„è¿‘ä¼¼å€¼ã€‚ Summary All CTRVçœç•¥è§£é‡‹ï¼Œå¯«å‡º state recursion çš„è¨ˆç®—ã€‚$$x= \\left( \\begin{array}{clr} p_x \\\\ p_y \\\\ v \\\\ \\psi \\\\ \\dot{\\psi} \\end{array} \\right)$$ if $\\dot{\\psi}_k\\neq0$, then$x_{k+1}=x_k+Deterministic_k+Stochastic_k$where$$Deterministic_k= \\left[ \\begin{array}{center} \\frac{v_k}{\\dot{\\psi}_k}(sin(\\psi_k+\\dot{\\psi}_k\\Delta{t})-sin(\\psi_k)) \\\\ \\frac{v_k}{\\dot{\\psi}_k}(-cos(\\psi_k+\\dot{\\psi}_k\\Delta{t})+cos(\\psi_k)) \\\\ 0 \\\\ \\dot{\\psi}_k\\cdot\\Delta{t} \\\\ 0 \\end{array} \\right]$$and$$Stochastic_k= \\left[ \\begin{array}{center} \\frac{1}{2}(\\Delta{t})^2cos(\\psi_k)\\cdot v_{a,k} \\\\ \\frac{1}{2}(\\Delta{t})^2sin(\\psi_k)\\cdot v_{a,k} \\\\ \\Delta{t}\\cdot v_{a,k} \\\\ \\frac{1}{2}(\\Delta{t})^2\\cdot v_{\\ddot{\\psi},k} \\\\ \\Delta{t}\\cdot v_{\\ddot{\\psi},k} \\end{array} \\right]$$otherwise $\\dot{\\psi}_k=0$, then$x_{k+1}=x_k+Deterministic&apos;_k+Stochastic_k$where$$Deterministic&apos;_k= \\left[ \\begin{array}{center} v_kcos(\\psi_k)\\Delta{t} \\\\ v_ksin(\\psi_k)\\Delta{t} \\\\ 0 \\\\ \\dot{\\psi}_k\\cdot\\Delta{t} \\\\ 0 \\end{array} \\right]$$ Unscented Kalman Filter ç°¡ä»‹ç”±æ–¼ CTRV æ˜¯éç·šæ€§çš„ï¼Œæœƒç ´å£ State-space model çš„ç·šæ€§å‡è¨­ï¼Œä¾‹å¦‚ä¸‹åœ–ä¸­åŸå…ˆç´…è‰²çš„é«˜æ–¯åˆ†å¸ƒç¶“ééç·šæ€§è½‰æ›å¾Œåˆ†å¸ƒç‚ºé»ƒè‰²ã€‚ä¸éæˆ‘å€‘çŸ¥é“ EKF å¯ä»¥åˆ©ç”¨ Jaccobian matrix åšç·šæ€§é€¼è¿‘è¨ˆç®—ï¼Œæ‰€ä»¥æˆ‘å€‘åŒæ¨£å¯ä»¥è¨ˆç®—ã€‚ä½†è¦è¨ˆç®—ä¸Šè¿°éç·šæ€§ç³»çµ±çš„ Jaccobian matrix å¯¦åœ¨é¡¯å¾—æœ‰é»è¤‡é›œï¼Œå¥½åœ¨ Unscented KF å¯ä»¥å®Œå…¨é¿é–‹é€™å€‹éº»ç…©ã€‚å®ƒåˆ©ç”¨é¸æ“‡å¹¾å€‹ä»£è¡¨çš„ candidates vectorsï¼Œå«åš Sigma Pointsï¼Œå»è¨ˆç®—ç¶“ééç·šæ€§è½‰æ›å¾Œçš„å€¼ï¼Œç„¶å¾Œå°±å¯ä»¥å¾—åˆ° output domain çš„ mean å’Œ covariance matrixï¼Œä¹Ÿå°±æ˜¯ä¸Šåœ–çš„ç¶ è‰²é«˜æ–¯åˆ†å¸ƒã€‚é€™é‚Šè¦æ³¨æ„çš„æ˜¯ï¼Œoutput domain çš„çœŸå¯¦åˆ†ä½ˆä¸æ˜¯é«˜æ–¯åˆ†å¸ƒ(é»ƒè‰²)ï¼Œä½†æˆ‘å€‘ä»ç„¶å°‡å®ƒç•¶æˆæ˜¯é«˜æ–¯åˆ†å¸ƒ(ç¶ è‰²)å»è¨ˆç®— mean å’Œ covariance matrixï¼Œå› ç‚ºé€™æ¨£æ‰èƒ½ç¹¼çºŒå¥—ç”¨ Kalman filter çš„æ–¹æ³•ã€‚èªªåˆ°é€™å¯çŸ¥é“ UKF ä»ç„¶åªæ˜¯é€¼è¿‘ï¼Œä¸éæ ¹æ“š Udacity çš„èªªæ³•ï¼Œå¯¦éš›æ‡‰ç”¨ä¸Š UKF æ˜¯å¾ˆå¿« (ä¸ç”¨è¨ˆç®— Jaccobian) ä¸”å¯¦éš›ä¸Šæ•ˆæœå¾ˆå¥½!ä¸‹å›é å‘Šï¼ŒUKFå®Œæ•´ä»‹ç´¹ã€‚","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"Motion Model","slug":"Motion-Model","permalink":"https://bobondemon.github.io/tags/Motion-Model/"},{"name":"Unscented Kalman Filter","slug":"Unscented-Kalman-Filter","permalink":"https://bobondemon.github.io/tags/Unscented-Kalman-Filter/"}]},{"title":"Notes for Kalman Filter and Extended KF","date":"2017-04-03T08:56:13.000Z","path":"2017/04/03/Kalman-Filter-and-Extended-KF-Notes/","text":"Udacity term2 (Sensor Fusion, Localization, and Control) çš„ç¬¬ä¸€å€‹ Project å°±æ˜¯ç”¨ KF and EKF å°‡ Lidar and Radar çš„è³‡è¨Šåš fusion ä¸¦ä¸”å¯ä»¥ trackingã€‚ç”±æ–¼ KF/EKF çš„æ•¸å­¸ç¬¦è™Ÿå¾ˆå¤šï¼Œå› æ­¤æƒ³ç­†è¨˜ä¸€ä¸‹æ–¹ä¾¿æ—¥å¾Œå›æƒ³ï¼Œæ‰€ä»¥ä¸»è¦ä»¥æˆ‘è‡ªå·±çœ‹çš„è§’åº¦ï¼Œå¯èƒ½æœ‰äº›åœ°æ–¹æœƒæ²’æœ‰æ˜ç¢ºèªªæ˜ã€‚æœ¬ç¯‡çš„ç­†è¨˜ä¾†æºæ˜¯ é€™è£¡ï¼Œé€™ç¯‡çœŸçš„è¬›çš„è¶…æ£’çš„ï¼Œæ¸…æ¥šæ˜“æ‡‚! éå¸¸å»ºè­°ç›´æ¥å»çœ‹! Udacity èª²ç¨‹å…§å®¹ è‹¥è¦å¯¦ä½œæ‰€æœ‰çš„è¨ˆç®—æµç¨‹ä¸ç®¡ç†è«–çš„è©±ï¼Œå¯ç›´æ¥è·³åˆ° â€œ7. ç¸½çµ Lidar and Radar Fusionâ€ã€‚ State Space Modelé€™æ˜¯æ•´å€‹ KF/EKF çš„æ¨¡å‹å‡è¨­ï¼Œå¯«å‡ºä¾†å¦‚ä¸‹: $$\\begin{align} x_k = F_kx_{k-1}+\\nu_k \\\\ z_k = H_kx_k+\\omega_k \\end{align}$$ \\(x_k\\) æ˜¯åœ¨æ™‚é–“é» \\(t\\) çš„ statesï¼Œä¹Ÿæ˜¯æˆ‘å€‘å¸Œæœ›èƒ½å¤ ä¼°è¨ˆå‡ºä¾†çš„(ä½†æ˜¯ç„¡æ³•ç›´æ¥è§€å¯Ÿåˆ°)ã€‚è€Œ states æ»¿è¶³ ç·šæ€§çš„ä¸€æ¬¡éè¿´ é—œä¿‚ï¼Œä¹Ÿå°±æ˜¯å¼å­(1)ã€‚ \\(\\nu_k\\sim\\mathcal{N}(0,Q_k)\\) æ˜¯ state noseã€‚\\(z_k\\) æ˜¯åœ¨æ™‚é–“é» \\(t\\) çš„ observationsï¼Œé€é \\(H_k\\) å°‡ states è½‰æ›åˆ° observationsã€‚ \\(\\omega_k\\sim\\mathcal{N}(0,R_k)\\) æ˜¯ sensor noiseï¼Œè€Œ \\(R_k\\) åŸºæœ¬ä¸Šæœƒç”±è£½é€ å» å•†æä¾›ã€‚åŸºæœ¬ä¸Šå…©å€‹ noises éƒ½è·Ÿæ‰€æœ‰äººéƒ½ independentã€‚ Prediction Stageæ•´å€‹ KF/EKF éƒ½æ˜¯åŸºæ–¼ Gaussian distributionã€‚å› æ­¤å‡è¨­æˆ‘å€‘æœ‰ \\(k-1\\) æ™‚é–“é»çš„ state ä¼°è¨ˆï¼Œæ‰€ä»¥æˆ‘å€‘çŸ¥é“ \\(x_{k}\\sim\\mathcal{N}(\\hat{x}_k,P_k)\\) æœƒè®Šæˆå¦‚ä¸‹çš„ä¸€å€‹ Gaussian: $$\\begin{align} \\hat{x}_{k}=F_k\\hat{x}_{k-1} \\\\ P_k = F_kP_{k-1}F_k^T+Q_k \\end{align}$$ å¼(3)and(4)å³ç‚º Prediction Stageã€‚åˆå› ç‚ºæˆ‘å€‘çŸ¥é“ observation è·Ÿ state ä¹‹é–“çš„é—œä¿‚ç‚ºé€é \\(H_k\\) è½‰æ›ï¼Œåœ¨å®Œå…¨æ²’æœ‰ sensor noise æƒ…æ³ä¸‹ï¼Œæ‰€ä»¥å¯ä»¥å¾—çŸ¥ prediction çš„è§€å¯Ÿå€¼ç‚º: $$\\begin{align} z_{expected}\\sim\\mathcal{N}(\\mu_{expected},\\Sigma_{expected}) \\\\ \\mathcal{N}\\left( \\begin{array}{c} \\vec{\\mu}_{expected}=H_k\\hat{x}_{k}, &amp; \\Sigma_{expected} = H_kP_kH_k^T \\end{array} \\right) \\end{align}$$ Update Stageæˆ‘å€‘ä»¤å¯¦éš›ä¸Šçš„è§€å¯Ÿå€¼ç‚º \\(z_k\\sim\\mathcal{N}(\\vec{z}_k,R_k)\\)ï¼Œå°‡è§€å¯Ÿå€¼çš„ Gaussian å’Œ predict çš„ Gaussian ç•«å‡ºå¦‚ä¸‹: è€Œå°‡å…©å€‹ Gaussian pdfs ç›¸ä¹˜çš„è©±:$$\\begin{align} \\mathcal{N}(x,\\mu_0,\\Sigma_0)\\cdot\\mathcal{N}(x,\\mu_1,\\Sigma_1)=\\mathcal{N}(x,\\mu&apos;,\\Sigma&apos;) \\\\ \\end{align}$$ä»ç„¶æœƒå¾—åˆ°å¦ä¸€å€‹ Gaussian:$$\\begin{align} K=\\Sigma_0(\\Sigma_0+\\Sigma_1)^{-1} \\\\ \\mu&apos;=\\mu_0+K(\\mu_1-\\mu_0) \\\\ \\Sigma&apos;=\\Sigma_0-K\\Sigma_0 \\end{align}$$ \\(K\\) ç¨±ç‚º Kalman Gainã€‚ç”±å¼(10)å¯çŸ¥ï¼Œupdate å¾Œçš„ covariance matrix æœƒæ„ˆä¾†æ„ˆå°ï¼Œè¡¨ç¤ºæˆ‘å€‘å°æ–¼ prediction çš„è§€å¯Ÿå€¼æœƒæ„ˆä¾†æ„ˆç¢ºå®šã€‚å¦å¤–ç”±(9)å¯çŸ¥ï¼ŒKalman Gain æ§åˆ¶è‘—è¦ç›¸ä¿¡å“ªé‚Šå¤šä¸€é»ã€‚æŠŠä¼°æ¸¬çš„è§€å¯Ÿå€¼ pdf å’Œå¯¦éš›è§€å¯Ÿå€¼çš„ pdfï¼Œå³ \\(z_k\\sim\\mathcal{N}(\\vec{z}_k,R_k)\\) å’Œå¼(5)å…©å€‹ pdfs ä»£å…¥åˆ°å¼ (8)~(10) å¾—åˆ°å¦‚ä¸‹: $$\\begin{align} H_k\\hat{x}_k&apos;=H_k\\hat{x}_k+K(\\vec{z}_k-H_k\\hat{x}_k) \\\\ H_kP_k&apos;H_k^T=H_kP_kH_k^T-KH_kP_kH_k^T \\\\ K=H_kP_kH_k^T(H_kP_kH_k^T+R_k)^{-1} \\end{align}$$ æŠŠ (11)~(13) é–‹é ­çš„ \\(H_k\\) å»æ‰ï¼Œä¸¦ä¸”æŠŠ (12) and (13) çµå°¾çš„ \\(H_k^T\\) å»æ‰è®Šæˆ$$\\begin{align} \\hat{x}_k&apos;=\\hat{x}_k+K(\\vec{z}_k-H_k\\hat{x}_k) \\\\ P_k&apos;=P_k-KH_kP_k \\\\ K=P_kH_k^T(H_kP_kH_k^T+R_k)^{-1} \\end{align}$$ (14)~(16)å°±æ˜¯ KF çš„ Update Stage! æ–°çš„ states ä¼°è¨ˆå€¼å°±è¢«æˆ‘å€‘å¾—åˆ°ï¼Œç„¶å¾Œé€™å€‹å€¼å°±å¯ä»¥è¢«ç•¶æˆä¸‹ä¸€æ¬¡ loop çš„åˆå§‹å€¼ã€‚ KF Flowæ“·å–ç¶²ç«™ä¸Šçš„åœ–ç‰‡: Lidar/Radar çš„ä¸€äº›è¨­å®šstate å®šç¾©ç‚º \\(x=(p_x,p_y,v_x,v_y)\\) åˆ†åˆ¥æ˜¯ (x çš„ä½ç½®, y çš„ä½ç½®, x çš„é€Ÿåº¦, y çš„é€Ÿåº¦)ã€‚ \\(F_k\\) æœƒæ ¹æ“šå…©æ¬¡ sensor data ä¹‹é–“çš„æ™‚é–“é–“éš” \\(\\vartriangle t\\) ä¾†è¡¨ç¤º: å¦å¤–æˆ‘å€‘å°‡ åŠ é€Ÿåº¦è€ƒæ…®ç‚ºä¸€å€‹ mean = 0, covariance matrix = Q çš„ä¸€å€‹ random noise çš„è©±ï¼Œå¼ (1) and (4) å¿…é ˆåšä¿®æ”¹ã€‚å…¶ä¸­ \\(Q_v\\) ä½¿ç”¨è€…è‡ªå·±è¨­å®šèª¿æ•´ï¼Œæ‰€ä»¥ state noise çš„ covariance matrix ç‚º Lidar åªæœƒè§€å¯Ÿåˆ°ä½ç½®ï¼Œå› æ­¤ Lidar çš„ \\(H\\) ç‚º:$$H_{lidar}= \\left( \\begin{array}{clr} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\end{array} \\right)$$ Radar å°±æ¯”è¼ƒç‰¹åˆ¥äº†ï¼Œå®ƒè§€å¯Ÿåˆ°çš„æ˜¯ä»¥ polar coordinate ä¾†è¡¨ç¤ºã€‚æ‰€ä»¥å®ƒçš„ states å’Œ observation ä¹‹é–“çš„é—œä¿‚ç„¡æ³•ç”¨ä¸€å€‹ matrix \\(H\\) ä¾†ä»£è¡¨ï¼Œæ˜¯å¦‚ä¸‹çš„ non-linear å¼å­:$$\\begin{align} h(x)= \\left( \\begin{array}{clr} \\rho \\\\ \\phi \\\\ \\dot{\\rho} \\end{array} \\right) = \\left( \\begin{array}{clr} \\sqrt{p_x^2+p_y^2} \\\\ \\arctan(p_y/p_x) \\\\ \\frac{p_xv_x+p_yv_y}{\\sqrt{p_x^2+p_y^2}} \\end{array} \\right) \\end{align}$$ ç‚ºäº†è®“å®ƒç¬¦åˆ state-space model çš„ç·šæ€§å¼å­ï¼Œåªå¥½ä½¿ç”¨ Taylor å±•é–‹å¼ï¼Œåªä½¿ç”¨ Jaccobian matrix é‡å° \\(h\\) å»å±•é–‹ï¼Œè€Œé€™å€‹å°±æ˜¯ Extended KFã€‚ EKFç¨å¾®æ”¹å¯«ä¸€ä¸‹ Update Stage:$$\\begin{align} y=(\\vec{z}_k-H_k\\hat{x}_k) \\\\ S=H_kP_kH_k^T+R_k \\\\ \\hat{x}_k&apos;=\\hat{x}_k+Ky \\\\ P_k&apos;=P_k-KH_kP_k \\\\ K=P_kH_k^TS^{-1} \\end{align}$$åœ¨ EKF ä¸­ï¼Œç”±æ–¼æˆ‘å€‘ä½¿ç”¨ Taylor å±•é–‹å¼å»é€¼è¿‘ \\(h\\)ï¼Œå› æ­¤ä¸Šè¿°çš„ \\(H_k\\) å¿…é ˆä½¿ç”¨å¦‚ä¸‹å¼å­è¨ˆç®—:ä½†æ˜¯ï¼Œé€™é‚Šé‚„æœ‰ä¸€å€‹ tricky çš„åœ°æ–¹! å°±æ˜¯ å¼(18)ç›´æ¥ä½¿ç”¨å¼(17) \\(h\\) çš„ non-linear function è¨ˆç®—!å›æƒ³ä¸€ä¸‹æˆ‘å€‘å°‡ \\(h\\) åš linearlization çš„ç›®çš„: å°±æ˜¯å¼(5),(6)ä¸‹çš„é‚£å¼µåœ–çš„è½‰æ›ã€‚å¦‚æœ Gaussian pdf ç¶“é nonlinear è½‰æ›å¾Œæœƒè®Šæˆ â€œéGaussianâ€ï¼Œå› æ­¤åªå¥½åšç·šæ€§é€¼è¿‘ã€‚æ—¢ç„¶ç·šæ€§è½‰æ›çš„ pdf éƒ½å·²ç¶“æ˜¯é€¼è¿‘äº†ï¼Œä¸å¦‚å°±å°‡ mean ä½¿ç”¨æœ€ç²¾ç¢ºçš„å€¼ï¼Œå› æ­¤ \\(y\\) å°±ç›´æ¥ä½¿ç”¨å¼(17)è¨ˆç®—ã€‚æ‰€ä»¥å¼(18)è¦æ”¹æˆ:$$\\begin{align} y=(\\vec{z}_k-h(\\hat{x}_k)) \\end{align}$$ ç¸½çµ Lidar and Radar Fusion [Predict]$$\\hat{x}_{k}=F_k\\hat{x}_{k-1} \\\\ P_k = F_kP_{k-1}F_k^T+Q$$ where [Lidar Update]$$y=(\\vec{z}_k-H_{lidar}\\hat{x}_k) \\\\ S=H_{lidar}P_kH_{lidar}^T+R_k \\\\ \\hat{x}_k&apos;=\\hat{x}_k+Ky \\\\ P_k&apos;=P_k-KH_{lidar}P_k \\\\ K=P_kH_{lidar}^TS^{-1}$$ where \\(R_k\\) sensor noise covariance matrix ç”±å» å•†æä¾›, and $$H_{lidar}= \\left( \\begin{array}{clr} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\end{array} \\right)$$ [Radar Update]$$y=(\\vec{z}_k-h(\\hat{x}_k)) \\\\ S=H_kP_kH_k^T+R_k \\\\ \\hat{x}_k&apos;=\\hat{x}_k+Ky \\\\ P_k&apos;=P_k-KH_kP_k \\\\ K=P_kH_k^TS^{-1}$$ where \\(R_k\\) sensor noise covariance matrix ç”±å» å•†æä¾›, and $$h(x)= \\left( \\begin{array}{clr} \\rho \\\\ \\phi \\\\ \\dot{\\rho} \\end{array} \\right) = \\left( \\begin{array}{clr} \\sqrt{p_x^2+p_y^2} \\\\ \\arctan(p_y/p_x) \\\\ \\frac{p_xv_x+p_yv_y}{\\sqrt{p_x^2+p_y^2}} \\end{array} \\right)$$ Reference How a Kalman filter works, in pictures Udacity Term2 Lecture","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"Kalman Filter","slug":"Kalman-Filter","permalink":"https://bobondemon.github.io/tags/Kalman-Filter/"},{"name":"Extended Kalman Filter","slug":"Extended-Kalman-Filter","permalink":"https://bobondemon.github.io/tags/Extended-Kalman-Filter/"}]},{"title":"WGAN Part 2: ä¸»è§’ W ç™»å ´","date":"2017-03-17T13:25:12.000Z","path":"2017/03/17/WGAN-Part-2/","text":"å‰æƒ…æè¦GAN ä½œè€…è¨­è¨ˆå‡ºä¸€å€‹ Minimax gameï¼Œè®“å…©å€‹ players: ç”Ÿæˆå™¨ G å’Œ é‘‘åˆ¥å™¨ D å»å½¼æ­¤ç«¶çˆ­ï¼Œä¸¦ä¸”é”åˆ°å¹³è¡¡é»æ™‚ï¼Œæ­¤å•é¡Œé”åˆ°æœ€ä½³è§£ä¸”ç”Ÿæˆå™¨ G éŠæˆã€‚å¤§è‡´ä¸Šè¨“ç·´æµç¨‹ç‚ºå…ˆ optimize é‘‘åˆ¥å™¨ D for some iterationsï¼Œç„¶å¾Œæ› optimize ç”Ÿæˆå™¨ G (åœ¨ optimize G æ™‚ï¼Œæ­¤å•é¡Œç­‰åƒ¹æ–¼æœ€ä½³åŒ– JSD è·é›¢)ï¼Œé‡è¤‡ä¸Šè¿° loop ç›´åˆ°é”åˆ°æœ€ä½³è§£ã€‚ä½†æ˜¯ä»”ç´°çœ‹çœ‹åŸä¾†çš„æœ€ä½³åŒ–å•é¡Œä¹‹è¨­è¨ˆï¼Œæˆ‘å€‘çŸ¥é“åœ¨æœ€ä½³åŒ– G çš„æ™‚å€™ï¼Œç­‰åƒ¹æ–¼æœ€ä½³åŒ–ä¸€å€‹ JSD è·é›¢ï¼Œè€Œ JSD åœ¨é‡åˆ°çœŸå¯¦è³‡æ–™çš„æ™‚æœƒå¾ˆæ‚²åŠ‡ã€‚æ€éº¼æ‚²åŠ‡å‘¢? åŸå› æ˜¯çœŸå¯¦è³‡æ–™éƒ½å­˜åœ¨ local manifold ä¸­ï¼Œé€ æˆ training data çš„ p.d.f. å’Œ ç”Ÿæˆå™¨çš„ p.d.f. å½¼æ­¤ä¹‹é–“ç„¡äº¤é›† (æˆ–äº¤é›†çš„æ¸¬åº¦ç‚º0)ï¼Œåœ¨é€™ç¨®ç‹€æ³ JSD = log2 (constant) almost every whereã€‚ä¹Ÿå› æ­¤é€ æˆ gradients = 0ã€‚é€™æ˜¯ GAN å¾ˆé›£è¨“ç·´çš„ä¸€å€‹ä¸»å› ã€‚ ä¹Ÿå› æ­¤ WGAN çš„ä¸»è¦æ²»æœ¬æ–¹å¼å°±æ˜¯æ›æ‰ JSDï¼Œæ”¹ç”¨ Wasserstein (Earth-Mover) distanceï¼Œè€Œä¿®æ”¹éå¾Œçš„æ¼”ç®—æ³•ä¹Ÿæ˜¯ç°¡å–®å¾—é©šäºº! Wasserstein (Earth-Mover) distanceæˆ‘å€‘å…ˆçµ¦å®šç¾©å¾Œï¼Œå†ç”¨ä½œè€…è«–æ–‡ä¸Šçš„ç¯„ä¾‹è§£é‡‹å®šç¾©å¦‚ä¸‹:$$\\begin{align} W(\\mathbb{P}_r,\\mathbb{P}_g)=\\inf_{\\gamma\\in\\prod(\\mathbb{P}_r,\\mathbb{P}_g)}E_{(x,y)\\sim \\gamma}[\\Vert x-y \\Vert] \\end{align}$$\\(\\gamma\\)æŒ‡çš„æ˜¯ real data and fake data çš„ joint distributionï¼Œå…¶ä¸­ marginal ç‚ºå„è‡ªå…©å€‹ distributionsã€‚å…ˆåˆ¥è¢«é€™äº›ç¬¦è™Ÿåš‡åˆ°ï¼Œç›´è§€çš„è§£é‡‹ç‚º: EM è·é›¢å¯ä»¥ç†è§£ç‚ºå°‡æŸå€‹æ©Ÿç‡åˆ†ä½ˆæ¬åˆ°å¦ä¸€å€‹æ©Ÿç‡åˆ†ä½ˆï¼Œæ‰€è¦èŠ±çš„æœ€å°åŠ›æ°£ã€‚ æˆ‘å€‘ç”¨ä¸‹é¢é€™å€‹ä¾‹å­æ˜ç¢ºèˆ‰ä¾‹ï¼Œå‡è¨­æˆ‘å€‘æœ‰å…©å€‹æ©Ÿç‡åˆ†ä½ˆ f1 and f2:$$\\begin{align*} f_1(a)=f_1(b)=f_1(c)=1/3 \\\\\\\\ f_1(A)=f_1(B)=f_1(C)=1/3 \\end{align*}$$é€™å…©å€‹æ©Ÿç‡åˆ†ä½ˆåœ¨ä¸€å€‹ 2 ç¶­å¹³é¢ï¼Œå¦‚ä¸‹:è€Œå…©å€‹ \\(\\gamma\\) å°æ‡‰åˆ°å…©ç¨® æ¬é‹é…å°æ³•$$\\begin{align*} \\gamma_1(a,A)=\\gamma_1(b,B)=\\gamma_1(c,C)=1/3 \\\\\\\\ \\gamma_2(a,B)=\\gamma_2(b,C)=\\gamma_2(c,A)=1/3 \\end{align*}$$å¯ä»¥å¾ˆå®¹æ˜“çŸ¥é“å®ƒå€‘çš„ marginal distributions æ­£å¥½ç¬¦åˆ f1 and f2 çš„æ©Ÿç‡åˆ†ä½ˆã€‚å‰‡é€™å…©ç¨®æ¬é‹æ³•é€ æˆçš„ EM distance åˆ†åˆ¥å¦‚ä¸‹:$$\\begin{align*} EM_{\\gamma_1}=\\gamma_1(a,A)*\\Vert a-A \\Vert + \\gamma_1(b,B)*\\Vert b-B \\Vert + \\gamma_1(c,C)*\\Vert c-C \\Vert \\\\\\\\ EM_{\\gamma_2}=\\gamma_2(a,B)*\\Vert a-B \\Vert + \\gamma_2(b,C)*\\Vert b-C \\Vert + \\gamma_2(c,A)*\\Vert c-A \\Vert \\end{align*}$$æ˜é¡¯çŸ¥é“ $\\theta=EM_{\\gamma_1}&lt;EM_{\\gamma_2}$è€Œ EM distance å°±æ˜¯åœ¨ç®—æ‰€æœ‰æ¬é‹æ³•ä¸­ï¼Œæœ€å°çš„é‚£å€‹ï¼Œä¸¦å°‡é‚£æœ€å°çš„ cost å®šç¾©ç‚ºæ­¤å…©æ©Ÿç‡åˆ†ä½ˆçš„è·é›¢ã€‚é€™å€‹è·é›¢å¦‚æœæ˜¯å…©æ¢å¹³è¡Œ 1 ç¶­çš„ç›´ç·š pdf (ä¸Šé¢çš„ä¾‹å­æ˜¯ç›´ç·šä¸Šåªæœ‰ä¸‰å€‹é›¢æ•£è³‡æ–™é»)ï¼Œæœƒæœ‰å¦‚ä¸‹çš„ cost: å°æ¯”æ­¤åœ–å’Œä¸Šä¸€ç¯‡çš„ JSD çš„çµæœï¼ŒEM èƒ½å¤ æ­£ç¢ºä¼°ç®—å…©å€‹æ²’æœ‰äº¤é›†çš„æ©Ÿç‡åˆ†ä½ˆçš„è·é›¢ï¼Œç›´æ¥çš„çµæœå°±æ˜¯ gradient é€£çºŒä¸”å¯å¾® ! ä½¿å¾— WGAN è¨“ç·´ä¸Šç©©å®šéå¸¸å¤šã€‚ ä¸€å€‹é—œéµçš„å¥½æ€§è³ª: Wasserstein (Earth-Mover) distance è™•è™•é€£çºŒå¯å¾®åŸå§‹ EM distance çš„å®šç¾© (å¼(1)) æ˜¯ intractableä¸€å€‹ç¥å¥‡çš„æ•¸å­¸å…¬å¼ (Kantorovich-Rubinstein duality) å°‡ EM distance è½‰æ›å¦‚ä¸‹:$$\\begin{align} W(\\mathbb{P}_r,\\mathbb{P}_\\theta)=\\sup_{\\Vert f \\Vert _L \\leq 1}{ E_{x \\sim \\mathbb{P}_r}[f(x)] - E_{x \\sim \\mathbb{P}_\\theta}[f(x)] } \\end{align}$$æ³¨æ„åˆ° sup æ˜¯é‡å°æ‰€æœ‰æ»¿è¶³ 1-Lipschitz çš„ functions fï¼Œå¦‚æœæ”¹æˆæ»¿è¶³ K-Lipschitz çš„ functionsï¼Œå‰‡å€¼æœƒç›¸å·®ä¸€å€‹ scale Kã€‚ä½†æ˜¯åœ¨å¯¦ä½œä¸Šæˆ‘å€‘éƒ½ä½¿ç”¨ä¸€å€‹ family of functionsï¼Œä¾‹å¦‚ä½¿ç”¨æ‰€æœ‰äºŒæ¬¡å¼çš„ functionsï¼Œæˆ–æ˜¯ Mixture of Gaussiansï¼Œç­‰ç­‰ã€‚è€Œç¶“éè¿‘å¹¾å¹´æ·±åº¦å­¸ç¿’çš„ç™¼å±•å¾Œï¼Œæˆ‘å€‘å¯ä»¥ç›¸ä¿¡ï¼Œä½¿ç”¨ DNN ç•¶ä½œ family of functions æ˜¯å¾ˆæ´½ç•¶çš„é¸æ“‡ï¼Œå› æ­¤å‡å®šæˆ‘å€‘çš„ NN æ‰€æœ‰åƒæ•¸ç‚º \\(W\\)ï¼Œå‰‡ä¸Šå¼å¯ä»¥è¡¨é”æˆ:$$\\begin{align} W(\\mathbb{P}_r,\\mathbb{P}_\\theta)\\approx\\max_{w\\in W}{ E_{x \\sim \\mathbb{P}_r}[f_w(x)] - E_{z \\sim p(z)}[f_w(g_{\\theta}(z))] } \\end{align}$$é€™è£¡ä¸å†æ˜¯ç­‰å¼ï¼Œè€Œæ˜¯é€¼è¿‘ï¼Œä¸é Deep Learning å„ªç•°çš„ Regression èƒ½åŠ›æ˜¯å¯ä»¥å¾ˆå¥½åœ°é€¼è¿‘çš„ã€‚ æˆ‘å€‘é‚„æ˜¯éœ€è¦ä¿è­‰æ•´å€‹ EM distance ä¿æŒè™•è™•é€£çºŒå¯å¾®åˆ†ï¼Œé€™æ¨£å¯ä»¥ç¢ºä¿æˆ‘å€‘åš gradient-based æœ€ä½³åŒ–å¯ä»¥é †åˆ©ï¼Œé‡å°é€™é»ï¼ŒWGAN ä½œè€…å¾ˆå¼·å¤§åœ°è­‰æ˜å®Œäº†ï¼Œå¾—åˆ°çµè«–å¦‚ä¸‹: é‡å°ç”Ÿæˆå™¨ \\(g_\\theta\\)ä»»ä½• feed-forward NN çš†å¯ é‡å°é‘‘åˆ¥å™¨ \\(f_w\\)ç•¶ \\(W\\) æ˜¯ compact set æ™‚ï¼Œè©² family of functions \\(\\{f_w\\}\\) æ»¿è¶³ K-Lipschitz for some Kã€‚å…·é«”å¯¦ç¾å¾ˆå®¹æ˜“ï¼Œå› ç‚ºåœ¨ \\(R^d\\) spaceï¼Œcompact set ç­‰åƒ¹æ–¼ closed and boundedï¼Œå› æ­¤åªéœ€è¦é‡å°æ‰€æœ‰çš„åƒæ•¸å– bounding boxå³å¯!è«–æ–‡è£¡ä½¿ç”¨äº† [-0.01,0.01] é€™å€‹ç¯„åœåš clippingã€‚ èˆ‡ GAN ç¬¬ä¸€å€‹ä¸åŒé»ç‚º: é‘‘åˆ¥å™¨åƒæ•¸å– clippingã€‚ EM distance ç‚ºç›®æ¨™å‡½å¼æ‰€é€ æˆçš„ä¸åŒæˆ‘å€‘å°‡å…©è€…çš„ç›®æ¨™å‡½å¼åˆ—å‡ºä¾†åšå€‹æ¯”è¼ƒ$$\\begin{align} GAN: E_{x \\sim \\mathbb{P}_r} [\\log f_w(x)] + E_{z \\sim p(z)}[\\log (1-f_w(g_{\\theta}(z)))] \\\\ WGAN: E_{x \\sim \\mathbb{P}_r}[f_w(x)] - E_{z \\sim p(z)}[f_w(g_{\\theta}(z))] \\end{align}$$ç™¼ç¾åˆ° WGAN ä¸å– logï¼ŒåŒæ™‚å°ç”Ÿæˆå™¨çš„ç›®æ¨™å‡½å¼ä¹Ÿåšäº†ä¿®æ”¹ èˆ‡ GAN ç¬¬äºŒå€‹ä¸åŒé»ç‚º: WGAN çš„ç›®æ¨™å‡½å¼ä¸å– logï¼ŒåŒæ™‚å°ç”Ÿæˆå™¨çš„ç›®æ¨™å‡½å¼ä¹Ÿåšäº†ä¿®æ”¹ã€‚ ç¬¬ä¸‰å€‹ä¸åŒé»æ˜¯ä½œè€…å¯¦é©—çš„ç™¼ç¾ èˆ‡ GAN ç¬¬ä¸‰å€‹ä¸åŒé»ç‚º: ä½¿ç”¨ Momentum é¡çš„æ¼”ç®—æ³•ï¼Œå¦‚ Adamï¼Œæœƒä¸ç©©å®šï¼Œå› æ­¤ä½¿ç”¨ SGD or RMSPropã€‚ WGAN æ¼”ç®—æ³•ç¸½çµä¸€ä¸‹èˆ‡ GAN çš„ä¿®æ”¹è™• A. é‘‘åˆ¥å™¨åƒæ•¸å– clippingã€‚B. WGAN çš„ç›®æ¨™å‡½å¼ä¸å– logï¼ŒåŒæ™‚å°ç”Ÿæˆå™¨çš„ç›®æ¨™å‡½å¼ä¹Ÿåšäº†ä¿®æ”¹ã€‚C. ä½¿ç”¨ SGD or RMSPropã€‚ WGAN çš„å„ªé»ä¸€: ç›®æ¨™å‡½å¼èˆ‡è¨“ç·´å“è³ªé«˜åº¦ç›¸é—œåŸå§‹çš„ GAN æ²’æœ‰é€™æ¨£çš„è©•é‡æŒ‡æ¨™ï¼Œå› æ­¤æœƒåœ¨è¨“ç·´ä¸­é€”ç”¨äººçœ¼å»æª¢æŸ¥è¨“ç·´æ˜¯å¦æ•´å€‹å£æ‰äº†ã€‚ WGAN è§£æ±ºäº†é€™å€‹éº»ç…©ã€‚ä½œè€…çš„ç¯„ä¾‹å¦‚ä¸‹ï¼Œå¯ä»¥ç™¼ç¾WGANçš„ç›®æ¨™å‡½å¼ Loss æ„ˆä½ï¼Œsamplingå‡ºä¾†çš„å“è³ªæ„ˆé«˜ã€‚ äºŒ: é‘‘åˆ¥å™¨å¯ä»¥ç›´æ¥è¨“ç·´åˆ°æœ€å¥½åŸå§‹çš„ GAN éœ€è¦å°å¿ƒè¨“ç·´ï¼Œä¸èƒ½ä¸€ä¸‹å­æŠŠé‘‘åˆ¥å™¨è¨“ç·´å¤ªå¼·å°è‡´å°å‡½æ•¸å£æ‰ ä¸‰: ä¸éœ€è¦ç‰¹åˆ¥è¨­è¨ˆ NN çš„æ¶æ§‹GNN ä½¿ç”¨ MLP (Fully connected layers) é›£ä»¥è¨“ç·´ï¼Œè¼ƒæˆåŠŸçš„éƒ½æ˜¯ CNN æ¶æ§‹ï¼Œä¸¦æ­é… batch normalizationã€‚è€Œåœ¨ WGAN æ¼”ç®—æ³•ä¸‹ï¼Œ MLPæ¶æ§‹å¯èƒ½ç©©å®šè¨“ç·´ (é›–ç„¶å“è³ªæœ‰ä¸‹é™) å››: æ²’æœ‰ collapse mode (ä¿æŒç”Ÿæˆå¤šæ¨£æ€§)ä½œè€…è‡ªå·±èªªåœ¨å¤šæ¬¡å¯¦é©—çš„éç¨‹éƒ½æ²’æœ‰ç™¼ç¾é€™ç¨®ç¾è±¡ My Questions åŸå…ˆ GAN æœƒæœ‰ collapse mode çœ‹åˆ°æœ‰äººè¨è«–æ˜¯å› ç‚º KL divergence ä¸å°ç¨±çš„é—œä¿‚å°è‡´å°æ–¼ â€œç”Ÿæˆå™¨ç”Ÿå‡ºéŒ¯èª¤çš„ sampleâ€ æ¯” â€œç”Ÿæˆå™¨æ²’ç”Ÿå‡ºæ‰€æœ‰è©²å°çš„sampleâ€ é€ç½°è¦å¤§å¾ˆå¤šï¼Œä¸éé€™é‚Šè‡ªå·±é‚„æ˜¯æœ‰ç–‘å•ï¼Œå› ç‚º JSD å·²ç¶“æ˜¯å°ç¨±çš„ KL äº†ï¼Œé‚„æœƒæœ‰é€ç½°ä¸åŒå°è‡´ collapse mode çš„å•é¡Œå—? éœ€è¦å†å¤šçœ‹ä¸€ä¸‹ paper äº†è§£ã€‚ å¦‚ä½•æ§åˆ¶ sample å‡ºä¾†çš„ outputï¼Œè­¬å¦‚ mnist è¦ sampling å‡ºæŸå€‹ classã€‚å‰ææ˜¯å¸Œæœ›ä¸èƒ½å° data æœ‰ä»»ä½•æ¨™è¨˜éï¼Œä¸ç„¶å°±æ²’æœ‰ unsupervised çš„æ¢ä»¶äº†ã€‚ Conditional GAN? æœ‰ç©ºå†ç ”ç©¶ä¸€ä¸‹é€™å€‹èª²é¡Œ Tensorflow ç¯„ä¾‹æ¸¬è©¦ä¸»è¦åƒè€ƒæ­¤ githubï¼Œç”¨è‡ªå·±çš„å¯«æ³•å¯«ä¸€æ¬¡ï¼Œä¸¦åšäº›æ¸¬è©¦ ç”¨ MNIST dataset åšæ¸¬è©¦ï¼ŒåŸå§‹ input ç‚º 28x28ï¼Œå°‡å®ƒ padding æˆ 32x32ï¼Œå› æ­¤ input domain ç‚º 32x32x1 ç”Ÿæˆå™¨å¹¾å€‹é‡é»ï¼Œç¬¬ä¸€å€‹æ˜¯ç”Ÿæˆå™¨ç”¨çš„æ˜¯ conv2d_transpose (doc)ï¼Œé€™æ˜¯ç”±æ–¼åŸå…ˆçš„ conv2d ç„¡æ³•å°‡ image çš„ size è®Šå¤§ï¼Œé ‚å¤šä¸€æ¨£ã€‚å› æ­¤è¦ç”¨ conv2d_transposeï¼Œä»¥ ç¬¬ 15 è¡Œèˆ‰ä¾‹ã€‚argument wc2 çš„ shape ç‚º [3, 3, 256, 512] åˆ†åˆ¥è¡¨ç¤º [filter_h, filter_w, output_depth, input_depth]ã€‚argument [batch_size, 8, 8, 256] è¡¨ç¤º output layer çš„ shapeã€‚å¾Œé¢å…©å€‹ argument å°±å¾ˆæ˜é¡¯äº†ï¼Œåˆ†åˆ¥æ˜¯ strides [batch_stride, h_stride, w_stride, channel_stride] å’Œ paddingã€‚ç¬¬äºŒå€‹é‡é»æ˜¯æœ€å¾Œä¸€å±¤ out_sample = tf.nn.tanh(conv5)ï¼Œç”±æ–¼æˆ‘å€‘æœƒå°‡ data å…ˆ normalize åˆ° [-1,1]ï¼Œå› æ­¤ä½¿ç”¨ tanh è®“ domain ä¸€è‡´ã€‚ 123456789101112131415161718192021222324252627282930313233z_dim = 128def generator_net(z): with tf.variable_scope('generator'): # Layer 1 - 128 to 4*4*512 wd1 = tf.get_variable(\"wd1\",[z_dim, 4*4*512]) bd1 = tf.get_variable(\"bd1\",[4*4*512]) dense1 = tf.add(tf.matmul(z, wd1), bd1) dense1 = tf.nn.relu(dense1) # reshape to 4*4*512 conv1 = tf.reshape(dense1, (batch_size, 4, 4, 512)) # Layer 2 - 4*4*512 to 8*8*256 wc2 = tf.get_variable(\"wc2\",[3, 3, 256, 512]) conv2 = tf.nn.conv2d_transpose(conv1, wc2, [batch_size, 8, 8, 256], [1,2,2,1], padding='SAME') conv2 = tf.nn.relu(conv2) # Layer 3 - 8*8*256 to 16*16*128 wc3 = tf.get_variable(\"wc3\",[3, 3, 128, 256]) conv3 = tf.nn.conv2d_transpose(conv2, wc3, [batch_size, 16, 16, 128], [1,2,2,1], padding='SAME') conv3 = tf.nn.relu(conv3) # Layer 4 - 16*16*128 to 32*32*64 wc4 = tf.get_variable(\"wc4\",[3, 3, 64, 128]) conv4 = tf.nn.conv2d_transpose(conv3, wc4, [batch_size, 32, 32, 64], [1,2,2,1], padding='SAME') conv4 = tf.nn.relu(conv4) # Layer 5 - 32*32*64 to 32*32*1 wc5 = tf.get_variable(\"wc5\",[3, 3, 1, 64]) conv5 = tf.nn.conv2d_transpose(conv4, wc5, [batch_size, 32, 32, 1], [1,1,1,1], padding='SAME') out_sample = tf.nn.tanh(conv5) return out_sample é‘‘åˆ¥å™¨é€™å€‹å°±æ˜¯æœ€ä¸€èˆ¬çš„ CNNï¼Œoutput æœ€å¾Œæ˜¯ä¸€å€‹æ²’æœ‰é log çš„ scaler ä¸”ä¹Ÿæ²’æœ‰ç¶“é activation functionã€‚æ¯”è¼ƒé‡è¦çš„æ˜¯è®Šæ•¸éƒ½æ˜¯ä½¿ç”¨ get_variable å’Œ scope.reuse_variables() (è«‹åƒè€ƒ Sharing Variables)ã€‚å…·é«”çš„åŸå› æ˜¯å› ç‚ºæˆ‘å€‘æœƒå° real data å‘¼å«ä¸€æ¬¡é‘‘åˆ¥å™¨ï¼Œè€Œå°æ–¼ fake data ä¹Ÿæœƒåœ¨å‘¼å«ä¸€æ¬¡ã€‚è‹¥æ²’æœ‰ share variablesï¼Œå°±æœƒå°è‡´ç”¢ç”Ÿå…©çµ„å„è‡ªçš„ weightsã€‚tf.get_variable() è·Ÿ tf.Variable() å·®åˆ¥åœ¨æ–¼å¦‚æœå·²ç¶“æœ‰åç¨±ä¸€æ¨£çš„è®Šæ•¸æ™‚ get_variable() ä¸æœƒå†ç”¢ç”Ÿå¦ä¸€å€‹è®Šæ•¸ï¼Œè€Œæœƒ shareï¼Œä½†æ˜¯è¦çœŸçš„ share é‚„å¿…é ˆå¤šä¸€å€‹å‹•ä½œ reuse_variables ç¢ºä¿ä¸æ˜¯ä¸å°å¿ƒ share åˆ°çš„ã€‚ 12345678910111213141516171819202122232425262728293031323334353637# Construct CriticNetdef conv2d(x, W, b, strides=1): x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME') x = tf.nn.bias_add(x, b) return tf.nn.relu(x)def critic_net(x, reuse=False): with tf.variable_scope('critic') as scope: size = 64 if reuse: scope.reuse_variables() # Layer 1 - 32*32*1 to 16*16*size wc1 = tf.get_variable(\"wc1\",[3, 3, 1, size]) bc1 = tf.get_variable(\"bc1\",[size]) conv1 = conv2d(x, wc1, bc1, strides=2) # Layer 2 - 16*16*size to 8*8*size*2 wc2 = tf.get_variable(\"wc2\",[3, 3, size, size*2]) bc2 = tf.get_variable(\"bc2\",[size*2]) conv2 = conv2d(conv1, wc2, bc2, strides=2) # Layer 3 - 8*8*size*2 to 4*4*size*4 wc3 = tf.get_variable(\"wc3\",[3, 3, size*2, size*4]) bc3 = tf.get_variable(\"bc3\",[size*4]) conv3 = conv2d(conv2, wc3, bc3, strides=2) # Layer 4 - 4*4*size*4 to 2*2*size*8 wc4 = tf.get_variable(\"wc4\",[3, 3, size*4, size*8]) bc4 = tf.get_variable(\"bc4\",[size*8]) conv4 = conv2d(conv3, wc4, bc4, strides=2) # Fully connected layer - 2*2*size*8 to 1 wd5 = tf.get_variable(\"wd5\",[2*2*size*8, 1]) bd5 = tf.get_variable(\"bd5\",[1]) fc5 = tf.reshape(conv4, [-1, wd5.get_shape().as_list()[0]]) logit = tf.add(tf.matmul(fc5, wd5), bd5) return logit Graphé€™è£¡æœ‰å¹¾å€‹é‡é»ï¼Œç¬¬ä¸€å€‹æ˜¯ç”±æ–¼æˆ‘å€‘åœ¨æœ€ä½³åŒ–éç¨‹ä¸­ï¼Œæœƒ fix ä½ä¸€é‚Šçš„åƒæ•¸ï¼Œç„¶å¾Œæœ€ä½³åŒ–å¦ä¸€é‚Šï¼Œæ¥è‘—åéä¾†ã€‚æ­¤ä½œæ³•åƒè€ƒ linkç¬¬äºŒå€‹é‡é»æ˜¯ä½¿ç”¨ tf.clip_by_valueï¼Œå¯ä»¥çœ‹åˆ°æˆ‘å€‘å°æ–¼æ‰€æœ‰é€é tf.get_collection è’é›†åˆ°çš„è®Šæ•¸éƒ½å¢åŠ ä¸€å€‹ clip opã€‚ç¬¬ä¸‰å€‹é‡é»æ˜¯ä½¿ç”¨ tf.control_dependencies([opt_c]) linkï¼Œé€™å€‹å®šç¾©äº† op ä¹‹é–“çš„é—œè¯æ€§ï¼Œå®ƒæœƒç­‰åˆ° argument å…§åŸ·è¡Œå®Œç•¢å¾Œï¼Œæ‰æœƒæ¥è‘—åŸ·è¡Œä¸‹å»ã€‚æ‰€ä»¥æˆ‘å€‘å¯ä»¥ç¢ºä¿å…ˆåšå®Œ RMSPropOptimizer æ‰æ¥è‘—åš clip_by_valueã€‚å¦å¤– tf.tuple link æœƒç­‰æ‰€æœ‰çš„ input arguments éƒ½åšå®Œæ‰æœƒçœŸçš„ return å‡ºå»ï¼Œä»¥ç¢ºä¿æ¯å€‹ tensors éƒ½åšå®Œ clipping äº†ã€‚ 1234567891011121314151617181920212223242526272829# build graphdef build_graph(): z = tf.placeholder(tf.float32, shape=(batch_size, z_dim)) fake_data = generator_net(z) real_data = tf.placeholder(tf.float32, shape=(batch_size, 32, 32, 1)) # Define loss and optimizer real_logit = critic_net(real_data) fake_logit = critic_net(fake_data, reuse=True) c_loss = tf.reduce_mean(fake_logit - real_logit) g_loss = tf.reduce_mean(-fake_logit) # get the trainable variables list theta_g = tf.get_collection( tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator') theta_c = tf.get_collection( tf.GraphKeys.TRAINABLE_VARIABLES, scope='critic') # freezing or only update designated variables opt_g = tf.train.RMSPropOptimizer(learning_rate=lr_generator).minimize(g_loss, var_list=theta_g) opt_c = tf.train.RMSPropOptimizer(learning_rate=lr_critic).minimize(c_loss, var_list=theta_c) # then pass those trainable variables to clip function clipped_var_c = [tf.assign(var, tf.clip_by_value(var, clip_lower, clip_upper)) for var in theta_c] # wait until RMSPropOptimizer is done with tf.control_dependencies([opt_c]): # fetch the clipped variables and output as op opt_c = tf.tuple(clipped_var_c) return opt_g, opt_c, z, real_data WGAN Algorithm Flowç…§ paper ä¸Šçš„æ¼”ç®—æ³• flow 123456789101112131415161718192021222324252627282930def wgan_train(): dataset = input_data.read_data_sets(\".\", one_hot=True) opt_g, opt_c, z, real_data = build_graph() saver = tf.train.Saver() config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True) config.gpu_options.allow_growth = True config.gpu_options.per_process_gpu_memory_fraction = 0.8 def next_feed_dict(): train_img = dataset.train.next_batch(batch_size)[0] train_img = 2*train_img-1 train_img = np.reshape(train_img, (-1, 28, 28)) npad = ((0, 0), (2, 2), (2, 2)) train_img = np.pad(train_img, pad_width=npad, mode='constant', constant_values=-1) train_img = np.expand_dims(train_img, -1) batch_z = np.random.normal(0, 1, [batch_size, z_dim]).astype(np.float32) feed_dict = &#123;real_data: train_img, z: batch_z&#125; return feed_dict with tf.Session(config=config) as sess: sess.run(tf.global_variables_initializer()) summary_writer = tf.summary.FileWriter(log_dir, sess.graph) for i in range(max_iter_step): print(\"itr = \",i) for j in range(c_iter): feed_dict = next_feed_dict() sess.run(opt_c, feed_dict=feed_dict) feed_dict = next_feed_dict() sess.run(opt_g, feed_dict=feed_dict) if i % 1000 == 999: saver.save(sess, os.path.join(ckpt_dir, \"model.ckpt\"), global_step=i) ä¸€é»å°çµè«–5.1. ä¸Šè¿°æ¶æ§‹æ²’æœ‰ç”¨ batch normalizationï¼Œæœ‰ç”¨çš„è©±æ•ˆæœæœƒå¥½å¾ˆå¤šï¼Œç”Ÿæˆå™¨å’Œé‘‘åˆ¥å™¨éƒ½å¯ç”¨ã€‚5.2. é‘‘åˆ¥å™¨æ›æˆå…¶ä»– CNN æ¶æ§‹ä¹Ÿå¯ä»¥ã€‚5.3. MLP æ¶æ§‹ä¹Ÿå¯ä»¥ã€‚ æ•´é«”ä¾†èªªï¼Œå°æ–¼ç†Ÿæ‚‰ tensorflow çš„äººä¾†èªªä¸é›£å¯¦ä½œ (å‰›å¥½æˆ‘ä¸æ˜¯å¾ˆç†Ÿ)ï¼Œå°¤å…¶ WGAN å¾æ ¹æœ¬ä¸Šåšçš„æ”¹é€²ï¼Œè®“æ•´å€‹ training å¾ˆå®¹æ˜“!è®“æˆ‘å€‘æœŸå¾…æ¥ä¸‹ä¾†çš„ç™¼å±•å§~ Reference GAN Wasserstein GANï¼Œä½œè€…çš„ github ä»¤äººæ‹æ¡ˆå«ç»çš„Wasserstein GAN A Tensorflow Implementation of WGAN: ä½¿ç”¨ tf.contrib.layersï¼Œä¸€å€‹ higher level çš„ APIï¼Œæ¯”æˆ‘ç¾åœ¨çš„å¯¦ä½œå¯ä»¥ç°¡æ½”å¾ˆå¤šã€‚ A GENTLE GUIDE TO USING BATCH NORMALIZATION IN TENSORFLOW: Batch Normalization, MLP, and CNN examples using tf.contrib.layers","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Generative Model","slug":"Generative-Model","permalink":"https://bobondemon.github.io/tags/Generative-Model/"}]},{"title":"WGAN Part 1: å…ˆç”¨ GAN é‹ªæ¢—","date":"2017-03-16T13:25:12.000Z","path":"2017/03/16/WGAN-Part-1/","text":"Open.ai é€™å¼µè¡¨é” generative modeling çš„æ„æ€å¾ˆæ¸…æ¥šï¼Œå¿ä¸ä½å°±å€Ÿç”¨äº†ã€‚ ç­†è€…æ‰ç–å­¸æ·ºï¼Œå¦‚æœ‰éŒ¯èª¤ï¼Œé‚„è«‹æŒ‡æ­£ Generative Adversarial Nets æå‡ºäº†ä¸€å€‹ NN çš„ generative modeling æ–¹æ³•ï¼Œåœ¨é€™ä¹‹å‰ï¼ŒNN è¦æˆç‚º p.d.f. å¿…é ˆä¾è³´æ–¼ sigmoid activation çš„ Restricted Boltzmann Machines (RBM) çµæ§‹ã€‚ä¾‹å¦‚ Deep Belief Netï¼Œæ•´å€‹ network æ‰æœƒæ˜¯ä¸€å€‹ p.d.f.ã€‚ç„¶è€Œå­¸ç¿’é€™æ¨£çš„ä¸€å€‹ p.d.f. å¿…é ˆä½¿ç”¨ Contrastive Divergence çš„ MCMC æ–¹æ³•ï¼Œ model è¨“ç·´å®Œå¾Œè¦ç”¢ç”Ÿ sample æ™‚ä¹Ÿé‚„æ˜¯å¿…é ˆä¾è³´ MCMCã€‚åŠ ä¸Šåœ¨å¯¦ç”¨ä¸Šï¼Œåå sigmoid å¾ˆå¤šæ™‚å€™æ•ˆæœä¸å¦‚ ReLu, maxout ç­‰ï¼Œä¾‹å¦‚ sigmoid æœ‰åš´é‡çš„ gradient vanish problemã€‚é€™ä½¿å¾— NN åœ¨ generative modeling åˆæˆ–æ˜¯ unsupervised learning ä¸Šä¸€ç›´å›°é›£é‡é‡ã€‚ GAN ä¸€å‡ºç«‹å³æ‰“ç ´é€™å€‹é›£å ªçš„é™åˆ¶ ! æ€éº¼èªªå‘¢? GAN æ¨æ£„èƒ½å¤ æ˜ç¢ºè¡¨é”å‡º p.d.f.çš„ä½œæ³•ï¼Œå¯«ä¸å‡ºæ˜ç¢ºçš„ p.d.f. ä¸€é»ä¹Ÿæ²’é—œä¿‚ï¼Œåªè¦èƒ½ç”Ÿæˆ å¤ çœŸçš„sampleé»ï¼Œä¸¦ä¸”sampleçš„æ©Ÿç‡è·Ÿtraining dataä¸€æ¨£å°±å¥½ ç„¶è€Œ GAN åœ¨å¯¦ä½œä¸Šå»æœƒé‡ä¸Šä¸€äº›å›°é›£ï¼Œä¾‹å¦‚ç”Ÿæˆçš„ samples å¤šæ¨£æ€§ä¸è¶³ï¼Œè¨“ç·´æµç¨‹/æ¶æ§‹ å’Œ hyper-parameters éœ€è¦å°å¿ƒé¸æ“‡ï¼Œç„¡æ³•æ˜ç¢ºçŸ¥é“è¨“ç·´çš„æ”¶æ–‚ç‹€æ³ï¼Œé€™äº›å•é¡Œç­‰ä¸‹æœƒèªªæ˜ã€‚ æœ¬ç¯‡çš„ä¸»è§’ (äº‹å¯¦ä¸Šä¸‹ä¸€ç¯‡æ‰æœƒç™»å ´) Wasserstein GAN (WGAN)ï¼Œå¾æœ¬è³ªä¸Šæ¢è¨ GAN ç›®æ¨™å‡½å¼ä¸­ä½¿ç”¨çš„ distance measureï¼Œé€²è€Œæ ¹æœ¬åœ°è§£æ±ºä¸Šè¿°ä¸‰å€‹å•é¡Œï¼Œé€™å¤§å¤§é™ä½äº† generative modeling è¨“ç·´é›£åº¦ ! æˆ‘å€‘é‚„æ˜¯ä¾†è«‡è«‡ GAN æ€éº¼ä¸€å›äº‹å…ˆå§ã€‚ Generative Adversarial NetsGAN ä½¿ç”¨ä¸€å€‹ two-player minimax gaming ç­–ç•¥ã€‚å…ˆç”¨ç›´è§€èªªï¼Œæˆ‘å€‘æœ‰ä¸€å€‹ ç”Ÿæˆå™¨ \\(G\\)ï¼Œç”¨ä¾†ç”Ÿæˆå¤ çœŸçš„ sampleï¼Œå¦å¤–é‚„æœ‰ä¸€å€‹ é‘‘åˆ¥å™¨ \\(D\\)ï¼Œç”¨ä¾†åˆ†è¾¨ sample ç©¶ç«Ÿæ˜¯çœŸå¯¦è³‡æ–™ (training data) ä¾†çš„å‘¢ï¼Œé‚„æ˜¯å‡çš„ (\\(G\\)ç”¢ç”Ÿçš„)ã€‚ç•¶é€™å…©å€‹æ¨¡å‹äº’ç›¸ç«¶çˆ­åˆ°ä¸€å€‹å¹³è¡¡é»çš„æ™‚å€™ï¼Œä¹Ÿå°±æ˜¯ \\(G\\) èƒ½å¤ ç”¢ç”Ÿåˆ° \\(D\\) åˆ†è¾¨ä¸å‡ºçœŸå‡çš„ sampleï¼Œæˆ‘å€‘çš„ç”Ÿæˆå™¨ \\(G\\) å°±éŠæˆäº†ã€‚è€Œ GAN ä½œè€…å²å®³çš„åœ°æ–¹å°±åœ¨æ–¼ ä¸€: å°‡é€™å…©å€‹modelçš„ç«¶çˆ­è¦å‰‡è½‰æ›æˆä¸€å€‹æœ€ä½³åŒ–å•é¡ŒäºŒ: ä¸¦ä¸”è­‰æ˜ï¼Œç•¶é”åˆ°è³½å±€çš„å¹³è¡¡é»æ™‚(é”åˆ°æœ€ä½³è§£)ï¼Œç”Ÿæˆå™¨å°±éŠæˆ (å¯ä»¥å®Œç¾è¡¨ç¤º training data çš„ pdfï¼Œä¸¦ä¸”å¯sampling) æˆ‘å€‘é‚„æ˜¯å¿…é ˆæŠŠä¸Šè¿°ç­–ç•¥åš´è¬¹çš„è¡¨é”å‡ºä¾† (å¯«æˆæœ€ä½³åŒ–å•é¡Œ)ï¼Œä¸¦è­‰æ˜ç•¶é”åˆ°æœ€ä½³åŒ–å•é¡Œçš„æœ€ä½³è§£æ™‚ï¼Œå°±å‰›å¥½å®Œæˆç”Ÿæˆå™¨çš„éŠæˆã€‚ Two-player Minimax GameåŸå‰‡ä¸Šæˆ‘å€‘å¸Œæœ›é‘‘åˆ¥å™¨ \\(D\\) èƒ½åˆ†è¾¨å‡ºçœŸå‡ sampleï¼Œå› æ­¤ \\(D(x)\\) å¾ˆè‡ªç„¶åœ°å¯ä»¥è¡¨ç¤ºç‚º sample \\(x\\) ç‚ºçœŸçš„æ©Ÿç‡å¦å¤–ç”Ÿæˆå™¨ \\(G\\) å‰‡æ˜¯è² è²¬ç”¢ç”Ÿå‡ sampleï¼Œä¹Ÿå¯ä»¥å¾ˆè‡ªç„¶åœ°è¡¨é”ç‚º \\(G(z)\\)ï¼Œå…¶ä¸­ \\(z\\) ç‚º latent variablesï¼Œä¸”æˆ‘å€‘å¯ä»¥å‡è¨­è©² latent variables \\(z\\) follow ä¸€å€‹ prior distribution \\(p_z(z)\\)ã€‚ æˆ‘å€‘å¸Œæœ› \\(D(x)\\) å°ä¾†è‡ªæ–¼çœŸå¯¦è³‡æ–™çš„ samples èƒ½å¤ ç›¡é‡å¤§ï¼Œè€Œå°ä¾†è‡ªæ–¼ \\(G\\) ç”¢ç”Ÿçš„è¦ç›¡é‡å°ï¼Œå› æ­¤å°æ–¼é‘‘åˆ¥å™¨ä¾†èªªï¼Œå®ƒçš„ç›®æ¨™å‡½å¼å¯å®šç¾©ç‚ºå¦‚ä¸‹: $$\\begin{align} Maximize: E_{x \\sim p_{data}(x)} [\\log D(x)] + E_{z \\sim p_z(z)}[\\log (1-D(G(z)))] \\end{align}$$ å¦ä¸€æ–¹é¢ï¼Œæˆ‘å€‘å¸Œæœ› \\(G\\) èƒ½å¤ å¼·åˆ°è®“ \\(D\\) ç„¡æ³•åˆ†è¾¨çœŸå½ï¼Œå› æ­¤ç”Ÿæˆå™¨çš„ç›®æ¨™å‡½å¼ç‚º: $$\\begin{align} Minimize: E_{z \\sim p_z(z)}[\\log (1-D(G(z)))] \\end{align}$$ çµåˆä¸Šè¿°å…©å€‹ç›®æ¨™å‡½å¼å°±æ˜¯å¦‚ä¸‹çš„ minmax problemäº† $$\\begin{align} \\min_G{ \\max_D{V(D,G)} } = E_{x \\sim p_{data}(x)} [\\log D(x)] + E_{z \\sim p_z(z)}[\\log (1-D(G(z)))] \\end{align}$$ é€™é‚Šä½œè€…å¾ˆæ¼‚äº®åœ°çµ¦å‡ºäº†ä¸Šè¿°å•é¡Œçš„ç†è«–è­‰æ˜ã€‚è­‰æ˜äº†å…©ä»¶äº‹æƒ…: ä¸Šè¿°æœ€ä½³åŒ–å•é¡Œ (å¼(3)) é”åˆ° global optimum æ™‚, \\( p_g = p_d \\)ã€‚ (ç”Ÿæˆå™¨ç”¢ç”Ÿå‡ºä¾†çš„ pdf æœƒç­‰æ–¼çœŸå¯¦è³‡æ–™çš„ pdfï¼Œå› æ­¤ç”Ÿæˆå™¨éŠæˆ!) ä½¿ç”¨å¦‚ä¸‹çš„æ¼”ç®—æ³•å¯ä»¥æ‰¾åˆ° global optimum æ¥ä¸‹ä¾†æˆ‘å€‘åªè¨è«–ç¬¬ä¸€å€‹äº‹æƒ…çš„è­‰æ˜ï¼Œå› ç‚ºé€™é—œä¿‚åˆ° GAN çš„å¼±é»ï¼Œä¹Ÿå°±æ˜¯ WGAN è¦è§£æ±ºçš„å•é¡Œæ ¹æº! è­‰æ˜ Global optimum ç™¼ç”Ÿæ™‚ï¼ŒéŠæˆç”Ÿæˆå™¨å¤§æ–¹å‘æ˜¯é€™æ¨£çš„ A. å‡å¦‚çµ¦å®š \\(G\\)ï¼Œæˆ‘å€‘éƒ½å¯ä»¥æ‰¾åˆ°ä¸€å€‹ç›¸å°æ‡‰çš„ \\(D_G^*\\) æœ€ä½³åŒ–é‘‘åˆ¥å™¨çš„ç›®æ¨™å‡½å¼ (1)ã€‚B. æ”¹å¯«åŸä¾†çš„ç›®æ¨™å‡½å¼ \\(V(G,D)\\)ï¼Œæ”¹å¯«å¾Œåªè·Ÿ \\(G\\) æœ‰é—œï¼Œæˆ‘å€‘å®šç¾©ç‚º \\(C(G)\\)ï¼Œé€™æ˜¯å› ç‚ºå°æ–¼æ¯ä¸€å€‹ \\(G\\) æˆ‘å€‘å·²ç¶“é…çµ¦å®ƒç›¸å°æ‡‰çš„ \\(D_G^*\\) äº†ï¼Œæ¥è‘—è­‰æ˜æœ€ä½³è§£åªç™¼ç”Ÿåœ¨ \\( p_g = p_d \\) çš„æƒ…æ³ã€‚ æ­¥é©Ÿ A: $$V(G,D)=\\int_{x}{p_d(x)\\log(D(x))dx}+\\int_{z}{p_z(z)\\log(1-D(g(z)))dz} \\\\ =\\int_x[p_d(x)\\log(D(x))+p_g(x)\\log(1-D(x))]dx$$ è€Œä¸€å€‹ function \\(f(x)=a\\log (y)+b\\log (1-y)\\) çš„æœ€ä½³è§£ç‚º \\(y=\\frac{a}{a+b}\\)å› æ­¤æˆ‘å€‘å¾—åˆ° \\( D_G^*(x) = \\frac{p_d(x)}{p_d(x)+p_g(x)} \\) æ­¥é©Ÿ B: $$\\begin{align*} &amp; C(G)=\\max_{D}V(G,D) \\\\ &amp; =E_{x \\sim p_d}[\\log D_G^*(x)]+E_{z \\sim p_z}[\\log(1-D_G^*(G(z)))] \\\\ &amp; =E_{x \\sim p_d}[\\log D_G^*(x)]+E_{x \\sim p_g}[\\log(1-D_G^*(x))] \\\\ &amp; =E_{x \\sim p_d}[\\log{\\frac{p_d(x)}{p_d(x)+p_g(x)}}]+E_{x \\sim p_g}[\\log{\\frac{p_g(x)}{p_d(x)+p_g(x)}}] \\end{align*}$$ ç„¶å¾Œæˆ‘å€‘ç‰¹åˆ¥è§€å¯Ÿå¦‚æœ \\(p_g = p_d\\)ï¼Œä¸Šå¼æœƒ $$\\begin{align} =E_{x \\sim p_d}[-\\log 2]+E_{x \\sim p_g}[-\\log 2]=-\\log4 \\end{align}$$ é‡æ–°æ”¹å¯«ä¸€ä¸‹ \\(C(G)\\) å¦‚ä¸‹ $$\\begin{align} C(G)=-\\log4+KL(p_d\\vert\\frac{p_d+p_g}{2})+KL(p_g\\vert\\frac{p_d+p_g}{2}) \\\\ =-\\log4+2JSD(p_d \\vert p_g) \\end{align}$$ é¦¬ä¸Šè§€å¯Ÿåˆ° \\(JSD\\geq0\\) å’Œ \\(JSD=0 \\Leftrightarrow p_g = p_d \\)é€™è¡¨ç¤º \\(C(G)\\) æœ€ä½³å€¼ç‚º \\(-\\log4\\)ï¼Œä¸”æˆ‘å€‘å·²çŸ¥ç•¶ \\(p_g = p_d\\) æ™‚é”åˆ°æœ€ä½³å€¼ (å¼(4))ï¼Œå› æ­¤ç‚ºæœ€ä½³è§£ çµè«–æ•´å€‹ GAN çš„æµç¨‹:æˆ‘å€‘åŸºæ–¼ä¸€å€‹ç”Ÿæˆå™¨ \\(G\\) å»æœ€ä½³åŒ– \\(D\\) å¾—åˆ° \\(D_G^*\\)ï¼Œæ¥è‘—è¦ç¹¼çºŒæœ€ä½³åŒ–ç”Ÿæˆå™¨çš„æ™‚å€™ï¼Œå•é¡Œå¾ç›®æ¨™å‡½å¼ (3) è®Šæˆç­‰åƒ¹æ–¼è¦æœ€ä½³åŒ–ä¸€å€‹ JSD çš„å•é¡Œ (å¼(5))ã€‚è—‰ç”±æœ€ä½³åŒ– JSD å•é¡Œï¼Œå¾—åˆ°æ–°çš„ \\(G\\)ï¼Œç„¶å¾Œé‡è¤‡ä¸Šé¢æ­¥é©Ÿï¼Œæœ€å¾Œé”åˆ°å¼(3)çš„æœ€ä½³è§£ï¼Œè€Œæˆ‘å€‘å¯ä»¥ä¿è­‰æ­¤æ™‚ç”Ÿæˆå™¨éŠæˆï¼Œ \\(p_g = p_d\\)ã€‚ å•é¡Œå‡ºåœ¨å“ª? å•é¡Œå°±å‡ºåœ¨æœ€ä½³åŒ–ä¸€å€‹ JSD çš„å•é¡Œä¸Šé¢ ! JSD æœ‰ä»€éº¼å•é¡Œ?æˆ‘å€‘é€šéæœ€ä½³åŒ– JSDï¼Œè€Œå°‡ \\(p_g\\) é€æ¼¸æ‹‰å‘ \\(p_d\\)ã€‚ä½†æ˜¯ JSD æœ‰å…©å€‹ä¸»è¦çš„å•é¡Œ: A. åœ¨ å¯¦éš›ç‹€æ³ ä¸‹ï¼Œç„¡æ³•çµ¦åˆé€£çºŒçš„è·é›¢å€¼ï¼Œå°è‡´ gradient å¤§éƒ¨åˆ†éƒ½æ˜¯ 0ï¼Œå› è€Œéå¸¸é›£ä»¥è¨“ç·´B. ç”¢ç”Ÿçš„æ¨£æœ¬å¤šæ¨£æ€§ä¸è¶³ï¼Œcollapse modeã€‚ é€™é‚Šè¦è§£é‡‹ä¸€ä¸‹ å¯¦éš›ç‹€æ³ æ˜¯ä»€éº¼æ„æ€ã€‚ä¸€èˆ¬ä¾†èªªï¼ŒçœŸå¯¦è³‡æ–™æˆ‘å€‘éƒ½æœƒç”¨éå¸¸é«˜çš„ç¶­åº¦å»è¡¨ç¤ºï¼Œç„¶è€Œè³‡æ–™çš„è®ŠåŒ–é€šå¸¸åªè¢«å°‘æ•¸å¹¾ç¨®è®Šå› æ‰€æ§åˆ¶ï¼Œä¹Ÿå°±æ˜¯åªå­˜åœ¨é«˜ç¶­ç©ºé–“ä¸­çš„ local manifoldã€‚ä¾‹å¦‚ä¸€å€‹ swiss roll é›–ç„¶æ˜¯åœ¨ 3 ç¶­ç©ºé–“ä¸­ï¼Œä½†å®ƒæ˜¯åœ¨ä¸€å€‹ 2 ç¶­çš„ manifold ç©ºé–“è£¡ã€‚ é€™æ¨£æœƒé€ æˆä¸€å€‹å•é¡Œå°±æ˜¯ï¼Œ \\(p_d\\) å’Œ \\(p_g\\)ï¼Œä¸æœƒæœ‰äº¤é›†ï¼Œåˆæˆ–è€…äº¤é›†è™•çš„é›†åˆæ¸¬åº¦ç‚º0!é€™æ¨£çš„æƒ…æ³åœ¨JSDè¡¡é‡å…©å€‹æ©Ÿç‡åˆ†å¸ƒçš„æ™‚å€™æœƒæ‚²åŠ‡ã€‚ä½œè€…çµ¦å‡ºäº†ä¸‹é¢ä¸€å€‹ç°¡å–®æ˜“æ‡‚çš„ä¾‹å­: å…©å€‹æ©Ÿç‡åˆ†å¸ƒéƒ½æ˜¯åœ¨ä¸€å€‹ 1 ç¶­çš„ manifold ç›´ç·šä¸Šï¼Œx è»¸çš„è·é›¢ç¶­ \\(\\theta\\)ï¼Œæ­¤æ™‚çš„ JSD å€¼ç‚ºå³åœ–æ‰€ç¤ºï¼Œå…¨éƒ¨éƒ½æ˜¯ \\(\\log2\\)ï¼Œé™¤äº†åœ¨ \\(\\theta\\) é‚£é»çš„å€¼æ˜¯ 0 (pdfå®Œå…¨é‡ç–Š)ã€‚é€™æ¨£è¨ˆç®—å‡ºçš„ Gradients å¹¾ä¹éƒ½æ˜¯ 0ï¼Œé€™ä¹Ÿå°±æ˜¯ç‚ºä»€éº¼ GAN å¾ˆé›£è¨“ç·´çš„åŸå› ã€‚ é€™å•é¡Œåœ¨ WGAN ä¹‹å‰é‚„æ˜¯æœ‰äººæå‡ºè§£æ±ºçš„æ–¹æ³•ï¼Œä¸éå°±å¾ˆåå·¥ç¨‹æ€è€ƒ: åŠ å…¥ noise ä½¿å¾—å…©å€‹æ©Ÿç‡åˆ†éƒ¨æœ‰ä¸å¯å¿½ç•¥çš„é‡ç–Šã€‚å› æ­¤è®“ GAN å…ˆå‹•èµ·ä¾†ï¼Œå‹•èµ·ä¾†ä¹‹å¾Œï¼Œå†æ…¢æ…¢åœ°æŠŠ noise ç¨‹åº¦ä¸‹é™ã€‚é€™æ˜¯è°æ˜å·¥ç¨‹å¸«çš„å²å®³è¾¦æ³•! ä½†çµ‚æ­¸ä¾†èªªé‚„æ˜¯æ²»æ¨™ã€‚çœŸæ­£çš„æ²»æœ¬æ–¹æ³•ï¼Œå¿…é ˆè¦æ›¿æ›æ‰ JSD é€™æ¨£çš„é‡æ¸¬å‡½å¼æ‰å¯ä»¥ã€‚ æœ¬ç¯‡é‹ªæ¢—çµæŸ (é€™æ¢—ä¹Ÿå¤ªé•·äº†)ã€‚ä¸‹ç¯‡çµ‚æ–¼è¼ªåˆ°ä¸»è§’ç™»å ´ï¼Œ WGAN çš„ W !","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Generative Model","slug":"Generative-Model","permalink":"https://bobondemon.github.io/tags/Generative-Model/"}]},{"title":"Why-Aggregation-Work","date":"2017-03-13T13:29:47.000Z","path":"2017/03/13/Why-Aggregation-Work/","text":"ç‚ºä½•ä¸‰å€‹è‡­çš®åŒ æœƒå‹éä¸€å€‹è«¸è‘›äº®?åœ¨ ML ä¸­æœ‰ä¸€é¡çš„æ¼”ç®—æ³•ç¨±ç‚º Aggregation Methodsï¼Œé€™æ–¹æ³•çš„é‹ä½œæ–¹å¼å…¶å¯¦æˆ‘å€‘å¯èƒ½å¾å°å°±æ¥è§¸åˆ°äº†ã€‚æœ‰æ²’æœ‰é‡éä¸€ç¨®æƒ…æ³å°±æ˜¯ï¼Œç•¶ä¸€ç¾¤äººé‡åˆ°ä¸€å€‹ä¸çŸ¥é“æœ€å¥½ç­”æ¡ˆçš„æ™‚å€™ï¼Œæœ€ç›´æ¥çš„æ–¹å¼å°±æ˜¯å¤§å®¶çš„ç­”æ¡ˆå–å¹³å‡ã€‚è½èµ·ä¾†å¾ˆç›´è¦ºï¼Œä½†å¿ƒè£¡è€è¦ºå¾—æ€ªæ€ªçš„ï¼Œå› ç‚ºæ ¹æœ¬ä¸çŸ¥é“åˆ°åº•å¯ä¸å¯é ã€‚Aggregation methods å°±æ˜¯é€™æ¨£çš„é‹ä½œæ¨¡å¼ï¼Œé€™é‚Šå°±çµ¦å€‹çµè«–ï¼Œå®ƒå¾ˆå¯é ! ä»¥ä¸‹çš„æ¨å°å‡ºè‡ªæ–¼æ—è»’ç”°æ•™æˆçš„è¬›ç¾©ï¼Œé€™è£¡ç”¨è‡ªå·±çš„ç†è§£æ–¹å¼é‡æ–°è¡¨é”ï¼Œä¸»è¦ä½œç­†è¨˜ç”¨ é–‹é ­é‚„æ˜¯çµ¦å…ˆå®šç¾©æ¸…æ¥šä¸€äº› termsï¼Œå°æ–¼ç†è§£å¼å­æ‰ä¸æœƒæ··æ·† å®šç¾©åœ¨å…ˆ Input: \\(x \\in X\\) æ­£ç¢ºç­”æ¡ˆ: \\(f(x)\\) è‡­çš®åŒ : \\(g_t(x),t=1,2,â€¦\\) è‡­çš®åŒ å€‘çš„æ±ºç­–çµæœ: \\(G(x)=avg_t(g_t(x))\\) è¡¡é‡æ–¹æ³• \\(g\\) çš„éŒ¯èª¤ç‡: \\( Error(g)=E_x[(g(x)-f(x))^2]\\) é€™é‚Šè¦ç‰¹åˆ¥èªªçš„æ˜¯è¡¡é‡ä¸€å€‹æ–¹æ³• \\(g\\) çš„éŒ¯èª¤ç‡ï¼Œæ˜¯é‡å°æ‰€æœ‰çš„ input \\(x\\)ï¼Œä¹Ÿå°±æ˜¯é‡å° \\(X\\) domain ä¾†ç®—æœŸæœ›å¹³æ–¹èª¤å·® é‹ç®—ç°¡å–®ä½†æœ‰é»ç¥å¥‡çš„æ¨å° æˆ‘å€‘å…ˆé‡å° ä¸€å€‹å›ºå®šçš„ xï¼Œä¾†çœ‹çœ‹è‡­çš®åŒ å€‘çµ±åˆçš„æ„è¦‹æ˜¯å¦çœŸçš„æœƒå¾—åˆ°è¼ƒå¥½çš„çµæœï¼Œç”±æ–¼inputå·²ç¶“å›ºå®šï¼Œæ‰€ä»¥ä¸‹é¢æœƒå¿½ç•¥ x çš„ termé¦–å…ˆæ˜¯ â€œè‡­çš®åŒ å€‘å„è‡ªçš„å¹³æ–¹éŒ¯èª¤ç‡â€ çš„å¹³å‡å€¼$$avg_t((g_t-f)^2)$$å°‡å¹³æ–¹æ‹†é–‹å¾Œå¾—$$=avg_t(g_t^2-2g_tf+f^2)$$å°‡ avg ç§»å…¥ä¸¦ç”¨ G=avg(gt) å®šç¾©å¾—åˆ°$$=avg_t(g_t^2)-2Gf+f^2$$å†åšå¦‚ä¸‹çš„ç°¡å–®ä»£æ•¸é‹ç®—$$=avg_t(g_t^2)-G^2+(G-f)^2 \\\\=avg_t(g_t^2)-2G^2+G^2+(G-f)^2 \\\\=avg_t(g_t^2-2g_tG+G^2)+(G-f)^2 \\\\=avg_t((g_t-G)^2)+(G-f)^2$$ ç›®å‰ç‚ºæ­¢æ˜¯é‡å° ä¸€å€‹ç‰¹å®šçš„è¼¸å…¥ xï¼Œè€Œæˆ‘å€‘éœ€è¦çŸ¥é“çš„æ˜¯å° æ•´å€‹ domain X çš„éŒ¯èª¤ç‡å› æ­¤çœŸæ­£è¦è¨ˆç®—çš„æ˜¯é€™å€‹ç›®æ¨™éŒ¯èª¤ç‡$$avg_t(Error(g_t))=avg_t(E_x[(g_t(x)-f(x))^2])$$å°‡ Expection for all x ä»£å…¥é€²å»å‰›å‰›ä¸Šé¢é‡å°ä¸€å€‹ x çš„çµæœï¼Œå¾—åˆ°å¦‚ä¸‹å¼å­\\begin{eqnarray}=avg_t(E_x[(g_t(x)-G(x))^2])+E_x[(G(x)-f(x))^2] \\\\=avg_t(E_x[(g_t(x)-G(x))^2])+Error(G) \\\\\\geq Error(G) \\end{eqnarray} æ€éº¼è§£é‡‹?é‡è¤‡ä¸€ä¸‹æœ€å¾Œçš„é‡è¦å¼å­: $$avg_t(Error(g_t)) = avg_t(E_x[(g_t(x)-G(x))^2])+Error(G) \\\\\\geq Error(G)$$ æœ€ç›´æ¥çš„çµè«–å°±æ˜¯: â€œçµ±åˆå‡ºä¾†çš„çµæœâ€çš„éŒ¯èª¤ç‡ æœƒæ¯” â€œå„è‡ªæ±ºå®šâ€çš„å¹³å‡éŒ¯èª¤ç‡ é‚„è¦ä½ å¯ä»¥çœ‹åˆ°é‡å° ä¸€çµ„å›ºå®š çš„è‡­çš®åŒ å€‘ \\({g_t}\\)ï¼Œä¸ç­‰å¼å·¦é‚Š \\(avg_t(Error(g_t))\\) æ˜¯å›ºå®šå€¼ï¼Œå› æ­¤è‹¥è¦æ‰¾ä¸€å€‹çµ±åˆå¤§å®¶æ„è¦‹çš„æ–¹æ³• \\(G\\)ï¼Œè€Œè©²æ–¹æ³•æœ‰æœ€å°çš„éŒ¯èª¤ç‡ (æœ€å°åŒ– \\(Error(G)\\) )ï¼Œå¾ˆæ˜é¡¯å°±æ˜¯è¦æœ€å¤§åŒ– \\(avg_t(E_x(g_t-G)^2)\\)ï¼Œè€Œæ­¤æœ€å¤§åŒ–çš„çµæœ å°±æ˜¯ \\(G\\) æ˜¯ \\({g_t}\\) çš„å¹³å‡å€¼(uniform blending)ï¼Œç¬¦åˆæˆ‘å€‘ä¸€é–‹å§‹èªªçš„æœ€ç›´è¦ºçš„ç­–ç•¥! å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘å€‘é¸åˆ°å…©çµ„ set \\({g_t}\\) and \\({h_t}\\) ä»–å€‘çš„ Error ç›¸åŒ: \\(avg_t(Error(g_t))= avg_t(Error(h_t))\\) ï¼Œé‚£æˆ‘å€‘ç•¶ç„¶æ˜¯è¦é¸æ“‡æ„è¦‹æœ€ä¸åŒçš„é‚£ä¸€çµ„è‡­çš®åŒ å€‘ï¼Œé€™æ˜¯å› ç‚ºæ„è¦‹æ„ˆä¸åŒä»£è¡¨ \\(avg_t(E_x(g_t-G)^2)\\) æ„ˆå¤§ï¼Œå› è€Œå°è‡´ \\(Error(G)\\) æœƒæ„ˆå°ã€‚ å°çµ å‰›å‰›ä¸Šé¢é€™å€‹çµè«–å°±å¾ˆæœ‰è¶£ï¼Œæ„è¦‹é‡ä¸åŒçš„è©±ï¼Œçµ±åˆèµ·ä¾†çš„æ•ˆæœæ„ˆå¥½ï¼Œä¹Ÿå°±æ˜¯ä½ æˆ‘ä¹‹é–“çš„æ„è¦‹æœ‰å¾ˆå¤§çš„åˆ†æ­§æ™‚ï¼Œé€™ä»£è¡¨æ˜¯å¥½äº‹! äº‹å¯¦ä¸Š Adaboost å°±æ˜¯æ¡å–é€™éº¼ä¸€å€‹ç­–ç•¥ï¼Œæ¯ä¸€æ¬¡çš„ iteration æœƒé¸æ“‡è·Ÿä¸Šæ¬¡çµ±åˆå®Œçš„çµæœæ„è¦‹å·®æœ€å¤šé‚£ä¸€ä½è‡­çš®åŒ é€²ä¾†ï¼Œæœ‰æ©Ÿæœƒå†è£œä¸Š Adaboostï¼Œé€™æ˜¯æˆ‘å¾ˆå–œæ­¡çš„ä¸€ç¨® ML æ¼”ç®—æ³•ã€‚ è€Œé€™é‚Šé‚„å¯ä»¥å¼•å‡ºä¸€å€‹æ–¹æ³•, Bootstrap. Bootstrap aggregationæ–¹æ³•å¾ˆç°¡å–®ã€‚å°æˆ‘å€‘çš„datasetæ¯ä¸€æ¬¡é‡æ–°resampling (e.g. å–Nâ€™ç­†ï¼Œæ¯æ¬¡å–çš„dataéƒ½å†æ”¾å›å»ï¼Œå› æ­¤dataå¯ä»¥é‡è¤‡ã€‚å¯é‡è¤‡é€™é»é€ æˆdatasetçš„pointå…·æœ‰weightçš„æ€§è³ªï¼Œé€™åœ¨adaboostæ¯ä¸€æ¬¡iterationçš„re-weightingæœ‰åŒæ¨£æ„æ€) é€™å€‹å«åšbootstrapï¼Œé‡å°è©²æ¬¡çš„dataç®—å‡ºæˆ‘å€‘çš„weak learner gtï¼Œiterateå¾ˆå¤šæ¬¡å¾Œï¼ŒæŠŠæ¯ä¸€æ¬¡çš„gtåšuniform blendingã€‚ æˆ‘èªç‚º aggregation methods å°±ç®—æ”¾åˆ°ç¾åœ¨çš„ Deep Learning ç«ç†±çš„æ™‚ä»£é‚„æ˜¯ç›¸ç•¶æœ‰ç”¨çš„ï¼Œé™¤äº†æœ¬èº«é€™äº›æ–¹æ³•å¦‚ adaboost å¥½ç”¨ä¹‹å¤–ï¼Œå…¶æ¦‚å¿µä¹Ÿç›¸ç•¶æœ‰ç”¨ï¼Œä¾‹å¦‚ Deep Learning çš„ dropout äº‹å¯¦ä¸Šå¯ä»¥ç”¨ bootstrap ä¾†è§£é‡‹ (æœ‰æ©Ÿæœƒå†è£œä¸Šè³‡æ–™)","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"uniform blending","slug":"uniform-blending","permalink":"https://bobondemon.github.io/tags/uniform-blending/"},{"name":"aggregation","slug":"aggregation","permalink":"https://bobondemon.github.io/tags/aggregation/"},{"name":"adaboost","slug":"adaboost","permalink":"https://bobondemon.github.io/tags/adaboost/"},{"name":"bootstrap","slug":"bootstrap","permalink":"https://bobondemon.github.io/tags/bootstrap/"}]},{"title":"Vehicle-Tracking","date":"2017-03-12T14:27:13.000Z","path":"2017/03/12/Vehicle-Tracking/","text":"é€™å€‹ Porject ç›®çš„æ˜¯è¦åµæ¸¬ç•«é¢ä¸­æ‰€æœ‰çš„è»Šå­, å¤§è‡´ä¸Šçš„æµç¨‹æ˜¯å…ˆè¨“ç·´å¥½ car/non-car çš„ classifer, ç„¶å¾Œç”¨ sliding window æ­é…ä¸åŒçš„ window size å»åµæ¸¬, æœ€å¾Œå†æŠŠ bounding boxes åšä¸€äº›å¾Œè™•ç†, ä¾‹å¦‚ merge boxes, å’Œå°æ™‚é–“åºåˆ—çš„è™•ç†ä»¥ä¸‹ç‚º git hub çš„ REAMDE.md The goals / steps of this project are the following: Perform a Histogram of Oriented Gradients (HOG) feature extraction I implement HOG feature extraction and using a subset of training data to search a good settings of parameters. Images are stored in output_images/HOG_with_YCrCb.jpg and output_images/grid_search.jpg Train Classifier I trained a Linear SVM classifier with HOG + color_hist + bin_spatial which achieved 98% accuracy on test set. Sliding Window Search I implemented a sliding window search method with two scales of window. HOG features are extracted once for an given image. Showing Examples so far I showed 4 examples with the pipeline so far. Image is stored in output_images/example_before_post_processing.jpg Video Implementation I showed the results with a short video clip (test_video.mp4) as well as the final result that adopted post-processing below. Further Post-processing A buffer for heat-maps is used for keeping a 6 consecutive heat-maps in frames. This will filtered out some false accepts. Discussion A short discussion is made. â€“ Rubric Points 1. Histogram of Oriented Gradients (HOG) Explain how (and identify where in your code) you extracted HOG features from the training images. Explain how you settled on your final choice of HOG parameters. I randomly selected examples of car and notcar and showed their HOG results in each channel of HLS space: In order to get a good enough setting for those parameters (orientations, pixels_per_cell and cells_per_block), I applied a grid searching method with a linear SVM on a small subset of training data. Grid searching space is defined as follows (24 combinations): 123orient_set = range(9,19,3)pix_per_cell_set = [4,8,16]cell_per_block_set = [1,2] The purpose of this stage is not finding the optimal, but rather, a good enough setting. So I choose orient=15, pix_per_cell=8, cell_per_block=2, cspace=&#39;RGB2YCrCb&#39; 2. Train Classifier Describe how (and identify where in your code) you trained a classifier using your selected HOG features (and color features if you used them). Before training the classifier, dataset should be processed first.Since the vehicles/GTI*/*.png contains time-series data, I manually selected images to avoid train and test sets having identical images. In addition, 20% images in each training folder are treated as test images. The same partition method applied to non-vehicles images too. Then I trianed a Linear SVM model with HOG + color_hist + bin_spatial features which has performance: 1inside-acc=1.0, outside-acc=0.9802036199095022 3. Sliding Window Search Describe how (and identify where in your code) you implemented a sliding window search. How did you decide what scales to search and how much to overlap windows? The course provided a very useful code snippet that can extract HOG features once no matter how much windows are. So I reuse it as the feature extraction function!I used two types of scales, 1.5 and 1.2, which deal with large and small window respectively (car with near and far positions from camera). Also, I found that the overlaping of cells_per_step = 1 (more dense windows) has better results in my implementation. Before going through, it is worth checking the image values. Since feature extraction pipeline processed .png files with mpimg.imread, it reads images with values [0,1]. However, mpimg.imread reads the .jpg file with values within [0,255]. So it is necessary to divide 255 before calling the feature extraction pipeline while reading .jpg images with mpimg.imread. Make sure your images are scaled correctly The training dataset provided for this project ( vehicle and non-vehicle images) are in the .png format. Somewhat confusingly, matplotlib image will read these in on a scale of 0 to 1, but cv2.imread() will scale them from 0 to 255. Be sure if you are switching between cv2.imread() and matplotlib image for reading images that you scale them appropriately! Otherwise your feature vectors can get screwed up. To add to the confusion, matplotlib image will read .jpg images in on a scale of 0 to 255 so if you are testing your pipeline on .jpg images remember to scale them accordingly. And if you take an image that is scaled from 0 to 1 and change color spaces using cv2.cvtColor() youâ€™ll get back an image scaled from 0 to 255. So just be sure to be consistent between your training data features and inference features! 4. Showing Examples Show some examples of test images to demonstrate how your pipeline is working. How did you optimize the performance of your classifier? The followings are some examples. As you can see in the example 2, there exists a false accept. This will be filtered out in the post-processing part. 5. Video Implementation Provide a link to your final video output. Your pipeline should perform reasonably well on the entire project video (somewhat wobbly or unstable bounding boxes are ok as long as you are identifying the vehicles most of the time with minimal false positives.) Following is the final result (combined with post-processing as described below) 6. Further Post-processing Describe how (and identify where in your code) you implemented some kind of filter for false positives and some method for combining overlapping bounding boxes. A heat-map to further filtered out some false positives. Moreover, I used a buffer to keep the 6 consecutive frames of heat-maps, and then accumulated those heat-maps in buffer. The accumulated heat-map then thresholded and produced the final results. 7. Discussion Briefly discuss any problems / issues you faced in your implementation of this project. Where will your pipeline likely fail? What could you do to make it more robust? There still have too much parameters that effect the robustness, like ystart, ystop, scale factors, thresholds for heat-maps, and etc. Moreover, with more challanging conditions, those settings might work in one condition but fail in others. I think the most important part in those pipelines is the classifier itself. The linear SVM I used in this project is not good enough as you can see in the video that still has few false accepts. So a deep-learning based classifier might achieve better results and actually helpful to the following pipelines. This would be my future work.","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"CV","slug":"CV","permalink":"https://bobondemon.github.io/tags/CV/"}]},{"title":"Lane-Finding","date":"2017-02-27T02:12:28.000Z","path":"2017/02/27/Lane-Finding/","text":"ä»¥ä¸‹æ˜¯ github ä¸Šçš„ README, å…¨è‹±æ–‡. æ­¤ Project ä¸»è¦éƒ½æ˜¯åœ¨åš Computer Vision ç›¸é—œçš„æ±è¥¿. å­¸åˆ°äº†è¨±å¤šä½¿ç”¨ Python and CV ç›¸é—œçš„æŠ€å·§. æ•´ç†ä¾†èªªæ˜¯å€‹æ»¿æœ‰è¶£çš„ project! The goals / steps of this project are the following: Compute the camera calibration matrix and distortion coefficients given a set of chessboard images. Apply a distortion correction to raw images. Use color transforms, gradients, etc., to create a thresholded binary image. Apply a perspective transform to rectify binary image (â€œbirds-eye viewâ€). Detect lane pixels and fit to find the lane boundary. Determine the curvature of the lane and vehicle position with respect to center. Warp the detected lane boundaries back onto the original image. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position. Rubric Points1. Camera calibrationThe images for calculating the distortion and 3-D to 2-D mapping matrix are stored in ./camera_cal/calibration*.jpg.Firstly, I used cv2.findChessboardCorners to find out all those corner points (corners) in the images.Then I used cv2.calibrateCamera to calculate the distortion (dist) and mapping matrix (mtx) given the corners pts and their corresponding predifined 3-D pts objp 2. Provide an example of a distortion-corrected imageHere is an example of distortion-corrected image: 3. Create a thresholded binary image and provide exampleI used magnitude of gradients, direction of gradients, and L and S in HLS color space.A combined rule is used: 12combined[((mag_binary == 1) &amp; (dir_binary == 1)) |\\ ((hls_binary == 1) &amp; (dir_binary == 1) &amp; (bright_binary == 1))] = 1 Example masking image is showed: Moreover, I used widgets to help tunning the parameters of those masking functions. It can provide instantaneous binary result that really help for accelarating this step. The widgets codes are list here: 123456789def interactive_mask(ksize, mag_low, mag_high, dir_low, dir_high, hls_low, hls_high, bright_low, bright_high): combined = combined_binary_mask(image,ksize, mag_low, mag_high, dir_low, dir_high,\\ hls_low, hls_high, bright_low, bright_high) plt.figure(figsize=(10,10)) plt.imshow(combined,cmap='gray') interact(interactive_mask, ksize=(1,31,2), mag_low=(0,255), mag_high=(0,255),\\ dir_low=(0, np.pi/2), dir_high=(0, np.pi/2), hls_low=(0,255),\\ hls_high=(0,255), bright_low=(0,255), bright_high=(0,255)) 4. Perspective transformFirst, I defined the source and destination of perspective points as follows: Source Destination 585, 460 320, 0 203, 720 320, 720 1127, 720 960, 720 695, 460 960, 0 Then the perspective_warper function is defined which returns perspective image and the matrix warpM as well.warM is needed for the later step which does the inverse perspective back to the original image. 1perspective_img, warpM = perspective_warper(undist,src,dst) An example is showed here: 5. Lane line pixel and polynomial fittingI applied a windowing approach to identify the lane pixels In this example, I used 9 windows for both lane lines. The window is processed in an order from the buttom to the top. Pixels are detected by the following function 1def identify_lane_pixel(img, lcenter_in, rcenter_in, win_num=9, win_half_width=150, start_from_button=False): lcenter_in and rcenter_inare the centers (in horizontal coordinate) of windows. win_num defines how many windows are used. In this example, 9. win_half_width refers to the half length of window width start_from_button indicates how the initial centers of windows are set. Specifically, Let the current window as j and current frame index as i. If start_from_button=True, the center of window j will be initally set as window j-1. Otherwise, it will be initally set as window j in frame i-1. Then, by using the initial position just set, the lane pixels are identified if the histogram of that window is high enough. Finally, based on those identified pixels, update the center position of current widnow j. Next, a simple second order polynomial fitting is applied to both identified pixels 123# Fit a second order polynomial to eachleft_fit = np.polyfit(lpixely, lpixelx, 2)right_fit = np.polyfit(rpixely, rpixelx, 2) But wait! Since we are assuming â€œbirds-eye viewâ€, both lanes should be parallel! So I first tried a method that ties the polynomial coefficients except the shifting ones! this method results in the following example As can be seen in the figure, curves are indeed parallel. However, when I applied this method to the final video, I found that it wobbling a lot! (see â€œ8. Videoâ€ below) After some investigation, I wonder that this problem is caused by the fixed source points of perspective. Since the pre-defined source points are always at the center of the camera while the lane curves are usually not, the result perspective curves is intrinsically not parellel! Hence, I applied a dynamic source point correction. Idea of method is showed in the follows: mapping inversely from coordinates in perspective images to original images can use the following formula: and results in the following example It works great! Unfortunately, if the lane curves are not stable, the resulting new source points may fail. This is the major difficulty of this method! (see â€œ8. Videoâ€ below) 6. Radius of curvature of the lane and the position of the vehicleThe curvature is calculated based on the following formula. Udacity provides a very good tutorial here ! 1234a1, b1, c1 = left_fit_coefficientsa2, b2, c2 = right_fit_coefficientsr1 = ((1+(2*a1*height*ym_per_pix+b1)**2)**1.5)/(2*np.abs(a1))r2 = ((1+(2*a2*height*ym_per_pix+b2)**2)**1.5)/(2*np.abs(a2)) Thereâ€™s no need to worry about absolute accuracy in this case, but your results should be â€œorder of magnitudeâ€ correct. So I divide my result by 10 to make it seems more reasonable. And of course, the â€œorder of magnitudeâ€ remains intact. 7. Warp the detected lane boundaries back onto the original imageIn order to warp back onto the original image, we need to calculate the inverse of perspective transform matrix warpMjust apply Minv = inv(warpM) which is from numpy.linalg import inv Then, simply apply cv2.warpPerspective with Minv as input. Note: use cv2.putText to print the curvature and position onto images 8. Video Simple poly-fit (Most stable! Simple is better ?!) Shared coefficients of poly-fit (Wobbling problem) Dynamic source points of perspective (Unstable, crash sometimes. If the lane curves are not stable, the resulting new source points may fail) DiscussionBasically, I applied those techniques suggested by Udacity. I did some efforts trying to parallize both curves in the perspective â€œbird eye viewâ€. Two methods are applied Shared coefficients of polynomial fitting Dynamic source points of perspetive Each has its own issue. For (1.), wobbling, and for (2.) unstable. Future works will focus on solving the (2.) unstable issue. Maybe a smoothing method is a good idea. Moreover, for more difficult videos, pixels may not be detected which makes the pipeline crash. One way to overcome this problem is when this issue happens, the lane curve is set to be the same as previous frame. Generelizing this idea, a confidence measure of lane pixels is worth to apply. If the confidence is low, then set the lane curve as the same as previous frame might be a good way to better estimate result. Finally, finding a robust combination of masking rule and tweaking those parameters precisely might help too. é™„ä¸Šä¸­æ–‡å…¶ä»–è¨è«–: Reviewer çµ¦äº†å¾ˆå¤šæœ‰ç”¨çš„ article links! é€™é‚Šé™„ä¸Šåšæœªä¾†åƒè€ƒ Perspective bird eye view:http://www.ijser.org/researchpaper%5CA-Simple-Birds-Eye-View-Transformation-Technique.pdfhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3355419/https://pdfs.semanticscholar.org/4964/9006f2d643c0fb613db4167f9e49462546dc.pdfhttps://pdfs.semanticscholar.org/4074/183ce3b303ac4bb879af8d400a71e27e4f0b.pdf Lane line pixel identification:https://www.researchgate.net/publication/257291768_A_Much_Advanced_and_Efficient_Lane_Detection_Algorithm_for_Intelligent_Highway_Safetyhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5017478/https://chatbotslife.com/robust-lane-finding-using-advanced-computer-vision-techniques-46875bb3c8aa#.l2uxq26sn lane detection with deep learning:http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w3/papers/Gurghian_DeepLanes_End-To-End_Lane_CVPR_2016_paper.pdfhttp://lmb.informatik.uni-freiburg.de/Publications/2016/OB16b/oliveira16iros.pdfhttp://link.springer.com/chapter/10.1007/978-3-319-12637-1_57 (chapter in the book Neural Information Processing)http://ocean.kisti.re.kr/downfile/volume/ieek1/OBDDBE/2016/v11n3/OBDDBE_2016_v11n3_163.pdf (in Korean, but some interesting insights can be found from illustrations)https://github.com/kjw0612/awesome-deep-vision (can be useful in project 5 - vehicle detection)å™å¿ƒåˆ°åè¡€çš„çœŸå¯¦æŒ‘æˆ°: é‚„æ˜¯è€è©±ä¸€å¥, çœŸçš„è¦æˆç‚ºå¯ç”¨çš„ç”¢å“, é›£é“è¶…ç´šç„¡æ•µé«˜é˜¿!!","tags":[{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"CV","slug":"CV","permalink":"https://bobondemon.github.io/tags/CV/"}]},{"title":"Neural Art","date":"2017-02-13T14:04:36.000Z","path":"2017/02/13/Neural-Art/","text":"Art with Neural Networké¢¨æ ¼, å‰µä½œé€™ç¨®èƒ½åŠ›åœ¨ç¾åœ¨Alpha Goå·²ç¶“ç¨±éœ¸çš„æ™‚ä»£, ç›®å‰è¦ºå¾—é‚„æ˜¯äººé¡ç¨æœ‰çš„ä¸éæœ‰è¶£çš„æ˜¯, å°æ–¼é‚£äº›å·²ç¶“åœ¨ ImageNet è¨“ç·´å¾—éå¸¸å¥½çš„æ¨¡å‹, å¦‚: VGG-19, æˆ‘å€‘é€šå¸¸å·²ç¶“åŒæ„æ¨¡å‹å¯ä»¥è¾¨åˆ¥ä¸€äº›è¼ƒæŠ½è±¡çš„æ¦‚å¿µé‚£éº¼æ˜¯å¦æ¨¡å‹è£¡, ä¹Ÿæœ‰å…·å‚™é¡ä¼¼é¢¨æ ¼å’Œå‰µä½œçš„å…ƒç´ å‘¢? åˆæˆ–è€…é¢¨æ ¼åœ¨æ¨¡å‹è£¡è©²æ€éº¼è¡¨é”? æœ¬ç¯‡æ–‡ç« ä¸»è¦æ˜¯ä»‹ç´¹é€™ç¯‡ A Neural Algorithm of Artistic Style çš„æ¦‚å¿µå’Œå¯¦ä½œ, å¦å¤–ä¸€å€‹å¾ˆå¥½çš„æŠ•å½±ç‰‡ by Mark Chang ä¹Ÿå¾ˆå€¼å¾—åƒè€ƒ å…ˆçµ¦å‡ºç¯„ä¾‹çµæœ, çµæœ = åŸå§‹çš„å…§å®¹ + å¸Œæœ›çš„é¢¨æ ¼ Content Image Style Image Result Image èªªåœ¨å‰é ­çš„æœ€ä½³åŒ–åœ¨è¬›ä¸‹å»ä¹‹å‰, æˆ‘å€‘å…ˆè¬› NN çš„äº‹æƒ…, ä¸€èˆ¬æƒ…æ³, æˆ‘å€‘æ˜¯çµ¦å®š input image x, è€Œåƒæ•¸ w å‰‡æ˜¯è¦æ±‚çš„è®Šæ•¸, åŒæ™‚å° loss (objective function) åš optimize, å¯¦ä½œä¸Šå°±æ˜¯ backprob.ä¸Šé¢è¬›åˆ°çš„ä¸‰ç¨®æ±è¥¿åˆ—å‡ºä¾†: x: input image (given, constant) w: NN parameters (variables) loss: objective function which is correlated to some desired measure äº‹å¯¦ä¸Š, backprob çš„è¨ˆç®— x and w è§’è‰²å¯ä»¥äº’æ›. ä¹Ÿå°±æ˜¯å°‡ w å›ºå®šç‚º constant, è€Œ x è®Šæˆ variables, å¦‚æ­¤ä¸€ä¾†, æˆ‘å€‘ä¸€æ¨£å¯ä»¥ç”¨ backprob å»è¨ˆç®—å‡ºæœ€ä½³çš„ image x.å› æ­¤, å¦‚æœæˆ‘å€‘èƒ½å°‡ loss å®šç¾©å¾—èˆ‡é¢¨æ ¼å’Œå…§å®¹é«˜åº¦ç›¸é—œ, é‚£éº¼æ±‚å¾—çš„æœ€ä½³ image x å°±æœƒæœ‰åŸå§‹çš„å…§å®¹å’Œå¸Œæœ›çš„é¢¨æ ¼äº†!é‚£éº¼å†ä¾†å°±å¾ˆæ˜ç¢ºäº†, æˆ‘å€‘è¦å®šç¾©å‡ºä»€éº¼æ˜¯ Content Loss å’Œ Style Loss äº† Content Lossé‡å°ä¸€å€‹å·²ç¶“è¨“ç·´å¥½çš„ model, æˆ‘å€‘å¸¸å¸¸å°‡å®ƒæ‹¿ä¾†åš feature extraction. ä¾‹å¦‚ä¸€å€‹ DNN æŠŠå®ƒæœ€å¾Œä¸€å±¤è¾¨è­˜çš„ softmax å±¤æ‹¿æ‰, è€Œå®ƒçš„å‰ä¸€å±¤çš„ response (åšforwardçš„çµæœ), å°±æœƒæ˜¯å°æ–¼åŸå§‹ input çš„ä¸€ç¨® encoding. ç†è«–ä¸Šä¹Ÿæœƒæœ‰å¾ˆå¥½çš„é‘‘åˆ¥åŠ› (å› æœ€åªå·®æœ€å¾Œä¸€å±¤çš„softmax). Udacity çš„ traffic-sign detection ä¹Ÿæœ‰æ‹¿ VGG-19, ResNet, å’Œ gooLeNet åš feature extraction, ç„¶å¾Œåªè¨“ç·´é‡æ–°åŠ ä¸Šçš„ softmax layer ä¾†å¾—åˆ°å¾ˆé«˜çš„è¾¨è­˜ç‡. å› æ­¤, æˆ‘å€‘å¯ä»¥å°‡ forward çš„ response image ç•¶ä½œæ˜¯ä¸€ç¨® measure content çš„æŒ‡æ¨™!çŸ¥é“é€™å€‹ç†ç”±å¾Œ, åŸæ–‡å…¬å¼å°±å¾ˆå¥½ç†è§£, å¼•ç”¨å¦‚ä¸‹: So let p and x be the original image and the image that is generated and Pl and Fl their respective feature representation in layer l. We then define the squared-error loss between the two feature representations ç°¡å–®ä¾†èªª Pl æ˜¯ content image P åœ¨ l å±¤çš„ response, è€Œ Fl æ˜¯ input image x (è¨˜å¾—å—? å®ƒæ˜¯è®Šæ•¸å–”) åœ¨ l å±¤çš„ response.é€™å…©å€‹ responses çš„ squared-error å®šç¾©ç‚º content loss, è¦æ„ˆå°æ„ˆå¥½. ç”±æ–¼ response ç‚º input çš„æŸç¨® encoded feature, æ‰€ä»¥å®ƒå€‘å¦‚æœæ„ˆæ¥è¿‘, input å°±æœƒæ„ˆæ¥è¿‘äº† (contentå°±æ„ˆæ¥è¿‘).å¼•ç”¨ Mark Chang çš„æŠ•å½±ç‰‡: Style Losså€‹äººè¦ºå¾—æœ€ç¥å¥‡çš„åœ°æ–¹å°±åœ¨é€™è£¡äº†! ç•¶æ™‚è‡ªå·±æ€éº¼çŒœæ¸¬éƒ½æ²’çŒœåˆ°å¯ä»¥é€™éº¼ formulate.æˆ‘å€‹äººçš„ç†è§£æ˜¯åŸºæ–¼ CNN ä¾†è§£é‡‹å‡è¨­å°æ–¼æŸä¸€å±¤ ConvNet çš„ kernel ç‚º w*h*k (width, hieght, depth), ConvNet çš„ k é€šå¸¸ä»£è¡¨äº†æœ‰å¹¾ç¨® feature mapsèªªç™½ä¸€é», æœ‰ k ç¨® filter responses çš„çµæœ, ä¾‹å¦‚ç¬¬ä¸€ç¨®æ˜¯ç·šæ¢é¡çš„response, ç¬¬äºŒç¨®æ˜¯å¼§å½¢é¡çš„responses â€¦ ç­‰ç­‰è€Œé¢¨æ ¼å°±æ˜¯é€™äº› responses çš„ correlation matrix! (å¯¦éš›ä¸Šç”¨ Gram matrix, ä½†æ„ç¾©é¡ä¼¼)åŸºæ–¼æˆ‘å€‘å°æ–¼ CNN çš„ç†è§£, æ„ˆå¾Œé¢çš„ layers èƒ½è™•ç†æ„ˆæŠ½è±¡çš„æ¦‚å¿µ, å› æ­¤æ„ˆå¾Œé¢çš„ Gram matrix ä¹Ÿå°±æ„ˆèƒ½ä»£è¡¨æŠ½è±¡çš„ style æ¦‚å¿µ.åŸæ–‡å…¬å¼å¼•ç”¨å¦‚ä¸‹: ç¸½ä¹‹å°±æ˜¯è¨ˆç®—åœ¨ l å±¤ä¸Š, sytle image a å’Œ input image x å®ƒå€‘çš„ Gram matrix çš„ L2-norm å€¼ ä¸€æ¨£å†ä¸€æ¬¡å¼•ç”¨ Mark Chang çš„æŠ•å½±ç‰‡:ä¹Ÿå¯ä»¥å»çœ‹çœ‹ä»–çš„æŠ•å½±ç‰‡, æœ‰ä¸åŒè§’åº¦çš„è§£é‡‹ å¯¦æˆ°ä¸»è¦åƒè€ƒæ­¤ gitHubä¸€é–‹å§‹ load VGG-19 model å°±ä¸èªªäº†, ä¸»è¦çš„å…©å€‹ loss, codes å¦‚ä¸‹:123456789101112131415161718def content_loss_func(sess, model): \"\"\" Content loss function as defined in the paper. \"\"\" def _content_loss(p, x): # N is the number of filters (at layer l). N = p.shape[3] # M is the height times the width of the feature map (at layer l). M = p.shape[1] * p.shape[2] # Interestingly, the paper uses this form instead: # # 0.5 * tf.reduce_sum(tf.pow(x - p, 2)) # # But this form is very slow in \"painting\" and thus could be missing # out some constants (from what I see in other source code), so I'll # replicate the same normalization constant as used in style loss. return (1 / (4 * N * M)) * tf.reduce_sum(tf.pow(x - p, 2)) return _content_loss(sess.run(model['conv4_2']), model['conv4_2']) 12345678910111213141516171819202122232425262728293031323334353637383940414243# Layers to use. We will use these layers as advised in the paper.# To have softer features, increase the weight of the higher layers# (conv5_1) and decrease the weight of the lower layers (conv1_1).# To have harder features, decrease the weight of the higher layers# (conv5_1) and increase the weight of the lower layers (conv1_1).STYLE_LAYERS = [ ('conv1_1', 0.5), ('conv2_1', 1.0), ('conv3_1', 1.5), ('conv4_1', 3.0), ('conv5_1', 4.0),]def style_loss_func(sess, model): \"\"\" Style loss function as defined in the paper. \"\"\" def _gram_matrix(F, N, M): \"\"\" The gram matrix G. \"\"\" Ft = tf.reshape(F, (M, N)) return tf.matmul(tf.transpose(Ft), Ft) def _style_loss(a, x): \"\"\" The style loss calculation. \"\"\" # N is the number of filters (at layer l). N = a.shape[3] # M is the height times the width of the feature map (at layer l). M = a.shape[1] * a.shape[2] # A is the style representation of the original image (at layer l). A = _gram_matrix(a, N, M) # G is the style representation of the generated image (at layer l). G = _gram_matrix(x, N, M) result = (1 / (4 * N**2 * M**2)) * tf.reduce_sum(tf.pow(G - A, 2)) return result E = [_style_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in STYLE_LAYERS] W = [w for _, w in STYLE_LAYERS] loss = sum([W[l] * E[l] for l in range(len(STYLE_LAYERS))]) return loss ä¸€é–‹å§‹çµ¦å®š random input image:style image é¸å®šå¦‚ä¸‹:éš¨è‘— iteration å¢åŠ æœƒåƒé€™æ¨£: ç¬¬ä¸€æ¬¡çš„ backprob: 1000 iteration: 2000 iteration: 3000 iteration: 4000 iteration: 5000 iteration: çŸ­ç¯€é€™ä¹‹é–“å¾ˆå¤šåƒæ•¸å¯ä»¥èª¿æ•´å»ç©, æœ‰èˆˆè¶£å¯ä»¥è‡ªå·±ä¸‹è¼‰ gitHub å»æ¸¬ ä¸Šä¸€ç¯‡çš„ â€œGTX 1070 åƒè¦‹â€ æœ‰æåˆ°, åŸä¾†ç”¨ CPU å»è¨ˆç®—, 1000 iteration èŠ±äº†å…­å€‹å°æ™‚! ä½†æ˜¯å¼·å¤§çš„ GTX 1070 åªéœ€è¦ 6 åˆ†é˜! ä¸é, å°±ç®—æ˜¯çµ¦æ‰‹æ©Ÿç”¨ä¸ŠGTX1070å¥½äº† (å“ˆå“ˆç•¶ç„¶ä¸å¯èƒ½), 6åˆ†é˜çš„ä¸€å€‹çµæœä¹Ÿæ˜¯ç„¡æ³•æ¥å—!PRISMA å¯ä»¥åœ¨ä¸€åˆ†é˜å…§è™•ç†å®Œ! é€™å¿…å®šä¸æ˜¯é€™ç¨®è¦ç®— optimization çš„æ–¹æ³•å¯ä»¥é”åˆ°çš„.äº‹å¯¦ä¸Š, æé£›é£›çš„åœ˜éšŠç™¼è¡¨äº†ä¸€ç¯‡è«–æ–‡ â€œPerceptual Losses for Real-Time Style Transfer and Super-Resolutionâ€œè¨“ç·´éå¾Œ, åªéœ€è¦åš forward propagation å³å¯! Standford University çš„ JC Johnson çš„ gitHub æœ‰å®Œæ•´çš„ source code!æ‰¾æ™‚é–“å†ä¾†å¯«é€™ç¯‡å¿ƒå¾—æ–‡å›‰!","tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Art","slug":"Art","permalink":"https://bobondemon.github.io/tags/Art/"}]},{"title":"GTX 1070","date":"2017-02-12T13:44:40.000Z","path":"2017/02/12/GTX-1070/","text":"NVIDIA GTX 1070 åƒè¦‹ç¶“éå…©æ¬¡çš„Udacity DNN Projectså¾Œ, æˆ‘å—ä¸äº†ç”¨CPUè¨“ç·´äº†! é€™å¯¦åœ¨æ˜¯å¤ªæ…¢äº†!è€ƒé‡æ‡‰è©²æœƒé•·æœŸä½¿ç”¨GPU, AWSå¯¦åœ¨ä¸æ€éº¼ä¾¿å®œ (1hr=1USD @ Tokyo site), åŠ ä¸Šlocalç«¯è¨“ç·´ä¹Ÿæ¯”è¼ƒæ–¹ä¾¿, å°±æ®ºä¸‹å»äº†!! å®‰è£ CUDA and cuDNNå¤§è‡´ä¸Šçš„å®‰è£æµç¨‹å¦‚ä¸‹, ä¸¦ä¸è¤‡é›œ, æ›´è©³ç´°å¯åƒè€ƒ link å®‰è£ CUDA Driversä¸Šè¿°è¯çµä¸­æœ‰ä¸‹è¼‰è·¯å¾‘, ç„¶å¾Œç…§é é¢ä¸€æ­¥æ­¥é¸æ“‡ (Operating System, Version, Installer Type)Installer Typeå¦‚æœç¶²è·¯ä¸å¥½å»ºè­°é¸æ“‡ exe local, ç„¶å¾Œä¸‹è¼‰å¾ŒåŸ·è¡Œå®‰è£å°±å°äº†Windows ç’°å¢ƒè®Šé‡ä¸­ CUDA_PATH æ˜¯ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0, ä½†æ˜¯ä»é ˆåŠ ä¸Š bin\\ å’Œ lib\\x64\\, è¨˜å¾—åŠ ä¸Š. å®‰è£ cuDNNè¦ä¸‹è¼‰é€™å€‹é‚„è¦å¡«ä¸€äº›ç™»å…¥è³‡æ–™, éœ€è¦å†Accelerated Computing Developer Programè¨»å†Š, ç¸½ä¹‹è¨»å†Šå¾Œå°±å¯ä¸‹è¼‰è§£å£“å¾Œæœƒæœ‰ä¸€å€‹è³‡æ–™å¤¾ cuda, è£¡é¢ä¸‰å€‹å­è³‡æ–™å¤¾ bin, include, libå°‡ä¸Šè¿°çš„æª”æ¡ˆæ”¾åˆ°ç›¸å°æ‡‰çš„ CUDA Driver çš„å®‰è£è·¯å¾‘å…§, é è¨­æ˜¯åœ¨ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0 å®‰è£ tensorflow-gpuæœ€ç°¡å–®çš„ä¸€æ­¥pip install tensorflow-gpuç„¶å¾Œå³å¯æ¸¬è©¦, å¦‚æœæœ‰æˆåŠŸæœƒæœ‰ä»¥ä¸‹ç•«é¢, æ³¨æ„ successfully å­—æœ‰ç„¡å‡ºç¾ 1234567&gt;&gt;&gt; import tensorflow as tfI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locallyI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locallyI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locallyI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locallyI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally&gt;&gt;&gt; æ¸¬è©¦ GTX 1070 å¼·å¤§èƒ½åŠ›ä½¿ç”¨å…©å€‹æ¥µç«¯ä¾‹å­åˆ†åˆ¥æ¸¬è©¦æœ‰ç„¡ä½¿ç”¨GPUé€Ÿåº¦ä¸Šçš„å·®ç•° Neural Art çš„ä¾‹å­: A Neural Algorithm of Artistic Style é€™å€‹ä¾‹å­æ˜¯æ‰€æœ‰çš„æ±è¥¿éƒ½å¯ä»¥ load é€² memory ä¸­, å› æ­¤æ²’æœ‰ä»»ä½• I/O, ç›´æ¥æ¯”æ‹šé‹ç®—èƒ½åŠ›! å› æ­¤å¯ä»¥ç›´æ¥çœ‹å‡º GPU å’Œ CPU çš„è¨ˆç®—èƒ½åŠ›å·®ç•° çµæœ: æ™‚é–“æ²’æœ‰å¾ˆåš´æ ¼è¨ˆç®—, æ˜¯çœ‹ç”¢ç”Ÿçµæœçš„æ™‚é–“ç¨å¾®è¨ˆç®—çš„, ä½†é€™æ•ˆèƒ½å·²ç¶“å¾ˆèª‡è£äº†, 60å€, 60å€, 60å€!è·‘å‡ºä¾†çš„åœ–: Content Image Style Image Result Image ä¸æ˜¯æ‰€æœ‰çš„æƒ…æ³éƒ½èƒ½æŠŠ training data å’Œ model éƒ½ load é€² memory ä¸­, æ‰€ä»¥å‹¢å¿…æœƒæœ‰å…¶ä»–æ‹–æ…¢é€Ÿåº¦çš„ç’°ç¯€, å…¶ä¸­æœ€æ…¢çš„å°±æ˜¯ I/O å‰›å¥½ Udacity çš„ project 3 å°±æ˜¯æ¯ç­† training data éƒ½éœ€è¦å» load image ä¸¦ä¸” on-the-fly é‹ç®—ä¸€å † preprocessing. é€™å€‹æƒ…æ³å‰›å¥½æ˜¯å¦ä¸€ç¨®å¯èƒ½çš„æ¥µç«¯ çµæœè·‘ä¸€å€‹epochæ‰€èŠ±çš„æ™‚é–“ç‚ºé€™ç¨®caseçœ‹ä¾†åªèƒ½åŠ é€Ÿåˆ°ç´„ 2å€. æ²’è¾¦æ³•, å…¶ä»–æ‹–æ²¹ç“¶çš„å‹•ä½œä½”å¤ªå¤šæ¯”ä¾‹äº† çŸ­çµå¤§éƒ¨åˆ†çš„æƒ…æ³ä¸‹, æå‡çš„é€Ÿåº¦ç¯„åœæœƒè½åœ¨ 2~60 å€ ä¹‹é–“, ç¸½ä¹‹æ˜¯å€¼å¾—çš„! å°±ç®—ä¸ç©DNN, é›»å‹•ä¹Ÿè¦æŠŠå®ƒæ‰“åˆ°ç‰©è¶…æ‰€å€¼!","tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"NVIDIA","slug":"NVIDIA","permalink":"https://bobondemon.github.io/tags/NVIDIA/"},{"name":"cuDNN","slug":"cuDNN","permalink":"https://bobondemon.github.io/tags/cuDNN/"},{"name":"CUDA","slug":"CUDA","permalink":"https://bobondemon.github.io/tags/CUDA/"}]},{"title":"Driving by Learning Your Style","date":"2017-02-05T13:58:07.000Z","path":"2017/02/05/Driving-by-Learning-Your-Style/","text":"Udacity Self Driving Project 3: behavioral cloningA great simulator is provided that can log your driving data (speed, throttle, brake, steering, and images) and test the driving algorithm.Two modes are provided, Training mode and Atuonomous mode. By using Training mode, you can collect training data to train the model. Then test the model with the Atuonomous mode. For those driving log data, steering and images are the most important features that we are going to use in this project. The goal is, given an image, find out the corresponding steering angle. Some might wonder that speed, throttle, and brake are features that are useful too.Also, driving images are time correlated, not just a given static image.With ignoring so much useful information, does the goal still reasonable? Nvidia just showed it works! and works pretty well!So our first step is to collect the data, and fortunately, Udacity provides data for us and I used it for training. Training Data Analysis8036 data are provided. Each data has 3 positions of images (left, center, right) with 1 corresponding steering angle.Most of angles are 0, and I found that randomly ignoring half of 0-angle data is fine and can speed up. Moreover, I duplicated some samples that has angles within the range +-[0.2, 1] in order to balance the data.Histograms of before/after data selection are shown below: Data AugmentationData augmentation is a practical way to avoid overfit and generalized the model. I used 5 types of augmentations: Flipping â€“ Flipping is a useful way to balance both turns of data. For each data, a 1/2 probability is used to decide wheter to flip. Also, steering angle is multiplied by -1. Horizontal shift â€“ [-20,+20] pixels are randomly selected as the shift value. By doing so, it can help to recover the vehicle when it goes outside the lane.By referencing this article, I added 0.004 steering angle units per pixel shift to the right, and subtracted 0.004 steering angle units per pixel shift to the left.Results in [-0.8~+0.8] steering values adjustment which corresponding to [-2~+2] degrees (steering value * 25 = degree) Brightness â€“ Brightness is done in the â€œHSVâ€ domain. I found that with a ratio of [0.5~1.1] for â€œVâ€ domain works fine. Blurring â€“ A Gaussian blur with kernel size 3 is applied. Not sure how useful of this method helps for robustness. Left/Right camera images â€“ These left/right images are very useful for data augmentation and also help for recovering off-lane driving. Udacity: You also might wonder why there are three cameras on the car: center, left, and right. Thatâ€™s because of the issue of recovering from being off-center.In the simulator, you can weave all over the road and turn recording on and off. In a real car, however, thatâ€™s not really possible. At least not legally.So in a real car, weâ€™ll have multiple cameras on the vehicle, and weâ€™ll map recovery paths from each camera. I adjusted the steering angles for left/right images with a naive method. Following figure shows how I correct the angle of right image: I found that setting offset = 6 or 5 is good enough. For large value, the car starts zig-zagging. An example of correction shows below, where the steering angles are indicated by red lines: Data Normalization Normalization â€“ Images are normalized with (x-128)/128. Cropping â€“ Images are trimmed with 40, 20, 20, and 20 pixels from top, bottom, left, and right respectively. This will cut most of the car hood and sky. Resizing â€“ resized to 66 x 200, same as NVIDIA CNN. Model ArchitectureI adopted NVIDIA CNN with dropout layers: Generator and Training Generator: It is very useful to use a python generator to feed the training data batch-by-batch rather than loading all the data in memory at once.A useful link to learn python iterator/generator list here ( for those who doesnâ€™t familiar with python just like me :) ). In order to further speed up. I tried pre-loading a chunck of data, e.g. 5000 images, into memory, and loaded another chunck if the batch data (required by generator) is outside the chunck in memory. However, it does not speed up! Somewhat weired. For each input images, a position is randomly chosen (left,center,right).Then flipping and shadowing are applied with a random fair coin. Finally, brighteness and horizonal shift are adopted with the corresponding angle adjustment. Training: Some hyper-parameters are listed: epochâ€“50 samples for each epoch â€“ 8896 optimizer â€“ Adam with 1e-4 batch-size â€“ 64 Although Keras did shuffle, it only applies in the batched data. So I shuffled the entire training set for each epoch to get more de-correlated data. Driving PolicyI found that instead of giving a constant throttle, controlling to a constant speed is more stable to drive.So I used a simple policy that tries to keep speed near 20. 123456789speed = float(speed) if speed &gt; 25: throttle = 0.05 elif speed &gt; 20: throttle = 0.2 elif speed &gt; 10: throttle = 0.35 else: throttle = 0.5 ResultsSee below for the track1 drive. However, I failed on track2. Hit a wall during a right turn and still working on it.Hope some tweaks on data selection and model architecture might work~","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"CNN","slug":"CNN","permalink":"https://bobondemon.github.io/tags/CNN/"}]},{"title":"Â–traffic-sign-detection","date":"2017-01-18T14:35:21.000Z","path":"2017/01/18/Â–traffic-sign-detection/","text":"å‰è¨€çµ‚æ–¼ä¾†åˆ° project 2 äº†, é€™æ¬¡çš„ä¸»è¦ç›®çš„æ˜¯ç·´ç¿’ä½¿ç”¨ tensorflow åšäº¤é€šè™ŸèªŒè­˜åˆ¥Dataset ç‚º German Traffic Sign Datasetæœ‰43ç¨®äº¤é€šè™ŸèªŒ, æ˜¯ä¸€ç¨®43é¸1çš„æ¦‚å¿µ, å› ç‚ºæ²’æœ‰è€ƒæ…®éƒ½ä¸æ˜¯é€™å€‹é¸é …, ç†è«–ä¸Šé€™é¡å•é¡Œè¼ƒç°¡å–®, æœ‰researcheré”åˆ°99.81%çš„è¾¨è­˜ç‡ å…± 51839 å¼µ training data, è€Œ testing æœ‰ 12630 å¼µ, åˆ†ä½ˆå¦‚ä¸‹, å¯ä»¥çœ‹çš„å‡ºä¾†è³‡æ–™åˆ†ä½ˆä¸å‡æ¯ç¨®é¡åˆ¥ random æŒ‘ä¸€å¼µå‡ºä¾†å¦‚ä¸‹åœ–Udacity å¾ˆå¥½å¿ƒçš„å¹«å¿™æŠŠæ‰€æœ‰çš„ image å¹«ä½ æ‰“åŒ…æˆåªå‰©ä¸‹ traffic sign Download, ä¸” cv2.resize(image,(32,32)) äº†, åªéœ€è¦ pickle.load ä¸‹ä¾†å°±æå®šè€ŒåŸå§‹çš„ data æ˜¯çµ¦ä½ ä¸€å¤§å¼µimage, ç„¶å¾Œå†å‘Šè¨´ä½ é‚£äº›traffic signsåœ¨imageä¸­çš„rectangular windowåº§æ¨™, é‚„è¦å†å¤šè™•ç†è¼ƒéº»ç…© è¦æ³¨æ„çš„ä¸€é»æ˜¯, dataset æ˜¯ç¶“ç”±ä¸€ç§’é˜çš„ video æ“·å–ä¸‹ä¾†, å› æ­¤é„°è¿‘çš„ data æœƒå¾ˆç›¸è¿‘ [1], å¦‚æœä½¿ç”¨ train_test_split æœƒ random é¸æ“‡, å°è‡´ train å’Œ validation æœƒç›¸è¿‘è€Œçœ‹ä¸å‡ºå·®ç•° Input Data PreprocessingUdacity å»ºè­°æˆ‘å€‘å¯ä»¥è™•ç†å¹¾å€‹æ–¹å‘ å°‡ data æ•¸é‡å¼„å¾—è¼ƒ balance NN ç®— loss çš„æ™‚å€™ä¸æœƒæ ¹æ“šæ¯å€‹é¡åˆ¥æ•¸é‡çš„å¤šå¯¡ä½œæ¬Šé‡, å› æ­¤æœ€å–®ç´”çš„æ–¹æ³•æ˜¯å°±æƒ³è¾¦æ³•ç”¢ç”Ÿå‡ºä¸€æ¨£å¤šçš„æ•¸é‡, å¦‚ç¬¬2é» å¯ä»¥å¢åŠ  fake data æˆ‘çš„ image processing å¯¦åœ¨å¾ˆå¼±, åªå–®ç´”çš„ä½¿ç”¨ rotation, è€Œä¸”åªæ•¢ç¨å¾®è®“angleç‚ºæ­£è² 5åº¦, æ€•é‚£ç¨®æœ‰æ–¹å‘ç®­é ­çš„è™ŸèªŒè½‰å£ 1cv2.getRotationMatrix2D(image_center, angle, scale) é€™æ¨£çš„æ–¹å¼æˆ‘å¯¦é©—èµ·ä¾†å…¶å¯¦æ²’å•¥å¹«åŠ©, XD æˆ‘çœ‹åˆ°æœ‰äººé‚„ä½¿ç”¨ cv2.WarpPerspective, æœç„¶å°ˆæ¥­å¤šäº†! æˆ‘ç›¸ä¿¡ç”¢ç”Ÿç¨®é¡å¤ å¤šçš„ fake data ä¸€å®šæœƒæœ‰å¹«åŠ©, ä¾‹å¦‚åŠ  noise, blur ç­‰ç­‰ å°‡ data åš normalization åšèªéŸ³ç¿’æ…£äº†, ç›´è¦ºå°±ç”¨ guassian normalization, mean=0, var=1, çµæœæ•´å€‹å¤§å¤±æ•—! åªæœ‰ä¸åˆ°1%è¾¨è­˜ç‡, why?? å¾Œä¾†ç”¨ mean substraction, ç„¶å¾Œé™¤ abs çš„æœ€å¤§å€¼, æˆ‘åªé¸æ“‡ä½¿ç”¨ YUV çš„ Y channel ç•¶ input CNN æ¶æ§‹è¦è¨­è¨ˆå’Œèª¿æ•´æ¶æ§‹æœ‰é»èŠ±æ™‚é–“, åŠ ä¸Šæˆ‘æ™‚é–“ä¸å¤š(æ‡¶), æ‰€ä»¥æˆ‘ç›´æ¥å°±ç”¨LeNetæ¶æ§‹1234567layer_depth = &#123; 'layer_1': 6, 'layer_2': 16, 'fully_connected_1': 120, 'fully_connected_2': 84, 'out': n_classes,&#125; è‡ªå·±å¤šåŠ äº† dropout å’Œ l2 regularization, åŸå› æ˜¯æ¯æ¬¡è·‘ training çš„ accuracy éƒ½è¦æ¨™åˆ°98 99, ä½†æ˜¯ validation set å§‹çµ‚å¾ˆé›£çªç ´ 93, ä¸€ç›´æœ‰ overfit çš„æ„Ÿè¦ºtensorflow çš„ dropout æ˜¯è¨­å®šè¦ä¿ç•™å¤šå°‘æ¯”ä¾‹ (keep_prob), åœ¨ training çš„æ™‚å€™è¨­å®šåœ¨æœ€å¾Œçš„å…©å±¤ fully connected layers, keep_prob æ„ˆå°åŸºæœ¬ä¸Šæ„ˆé›£è¨“ç·´ä¹Ÿéœ€è¦æ„ˆå¤š epochå¦å¤–è¨˜å¾—åœ¨åš evaluation çš„æ™‚å€™è¦æŠŠ keep_prob è¨­å®šæˆå› 1 [1] çš„æ¶æ§‹æƒ³æ³•ä¸éŒ¯, å°‡è¼ƒä½å±¤çš„ conv. layer å’Œè¼ƒä¸Šå±¤çš„ conv. layer ä¸€ä½µç•¶ä½œ fully connected layer çš„ input, é€™æ¨£åŒæ™‚èƒ½å¤ æœ‰ low-level feature, higher-resolution å’Œ high-level feature, lower-resolution å…©ç¨®è³‡è¨Šä¸€èµ·ç•¶æ±ºç­– å…¶ä»– Hyper-parameters Optimizer: èªªå¯¦è©±, è¦ä¸åœçš„èª¿æ•´å‡ºæœ€å¥½çš„åƒæ•¸å¯¦åœ¨æ²’é‚£å€‹å¿ƒåŠ›, æ‰€ä»¥èˆ‡å…¶ç”¨SGD, æˆ‘å°±ç›´æ¥ç”¨ Adam äº† (Adagradä¹Ÿæ˜¯ä¸€ç¨®æ‡¶äººé¸æ“‡) pooling: æ²’å•¥ç‰¹åˆ¥é¸, å› æ­¤ç”¨ max-pooling batch-size: åŸå…ˆè¨­å®š128, æœ‰ä¸€æ¬¡æ”¹æˆ256å°±å¯¦åœ¨trainä¸å¥½, å°±é€€å›128äº† learning rate: 0.001 l2 weight: 0.01 Learning Performancetest set accuracy = 0.893 è‡ªé¸æ¸¬è©¦åœ–ç‰‡Udacityå¸Œæœ›èƒ½å­¸å“¡è‡ªå·±æ‰¾åœ–ç‰‡ä¾†æ¸¬è©¦, å› æ­¤æˆ‘å°±åœ¨å¾·åœ‹çš„ google map ä¸Šæ‰¾åœ–, (çœ‹è‘—çœ‹è‘—å¿ƒéƒ½é£„éå»äº†)20å¼µåœ–è¾¨è­˜çµæœå¦‚ä¸‹:å‰›å¥½éŒ¯10å€‹, åªæœ‰ 50% æ­£ç¢ºç‡, é€™å¯¦åœ¨æœ‰é»æ‚²åŠ‡å…¶ä¸­æœ‰å…©å€‹éŒ¯èª¤å€¼å¾—æ³¨æ„å³åœ–æ˜¯top5è¾¨è­˜åˆ°çš„é¡åˆ¥åŠæ©Ÿç‡, å¯ä»¥ç™¼ç¾é™¤äº†æ­£ç¢ºç­”æ¡ˆçš„ traffic signal åœ¨ç¬¬äºŒåå¤–, ç¬¬ä¸€åçš„ general causion å…¶å¯¦è·Ÿ traffic signal è¶…åƒçš„ (åªçœ‹ç°éš)çœ‹ä¾†å¿…é ˆæŠŠ input çš„è‰²å½©è³‡è¨Šä¹ŸåŠ é€²å»æ‰èƒ½é€²ä¸€æ­¥æ”¹å–„äº†å¦ä¸€å€‹æ˜¯å¦‚ä¸‹é€™å€‹éŒ¯èª¤è‡ªå·±åˆ†æçš„åŸå› æ˜¯å› ç‚º training data çš„ speed limit éƒ½æ˜¯åœ“çš„å¤–æ¡†, è€Œæ­¤caseå‰›å¥½æ˜¯ä¸€å€‹é•·æ–¹å½¢ç‰Œå­, è£¡é¢æ‰æ˜¯é€€è‰²å¾ˆåš´é‡çš„åœ“å½¢, æ‰€ä»¥å°è‡´è¾¨è­˜å¤±æ•—æˆ–è¨±çœŸçš„ train å¾—å¾ˆå¥½çš„ CNN æœ‰èƒ½åŠ›æ‰¾å‡ºé‡è¦çš„åˆ¤æ–·è³‡è¨Š, å› æ­¤æœƒå»å¿½ç•¥å¤–é¢çš„æ–¹æ¡†, è€Œé¸æ“‡å»â€çœ‹â€å¤–é¢é€€è‰²çš„åœ“å½¢å’Œè£¡é¢çš„æ•¸å­—çµè«–å°±æ˜¯, æ‡‰è©²æ˜¯æˆ‘è‡ªå·±æ²’trainå¥½å§ ?! çŸ­çµå°å°åšéä¸€è¼ªäº¤é€šè™ŸèªŒè¾¨è­˜, æ‰æ¯”è¼ƒæœ‰æ„Ÿè¦ºçœŸå¯¦ç‹€æ³æœƒæœ‰å¤šå›°é›£é˜¿~æ‰¾æ™‚é–“ä¾† visualize ä¸€ä¸‹æ¯å±¤çš„ hidden units å°ä»€éº¼æ¨£çš„ image æœƒæœ‰è¼ƒé«˜çš„ activation! This paper by Zeiler and Fergus with toolbox è¦èƒ½ train å‡ºå¥½ model é™¤äº†åƒè€ƒæ–‡ç»åŸ¹é¤Šå° model æ¶æ§‹çš„å¥½ç›´è¦ºå¤–, engineering çš„è‹¦å·¥ä¹Ÿæœƒæ˜¯å¾ˆå¤§çš„é—œéµ! å¾ŒçºŒå˜—è©¦å°æ–¼ç›®å‰çš„è¾¨è­˜ç‡å¾ˆä¸æ»¿æ„. ä¸æ­»å¿ƒä¸‹å°±å¯¦ä½œ[1]çš„æ¶æ§‹, ç„¶å¾Œå°‡ NN çš„ model size æ“´å¤§, ä¸¦ä¸”å°‡é¡è‰²è³‡è¨Š YUV çš„ U åŠ é€²å»è¨“ç·´ (çµæœä¸Šè¿°å› é¡è‰²éŒ¯èª¤çš„traffic signalå°±åˆ†å°äº†)12345678910111213# Hyper-parametersEPOCHS = 30BATCH_SIZE = 128rate = 0.001drop_out_keep_prob = 0.5layer_depth = &#123; 'layer_1': 16, 'layer_2': 32, 'fully_connected_1': 256, 'fully_connected_2': 128, 'out': n_classes,&#125; å¾—åˆ°äº† Test Accuracy = 0.953 ! ä½†æ˜¯è‡ªé¸åœ–é›–æœ‰é€²æ­¥ä»å¾ˆä½ 65%å¦å¤–, ä¸Šè¿°çš„åƒæ•¸è¨­å®šä¸‹, å¦‚æœåŠ äº† l2_weight = 0.01 çš„è©±, validation åªèƒ½åˆ° 0.91x, å¯¦åœ¨ä¸å¤§å¥½è¨“ç·´, å¾Œä¾†åªå¥½æ”¾æ£„ç¬¬ä¸€æ¬¡çš„ submission, reviewer çµ¦äº†ä¸€äº›ä¸éŒ¯çš„ reference å¦‚ä¸‹: Extra Important MaterialLately on slack few students asked for a good Deep Learning book.So after lot of research found a book which is also recommended by Elon Musk Deep Learning (Adaptive Computation and Machine Learning series) Github and on Amazon Fast.ai A Guide to Deep LearningFew Articles Traffic sign classification using brightness augmentation Dealing with unbalanced dataExtra Materials I noted a linkage here to discuss about how should we choose the batch_size of Stochastic Gradient Decent Since you might be interested into â€œAdam Optimizerâ€, here is a website that talks about it. You might like to learn the whole idea of Dropout Itâ€™s gives a brief analysis of the technique. reviewer å¾ˆç”¨å¿ƒé˜¿!æ£’æ£’! Reference[1.] Traffic Sign Recognition with Multi-Scale Convolutional Networks","tags":[{"name":"ML","slug":"ML","permalink":"https://bobondemon.github.io/tags/ML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://bobondemon.github.io/tags/Deep-Learning/"},{"name":"Udacity","slug":"Udacity","permalink":"https://bobondemon.github.io/tags/Udacity/"},{"name":"CNN","slug":"CNN","permalink":"https://bobondemon.github.io/tags/CNN/"}]},{"title":"ä½¿ç”¨AWSè¨“ç·´DNNæ­¥é©Ÿ","date":"2017-01-16T13:47:43.000Z","path":"2017/01/16/aws-procedure/","text":"AWS Instanceæ³¨æ„äº‹é …åŠé€£ç·šå»ºç«‹AWS instanceçš„æ™‚å€™, ç”±æ–¼æˆ‘å€‘ä½¿ç”¨jupyteréœ€è¦port 8888, éœ€è¦ Configure the Security Group Running and accessing a Jupyter notebook from AWS requires special configurations. Most of these configurations are already set up on the udacity-carnd AMI. However, you must also configure the security group correctly when you launch the instance. By default, AWS restricts access to most ports on an EC2 instance. In order to access the Jupyter notebook, you must configure the AWS Security Group to allow access to port 8888.Click on â€œEdit security groupsâ€.On the â€œConfigure Security Groupâ€ page:Select â€œCreate a new security groupâ€Set the â€œSecurity group nameâ€ (i.e. â€œJupyterâ€)Click â€œAdd Ruleâ€Set a â€œCustom TCP Ruleâ€Set the â€œPort Rangeâ€ to â€œ8888â€Select â€œAnywhereâ€ as the â€œSourceâ€Click â€œReview and Launchâ€ (again) æˆåŠŸå»ºç«‹AWS instanceä¹‹å¾Œ, é–‹å•Ÿgit bashssh -i â€˜C:\\Users\\bobon\\.ssh\\MyKeyPair.pemâ€™ carnd@54.65.11.64å…¶ä¸­54.65.11.64æ˜¯instanceçš„ip AWSä¸Šé–‹å•Ÿjupyter notebook kernelé¦–å…ˆå…ˆæŠŠproject cloneä¸‹ä¾†, ä¸¦è¨­å®šå¥½conda env1234git clone https://github.com/udacity/CarND-Traffic-Sign-Classifier-Projectcd CarND-Traffic-Sign-Classifier-Projectconda env create -f environment.ymlsource activate CarND-Traffic-Sign-Classifier-Project æ¥è‘—å®‰è£tensorflow-gpu1pip install tensorflow-gpu opencv å®‰è£1conda install -c https://conda.binstar.org/menpo opencv å‰›å‰›å·²ç¶“å»ºç«‹condaçš„ç’°å¢ƒ, ä¸”activate CarND-Traffic-Sign-Classifier-Project, æ‰€ä»¥å¯ä»¥ç›´æ¥é–‹å•Ÿkernel1jupyter notebook åœ¨localç€è¦½å™¨ä¸Šè¼¸å…¥http://[all ip addresses on your system]:8888/ä¾‹å¦‚aws ipç‚º54.65.11.641http://54.65.11.64:8888/ æŠ“å–AWSä¸Šçš„è³‡æ–™ä¸‹ä¾†localç«¯åœ¨è‡ªå·±localçš„terminalä¸Š12scp -i &apos;C:\\Users\\bobon\\.ssh\\MyKeyPair.pem&apos; carnd@54.65.11.64:/home/carnd/Traffic-sign/cnn-traffic-sign* ./models/scp -i &apos;C:\\Users\\bobon\\.ssh\\MyKeyPair.pem&apos; carnd@54.65.11.64:/home/carnd/Traffic-sign/checkpoint ./models/ æ¥è‘—è¼¸å…¥å¯†ç¢¼å³å¯ (carnd)","tags":[{"name":"aws","slug":"aws","permalink":"https://bobondemon.github.io/tags/aws/"}]},{"title":"Hexo ä¸­æ–‡é¡¯ç¤º and Markdown æ¸¬è©¦","date":"2017-01-08T13:47:43.000Z","path":"2017/01/08/chinese-encoding/","text":"é™¤äº†å°‡Hexoçš„_config.yml è¨­å®šæˆ language: zh-tw ä¹‹å¤–æ–‡ç« å¦‚æœç”¨UltraEditç·¨è¼¯çš„è©±çš„è©±, è¦ä½¿ç”¨è½‰æ›ç·¨ç¢¼, å°‡ASCIIè½‰UTF-8(Unicodeç·¨è¼¯), ä¸­æ–‡æ‰èƒ½æ­£å¸¸é¡¯ç¤º å¼•è¨€æ¸¬è©¦åŒä¸€å€‹å€å¡Šçš„å¼•è¨€ å…§å®¹æ–‡å­—, å¼·èª¿ å¼•è¨€æ¸¬è©¦äºŒåŒä¸€å€‹å¼•è¨€æ¸¬è©¦äºŒçš„å€å¡Š ç„¡åºæ¸…å–®, item1 ä»ç„¶æ˜¯item1çš„å…§å®¹ item2 item3 æœ‰åºitem1 item2 ä»ç„¶æ˜¯item2çš„å…§å®¹ item3 1234567891011121314151617181920212223bool text(const string inPath, const string outPath)&#123; ifstream ifs(inPath.c_str()); if (!ifs) return false; ofstream ofs(outPath.c_str()); if (!ofs) return false; string line; while (getline(ifs,line)) &#123; istringstream iss(line); string token; while (iss&gt;&gt;token) &#123; cout &lt;&lt; \"&lt;Token&gt;: \" &lt;&lt; token &lt;&lt; endl; ofs &lt;&lt; \"&lt;Token&gt;: \" &lt;&lt; token &lt;&lt; endl; &#125; &#125; ofs.close(); ifs.close(); return true;&#125; æ–°çš„item? Here is an example of AppleScript: tell application &quot;Foo&quot; beep end tell Normal paragrah ä»¥ä¸‹ç‚ºåˆ†éš”ç·š ä¸Šç·šä½¿ç”¨ä¸‰å€‹*ä¸­é–“æœ‰ç©ºæ ¼ ä¸Šç·šä½¿ç”¨ä¸‰å€‹*ä¸­é–“ç„¡ç©ºæ ¼ ä¸Šç·šä½¿ç”¨5å€‹*ä¸­é–“æœ‰ç©ºæ ¼ ä¸Šç·šä½¿ç”¨ä¸‰å€‹-ä¸­é–“æœ‰ç©ºæ ¼ æ•¸å­¸å…¬å¼æ¸¬è©¦ $$x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$$\\(x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\\ æ–¹æ³•:åœ¨æ–‡ç« è¦æœ‰ &lt;script type=â€text/javascriptâ€ src=â€http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=defaultâ€œ &gt;&lt;/script&gt; é€™è¡ŒæŒ‡ä»¤ç„¶å¾Œå®‰è£…æ’ä»¶ Hexo-math, å®‰è£…æ–¹æ³•å¦‚ä¸‹, ä¾æ¬¡ä¸º1$ npm install hexo-math --save åœ¨ Hexo æ–‡ä»¶å¤¹ä¸­æ‰§è¡Œï¼š1$ hexo math install åœ¨ _config.yml æ–‡ä»¶ä¸­æ·»åŠ ï¼š1plugins: hexo-math","tags":[{"name":"markdown","slug":"markdown","permalink":"https://bobondemon.github.io/tags/markdown/"},{"name":"hexo","slug":"hexo","permalink":"https://bobondemon.github.io/tags/hexo/"}]}]